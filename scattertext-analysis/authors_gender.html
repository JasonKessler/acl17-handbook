<!-- some code adapted from www.degeneratestate.org/static/metal_lyrics/metal_line.html -->
<!-- <!DOCTYPE html>
<meta content="utf-8"> -->
<style> /* set the CSS */

body {
  font: 12px Arial;
}


svg {
  font: 12px Helvetica;
}

path {
  stroke: steelblue;
  stroke-width: 2;
  fill: none;
}

.axis path,
.axis lineper {
  fill: none;
  stroke: grey;
  stroke-width: 1;
  shape-rendering: crispEdges;
}

div.tooltip {
  position: absolute;
  text-align: center;
  width: 150px;
  height: 28px;
  padding: 2px;
  font: 12px sans-serif;
  background: lightsteelblue;
  border: 0px;
  border-radius: 8px;
  pointer-events: none;
}

div.tooltipscore {
  position: absolute;
  text-align: center;
  width: 150px;
  height: 42px;
  padding: 2px;
  font: 10px sans-serif;
  background: lightsteelblue;
  border: 0px;
  border-radius: 8px;
  pointer-events: none;
}


.category_header {
  font: 12px sans-serif;
  font-weight: bolder;
  text-decoration: underline;
}

div.label {
  color: rgb(252, 251, 253);
  color: rgb(63, 0, 125);
  color: rgb(158, 155, 201);

  position: absolute;
  text-align: left;
  padding: 1px;
  border-spacing: 1px;
  font: 10px sans-serif;
  font-family: Sans-Serif;
  border: 0;
  pointer-events: none;
}

input {
  border: 1px dotted #ccc;
  background: white;
  font-family: monospace;
  padding: 10px 20px;
  font-size: 14px;
  margin: 20px 10px 30px 0;
  color: darkred;
}

.alert {
  font-family: monospace;
  padding: 10px 20px;
  font-size: 14px;
  margin: 20px 10px 30px 0;
  color: darkred;
}

ul.top_terms li {
  padding-right: 20px;
  font-size: 30pt;
  color: red;
}

input:focus {
  background-color: lightyellow;
  outline: none;
}

.snippet {
  padding-bottom: 10px;
  padding-left: 5px;
  padding-right: 5px;
  white-space: pre-wrap;
}

.snippet_header {
  font-size: 20px;
  font-family: Helvetica, Arial, Sans-Serif;
  font-weight: bolder;
  #text-decoration: underline;
  text-align: center;
  border-bottom-width: 10px;
  border-bottom-color: #888888;
  padding-bottom: 10px;
}


#title-div {
  font-size: 20px;
  font-family: Helvetica, Arial, Sans-Serif;
  text-align: center;
}


.text_header {
  font: 18px sans-serif;
  font-size: 18px;
  font-family: Helvetica, Arial, Sans-Serif;

  font-weight: bolder;
  text-decoration: underline;
  text-align: center;
  color: darkblue;
  padding-bottom: 10px;
}

.text_subheader {
  font-size: 14px;
  font-family: Helvetica, Arial, Sans-Serif;

  text-align: center;
}


.snippet_meta {
  border-top: 3px solid #4588ba;
  font-size: 12px;
  font-family: Helvetica, Arial, Sans-Serif;
color: darkblue;
}

.left_contexts {
  width: 45%;
  float: left;
}

.right_contexts {
  width: 45%;
  float: left;
}

.scattertext {
  font-size: 10px;
  font-family: Helvetica, Arial, Sans-Serif;
}

.label {
  font-size: 10px;
  font-family: Helvetica, Arial, Sans-Serif;
}


.small_label {
  font-size: 10px;
}

#corpus-stats {
  text-align: center;
}

#cat {
}

#notcat {
}

</style>
<script src="https://cdnjs.cloudflare.com/ajax/libs/d3/4.6.0/d3.min.js" charset="utf-8"></script>
<script src="https://d3js.org/d3-scale-chromatic.v1.min.js" charset="utf-8"></script>


<span id="title-div"></span>
<div class="scattertext" id="d3-div-1"> </div>
<div id="corpus-stats"> </div>
<form name="termForm" onSubmit="handleSearch(); return false;">
  <input name="Submit" type="submit" value="Search for term">
  <input type="text" id="searchTerm" placeholder="Type a word or two&hellip;">
  <span id="alertMessage" class="alert"></span>
</form>
<a name="snippets"></a>
<a name="snippetsalt"></a>
<div id="termstats"></div>
<div id="d3-div-2">
 <div class="snippet_header left_contexts" id="cathead"></div>
 <div class="snippet_header right_contexts" id="notcathead"></div>
 <div class="snippet left_contexts" id="cat"></div>
 <div class="snippet right_contexts" id="notcat"></div>
</div>
<script charset="utf-8">
  // Created using Cozy: github.com/uwplse/cozy
function Rectangle(ax1, ay1, ax2, ay2) {
    this.ax1 = ax1;
    this.ay1 = ay1;
    this.ax2 = ax2;
    this.ay2 = ay2;
    this._left7 = undefined;
    this._right8 = undefined;
    this._parent9 = undefined;
    this._min_ax12 = undefined;
    this._min_ay13 = undefined;
    this._max_ay24 = undefined;
    this._height10 = undefined;
}
function RectangleHolder() {
    this.my_size = 0;
    (this)._root1 = null;
}
RectangleHolder.prototype.size = function () {
    return this.my_size;
};
RectangleHolder.prototype.add = function (x) {
    ++this.my_size;
    var _idx69 = (x).ax2;
    (x)._left7 = null;
    (x)._right8 = null;
    (x)._min_ax12 = (x).ax1;
    (x)._min_ay13 = (x).ay1;
    (x)._max_ay24 = (x).ay2;
    (x)._height10 = 0;
    var _previous70 = null;
    var _current71 = (this)._root1;
    var _is_left72 = false;
    while (!((_current71) == null)) {
        _previous70 = _current71;
        if ((_idx69) < ((_current71).ax2)) {
            _current71 = (_current71)._left7;
            _is_left72 = true;
        } else {
            _current71 = (_current71)._right8;
            _is_left72 = false;
        }
    }
    if ((_previous70) == null) {
        (this)._root1 = x;
    } else {
        (x)._parent9 = _previous70;
        if (_is_left72) {
            (_previous70)._left7 = x;
        } else {
            (_previous70)._right8 = x;
        }
    }
    var _cursor73 = (x)._parent9;
    var _changed74 = true;
    while ((_changed74) && (!((_cursor73) == (null)))) {
        var _old__min_ax1275 = (_cursor73)._min_ax12;
        var _old__min_ay1376 = (_cursor73)._min_ay13;
        var _old__max_ay2477 = (_cursor73)._max_ay24;
        var _old_height78 = (_cursor73)._height10;
        /* _min_ax12 is min of ax1 */
        var _augval79 = (_cursor73).ax1;
        var _child80 = (_cursor73)._left7;
        if (!((_child80) == null)) {
            var _val81 = (_child80)._min_ax12;
            _augval79 = ((_augval79) < (_val81)) ? (_augval79) : (_val81);
        }
        var _child82 = (_cursor73)._right8;
        if (!((_child82) == null)) {
            var _val83 = (_child82)._min_ax12;
            _augval79 = ((_augval79) < (_val83)) ? (_augval79) : (_val83);
        }
        (_cursor73)._min_ax12 = _augval79;
        /* _min_ay13 is min of ay1 */
        var _augval84 = (_cursor73).ay1;
        var _child85 = (_cursor73)._left7;
        if (!((_child85) == null)) {
            var _val86 = (_child85)._min_ay13;
            _augval84 = ((_augval84) < (_val86)) ? (_augval84) : (_val86);
        }
        var _child87 = (_cursor73)._right8;
        if (!((_child87) == null)) {
            var _val88 = (_child87)._min_ay13;
            _augval84 = ((_augval84) < (_val88)) ? (_augval84) : (_val88);
        }
        (_cursor73)._min_ay13 = _augval84;
        /* _max_ay24 is max of ay2 */
        var _augval89 = (_cursor73).ay2;
        var _child90 = (_cursor73)._left7;
        if (!((_child90) == null)) {
            var _val91 = (_child90)._max_ay24;
            _augval89 = ((_augval89) < (_val91)) ? (_val91) : (_augval89);
        }
        var _child92 = (_cursor73)._right8;
        if (!((_child92) == null)) {
            var _val93 = (_child92)._max_ay24;
            _augval89 = ((_augval89) < (_val93)) ? (_val93) : (_augval89);
        }
        (_cursor73)._max_ay24 = _augval89;
        (_cursor73)._height10 = 1 + ((((((_cursor73)._left7) == null) ? (-1) : (((_cursor73)._left7)._height10)) > ((((_cursor73)._right8) == null) ? (-1) : (((_cursor73)._right8)._height10))) ? ((((_cursor73)._left7) == null) ? (-1) : (((_cursor73)._left7)._height10)) : ((((_cursor73)._right8) == null) ? (-1) : (((_cursor73)._right8)._height10)));
        _changed74 = false;
        _changed74 = (_changed74) || (!((_old__min_ax1275) == ((_cursor73)._min_ax12)));
        _changed74 = (_changed74) || (!((_old__min_ay1376) == ((_cursor73)._min_ay13)));
        _changed74 = (_changed74) || (!((_old__max_ay2477) == ((_cursor73)._max_ay24)));
        _changed74 = (_changed74) || (!((_old_height78) == ((_cursor73)._height10)));
        _cursor73 = (_cursor73)._parent9;
    }
    /* rebalance AVL tree */
    var _cursor94 = x;
    var _imbalance95;
    while (!(((_cursor94)._parent9) == null)) {
        _cursor94 = (_cursor94)._parent9;
        (_cursor94)._height10 = 1 + ((((((_cursor94)._left7) == null) ? (-1) : (((_cursor94)._left7)._height10)) > ((((_cursor94)._right8) == null) ? (-1) : (((_cursor94)._right8)._height10))) ? ((((_cursor94)._left7) == null) ? (-1) : (((_cursor94)._left7)._height10)) : ((((_cursor94)._right8) == null) ? (-1) : (((_cursor94)._right8)._height10)));
        _imbalance95 = ((((_cursor94)._left7) == null) ? (-1) : (((_cursor94)._left7)._height10)) - ((((_cursor94)._right8) == null) ? (-1) : (((_cursor94)._right8)._height10));
        if ((_imbalance95) > (1)) {
            if ((((((_cursor94)._left7)._left7) == null) ? (-1) : ((((_cursor94)._left7)._left7)._height10)) < (((((_cursor94)._left7)._right8) == null) ? (-1) : ((((_cursor94)._left7)._right8)._height10))) {
                /* rotate ((_cursor94)._left7)._right8 */
                var _a96 = (_cursor94)._left7;
                var _b97 = (_a96)._right8;
                var _c98 = (_b97)._left7;
                /* replace _a96 with _b97 in (_a96)._parent9 */
                if (!(((_a96)._parent9) == null)) {
                    if ((((_a96)._parent9)._left7) == (_a96)) {
                        ((_a96)._parent9)._left7 = _b97;
                    } else {
                        ((_a96)._parent9)._right8 = _b97;
                    }
                }
                if (!((_b97) == null)) {
                    (_b97)._parent9 = (_a96)._parent9;
                }
                /* replace _c98 with _a96 in _b97 */
                (_b97)._left7 = _a96;
                if (!((_a96) == null)) {
                    (_a96)._parent9 = _b97;
                }
                /* replace _b97 with _c98 in _a96 */
                (_a96)._right8 = _c98;
                if (!((_c98) == null)) {
                    (_c98)._parent9 = _a96;
                }
                /* _min_ax12 is min of ax1 */
                var _augval99 = (_a96).ax1;
                var _child100 = (_a96)._left7;
                if (!((_child100) == null)) {
                    var _val101 = (_child100)._min_ax12;
                    _augval99 = ((_augval99) < (_val101)) ? (_augval99) : (_val101);
                }
                var _child102 = (_a96)._right8;
                if (!((_child102) == null)) {
                    var _val103 = (_child102)._min_ax12;
                    _augval99 = ((_augval99) < (_val103)) ? (_augval99) : (_val103);
                }
                (_a96)._min_ax12 = _augval99;
                /* _min_ay13 is min of ay1 */
                var _augval104 = (_a96).ay1;
                var _child105 = (_a96)._left7;
                if (!((_child105) == null)) {
                    var _val106 = (_child105)._min_ay13;
                    _augval104 = ((_augval104) < (_val106)) ? (_augval104) : (_val106);
                }
                var _child107 = (_a96)._right8;
                if (!((_child107) == null)) {
                    var _val108 = (_child107)._min_ay13;
                    _augval104 = ((_augval104) < (_val108)) ? (_augval104) : (_val108);
                }
                (_a96)._min_ay13 = _augval104;
                /* _max_ay24 is max of ay2 */
                var _augval109 = (_a96).ay2;
                var _child110 = (_a96)._left7;
                if (!((_child110) == null)) {
                    var _val111 = (_child110)._max_ay24;
                    _augval109 = ((_augval109) < (_val111)) ? (_val111) : (_augval109);
                }
                var _child112 = (_a96)._right8;
                if (!((_child112) == null)) {
                    var _val113 = (_child112)._max_ay24;
                    _augval109 = ((_augval109) < (_val113)) ? (_val113) : (_augval109);
                }
                (_a96)._max_ay24 = _augval109;
                (_a96)._height10 = 1 + ((((((_a96)._left7) == null) ? (-1) : (((_a96)._left7)._height10)) > ((((_a96)._right8) == null) ? (-1) : (((_a96)._right8)._height10))) ? ((((_a96)._left7) == null) ? (-1) : (((_a96)._left7)._height10)) : ((((_a96)._right8) == null) ? (-1) : (((_a96)._right8)._height10)));
                /* _min_ax12 is min of ax1 */
                var _augval114 = (_b97).ax1;
                var _child115 = (_b97)._left7;
                if (!((_child115) == null)) {
                    var _val116 = (_child115)._min_ax12;
                    _augval114 = ((_augval114) < (_val116)) ? (_augval114) : (_val116);
                }
                var _child117 = (_b97)._right8;
                if (!((_child117) == null)) {
                    var _val118 = (_child117)._min_ax12;
                    _augval114 = ((_augval114) < (_val118)) ? (_augval114) : (_val118);
                }
                (_b97)._min_ax12 = _augval114;
                /* _min_ay13 is min of ay1 */
                var _augval119 = (_b97).ay1;
                var _child120 = (_b97)._left7;
                if (!((_child120) == null)) {
                    var _val121 = (_child120)._min_ay13;
                    _augval119 = ((_augval119) < (_val121)) ? (_augval119) : (_val121);
                }
                var _child122 = (_b97)._right8;
                if (!((_child122) == null)) {
                    var _val123 = (_child122)._min_ay13;
                    _augval119 = ((_augval119) < (_val123)) ? (_augval119) : (_val123);
                }
                (_b97)._min_ay13 = _augval119;
                /* _max_ay24 is max of ay2 */
                var _augval124 = (_b97).ay2;
                var _child125 = (_b97)._left7;
                if (!((_child125) == null)) {
                    var _val126 = (_child125)._max_ay24;
                    _augval124 = ((_augval124) < (_val126)) ? (_val126) : (_augval124);
                }
                var _child127 = (_b97)._right8;
                if (!((_child127) == null)) {
                    var _val128 = (_child127)._max_ay24;
                    _augval124 = ((_augval124) < (_val128)) ? (_val128) : (_augval124);
                }
                (_b97)._max_ay24 = _augval124;
                (_b97)._height10 = 1 + ((((((_b97)._left7) == null) ? (-1) : (((_b97)._left7)._height10)) > ((((_b97)._right8) == null) ? (-1) : (((_b97)._right8)._height10))) ? ((((_b97)._left7) == null) ? (-1) : (((_b97)._left7)._height10)) : ((((_b97)._right8) == null) ? (-1) : (((_b97)._right8)._height10)));
                if (!(((_b97)._parent9) == null)) {
                    /* _min_ax12 is min of ax1 */
                    var _augval129 = ((_b97)._parent9).ax1;
                    var _child130 = ((_b97)._parent9)._left7;
                    if (!((_child130) == null)) {
                        var _val131 = (_child130)._min_ax12;
                        _augval129 = ((_augval129) < (_val131)) ? (_augval129) : (_val131);
                    }
                    var _child132 = ((_b97)._parent9)._right8;
                    if (!((_child132) == null)) {
                        var _val133 = (_child132)._min_ax12;
                        _augval129 = ((_augval129) < (_val133)) ? (_augval129) : (_val133);
                    }
                    ((_b97)._parent9)._min_ax12 = _augval129;
                    /* _min_ay13 is min of ay1 */
                    var _augval134 = ((_b97)._parent9).ay1;
                    var _child135 = ((_b97)._parent9)._left7;
                    if (!((_child135) == null)) {
                        var _val136 = (_child135)._min_ay13;
                        _augval134 = ((_augval134) < (_val136)) ? (_augval134) : (_val136);
                    }
                    var _child137 = ((_b97)._parent9)._right8;
                    if (!((_child137) == null)) {
                        var _val138 = (_child137)._min_ay13;
                        _augval134 = ((_augval134) < (_val138)) ? (_augval134) : (_val138);
                    }
                    ((_b97)._parent9)._min_ay13 = _augval134;
                    /* _max_ay24 is max of ay2 */
                    var _augval139 = ((_b97)._parent9).ay2;
                    var _child140 = ((_b97)._parent9)._left7;
                    if (!((_child140) == null)) {
                        var _val141 = (_child140)._max_ay24;
                        _augval139 = ((_augval139) < (_val141)) ? (_val141) : (_augval139);
                    }
                    var _child142 = ((_b97)._parent9)._right8;
                    if (!((_child142) == null)) {
                        var _val143 = (_child142)._max_ay24;
                        _augval139 = ((_augval139) < (_val143)) ? (_val143) : (_augval139);
                    }
                    ((_b97)._parent9)._max_ay24 = _augval139;
                    ((_b97)._parent9)._height10 = 1 + (((((((_b97)._parent9)._left7) == null) ? (-1) : ((((_b97)._parent9)._left7)._height10)) > (((((_b97)._parent9)._right8) == null) ? (-1) : ((((_b97)._parent9)._right8)._height10))) ? (((((_b97)._parent9)._left7) == null) ? (-1) : ((((_b97)._parent9)._left7)._height10)) : (((((_b97)._parent9)._right8) == null) ? (-1) : ((((_b97)._parent9)._right8)._height10)));
                } else {
                    (this)._root1 = _b97;
                }
            }
            /* rotate (_cursor94)._left7 */
            var _a144 = _cursor94;
            var _b145 = (_a144)._left7;
            var _c146 = (_b145)._right8;
            /* replace _a144 with _b145 in (_a144)._parent9 */
            if (!(((_a144)._parent9) == null)) {
                if ((((_a144)._parent9)._left7) == (_a144)) {
                    ((_a144)._parent9)._left7 = _b145;
                } else {
                    ((_a144)._parent9)._right8 = _b145;
                }
            }
            if (!((_b145) == null)) {
                (_b145)._parent9 = (_a144)._parent9;
            }
            /* replace _c146 with _a144 in _b145 */
            (_b145)._right8 = _a144;
            if (!((_a144) == null)) {
                (_a144)._parent9 = _b145;
            }
            /* replace _b145 with _c146 in _a144 */
            (_a144)._left7 = _c146;
            if (!((_c146) == null)) {
                (_c146)._parent9 = _a144;
            }
            /* _min_ax12 is min of ax1 */
            var _augval147 = (_a144).ax1;
            var _child148 = (_a144)._left7;
            if (!((_child148) == null)) {
                var _val149 = (_child148)._min_ax12;
                _augval147 = ((_augval147) < (_val149)) ? (_augval147) : (_val149);
            }
            var _child150 = (_a144)._right8;
            if (!((_child150) == null)) {
                var _val151 = (_child150)._min_ax12;
                _augval147 = ((_augval147) < (_val151)) ? (_augval147) : (_val151);
            }
            (_a144)._min_ax12 = _augval147;
            /* _min_ay13 is min of ay1 */
            var _augval152 = (_a144).ay1;
            var _child153 = (_a144)._left7;
            if (!((_child153) == null)) {
                var _val154 = (_child153)._min_ay13;
                _augval152 = ((_augval152) < (_val154)) ? (_augval152) : (_val154);
            }
            var _child155 = (_a144)._right8;
            if (!((_child155) == null)) {
                var _val156 = (_child155)._min_ay13;
                _augval152 = ((_augval152) < (_val156)) ? (_augval152) : (_val156);
            }
            (_a144)._min_ay13 = _augval152;
            /* _max_ay24 is max of ay2 */
            var _augval157 = (_a144).ay2;
            var _child158 = (_a144)._left7;
            if (!((_child158) == null)) {
                var _val159 = (_child158)._max_ay24;
                _augval157 = ((_augval157) < (_val159)) ? (_val159) : (_augval157);
            }
            var _child160 = (_a144)._right8;
            if (!((_child160) == null)) {
                var _val161 = (_child160)._max_ay24;
                _augval157 = ((_augval157) < (_val161)) ? (_val161) : (_augval157);
            }
            (_a144)._max_ay24 = _augval157;
            (_a144)._height10 = 1 + ((((((_a144)._left7) == null) ? (-1) : (((_a144)._left7)._height10)) > ((((_a144)._right8) == null) ? (-1) : (((_a144)._right8)._height10))) ? ((((_a144)._left7) == null) ? (-1) : (((_a144)._left7)._height10)) : ((((_a144)._right8) == null) ? (-1) : (((_a144)._right8)._height10)));
            /* _min_ax12 is min of ax1 */
            var _augval162 = (_b145).ax1;
            var _child163 = (_b145)._left7;
            if (!((_child163) == null)) {
                var _val164 = (_child163)._min_ax12;
                _augval162 = ((_augval162) < (_val164)) ? (_augval162) : (_val164);
            }
            var _child165 = (_b145)._right8;
            if (!((_child165) == null)) {
                var _val166 = (_child165)._min_ax12;
                _augval162 = ((_augval162) < (_val166)) ? (_augval162) : (_val166);
            }
            (_b145)._min_ax12 = _augval162;
            /* _min_ay13 is min of ay1 */
            var _augval167 = (_b145).ay1;
            var _child168 = (_b145)._left7;
            if (!((_child168) == null)) {
                var _val169 = (_child168)._min_ay13;
                _augval167 = ((_augval167) < (_val169)) ? (_augval167) : (_val169);
            }
            var _child170 = (_b145)._right8;
            if (!((_child170) == null)) {
                var _val171 = (_child170)._min_ay13;
                _augval167 = ((_augval167) < (_val171)) ? (_augval167) : (_val171);
            }
            (_b145)._min_ay13 = _augval167;
            /* _max_ay24 is max of ay2 */
            var _augval172 = (_b145).ay2;
            var _child173 = (_b145)._left7;
            if (!((_child173) == null)) {
                var _val174 = (_child173)._max_ay24;
                _augval172 = ((_augval172) < (_val174)) ? (_val174) : (_augval172);
            }
            var _child175 = (_b145)._right8;
            if (!((_child175) == null)) {
                var _val176 = (_child175)._max_ay24;
                _augval172 = ((_augval172) < (_val176)) ? (_val176) : (_augval172);
            }
            (_b145)._max_ay24 = _augval172;
            (_b145)._height10 = 1 + ((((((_b145)._left7) == null) ? (-1) : (((_b145)._left7)._height10)) > ((((_b145)._right8) == null) ? (-1) : (((_b145)._right8)._height10))) ? ((((_b145)._left7) == null) ? (-1) : (((_b145)._left7)._height10)) : ((((_b145)._right8) == null) ? (-1) : (((_b145)._right8)._height10)));
            if (!(((_b145)._parent9) == null)) {
                /* _min_ax12 is min of ax1 */
                var _augval177 = ((_b145)._parent9).ax1;
                var _child178 = ((_b145)._parent9)._left7;
                if (!((_child178) == null)) {
                    var _val179 = (_child178)._min_ax12;
                    _augval177 = ((_augval177) < (_val179)) ? (_augval177) : (_val179);
                }
                var _child180 = ((_b145)._parent9)._right8;
                if (!((_child180) == null)) {
                    var _val181 = (_child180)._min_ax12;
                    _augval177 = ((_augval177) < (_val181)) ? (_augval177) : (_val181);
                }
                ((_b145)._parent9)._min_ax12 = _augval177;
                /* _min_ay13 is min of ay1 */
                var _augval182 = ((_b145)._parent9).ay1;
                var _child183 = ((_b145)._parent9)._left7;
                if (!((_child183) == null)) {
                    var _val184 = (_child183)._min_ay13;
                    _augval182 = ((_augval182) < (_val184)) ? (_augval182) : (_val184);
                }
                var _child185 = ((_b145)._parent9)._right8;
                if (!((_child185) == null)) {
                    var _val186 = (_child185)._min_ay13;
                    _augval182 = ((_augval182) < (_val186)) ? (_augval182) : (_val186);
                }
                ((_b145)._parent9)._min_ay13 = _augval182;
                /* _max_ay24 is max of ay2 */
                var _augval187 = ((_b145)._parent9).ay2;
                var _child188 = ((_b145)._parent9)._left7;
                if (!((_child188) == null)) {
                    var _val189 = (_child188)._max_ay24;
                    _augval187 = ((_augval187) < (_val189)) ? (_val189) : (_augval187);
                }
                var _child190 = ((_b145)._parent9)._right8;
                if (!((_child190) == null)) {
                    var _val191 = (_child190)._max_ay24;
                    _augval187 = ((_augval187) < (_val191)) ? (_val191) : (_augval187);
                }
                ((_b145)._parent9)._max_ay24 = _augval187;
                ((_b145)._parent9)._height10 = 1 + (((((((_b145)._parent9)._left7) == null) ? (-1) : ((((_b145)._parent9)._left7)._height10)) > (((((_b145)._parent9)._right8) == null) ? (-1) : ((((_b145)._parent9)._right8)._height10))) ? (((((_b145)._parent9)._left7) == null) ? (-1) : ((((_b145)._parent9)._left7)._height10)) : (((((_b145)._parent9)._right8) == null) ? (-1) : ((((_b145)._parent9)._right8)._height10)));
            } else {
                (this)._root1 = _b145;
            }
            _cursor94 = (_cursor94)._parent9;
        } else if ((_imbalance95) < (-1)) {
            if ((((((_cursor94)._right8)._left7) == null) ? (-1) : ((((_cursor94)._right8)._left7)._height10)) > (((((_cursor94)._right8)._right8) == null) ? (-1) : ((((_cursor94)._right8)._right8)._height10))) {
                /* rotate ((_cursor94)._right8)._left7 */
                var _a192 = (_cursor94)._right8;
                var _b193 = (_a192)._left7;
                var _c194 = (_b193)._right8;
                /* replace _a192 with _b193 in (_a192)._parent9 */
                if (!(((_a192)._parent9) == null)) {
                    if ((((_a192)._parent9)._left7) == (_a192)) {
                        ((_a192)._parent9)._left7 = _b193;
                    } else {
                        ((_a192)._parent9)._right8 = _b193;
                    }
                }
                if (!((_b193) == null)) {
                    (_b193)._parent9 = (_a192)._parent9;
                }
                /* replace _c194 with _a192 in _b193 */
                (_b193)._right8 = _a192;
                if (!((_a192) == null)) {
                    (_a192)._parent9 = _b193;
                }
                /* replace _b193 with _c194 in _a192 */
                (_a192)._left7 = _c194;
                if (!((_c194) == null)) {
                    (_c194)._parent9 = _a192;
                }
                /* _min_ax12 is min of ax1 */
                var _augval195 = (_a192).ax1;
                var _child196 = (_a192)._left7;
                if (!((_child196) == null)) {
                    var _val197 = (_child196)._min_ax12;
                    _augval195 = ((_augval195) < (_val197)) ? (_augval195) : (_val197);
                }
                var _child198 = (_a192)._right8;
                if (!((_child198) == null)) {
                    var _val199 = (_child198)._min_ax12;
                    _augval195 = ((_augval195) < (_val199)) ? (_augval195) : (_val199);
                }
                (_a192)._min_ax12 = _augval195;
                /* _min_ay13 is min of ay1 */
                var _augval200 = (_a192).ay1;
                var _child201 = (_a192)._left7;
                if (!((_child201) == null)) {
                    var _val202 = (_child201)._min_ay13;
                    _augval200 = ((_augval200) < (_val202)) ? (_augval200) : (_val202);
                }
                var _child203 = (_a192)._right8;
                if (!((_child203) == null)) {
                    var _val204 = (_child203)._min_ay13;
                    _augval200 = ((_augval200) < (_val204)) ? (_augval200) : (_val204);
                }
                (_a192)._min_ay13 = _augval200;
                /* _max_ay24 is max of ay2 */
                var _augval205 = (_a192).ay2;
                var _child206 = (_a192)._left7;
                if (!((_child206) == null)) {
                    var _val207 = (_child206)._max_ay24;
                    _augval205 = ((_augval205) < (_val207)) ? (_val207) : (_augval205);
                }
                var _child208 = (_a192)._right8;
                if (!((_child208) == null)) {
                    var _val209 = (_child208)._max_ay24;
                    _augval205 = ((_augval205) < (_val209)) ? (_val209) : (_augval205);
                }
                (_a192)._max_ay24 = _augval205;
                (_a192)._height10 = 1 + ((((((_a192)._left7) == null) ? (-1) : (((_a192)._left7)._height10)) > ((((_a192)._right8) == null) ? (-1) : (((_a192)._right8)._height10))) ? ((((_a192)._left7) == null) ? (-1) : (((_a192)._left7)._height10)) : ((((_a192)._right8) == null) ? (-1) : (((_a192)._right8)._height10)));
                /* _min_ax12 is min of ax1 */
                var _augval210 = (_b193).ax1;
                var _child211 = (_b193)._left7;
                if (!((_child211) == null)) {
                    var _val212 = (_child211)._min_ax12;
                    _augval210 = ((_augval210) < (_val212)) ? (_augval210) : (_val212);
                }
                var _child213 = (_b193)._right8;
                if (!((_child213) == null)) {
                    var _val214 = (_child213)._min_ax12;
                    _augval210 = ((_augval210) < (_val214)) ? (_augval210) : (_val214);
                }
                (_b193)._min_ax12 = _augval210;
                /* _min_ay13 is min of ay1 */
                var _augval215 = (_b193).ay1;
                var _child216 = (_b193)._left7;
                if (!((_child216) == null)) {
                    var _val217 = (_child216)._min_ay13;
                    _augval215 = ((_augval215) < (_val217)) ? (_augval215) : (_val217);
                }
                var _child218 = (_b193)._right8;
                if (!((_child218) == null)) {
                    var _val219 = (_child218)._min_ay13;
                    _augval215 = ((_augval215) < (_val219)) ? (_augval215) : (_val219);
                }
                (_b193)._min_ay13 = _augval215;
                /* _max_ay24 is max of ay2 */
                var _augval220 = (_b193).ay2;
                var _child221 = (_b193)._left7;
                if (!((_child221) == null)) {
                    var _val222 = (_child221)._max_ay24;
                    _augval220 = ((_augval220) < (_val222)) ? (_val222) : (_augval220);
                }
                var _child223 = (_b193)._right8;
                if (!((_child223) == null)) {
                    var _val224 = (_child223)._max_ay24;
                    _augval220 = ((_augval220) < (_val224)) ? (_val224) : (_augval220);
                }
                (_b193)._max_ay24 = _augval220;
                (_b193)._height10 = 1 + ((((((_b193)._left7) == null) ? (-1) : (((_b193)._left7)._height10)) > ((((_b193)._right8) == null) ? (-1) : (((_b193)._right8)._height10))) ? ((((_b193)._left7) == null) ? (-1) : (((_b193)._left7)._height10)) : ((((_b193)._right8) == null) ? (-1) : (((_b193)._right8)._height10)));
                if (!(((_b193)._parent9) == null)) {
                    /* _min_ax12 is min of ax1 */
                    var _augval225 = ((_b193)._parent9).ax1;
                    var _child226 = ((_b193)._parent9)._left7;
                    if (!((_child226) == null)) {
                        var _val227 = (_child226)._min_ax12;
                        _augval225 = ((_augval225) < (_val227)) ? (_augval225) : (_val227);
                    }
                    var _child228 = ((_b193)._parent9)._right8;
                    if (!((_child228) == null)) {
                        var _val229 = (_child228)._min_ax12;
                        _augval225 = ((_augval225) < (_val229)) ? (_augval225) : (_val229);
                    }
                    ((_b193)._parent9)._min_ax12 = _augval225;
                    /* _min_ay13 is min of ay1 */
                    var _augval230 = ((_b193)._parent9).ay1;
                    var _child231 = ((_b193)._parent9)._left7;
                    if (!((_child231) == null)) {
                        var _val232 = (_child231)._min_ay13;
                        _augval230 = ((_augval230) < (_val232)) ? (_augval230) : (_val232);
                    }
                    var _child233 = ((_b193)._parent9)._right8;
                    if (!((_child233) == null)) {
                        var _val234 = (_child233)._min_ay13;
                        _augval230 = ((_augval230) < (_val234)) ? (_augval230) : (_val234);
                    }
                    ((_b193)._parent9)._min_ay13 = _augval230;
                    /* _max_ay24 is max of ay2 */
                    var _augval235 = ((_b193)._parent9).ay2;
                    var _child236 = ((_b193)._parent9)._left7;
                    if (!((_child236) == null)) {
                        var _val237 = (_child236)._max_ay24;
                        _augval235 = ((_augval235) < (_val237)) ? (_val237) : (_augval235);
                    }
                    var _child238 = ((_b193)._parent9)._right8;
                    if (!((_child238) == null)) {
                        var _val239 = (_child238)._max_ay24;
                        _augval235 = ((_augval235) < (_val239)) ? (_val239) : (_augval235);
                    }
                    ((_b193)._parent9)._max_ay24 = _augval235;
                    ((_b193)._parent9)._height10 = 1 + (((((((_b193)._parent9)._left7) == null) ? (-1) : ((((_b193)._parent9)._left7)._height10)) > (((((_b193)._parent9)._right8) == null) ? (-1) : ((((_b193)._parent9)._right8)._height10))) ? (((((_b193)._parent9)._left7) == null) ? (-1) : ((((_b193)._parent9)._left7)._height10)) : (((((_b193)._parent9)._right8) == null) ? (-1) : ((((_b193)._parent9)._right8)._height10)));
                } else {
                    (this)._root1 = _b193;
                }
            }
            /* rotate (_cursor94)._right8 */
            var _a240 = _cursor94;
            var _b241 = (_a240)._right8;
            var _c242 = (_b241)._left7;
            /* replace _a240 with _b241 in (_a240)._parent9 */
            if (!(((_a240)._parent9) == null)) {
                if ((((_a240)._parent9)._left7) == (_a240)) {
                    ((_a240)._parent9)._left7 = _b241;
                } else {
                    ((_a240)._parent9)._right8 = _b241;
                }
            }
            if (!((_b241) == null)) {
                (_b241)._parent9 = (_a240)._parent9;
            }
            /* replace _c242 with _a240 in _b241 */
            (_b241)._left7 = _a240;
            if (!((_a240) == null)) {
                (_a240)._parent9 = _b241;
            }
            /* replace _b241 with _c242 in _a240 */
            (_a240)._right8 = _c242;
            if (!((_c242) == null)) {
                (_c242)._parent9 = _a240;
            }
            /* _min_ax12 is min of ax1 */
            var _augval243 = (_a240).ax1;
            var _child244 = (_a240)._left7;
            if (!((_child244) == null)) {
                var _val245 = (_child244)._min_ax12;
                _augval243 = ((_augval243) < (_val245)) ? (_augval243) : (_val245);
            }
            var _child246 = (_a240)._right8;
            if (!((_child246) == null)) {
                var _val247 = (_child246)._min_ax12;
                _augval243 = ((_augval243) < (_val247)) ? (_augval243) : (_val247);
            }
            (_a240)._min_ax12 = _augval243;
            /* _min_ay13 is min of ay1 */
            var _augval248 = (_a240).ay1;
            var _child249 = (_a240)._left7;
            if (!((_child249) == null)) {
                var _val250 = (_child249)._min_ay13;
                _augval248 = ((_augval248) < (_val250)) ? (_augval248) : (_val250);
            }
            var _child251 = (_a240)._right8;
            if (!((_child251) == null)) {
                var _val252 = (_child251)._min_ay13;
                _augval248 = ((_augval248) < (_val252)) ? (_augval248) : (_val252);
            }
            (_a240)._min_ay13 = _augval248;
            /* _max_ay24 is max of ay2 */
            var _augval253 = (_a240).ay2;
            var _child254 = (_a240)._left7;
            if (!((_child254) == null)) {
                var _val255 = (_child254)._max_ay24;
                _augval253 = ((_augval253) < (_val255)) ? (_val255) : (_augval253);
            }
            var _child256 = (_a240)._right8;
            if (!((_child256) == null)) {
                var _val257 = (_child256)._max_ay24;
                _augval253 = ((_augval253) < (_val257)) ? (_val257) : (_augval253);
            }
            (_a240)._max_ay24 = _augval253;
            (_a240)._height10 = 1 + ((((((_a240)._left7) == null) ? (-1) : (((_a240)._left7)._height10)) > ((((_a240)._right8) == null) ? (-1) : (((_a240)._right8)._height10))) ? ((((_a240)._left7) == null) ? (-1) : (((_a240)._left7)._height10)) : ((((_a240)._right8) == null) ? (-1) : (((_a240)._right8)._height10)));
            /* _min_ax12 is min of ax1 */
            var _augval258 = (_b241).ax1;
            var _child259 = (_b241)._left7;
            if (!((_child259) == null)) {
                var _val260 = (_child259)._min_ax12;
                _augval258 = ((_augval258) < (_val260)) ? (_augval258) : (_val260);
            }
            var _child261 = (_b241)._right8;
            if (!((_child261) == null)) {
                var _val262 = (_child261)._min_ax12;
                _augval258 = ((_augval258) < (_val262)) ? (_augval258) : (_val262);
            }
            (_b241)._min_ax12 = _augval258;
            /* _min_ay13 is min of ay1 */
            var _augval263 = (_b241).ay1;
            var _child264 = (_b241)._left7;
            if (!((_child264) == null)) {
                var _val265 = (_child264)._min_ay13;
                _augval263 = ((_augval263) < (_val265)) ? (_augval263) : (_val265);
            }
            var _child266 = (_b241)._right8;
            if (!((_child266) == null)) {
                var _val267 = (_child266)._min_ay13;
                _augval263 = ((_augval263) < (_val267)) ? (_augval263) : (_val267);
            }
            (_b241)._min_ay13 = _augval263;
            /* _max_ay24 is max of ay2 */
            var _augval268 = (_b241).ay2;
            var _child269 = (_b241)._left7;
            if (!((_child269) == null)) {
                var _val270 = (_child269)._max_ay24;
                _augval268 = ((_augval268) < (_val270)) ? (_val270) : (_augval268);
            }
            var _child271 = (_b241)._right8;
            if (!((_child271) == null)) {
                var _val272 = (_child271)._max_ay24;
                _augval268 = ((_augval268) < (_val272)) ? (_val272) : (_augval268);
            }
            (_b241)._max_ay24 = _augval268;
            (_b241)._height10 = 1 + ((((((_b241)._left7) == null) ? (-1) : (((_b241)._left7)._height10)) > ((((_b241)._right8) == null) ? (-1) : (((_b241)._right8)._height10))) ? ((((_b241)._left7) == null) ? (-1) : (((_b241)._left7)._height10)) : ((((_b241)._right8) == null) ? (-1) : (((_b241)._right8)._height10)));
            if (!(((_b241)._parent9) == null)) {
                /* _min_ax12 is min of ax1 */
                var _augval273 = ((_b241)._parent9).ax1;
                var _child274 = ((_b241)._parent9)._left7;
                if (!((_child274) == null)) {
                    var _val275 = (_child274)._min_ax12;
                    _augval273 = ((_augval273) < (_val275)) ? (_augval273) : (_val275);
                }
                var _child276 = ((_b241)._parent9)._right8;
                if (!((_child276) == null)) {
                    var _val277 = (_child276)._min_ax12;
                    _augval273 = ((_augval273) < (_val277)) ? (_augval273) : (_val277);
                }
                ((_b241)._parent9)._min_ax12 = _augval273;
                /* _min_ay13 is min of ay1 */
                var _augval278 = ((_b241)._parent9).ay1;
                var _child279 = ((_b241)._parent9)._left7;
                if (!((_child279) == null)) {
                    var _val280 = (_child279)._min_ay13;
                    _augval278 = ((_augval278) < (_val280)) ? (_augval278) : (_val280);
                }
                var _child281 = ((_b241)._parent9)._right8;
                if (!((_child281) == null)) {
                    var _val282 = (_child281)._min_ay13;
                    _augval278 = ((_augval278) < (_val282)) ? (_augval278) : (_val282);
                }
                ((_b241)._parent9)._min_ay13 = _augval278;
                /* _max_ay24 is max of ay2 */
                var _augval283 = ((_b241)._parent9).ay2;
                var _child284 = ((_b241)._parent9)._left7;
                if (!((_child284) == null)) {
                    var _val285 = (_child284)._max_ay24;
                    _augval283 = ((_augval283) < (_val285)) ? (_val285) : (_augval283);
                }
                var _child286 = ((_b241)._parent9)._right8;
                if (!((_child286) == null)) {
                    var _val287 = (_child286)._max_ay24;
                    _augval283 = ((_augval283) < (_val287)) ? (_val287) : (_augval283);
                }
                ((_b241)._parent9)._max_ay24 = _augval283;
                ((_b241)._parent9)._height10 = 1 + (((((((_b241)._parent9)._left7) == null) ? (-1) : ((((_b241)._parent9)._left7)._height10)) > (((((_b241)._parent9)._right8) == null) ? (-1) : ((((_b241)._parent9)._right8)._height10))) ? (((((_b241)._parent9)._left7) == null) ? (-1) : ((((_b241)._parent9)._left7)._height10)) : (((((_b241)._parent9)._right8) == null) ? (-1) : ((((_b241)._parent9)._right8)._height10)));
            } else {
                (this)._root1 = _b241;
            }
            _cursor94 = (_cursor94)._parent9;
        }
    }
};
RectangleHolder.prototype.remove = function (x) {
    --this.my_size;
    var _parent288 = (x)._parent9;
    var _left289 = (x)._left7;
    var _right290 = (x)._right8;
    var _new_x291;
    if (((_left289) == null) && ((_right290) == null)) {
        _new_x291 = null;
        /* replace x with _new_x291 in _parent288 */
        if (!((_parent288) == null)) {
            if (((_parent288)._left7) == (x)) {
                (_parent288)._left7 = _new_x291;
            } else {
                (_parent288)._right8 = _new_x291;
            }
        }
        if (!((_new_x291) == null)) {
            (_new_x291)._parent9 = _parent288;
        }
    } else if ((!((_left289) == null)) && ((_right290) == null)) {
        _new_x291 = _left289;
        /* replace x with _new_x291 in _parent288 */
        if (!((_parent288) == null)) {
            if (((_parent288)._left7) == (x)) {
                (_parent288)._left7 = _new_x291;
            } else {
                (_parent288)._right8 = _new_x291;
            }
        }
        if (!((_new_x291) == null)) {
            (_new_x291)._parent9 = _parent288;
        }
    } else if (((_left289) == null) && (!((_right290) == null))) {
        _new_x291 = _right290;
        /* replace x with _new_x291 in _parent288 */
        if (!((_parent288) == null)) {
            if (((_parent288)._left7) == (x)) {
                (_parent288)._left7 = _new_x291;
            } else {
                (_parent288)._right8 = _new_x291;
            }
        }
        if (!((_new_x291) == null)) {
            (_new_x291)._parent9 = _parent288;
        }
    } else {
        var _root292 = (x)._right8;
        var _x293 = _root292;
        var _descend294 = true;
        var _from_left295 = true;
        while (true) {
            if ((_x293) == null) {
                _x293 = null;
                break;
            }
            if (_descend294) {
                /* too small? */
                if (false) {
                    if ((!(((_x293)._right8) == null)) && (true)) {
                        if ((_x293) == (_root292)) {
                            _root292 = (_x293)._right8;
                        }
                        _x293 = (_x293)._right8;
                    } else if ((_x293) == (_root292)) {
                        _x293 = null;
                        break;
                    } else {
                        _descend294 = false;
                        _from_left295 = (!(((_x293)._parent9) == null)) && ((_x293) == (((_x293)._parent9)._left7));
                        _x293 = (_x293)._parent9;
                    }
                } else if ((!(((_x293)._left7) == null)) && (true)) {
                    _x293 = (_x293)._left7;
                    /* too large? */
                } else if (false) {
                    if ((_x293) == (_root292)) {
                        _x293 = null;
                        break;
                    } else {
                        _descend294 = false;
                        _from_left295 = (!(((_x293)._parent9) == null)) && ((_x293) == (((_x293)._parent9)._left7));
                        _x293 = (_x293)._parent9;
                    }
                    /* node ok? */
                } else if (true) {
                    break;
                } else if ((_x293) == (_root292)) {
                    _root292 = (_x293)._right8;
                    _x293 = (_x293)._right8;
                } else {
                    if ((!(((_x293)._right8) == null)) && (true)) {
                        if ((_x293) == (_root292)) {
                            _root292 = (_x293)._right8;
                        }
                        _x293 = (_x293)._right8;
                    } else {
                        _descend294 = false;
                        _from_left295 = (!(((_x293)._parent9) == null)) && ((_x293) == (((_x293)._parent9)._left7));
                        _x293 = (_x293)._parent9;
                    }
                }
            } else if (_from_left295) {
                if (false) {
                    _x293 = null;
                    break;
                } else if (true) {
                    break;
                } else if ((!(((_x293)._right8) == null)) && (true)) {
                    _descend294 = true;
                    if ((_x293) == (_root292)) {
                        _root292 = (_x293)._right8;
                    }
                    _x293 = (_x293)._right8;
                } else if ((_x293) == (_root292)) {
                    _x293 = null;
                    break;
                } else {
                    _descend294 = false;
                    _from_left295 = (!(((_x293)._parent9) == null)) && ((_x293) == (((_x293)._parent9)._left7));
                    _x293 = (_x293)._parent9;
                }
            } else {
                if ((_x293) == (_root292)) {
                    _x293 = null;
                    break;
                } else {
                    _descend294 = false;
                    _from_left295 = (!(((_x293)._parent9) == null)) && ((_x293) == (((_x293)._parent9)._left7));
                    _x293 = (_x293)._parent9;
                }
            }
        }
        _new_x291 = _x293;
        var _mp296 = (_x293)._parent9;
        var _mr297 = (_x293)._right8;
        /* replace _x293 with _mr297 in _mp296 */
        if (!((_mp296) == null)) {
            if (((_mp296)._left7) == (_x293)) {
                (_mp296)._left7 = _mr297;
            } else {
                (_mp296)._right8 = _mr297;
            }
        }
        if (!((_mr297) == null)) {
            (_mr297)._parent9 = _mp296;
        }
        /* replace x with _x293 in _parent288 */
        if (!((_parent288) == null)) {
            if (((_parent288)._left7) == (x)) {
                (_parent288)._left7 = _x293;
            } else {
                (_parent288)._right8 = _x293;
            }
        }
        if (!((_x293) == null)) {
            (_x293)._parent9 = _parent288;
        }
        /* replace null with _left289 in _x293 */
        (_x293)._left7 = _left289;
        if (!((_left289) == null)) {
            (_left289)._parent9 = _x293;
        }
        /* replace _mr297 with (x)._right8 in _x293 */
        (_x293)._right8 = (x)._right8;
        if (!(((x)._right8) == null)) {
            ((x)._right8)._parent9 = _x293;
        }
        /* _min_ax12 is min of ax1 */
        var _augval298 = (_x293).ax1;
        var _child299 = (_x293)._left7;
        if (!((_child299) == null)) {
            var _val300 = (_child299)._min_ax12;
            _augval298 = ((_augval298) < (_val300)) ? (_augval298) : (_val300);
        }
        var _child301 = (_x293)._right8;
        if (!((_child301) == null)) {
            var _val302 = (_child301)._min_ax12;
            _augval298 = ((_augval298) < (_val302)) ? (_augval298) : (_val302);
        }
        (_x293)._min_ax12 = _augval298;
        /* _min_ay13 is min of ay1 */
        var _augval303 = (_x293).ay1;
        var _child304 = (_x293)._left7;
        if (!((_child304) == null)) {
            var _val305 = (_child304)._min_ay13;
            _augval303 = ((_augval303) < (_val305)) ? (_augval303) : (_val305);
        }
        var _child306 = (_x293)._right8;
        if (!((_child306) == null)) {
            var _val307 = (_child306)._min_ay13;
            _augval303 = ((_augval303) < (_val307)) ? (_augval303) : (_val307);
        }
        (_x293)._min_ay13 = _augval303;
        /* _max_ay24 is max of ay2 */
        var _augval308 = (_x293).ay2;
        var _child309 = (_x293)._left7;
        if (!((_child309) == null)) {
            var _val310 = (_child309)._max_ay24;
            _augval308 = ((_augval308) < (_val310)) ? (_val310) : (_augval308);
        }
        var _child311 = (_x293)._right8;
        if (!((_child311) == null)) {
            var _val312 = (_child311)._max_ay24;
            _augval308 = ((_augval308) < (_val312)) ? (_val312) : (_augval308);
        }
        (_x293)._max_ay24 = _augval308;
        (_x293)._height10 = 1 + ((((((_x293)._left7) == null) ? (-1) : (((_x293)._left7)._height10)) > ((((_x293)._right8) == null) ? (-1) : (((_x293)._right8)._height10))) ? ((((_x293)._left7) == null) ? (-1) : (((_x293)._left7)._height10)) : ((((_x293)._right8) == null) ? (-1) : (((_x293)._right8)._height10)));
        var _cursor313 = _mp296;
        var _changed314 = true;
        while ((_changed314) && (!((_cursor313) == (_parent288)))) {
            var _old__min_ax12315 = (_cursor313)._min_ax12;
            var _old__min_ay13316 = (_cursor313)._min_ay13;
            var _old__max_ay24317 = (_cursor313)._max_ay24;
            var _old_height318 = (_cursor313)._height10;
            /* _min_ax12 is min of ax1 */
            var _augval319 = (_cursor313).ax1;
            var _child320 = (_cursor313)._left7;
            if (!((_child320) == null)) {
                var _val321 = (_child320)._min_ax12;
                _augval319 = ((_augval319) < (_val321)) ? (_augval319) : (_val321);
            }
            var _child322 = (_cursor313)._right8;
            if (!((_child322) == null)) {
                var _val323 = (_child322)._min_ax12;
                _augval319 = ((_augval319) < (_val323)) ? (_augval319) : (_val323);
            }
            (_cursor313)._min_ax12 = _augval319;
            /* _min_ay13 is min of ay1 */
            var _augval324 = (_cursor313).ay1;
            var _child325 = (_cursor313)._left7;
            if (!((_child325) == null)) {
                var _val326 = (_child325)._min_ay13;
                _augval324 = ((_augval324) < (_val326)) ? (_augval324) : (_val326);
            }
            var _child327 = (_cursor313)._right8;
            if (!((_child327) == null)) {
                var _val328 = (_child327)._min_ay13;
                _augval324 = ((_augval324) < (_val328)) ? (_augval324) : (_val328);
            }
            (_cursor313)._min_ay13 = _augval324;
            /* _max_ay24 is max of ay2 */
            var _augval329 = (_cursor313).ay2;
            var _child330 = (_cursor313)._left7;
            if (!((_child330) == null)) {
                var _val331 = (_child330)._max_ay24;
                _augval329 = ((_augval329) < (_val331)) ? (_val331) : (_augval329);
            }
            var _child332 = (_cursor313)._right8;
            if (!((_child332) == null)) {
                var _val333 = (_child332)._max_ay24;
                _augval329 = ((_augval329) < (_val333)) ? (_val333) : (_augval329);
            }
            (_cursor313)._max_ay24 = _augval329;
            (_cursor313)._height10 = 1 + ((((((_cursor313)._left7) == null) ? (-1) : (((_cursor313)._left7)._height10)) > ((((_cursor313)._right8) == null) ? (-1) : (((_cursor313)._right8)._height10))) ? ((((_cursor313)._left7) == null) ? (-1) : (((_cursor313)._left7)._height10)) : ((((_cursor313)._right8) == null) ? (-1) : (((_cursor313)._right8)._height10)));
            _changed314 = false;
            _changed314 = (_changed314) || (!((_old__min_ax12315) == ((_cursor313)._min_ax12)));
            _changed314 = (_changed314) || (!((_old__min_ay13316) == ((_cursor313)._min_ay13)));
            _changed314 = (_changed314) || (!((_old__max_ay24317) == ((_cursor313)._max_ay24)));
            _changed314 = (_changed314) || (!((_old_height318) == ((_cursor313)._height10)));
            _cursor313 = (_cursor313)._parent9;
        }
    }
    var _cursor334 = _parent288;
    var _changed335 = true;
    while ((_changed335) && (!((_cursor334) == (null)))) {
        var _old__min_ax12336 = (_cursor334)._min_ax12;
        var _old__min_ay13337 = (_cursor334)._min_ay13;
        var _old__max_ay24338 = (_cursor334)._max_ay24;
        var _old_height339 = (_cursor334)._height10;
        /* _min_ax12 is min of ax1 */
        var _augval340 = (_cursor334).ax1;
        var _child341 = (_cursor334)._left7;
        if (!((_child341) == null)) {
            var _val342 = (_child341)._min_ax12;
            _augval340 = ((_augval340) < (_val342)) ? (_augval340) : (_val342);
        }
        var _child343 = (_cursor334)._right8;
        if (!((_child343) == null)) {
            var _val344 = (_child343)._min_ax12;
            _augval340 = ((_augval340) < (_val344)) ? (_augval340) : (_val344);
        }
        (_cursor334)._min_ax12 = _augval340;
        /* _min_ay13 is min of ay1 */
        var _augval345 = (_cursor334).ay1;
        var _child346 = (_cursor334)._left7;
        if (!((_child346) == null)) {
            var _val347 = (_child346)._min_ay13;
            _augval345 = ((_augval345) < (_val347)) ? (_augval345) : (_val347);
        }
        var _child348 = (_cursor334)._right8;
        if (!((_child348) == null)) {
            var _val349 = (_child348)._min_ay13;
            _augval345 = ((_augval345) < (_val349)) ? (_augval345) : (_val349);
        }
        (_cursor334)._min_ay13 = _augval345;
        /* _max_ay24 is max of ay2 */
        var _augval350 = (_cursor334).ay2;
        var _child351 = (_cursor334)._left7;
        if (!((_child351) == null)) {
            var _val352 = (_child351)._max_ay24;
            _augval350 = ((_augval350) < (_val352)) ? (_val352) : (_augval350);
        }
        var _child353 = (_cursor334)._right8;
        if (!((_child353) == null)) {
            var _val354 = (_child353)._max_ay24;
            _augval350 = ((_augval350) < (_val354)) ? (_val354) : (_augval350);
        }
        (_cursor334)._max_ay24 = _augval350;
        (_cursor334)._height10 = 1 + ((((((_cursor334)._left7) == null) ? (-1) : (((_cursor334)._left7)._height10)) > ((((_cursor334)._right8) == null) ? (-1) : (((_cursor334)._right8)._height10))) ? ((((_cursor334)._left7) == null) ? (-1) : (((_cursor334)._left7)._height10)) : ((((_cursor334)._right8) == null) ? (-1) : (((_cursor334)._right8)._height10)));
        _changed335 = false;
        _changed335 = (_changed335) || (!((_old__min_ax12336) == ((_cursor334)._min_ax12)));
        _changed335 = (_changed335) || (!((_old__min_ay13337) == ((_cursor334)._min_ay13)));
        _changed335 = (_changed335) || (!((_old__max_ay24338) == ((_cursor334)._max_ay24)));
        _changed335 = (_changed335) || (!((_old_height339) == ((_cursor334)._height10)));
        _cursor334 = (_cursor334)._parent9;
    }
    if (((this)._root1) == (x)) {
        (this)._root1 = _new_x291;
    }
};
RectangleHolder.prototype.updateAx1 = function (__x, new_val) {
    if ((__x).ax1 != new_val) {
        /* _min_ax12 is min of ax1 */
        var _augval355 = new_val;
        var _child356 = (__x)._left7;
        if (!((_child356) == null)) {
            var _val357 = (_child356)._min_ax12;
            _augval355 = ((_augval355) < (_val357)) ? (_augval355) : (_val357);
        }
        var _child358 = (__x)._right8;
        if (!((_child358) == null)) {
            var _val359 = (_child358)._min_ax12;
            _augval355 = ((_augval355) < (_val359)) ? (_augval355) : (_val359);
        }
        (__x)._min_ax12 = _augval355;
        var _cursor360 = (__x)._parent9;
        var _changed361 = true;
        while ((_changed361) && (!((_cursor360) == (null)))) {
            var _old__min_ax12362 = (_cursor360)._min_ax12;
            var _old_height363 = (_cursor360)._height10;
            /* _min_ax12 is min of ax1 */
            var _augval364 = (_cursor360).ax1;
            var _child365 = (_cursor360)._left7;
            if (!((_child365) == null)) {
                var _val366 = (_child365)._min_ax12;
                _augval364 = ((_augval364) < (_val366)) ? (_augval364) : (_val366);
            }
            var _child367 = (_cursor360)._right8;
            if (!((_child367) == null)) {
                var _val368 = (_child367)._min_ax12;
                _augval364 = ((_augval364) < (_val368)) ? (_augval364) : (_val368);
            }
            (_cursor360)._min_ax12 = _augval364;
            (_cursor360)._height10 = 1 + ((((((_cursor360)._left7) == null) ? (-1) : (((_cursor360)._left7)._height10)) > ((((_cursor360)._right8) == null) ? (-1) : (((_cursor360)._right8)._height10))) ? ((((_cursor360)._left7) == null) ? (-1) : (((_cursor360)._left7)._height10)) : ((((_cursor360)._right8) == null) ? (-1) : (((_cursor360)._right8)._height10)));
            _changed361 = false;
            _changed361 = (_changed361) || (!((_old__min_ax12362) == ((_cursor360)._min_ax12)));
            _changed361 = (_changed361) || (!((_old_height363) == ((_cursor360)._height10)));
            _cursor360 = (_cursor360)._parent9;
        }
        (__x).ax1 = new_val;
    }
}
RectangleHolder.prototype.updateAy1 = function (__x, new_val) {
    if ((__x).ay1 != new_val) {
        /* _min_ay13 is min of ay1 */
        var _augval369 = new_val;
        var _child370 = (__x)._left7;
        if (!((_child370) == null)) {
            var _val371 = (_child370)._min_ay13;
            _augval369 = ((_augval369) < (_val371)) ? (_augval369) : (_val371);
        }
        var _child372 = (__x)._right8;
        if (!((_child372) == null)) {
            var _val373 = (_child372)._min_ay13;
            _augval369 = ((_augval369) < (_val373)) ? (_augval369) : (_val373);
        }
        (__x)._min_ay13 = _augval369;
        var _cursor374 = (__x)._parent9;
        var _changed375 = true;
        while ((_changed375) && (!((_cursor374) == (null)))) {
            var _old__min_ay13376 = (_cursor374)._min_ay13;
            var _old_height377 = (_cursor374)._height10;
            /* _min_ay13 is min of ay1 */
            var _augval378 = (_cursor374).ay1;
            var _child379 = (_cursor374)._left7;
            if (!((_child379) == null)) {
                var _val380 = (_child379)._min_ay13;
                _augval378 = ((_augval378) < (_val380)) ? (_augval378) : (_val380);
            }
            var _child381 = (_cursor374)._right8;
            if (!((_child381) == null)) {
                var _val382 = (_child381)._min_ay13;
                _augval378 = ((_augval378) < (_val382)) ? (_augval378) : (_val382);
            }
            (_cursor374)._min_ay13 = _augval378;
            (_cursor374)._height10 = 1 + ((((((_cursor374)._left7) == null) ? (-1) : (((_cursor374)._left7)._height10)) > ((((_cursor374)._right8) == null) ? (-1) : (((_cursor374)._right8)._height10))) ? ((((_cursor374)._left7) == null) ? (-1) : (((_cursor374)._left7)._height10)) : ((((_cursor374)._right8) == null) ? (-1) : (((_cursor374)._right8)._height10)));
            _changed375 = false;
            _changed375 = (_changed375) || (!((_old__min_ay13376) == ((_cursor374)._min_ay13)));
            _changed375 = (_changed375) || (!((_old_height377) == ((_cursor374)._height10)));
            _cursor374 = (_cursor374)._parent9;
        }
        (__x).ay1 = new_val;
    }
}
RectangleHolder.prototype.updateAx2 = function (__x, new_val) {
    if ((__x).ax2 != new_val) {
        var _parent383 = (__x)._parent9;
        var _left384 = (__x)._left7;
        var _right385 = (__x)._right8;
        var _new_x386;
        if (((_left384) == null) && ((_right385) == null)) {
            _new_x386 = null;
            /* replace __x with _new_x386 in _parent383 */
            if (!((_parent383) == null)) {
                if (((_parent383)._left7) == (__x)) {
                    (_parent383)._left7 = _new_x386;
                } else {
                    (_parent383)._right8 = _new_x386;
                }
            }
            if (!((_new_x386) == null)) {
                (_new_x386)._parent9 = _parent383;
            }
        } else if ((!((_left384) == null)) && ((_right385) == null)) {
            _new_x386 = _left384;
            /* replace __x with _new_x386 in _parent383 */
            if (!((_parent383) == null)) {
                if (((_parent383)._left7) == (__x)) {
                    (_parent383)._left7 = _new_x386;
                } else {
                    (_parent383)._right8 = _new_x386;
                }
            }
            if (!((_new_x386) == null)) {
                (_new_x386)._parent9 = _parent383;
            }
        } else if (((_left384) == null) && (!((_right385) == null))) {
            _new_x386 = _right385;
            /* replace __x with _new_x386 in _parent383 */
            if (!((_parent383) == null)) {
                if (((_parent383)._left7) == (__x)) {
                    (_parent383)._left7 = _new_x386;
                } else {
                    (_parent383)._right8 = _new_x386;
                }
            }
            if (!((_new_x386) == null)) {
                (_new_x386)._parent9 = _parent383;
            }
        } else {
            var _root387 = (__x)._right8;
            var _x388 = _root387;
            var _descend389 = true;
            var _from_left390 = true;
            while (true) {
                if ((_x388) == null) {
                    _x388 = null;
                    break;
                }
                if (_descend389) {
                    /* too small? */
                    if (false) {
                        if ((!(((_x388)._right8) == null)) && (true)) {
                            if ((_x388) == (_root387)) {
                                _root387 = (_x388)._right8;
                            }
                            _x388 = (_x388)._right8;
                        } else if ((_x388) == (_root387)) {
                            _x388 = null;
                            break;
                        } else {
                            _descend389 = false;
                            _from_left390 = (!(((_x388)._parent9) == null)) && ((_x388) == (((_x388)._parent9)._left7));
                            _x388 = (_x388)._parent9;
                        }
                    } else if ((!(((_x388)._left7) == null)) && (true)) {
                        _x388 = (_x388)._left7;
                        /* too large? */
                    } else if (false) {
                        if ((_x388) == (_root387)) {
                            _x388 = null;
                            break;
                        } else {
                            _descend389 = false;
                            _from_left390 = (!(((_x388)._parent9) == null)) && ((_x388) == (((_x388)._parent9)._left7));
                            _x388 = (_x388)._parent9;
                        }
                        /* node ok? */
                    } else if (true) {
                        break;
                    } else if ((_x388) == (_root387)) {
                        _root387 = (_x388)._right8;
                        _x388 = (_x388)._right8;
                    } else {
                        if ((!(((_x388)._right8) == null)) && (true)) {
                            if ((_x388) == (_root387)) {
                                _root387 = (_x388)._right8;
                            }
                            _x388 = (_x388)._right8;
                        } else {
                            _descend389 = false;
                            _from_left390 = (!(((_x388)._parent9) == null)) && ((_x388) == (((_x388)._parent9)._left7));
                            _x388 = (_x388)._parent9;
                        }
                    }
                } else if (_from_left390) {
                    if (false) {
                        _x388 = null;
                        break;
                    } else if (true) {
                        break;
                    } else if ((!(((_x388)._right8) == null)) && (true)) {
                        _descend389 = true;
                        if ((_x388) == (_root387)) {
                            _root387 = (_x388)._right8;
                        }
                        _x388 = (_x388)._right8;
                    } else if ((_x388) == (_root387)) {
                        _x388 = null;
                        break;
                    } else {
                        _descend389 = false;
                        _from_left390 = (!(((_x388)._parent9) == null)) && ((_x388) == (((_x388)._parent9)._left7));
                        _x388 = (_x388)._parent9;
                    }
                } else {
                    if ((_x388) == (_root387)) {
                        _x388 = null;
                        break;
                    } else {
                        _descend389 = false;
                        _from_left390 = (!(((_x388)._parent9) == null)) && ((_x388) == (((_x388)._parent9)._left7));
                        _x388 = (_x388)._parent9;
                    }
                }
            }
            _new_x386 = _x388;
            var _mp391 = (_x388)._parent9;
            var _mr392 = (_x388)._right8;
            /* replace _x388 with _mr392 in _mp391 */
            if (!((_mp391) == null)) {
                if (((_mp391)._left7) == (_x388)) {
                    (_mp391)._left7 = _mr392;
                } else {
                    (_mp391)._right8 = _mr392;
                }
            }
            if (!((_mr392) == null)) {
                (_mr392)._parent9 = _mp391;
            }
            /* replace __x with _x388 in _parent383 */
            if (!((_parent383) == null)) {
                if (((_parent383)._left7) == (__x)) {
                    (_parent383)._left7 = _x388;
                } else {
                    (_parent383)._right8 = _x388;
                }
            }
            if (!((_x388) == null)) {
                (_x388)._parent9 = _parent383;
            }
            /* replace null with _left384 in _x388 */
            (_x388)._left7 = _left384;
            if (!((_left384) == null)) {
                (_left384)._parent9 = _x388;
            }
            /* replace _mr392 with (__x)._right8 in _x388 */
            (_x388)._right8 = (__x)._right8;
            if (!(((__x)._right8) == null)) {
                ((__x)._right8)._parent9 = _x388;
            }
            /* _min_ax12 is min of ax1 */
            var _augval393 = (_x388).ax1;
            var _child394 = (_x388)._left7;
            if (!((_child394) == null)) {
                var _val395 = (_child394)._min_ax12;
                _augval393 = ((_augval393) < (_val395)) ? (_augval393) : (_val395);
            }
            var _child396 = (_x388)._right8;
            if (!((_child396) == null)) {
                var _val397 = (_child396)._min_ax12;
                _augval393 = ((_augval393) < (_val397)) ? (_augval393) : (_val397);
            }
            (_x388)._min_ax12 = _augval393;
            /* _min_ay13 is min of ay1 */
            var _augval398 = (_x388).ay1;
            var _child399 = (_x388)._left7;
            if (!((_child399) == null)) {
                var _val400 = (_child399)._min_ay13;
                _augval398 = ((_augval398) < (_val400)) ? (_augval398) : (_val400);
            }
            var _child401 = (_x388)._right8;
            if (!((_child401) == null)) {
                var _val402 = (_child401)._min_ay13;
                _augval398 = ((_augval398) < (_val402)) ? (_augval398) : (_val402);
            }
            (_x388)._min_ay13 = _augval398;
            /* _max_ay24 is max of ay2 */
            var _augval403 = (_x388).ay2;
            var _child404 = (_x388)._left7;
            if (!((_child404) == null)) {
                var _val405 = (_child404)._max_ay24;
                _augval403 = ((_augval403) < (_val405)) ? (_val405) : (_augval403);
            }
            var _child406 = (_x388)._right8;
            if (!((_child406) == null)) {
                var _val407 = (_child406)._max_ay24;
                _augval403 = ((_augval403) < (_val407)) ? (_val407) : (_augval403);
            }
            (_x388)._max_ay24 = _augval403;
            (_x388)._height10 = 1 + ((((((_x388)._left7) == null) ? (-1) : (((_x388)._left7)._height10)) > ((((_x388)._right8) == null) ? (-1) : (((_x388)._right8)._height10))) ? ((((_x388)._left7) == null) ? (-1) : (((_x388)._left7)._height10)) : ((((_x388)._right8) == null) ? (-1) : (((_x388)._right8)._height10)));
            var _cursor408 = _mp391;
            var _changed409 = true;
            while ((_changed409) && (!((_cursor408) == (_parent383)))) {
                var _old__min_ax12410 = (_cursor408)._min_ax12;
                var _old__min_ay13411 = (_cursor408)._min_ay13;
                var _old__max_ay24412 = (_cursor408)._max_ay24;
                var _old_height413 = (_cursor408)._height10;
                /* _min_ax12 is min of ax1 */
                var _augval414 = (_cursor408).ax1;
                var _child415 = (_cursor408)._left7;
                if (!((_child415) == null)) {
                    var _val416 = (_child415)._min_ax12;
                    _augval414 = ((_augval414) < (_val416)) ? (_augval414) : (_val416);
                }
                var _child417 = (_cursor408)._right8;
                if (!((_child417) == null)) {
                    var _val418 = (_child417)._min_ax12;
                    _augval414 = ((_augval414) < (_val418)) ? (_augval414) : (_val418);
                }
                (_cursor408)._min_ax12 = _augval414;
                /* _min_ay13 is min of ay1 */
                var _augval419 = (_cursor408).ay1;
                var _child420 = (_cursor408)._left7;
                if (!((_child420) == null)) {
                    var _val421 = (_child420)._min_ay13;
                    _augval419 = ((_augval419) < (_val421)) ? (_augval419) : (_val421);
                }
                var _child422 = (_cursor408)._right8;
                if (!((_child422) == null)) {
                    var _val423 = (_child422)._min_ay13;
                    _augval419 = ((_augval419) < (_val423)) ? (_augval419) : (_val423);
                }
                (_cursor408)._min_ay13 = _augval419;
                /* _max_ay24 is max of ay2 */
                var _augval424 = (_cursor408).ay2;
                var _child425 = (_cursor408)._left7;
                if (!((_child425) == null)) {
                    var _val426 = (_child425)._max_ay24;
                    _augval424 = ((_augval424) < (_val426)) ? (_val426) : (_augval424);
                }
                var _child427 = (_cursor408)._right8;
                if (!((_child427) == null)) {
                    var _val428 = (_child427)._max_ay24;
                    _augval424 = ((_augval424) < (_val428)) ? (_val428) : (_augval424);
                }
                (_cursor408)._max_ay24 = _augval424;
                (_cursor408)._height10 = 1 + ((((((_cursor408)._left7) == null) ? (-1) : (((_cursor408)._left7)._height10)) > ((((_cursor408)._right8) == null) ? (-1) : (((_cursor408)._right8)._height10))) ? ((((_cursor408)._left7) == null) ? (-1) : (((_cursor408)._left7)._height10)) : ((((_cursor408)._right8) == null) ? (-1) : (((_cursor408)._right8)._height10)));
                _changed409 = false;
                _changed409 = (_changed409) || (!((_old__min_ax12410) == ((_cursor408)._min_ax12)));
                _changed409 = (_changed409) || (!((_old__min_ay13411) == ((_cursor408)._min_ay13)));
                _changed409 = (_changed409) || (!((_old__max_ay24412) == ((_cursor408)._max_ay24)));
                _changed409 = (_changed409) || (!((_old_height413) == ((_cursor408)._height10)));
                _cursor408 = (_cursor408)._parent9;
            }
        }
        var _cursor429 = _parent383;
        var _changed430 = true;
        while ((_changed430) && (!((_cursor429) == (null)))) {
            var _old__min_ax12431 = (_cursor429)._min_ax12;
            var _old__min_ay13432 = (_cursor429)._min_ay13;
            var _old__max_ay24433 = (_cursor429)._max_ay24;
            var _old_height434 = (_cursor429)._height10;
            /* _min_ax12 is min of ax1 */
            var _augval435 = (_cursor429).ax1;
            var _child436 = (_cursor429)._left7;
            if (!((_child436) == null)) {
                var _val437 = (_child436)._min_ax12;
                _augval435 = ((_augval435) < (_val437)) ? (_augval435) : (_val437);
            }
            var _child438 = (_cursor429)._right8;
            if (!((_child438) == null)) {
                var _val439 = (_child438)._min_ax12;
                _augval435 = ((_augval435) < (_val439)) ? (_augval435) : (_val439);
            }
            (_cursor429)._min_ax12 = _augval435;
            /* _min_ay13 is min of ay1 */
            var _augval440 = (_cursor429).ay1;
            var _child441 = (_cursor429)._left7;
            if (!((_child441) == null)) {
                var _val442 = (_child441)._min_ay13;
                _augval440 = ((_augval440) < (_val442)) ? (_augval440) : (_val442);
            }
            var _child443 = (_cursor429)._right8;
            if (!((_child443) == null)) {
                var _val444 = (_child443)._min_ay13;
                _augval440 = ((_augval440) < (_val444)) ? (_augval440) : (_val444);
            }
            (_cursor429)._min_ay13 = _augval440;
            /* _max_ay24 is max of ay2 */
            var _augval445 = (_cursor429).ay2;
            var _child446 = (_cursor429)._left7;
            if (!((_child446) == null)) {
                var _val447 = (_child446)._max_ay24;
                _augval445 = ((_augval445) < (_val447)) ? (_val447) : (_augval445);
            }
            var _child448 = (_cursor429)._right8;
            if (!((_child448) == null)) {
                var _val449 = (_child448)._max_ay24;
                _augval445 = ((_augval445) < (_val449)) ? (_val449) : (_augval445);
            }
            (_cursor429)._max_ay24 = _augval445;
            (_cursor429)._height10 = 1 + ((((((_cursor429)._left7) == null) ? (-1) : (((_cursor429)._left7)._height10)) > ((((_cursor429)._right8) == null) ? (-1) : (((_cursor429)._right8)._height10))) ? ((((_cursor429)._left7) == null) ? (-1) : (((_cursor429)._left7)._height10)) : ((((_cursor429)._right8) == null) ? (-1) : (((_cursor429)._right8)._height10)));
            _changed430 = false;
            _changed430 = (_changed430) || (!((_old__min_ax12431) == ((_cursor429)._min_ax12)));
            _changed430 = (_changed430) || (!((_old__min_ay13432) == ((_cursor429)._min_ay13)));
            _changed430 = (_changed430) || (!((_old__max_ay24433) == ((_cursor429)._max_ay24)));
            _changed430 = (_changed430) || (!((_old_height434) == ((_cursor429)._height10)));
            _cursor429 = (_cursor429)._parent9;
        }
        if (((this)._root1) == (__x)) {
            (this)._root1 = _new_x386;
        }
        (__x)._left7 = null;
        (__x)._right8 = null;
        (__x)._min_ax12 = (__x).ax1;
        (__x)._min_ay13 = (__x).ay1;
        (__x)._max_ay24 = (__x).ay2;
        (__x)._height10 = 0;
        var _previous450 = null;
        var _current451 = (this)._root1;
        var _is_left452 = false;
        while (!((_current451) == null)) {
            _previous450 = _current451;
            if ((new_val) < ((_current451).ax2)) {
                _current451 = (_current451)._left7;
                _is_left452 = true;
            } else {
                _current451 = (_current451)._right8;
                _is_left452 = false;
            }
        }
        if ((_previous450) == null) {
            (this)._root1 = __x;
        } else {
            (__x)._parent9 = _previous450;
            if (_is_left452) {
                (_previous450)._left7 = __x;
            } else {
                (_previous450)._right8 = __x;
            }
        }
        var _cursor453 = (__x)._parent9;
        var _changed454 = true;
        while ((_changed454) && (!((_cursor453) == (null)))) {
            var _old__min_ax12455 = (_cursor453)._min_ax12;
            var _old__min_ay13456 = (_cursor453)._min_ay13;
            var _old__max_ay24457 = (_cursor453)._max_ay24;
            var _old_height458 = (_cursor453)._height10;
            /* _min_ax12 is min of ax1 */
            var _augval459 = (_cursor453).ax1;
            var _child460 = (_cursor453)._left7;
            if (!((_child460) == null)) {
                var _val461 = (_child460)._min_ax12;
                _augval459 = ((_augval459) < (_val461)) ? (_augval459) : (_val461);
            }
            var _child462 = (_cursor453)._right8;
            if (!((_child462) == null)) {
                var _val463 = (_child462)._min_ax12;
                _augval459 = ((_augval459) < (_val463)) ? (_augval459) : (_val463);
            }
            (_cursor453)._min_ax12 = _augval459;
            /* _min_ay13 is min of ay1 */
            var _augval464 = (_cursor453).ay1;
            var _child465 = (_cursor453)._left7;
            if (!((_child465) == null)) {
                var _val466 = (_child465)._min_ay13;
                _augval464 = ((_augval464) < (_val466)) ? (_augval464) : (_val466);
            }
            var _child467 = (_cursor453)._right8;
            if (!((_child467) == null)) {
                var _val468 = (_child467)._min_ay13;
                _augval464 = ((_augval464) < (_val468)) ? (_augval464) : (_val468);
            }
            (_cursor453)._min_ay13 = _augval464;
            /* _max_ay24 is max of ay2 */
            var _augval469 = (_cursor453).ay2;
            var _child470 = (_cursor453)._left7;
            if (!((_child470) == null)) {
                var _val471 = (_child470)._max_ay24;
                _augval469 = ((_augval469) < (_val471)) ? (_val471) : (_augval469);
            }
            var _child472 = (_cursor453)._right8;
            if (!((_child472) == null)) {
                var _val473 = (_child472)._max_ay24;
                _augval469 = ((_augval469) < (_val473)) ? (_val473) : (_augval469);
            }
            (_cursor453)._max_ay24 = _augval469;
            (_cursor453)._height10 = 1 + ((((((_cursor453)._left7) == null) ? (-1) : (((_cursor453)._left7)._height10)) > ((((_cursor453)._right8) == null) ? (-1) : (((_cursor453)._right8)._height10))) ? ((((_cursor453)._left7) == null) ? (-1) : (((_cursor453)._left7)._height10)) : ((((_cursor453)._right8) == null) ? (-1) : (((_cursor453)._right8)._height10)));
            _changed454 = false;
            _changed454 = (_changed454) || (!((_old__min_ax12455) == ((_cursor453)._min_ax12)));
            _changed454 = (_changed454) || (!((_old__min_ay13456) == ((_cursor453)._min_ay13)));
            _changed454 = (_changed454) || (!((_old__max_ay24457) == ((_cursor453)._max_ay24)));
            _changed454 = (_changed454) || (!((_old_height458) == ((_cursor453)._height10)));
            _cursor453 = (_cursor453)._parent9;
        }
        /* rebalance AVL tree */
        var _cursor474 = __x;
        var _imbalance475;
        while (!(((_cursor474)._parent9) == null)) {
            _cursor474 = (_cursor474)._parent9;
            (_cursor474)._height10 = 1 + ((((((_cursor474)._left7) == null) ? (-1) : (((_cursor474)._left7)._height10)) > ((((_cursor474)._right8) == null) ? (-1) : (((_cursor474)._right8)._height10))) ? ((((_cursor474)._left7) == null) ? (-1) : (((_cursor474)._left7)._height10)) : ((((_cursor474)._right8) == null) ? (-1) : (((_cursor474)._right8)._height10)));
            _imbalance475 = ((((_cursor474)._left7) == null) ? (-1) : (((_cursor474)._left7)._height10)) - ((((_cursor474)._right8) == null) ? (-1) : (((_cursor474)._right8)._height10));
            if ((_imbalance475) > (1)) {
                if ((((((_cursor474)._left7)._left7) == null) ? (-1) : ((((_cursor474)._left7)._left7)._height10)) < (((((_cursor474)._left7)._right8) == null) ? (-1) : ((((_cursor474)._left7)._right8)._height10))) {
                    /* rotate ((_cursor474)._left7)._right8 */
                    var _a476 = (_cursor474)._left7;
                    var _b477 = (_a476)._right8;
                    var _c478 = (_b477)._left7;
                    /* replace _a476 with _b477 in (_a476)._parent9 */
                    if (!(((_a476)._parent9) == null)) {
                        if ((((_a476)._parent9)._left7) == (_a476)) {
                            ((_a476)._parent9)._left7 = _b477;
                        } else {
                            ((_a476)._parent9)._right8 = _b477;
                        }
                    }
                    if (!((_b477) == null)) {
                        (_b477)._parent9 = (_a476)._parent9;
                    }
                    /* replace _c478 with _a476 in _b477 */
                    (_b477)._left7 = _a476;
                    if (!((_a476) == null)) {
                        (_a476)._parent9 = _b477;
                    }
                    /* replace _b477 with _c478 in _a476 */
                    (_a476)._right8 = _c478;
                    if (!((_c478) == null)) {
                        (_c478)._parent9 = _a476;
                    }
                    /* _min_ax12 is min of ax1 */
                    var _augval479 = (_a476).ax1;
                    var _child480 = (_a476)._left7;
                    if (!((_child480) == null)) {
                        var _val481 = (_child480)._min_ax12;
                        _augval479 = ((_augval479) < (_val481)) ? (_augval479) : (_val481);
                    }
                    var _child482 = (_a476)._right8;
                    if (!((_child482) == null)) {
                        var _val483 = (_child482)._min_ax12;
                        _augval479 = ((_augval479) < (_val483)) ? (_augval479) : (_val483);
                    }
                    (_a476)._min_ax12 = _augval479;
                    /* _min_ay13 is min of ay1 */
                    var _augval484 = (_a476).ay1;
                    var _child485 = (_a476)._left7;
                    if (!((_child485) == null)) {
                        var _val486 = (_child485)._min_ay13;
                        _augval484 = ((_augval484) < (_val486)) ? (_augval484) : (_val486);
                    }
                    var _child487 = (_a476)._right8;
                    if (!((_child487) == null)) {
                        var _val488 = (_child487)._min_ay13;
                        _augval484 = ((_augval484) < (_val488)) ? (_augval484) : (_val488);
                    }
                    (_a476)._min_ay13 = _augval484;
                    /* _max_ay24 is max of ay2 */
                    var _augval489 = (_a476).ay2;
                    var _child490 = (_a476)._left7;
                    if (!((_child490) == null)) {
                        var _val491 = (_child490)._max_ay24;
                        _augval489 = ((_augval489) < (_val491)) ? (_val491) : (_augval489);
                    }
                    var _child492 = (_a476)._right8;
                    if (!((_child492) == null)) {
                        var _val493 = (_child492)._max_ay24;
                        _augval489 = ((_augval489) < (_val493)) ? (_val493) : (_augval489);
                    }
                    (_a476)._max_ay24 = _augval489;
                    (_a476)._height10 = 1 + ((((((_a476)._left7) == null) ? (-1) : (((_a476)._left7)._height10)) > ((((_a476)._right8) == null) ? (-1) : (((_a476)._right8)._height10))) ? ((((_a476)._left7) == null) ? (-1) : (((_a476)._left7)._height10)) : ((((_a476)._right8) == null) ? (-1) : (((_a476)._right8)._height10)));
                    /* _min_ax12 is min of ax1 */
                    var _augval494 = (_b477).ax1;
                    var _child495 = (_b477)._left7;
                    if (!((_child495) == null)) {
                        var _val496 = (_child495)._min_ax12;
                        _augval494 = ((_augval494) < (_val496)) ? (_augval494) : (_val496);
                    }
                    var _child497 = (_b477)._right8;
                    if (!((_child497) == null)) {
                        var _val498 = (_child497)._min_ax12;
                        _augval494 = ((_augval494) < (_val498)) ? (_augval494) : (_val498);
                    }
                    (_b477)._min_ax12 = _augval494;
                    /* _min_ay13 is min of ay1 */
                    var _augval499 = (_b477).ay1;
                    var _child500 = (_b477)._left7;
                    if (!((_child500) == null)) {
                        var _val501 = (_child500)._min_ay13;
                        _augval499 = ((_augval499) < (_val501)) ? (_augval499) : (_val501);
                    }
                    var _child502 = (_b477)._right8;
                    if (!((_child502) == null)) {
                        var _val503 = (_child502)._min_ay13;
                        _augval499 = ((_augval499) < (_val503)) ? (_augval499) : (_val503);
                    }
                    (_b477)._min_ay13 = _augval499;
                    /* _max_ay24 is max of ay2 */
                    var _augval504 = (_b477).ay2;
                    var _child505 = (_b477)._left7;
                    if (!((_child505) == null)) {
                        var _val506 = (_child505)._max_ay24;
                        _augval504 = ((_augval504) < (_val506)) ? (_val506) : (_augval504);
                    }
                    var _child507 = (_b477)._right8;
                    if (!((_child507) == null)) {
                        var _val508 = (_child507)._max_ay24;
                        _augval504 = ((_augval504) < (_val508)) ? (_val508) : (_augval504);
                    }
                    (_b477)._max_ay24 = _augval504;
                    (_b477)._height10 = 1 + ((((((_b477)._left7) == null) ? (-1) : (((_b477)._left7)._height10)) > ((((_b477)._right8) == null) ? (-1) : (((_b477)._right8)._height10))) ? ((((_b477)._left7) == null) ? (-1) : (((_b477)._left7)._height10)) : ((((_b477)._right8) == null) ? (-1) : (((_b477)._right8)._height10)));
                    if (!(((_b477)._parent9) == null)) {
                        /* _min_ax12 is min of ax1 */
                        var _augval509 = ((_b477)._parent9).ax1;
                        var _child510 = ((_b477)._parent9)._left7;
                        if (!((_child510) == null)) {
                            var _val511 = (_child510)._min_ax12;
                            _augval509 = ((_augval509) < (_val511)) ? (_augval509) : (_val511);
                        }
                        var _child512 = ((_b477)._parent9)._right8;
                        if (!((_child512) == null)) {
                            var _val513 = (_child512)._min_ax12;
                            _augval509 = ((_augval509) < (_val513)) ? (_augval509) : (_val513);
                        }
                        ((_b477)._parent9)._min_ax12 = _augval509;
                        /* _min_ay13 is min of ay1 */
                        var _augval514 = ((_b477)._parent9).ay1;
                        var _child515 = ((_b477)._parent9)._left7;
                        if (!((_child515) == null)) {
                            var _val516 = (_child515)._min_ay13;
                            _augval514 = ((_augval514) < (_val516)) ? (_augval514) : (_val516);
                        }
                        var _child517 = ((_b477)._parent9)._right8;
                        if (!((_child517) == null)) {
                            var _val518 = (_child517)._min_ay13;
                            _augval514 = ((_augval514) < (_val518)) ? (_augval514) : (_val518);
                        }
                        ((_b477)._parent9)._min_ay13 = _augval514;
                        /* _max_ay24 is max of ay2 */
                        var _augval519 = ((_b477)._parent9).ay2;
                        var _child520 = ((_b477)._parent9)._left7;
                        if (!((_child520) == null)) {
                            var _val521 = (_child520)._max_ay24;
                            _augval519 = ((_augval519) < (_val521)) ? (_val521) : (_augval519);
                        }
                        var _child522 = ((_b477)._parent9)._right8;
                        if (!((_child522) == null)) {
                            var _val523 = (_child522)._max_ay24;
                            _augval519 = ((_augval519) < (_val523)) ? (_val523) : (_augval519);
                        }
                        ((_b477)._parent9)._max_ay24 = _augval519;
                        ((_b477)._parent9)._height10 = 1 + (((((((_b477)._parent9)._left7) == null) ? (-1) : ((((_b477)._parent9)._left7)._height10)) > (((((_b477)._parent9)._right8) == null) ? (-1) : ((((_b477)._parent9)._right8)._height10))) ? (((((_b477)._parent9)._left7) == null) ? (-1) : ((((_b477)._parent9)._left7)._height10)) : (((((_b477)._parent9)._right8) == null) ? (-1) : ((((_b477)._parent9)._right8)._height10)));
                    } else {
                        (this)._root1 = _b477;
                    }
                }
                /* rotate (_cursor474)._left7 */
                var _a524 = _cursor474;
                var _b525 = (_a524)._left7;
                var _c526 = (_b525)._right8;
                /* replace _a524 with _b525 in (_a524)._parent9 */
                if (!(((_a524)._parent9) == null)) {
                    if ((((_a524)._parent9)._left7) == (_a524)) {
                        ((_a524)._parent9)._left7 = _b525;
                    } else {
                        ((_a524)._parent9)._right8 = _b525;
                    }
                }
                if (!((_b525) == null)) {
                    (_b525)._parent9 = (_a524)._parent9;
                }
                /* replace _c526 with _a524 in _b525 */
                (_b525)._right8 = _a524;
                if (!((_a524) == null)) {
                    (_a524)._parent9 = _b525;
                }
                /* replace _b525 with _c526 in _a524 */
                (_a524)._left7 = _c526;
                if (!((_c526) == null)) {
                    (_c526)._parent9 = _a524;
                }
                /* _min_ax12 is min of ax1 */
                var _augval527 = (_a524).ax1;
                var _child528 = (_a524)._left7;
                if (!((_child528) == null)) {
                    var _val529 = (_child528)._min_ax12;
                    _augval527 = ((_augval527) < (_val529)) ? (_augval527) : (_val529);
                }
                var _child530 = (_a524)._right8;
                if (!((_child530) == null)) {
                    var _val531 = (_child530)._min_ax12;
                    _augval527 = ((_augval527) < (_val531)) ? (_augval527) : (_val531);
                }
                (_a524)._min_ax12 = _augval527;
                /* _min_ay13 is min of ay1 */
                var _augval532 = (_a524).ay1;
                var _child533 = (_a524)._left7;
                if (!((_child533) == null)) {
                    var _val534 = (_child533)._min_ay13;
                    _augval532 = ((_augval532) < (_val534)) ? (_augval532) : (_val534);
                }
                var _child535 = (_a524)._right8;
                if (!((_child535) == null)) {
                    var _val536 = (_child535)._min_ay13;
                    _augval532 = ((_augval532) < (_val536)) ? (_augval532) : (_val536);
                }
                (_a524)._min_ay13 = _augval532;
                /* _max_ay24 is max of ay2 */
                var _augval537 = (_a524).ay2;
                var _child538 = (_a524)._left7;
                if (!((_child538) == null)) {
                    var _val539 = (_child538)._max_ay24;
                    _augval537 = ((_augval537) < (_val539)) ? (_val539) : (_augval537);
                }
                var _child540 = (_a524)._right8;
                if (!((_child540) == null)) {
                    var _val541 = (_child540)._max_ay24;
                    _augval537 = ((_augval537) < (_val541)) ? (_val541) : (_augval537);
                }
                (_a524)._max_ay24 = _augval537;
                (_a524)._height10 = 1 + ((((((_a524)._left7) == null) ? (-1) : (((_a524)._left7)._height10)) > ((((_a524)._right8) == null) ? (-1) : (((_a524)._right8)._height10))) ? ((((_a524)._left7) == null) ? (-1) : (((_a524)._left7)._height10)) : ((((_a524)._right8) == null) ? (-1) : (((_a524)._right8)._height10)));
                /* _min_ax12 is min of ax1 */
                var _augval542 = (_b525).ax1;
                var _child543 = (_b525)._left7;
                if (!((_child543) == null)) {
                    var _val544 = (_child543)._min_ax12;
                    _augval542 = ((_augval542) < (_val544)) ? (_augval542) : (_val544);
                }
                var _child545 = (_b525)._right8;
                if (!((_child545) == null)) {
                    var _val546 = (_child545)._min_ax12;
                    _augval542 = ((_augval542) < (_val546)) ? (_augval542) : (_val546);
                }
                (_b525)._min_ax12 = _augval542;
                /* _min_ay13 is min of ay1 */
                var _augval547 = (_b525).ay1;
                var _child548 = (_b525)._left7;
                if (!((_child548) == null)) {
                    var _val549 = (_child548)._min_ay13;
                    _augval547 = ((_augval547) < (_val549)) ? (_augval547) : (_val549);
                }
                var _child550 = (_b525)._right8;
                if (!((_child550) == null)) {
                    var _val551 = (_child550)._min_ay13;
                    _augval547 = ((_augval547) < (_val551)) ? (_augval547) : (_val551);
                }
                (_b525)._min_ay13 = _augval547;
                /* _max_ay24 is max of ay2 */
                var _augval552 = (_b525).ay2;
                var _child553 = (_b525)._left7;
                if (!((_child553) == null)) {
                    var _val554 = (_child553)._max_ay24;
                    _augval552 = ((_augval552) < (_val554)) ? (_val554) : (_augval552);
                }
                var _child555 = (_b525)._right8;
                if (!((_child555) == null)) {
                    var _val556 = (_child555)._max_ay24;
                    _augval552 = ((_augval552) < (_val556)) ? (_val556) : (_augval552);
                }
                (_b525)._max_ay24 = _augval552;
                (_b525)._height10 = 1 + ((((((_b525)._left7) == null) ? (-1) : (((_b525)._left7)._height10)) > ((((_b525)._right8) == null) ? (-1) : (((_b525)._right8)._height10))) ? ((((_b525)._left7) == null) ? (-1) : (((_b525)._left7)._height10)) : ((((_b525)._right8) == null) ? (-1) : (((_b525)._right8)._height10)));
                if (!(((_b525)._parent9) == null)) {
                    /* _min_ax12 is min of ax1 */
                    var _augval557 = ((_b525)._parent9).ax1;
                    var _child558 = ((_b525)._parent9)._left7;
                    if (!((_child558) == null)) {
                        var _val559 = (_child558)._min_ax12;
                        _augval557 = ((_augval557) < (_val559)) ? (_augval557) : (_val559);
                    }
                    var _child560 = ((_b525)._parent9)._right8;
                    if (!((_child560) == null)) {
                        var _val561 = (_child560)._min_ax12;
                        _augval557 = ((_augval557) < (_val561)) ? (_augval557) : (_val561);
                    }
                    ((_b525)._parent9)._min_ax12 = _augval557;
                    /* _min_ay13 is min of ay1 */
                    var _augval562 = ((_b525)._parent9).ay1;
                    var _child563 = ((_b525)._parent9)._left7;
                    if (!((_child563) == null)) {
                        var _val564 = (_child563)._min_ay13;
                        _augval562 = ((_augval562) < (_val564)) ? (_augval562) : (_val564);
                    }
                    var _child565 = ((_b525)._parent9)._right8;
                    if (!((_child565) == null)) {
                        var _val566 = (_child565)._min_ay13;
                        _augval562 = ((_augval562) < (_val566)) ? (_augval562) : (_val566);
                    }
                    ((_b525)._parent9)._min_ay13 = _augval562;
                    /* _max_ay24 is max of ay2 */
                    var _augval567 = ((_b525)._parent9).ay2;
                    var _child568 = ((_b525)._parent9)._left7;
                    if (!((_child568) == null)) {
                        var _val569 = (_child568)._max_ay24;
                        _augval567 = ((_augval567) < (_val569)) ? (_val569) : (_augval567);
                    }
                    var _child570 = ((_b525)._parent9)._right8;
                    if (!((_child570) == null)) {
                        var _val571 = (_child570)._max_ay24;
                        _augval567 = ((_augval567) < (_val571)) ? (_val571) : (_augval567);
                    }
                    ((_b525)._parent9)._max_ay24 = _augval567;
                    ((_b525)._parent9)._height10 = 1 + (((((((_b525)._parent9)._left7) == null) ? (-1) : ((((_b525)._parent9)._left7)._height10)) > (((((_b525)._parent9)._right8) == null) ? (-1) : ((((_b525)._parent9)._right8)._height10))) ? (((((_b525)._parent9)._left7) == null) ? (-1) : ((((_b525)._parent9)._left7)._height10)) : (((((_b525)._parent9)._right8) == null) ? (-1) : ((((_b525)._parent9)._right8)._height10)));
                } else {
                    (this)._root1 = _b525;
                }
                _cursor474 = (_cursor474)._parent9;
            } else if ((_imbalance475) < (-1)) {
                if ((((((_cursor474)._right8)._left7) == null) ? (-1) : ((((_cursor474)._right8)._left7)._height10)) > (((((_cursor474)._right8)._right8) == null) ? (-1) : ((((_cursor474)._right8)._right8)._height10))) {
                    /* rotate ((_cursor474)._right8)._left7 */
                    var _a572 = (_cursor474)._right8;
                    var _b573 = (_a572)._left7;
                    var _c574 = (_b573)._right8;
                    /* replace _a572 with _b573 in (_a572)._parent9 */
                    if (!(((_a572)._parent9) == null)) {
                        if ((((_a572)._parent9)._left7) == (_a572)) {
                            ((_a572)._parent9)._left7 = _b573;
                        } else {
                            ((_a572)._parent9)._right8 = _b573;
                        }
                    }
                    if (!((_b573) == null)) {
                        (_b573)._parent9 = (_a572)._parent9;
                    }
                    /* replace _c574 with _a572 in _b573 */
                    (_b573)._right8 = _a572;
                    if (!((_a572) == null)) {
                        (_a572)._parent9 = _b573;
                    }
                    /* replace _b573 with _c574 in _a572 */
                    (_a572)._left7 = _c574;
                    if (!((_c574) == null)) {
                        (_c574)._parent9 = _a572;
                    }
                    /* _min_ax12 is min of ax1 */
                    var _augval575 = (_a572).ax1;
                    var _child576 = (_a572)._left7;
                    if (!((_child576) == null)) {
                        var _val577 = (_child576)._min_ax12;
                        _augval575 = ((_augval575) < (_val577)) ? (_augval575) : (_val577);
                    }
                    var _child578 = (_a572)._right8;
                    if (!((_child578) == null)) {
                        var _val579 = (_child578)._min_ax12;
                        _augval575 = ((_augval575) < (_val579)) ? (_augval575) : (_val579);
                    }
                    (_a572)._min_ax12 = _augval575;
                    /* _min_ay13 is min of ay1 */
                    var _augval580 = (_a572).ay1;
                    var _child581 = (_a572)._left7;
                    if (!((_child581) == null)) {
                        var _val582 = (_child581)._min_ay13;
                        _augval580 = ((_augval580) < (_val582)) ? (_augval580) : (_val582);
                    }
                    var _child583 = (_a572)._right8;
                    if (!((_child583) == null)) {
                        var _val584 = (_child583)._min_ay13;
                        _augval580 = ((_augval580) < (_val584)) ? (_augval580) : (_val584);
                    }
                    (_a572)._min_ay13 = _augval580;
                    /* _max_ay24 is max of ay2 */
                    var _augval585 = (_a572).ay2;
                    var _child586 = (_a572)._left7;
                    if (!((_child586) == null)) {
                        var _val587 = (_child586)._max_ay24;
                        _augval585 = ((_augval585) < (_val587)) ? (_val587) : (_augval585);
                    }
                    var _child588 = (_a572)._right8;
                    if (!((_child588) == null)) {
                        var _val589 = (_child588)._max_ay24;
                        _augval585 = ((_augval585) < (_val589)) ? (_val589) : (_augval585);
                    }
                    (_a572)._max_ay24 = _augval585;
                    (_a572)._height10 = 1 + ((((((_a572)._left7) == null) ? (-1) : (((_a572)._left7)._height10)) > ((((_a572)._right8) == null) ? (-1) : (((_a572)._right8)._height10))) ? ((((_a572)._left7) == null) ? (-1) : (((_a572)._left7)._height10)) : ((((_a572)._right8) == null) ? (-1) : (((_a572)._right8)._height10)));
                    /* _min_ax12 is min of ax1 */
                    var _augval590 = (_b573).ax1;
                    var _child591 = (_b573)._left7;
                    if (!((_child591) == null)) {
                        var _val592 = (_child591)._min_ax12;
                        _augval590 = ((_augval590) < (_val592)) ? (_augval590) : (_val592);
                    }
                    var _child593 = (_b573)._right8;
                    if (!((_child593) == null)) {
                        var _val594 = (_child593)._min_ax12;
                        _augval590 = ((_augval590) < (_val594)) ? (_augval590) : (_val594);
                    }
                    (_b573)._min_ax12 = _augval590;
                    /* _min_ay13 is min of ay1 */
                    var _augval595 = (_b573).ay1;
                    var _child596 = (_b573)._left7;
                    if (!((_child596) == null)) {
                        var _val597 = (_child596)._min_ay13;
                        _augval595 = ((_augval595) < (_val597)) ? (_augval595) : (_val597);
                    }
                    var _child598 = (_b573)._right8;
                    if (!((_child598) == null)) {
                        var _val599 = (_child598)._min_ay13;
                        _augval595 = ((_augval595) < (_val599)) ? (_augval595) : (_val599);
                    }
                    (_b573)._min_ay13 = _augval595;
                    /* _max_ay24 is max of ay2 */
                    var _augval600 = (_b573).ay2;
                    var _child601 = (_b573)._left7;
                    if (!((_child601) == null)) {
                        var _val602 = (_child601)._max_ay24;
                        _augval600 = ((_augval600) < (_val602)) ? (_val602) : (_augval600);
                    }
                    var _child603 = (_b573)._right8;
                    if (!((_child603) == null)) {
                        var _val604 = (_child603)._max_ay24;
                        _augval600 = ((_augval600) < (_val604)) ? (_val604) : (_augval600);
                    }
                    (_b573)._max_ay24 = _augval600;
                    (_b573)._height10 = 1 + ((((((_b573)._left7) == null) ? (-1) : (((_b573)._left7)._height10)) > ((((_b573)._right8) == null) ? (-1) : (((_b573)._right8)._height10))) ? ((((_b573)._left7) == null) ? (-1) : (((_b573)._left7)._height10)) : ((((_b573)._right8) == null) ? (-1) : (((_b573)._right8)._height10)));
                    if (!(((_b573)._parent9) == null)) {
                        /* _min_ax12 is min of ax1 */
                        var _augval605 = ((_b573)._parent9).ax1;
                        var _child606 = ((_b573)._parent9)._left7;
                        if (!((_child606) == null)) {
                            var _val607 = (_child606)._min_ax12;
                            _augval605 = ((_augval605) < (_val607)) ? (_augval605) : (_val607);
                        }
                        var _child608 = ((_b573)._parent9)._right8;
                        if (!((_child608) == null)) {
                            var _val609 = (_child608)._min_ax12;
                            _augval605 = ((_augval605) < (_val609)) ? (_augval605) : (_val609);
                        }
                        ((_b573)._parent9)._min_ax12 = _augval605;
                        /* _min_ay13 is min of ay1 */
                        var _augval610 = ((_b573)._parent9).ay1;
                        var _child611 = ((_b573)._parent9)._left7;
                        if (!((_child611) == null)) {
                            var _val612 = (_child611)._min_ay13;
                            _augval610 = ((_augval610) < (_val612)) ? (_augval610) : (_val612);
                        }
                        var _child613 = ((_b573)._parent9)._right8;
                        if (!((_child613) == null)) {
                            var _val614 = (_child613)._min_ay13;
                            _augval610 = ((_augval610) < (_val614)) ? (_augval610) : (_val614);
                        }
                        ((_b573)._parent9)._min_ay13 = _augval610;
                        /* _max_ay24 is max of ay2 */
                        var _augval615 = ((_b573)._parent9).ay2;
                        var _child616 = ((_b573)._parent9)._left7;
                        if (!((_child616) == null)) {
                            var _val617 = (_child616)._max_ay24;
                            _augval615 = ((_augval615) < (_val617)) ? (_val617) : (_augval615);
                        }
                        var _child618 = ((_b573)._parent9)._right8;
                        if (!((_child618) == null)) {
                            var _val619 = (_child618)._max_ay24;
                            _augval615 = ((_augval615) < (_val619)) ? (_val619) : (_augval615);
                        }
                        ((_b573)._parent9)._max_ay24 = _augval615;
                        ((_b573)._parent9)._height10 = 1 + (((((((_b573)._parent9)._left7) == null) ? (-1) : ((((_b573)._parent9)._left7)._height10)) > (((((_b573)._parent9)._right8) == null) ? (-1) : ((((_b573)._parent9)._right8)._height10))) ? (((((_b573)._parent9)._left7) == null) ? (-1) : ((((_b573)._parent9)._left7)._height10)) : (((((_b573)._parent9)._right8) == null) ? (-1) : ((((_b573)._parent9)._right8)._height10)));
                    } else {
                        (this)._root1 = _b573;
                    }
                }
                /* rotate (_cursor474)._right8 */
                var _a620 = _cursor474;
                var _b621 = (_a620)._right8;
                var _c622 = (_b621)._left7;
                /* replace _a620 with _b621 in (_a620)._parent9 */
                if (!(((_a620)._parent9) == null)) {
                    if ((((_a620)._parent9)._left7) == (_a620)) {
                        ((_a620)._parent9)._left7 = _b621;
                    } else {
                        ((_a620)._parent9)._right8 = _b621;
                    }
                }
                if (!((_b621) == null)) {
                    (_b621)._parent9 = (_a620)._parent9;
                }
                /* replace _c622 with _a620 in _b621 */
                (_b621)._left7 = _a620;
                if (!((_a620) == null)) {
                    (_a620)._parent9 = _b621;
                }
                /* replace _b621 with _c622 in _a620 */
                (_a620)._right8 = _c622;
                if (!((_c622) == null)) {
                    (_c622)._parent9 = _a620;
                }
                /* _min_ax12 is min of ax1 */
                var _augval623 = (_a620).ax1;
                var _child624 = (_a620)._left7;
                if (!((_child624) == null)) {
                    var _val625 = (_child624)._min_ax12;
                    _augval623 = ((_augval623) < (_val625)) ? (_augval623) : (_val625);
                }
                var _child626 = (_a620)._right8;
                if (!((_child626) == null)) {
                    var _val627 = (_child626)._min_ax12;
                    _augval623 = ((_augval623) < (_val627)) ? (_augval623) : (_val627);
                }
                (_a620)._min_ax12 = _augval623;
                /* _min_ay13 is min of ay1 */
                var _augval628 = (_a620).ay1;
                var _child629 = (_a620)._left7;
                if (!((_child629) == null)) {
                    var _val630 = (_child629)._min_ay13;
                    _augval628 = ((_augval628) < (_val630)) ? (_augval628) : (_val630);
                }
                var _child631 = (_a620)._right8;
                if (!((_child631) == null)) {
                    var _val632 = (_child631)._min_ay13;
                    _augval628 = ((_augval628) < (_val632)) ? (_augval628) : (_val632);
                }
                (_a620)._min_ay13 = _augval628;
                /* _max_ay24 is max of ay2 */
                var _augval633 = (_a620).ay2;
                var _child634 = (_a620)._left7;
                if (!((_child634) == null)) {
                    var _val635 = (_child634)._max_ay24;
                    _augval633 = ((_augval633) < (_val635)) ? (_val635) : (_augval633);
                }
                var _child636 = (_a620)._right8;
                if (!((_child636) == null)) {
                    var _val637 = (_child636)._max_ay24;
                    _augval633 = ((_augval633) < (_val637)) ? (_val637) : (_augval633);
                }
                (_a620)._max_ay24 = _augval633;
                (_a620)._height10 = 1 + ((((((_a620)._left7) == null) ? (-1) : (((_a620)._left7)._height10)) > ((((_a620)._right8) == null) ? (-1) : (((_a620)._right8)._height10))) ? ((((_a620)._left7) == null) ? (-1) : (((_a620)._left7)._height10)) : ((((_a620)._right8) == null) ? (-1) : (((_a620)._right8)._height10)));
                /* _min_ax12 is min of ax1 */
                var _augval638 = (_b621).ax1;
                var _child639 = (_b621)._left7;
                if (!((_child639) == null)) {
                    var _val640 = (_child639)._min_ax12;
                    _augval638 = ((_augval638) < (_val640)) ? (_augval638) : (_val640);
                }
                var _child641 = (_b621)._right8;
                if (!((_child641) == null)) {
                    var _val642 = (_child641)._min_ax12;
                    _augval638 = ((_augval638) < (_val642)) ? (_augval638) : (_val642);
                }
                (_b621)._min_ax12 = _augval638;
                /* _min_ay13 is min of ay1 */
                var _augval643 = (_b621).ay1;
                var _child644 = (_b621)._left7;
                if (!((_child644) == null)) {
                    var _val645 = (_child644)._min_ay13;
                    _augval643 = ((_augval643) < (_val645)) ? (_augval643) : (_val645);
                }
                var _child646 = (_b621)._right8;
                if (!((_child646) == null)) {
                    var _val647 = (_child646)._min_ay13;
                    _augval643 = ((_augval643) < (_val647)) ? (_augval643) : (_val647);
                }
                (_b621)._min_ay13 = _augval643;
                /* _max_ay24 is max of ay2 */
                var _augval648 = (_b621).ay2;
                var _child649 = (_b621)._left7;
                if (!((_child649) == null)) {
                    var _val650 = (_child649)._max_ay24;
                    _augval648 = ((_augval648) < (_val650)) ? (_val650) : (_augval648);
                }
                var _child651 = (_b621)._right8;
                if (!((_child651) == null)) {
                    var _val652 = (_child651)._max_ay24;
                    _augval648 = ((_augval648) < (_val652)) ? (_val652) : (_augval648);
                }
                (_b621)._max_ay24 = _augval648;
                (_b621)._height10 = 1 + ((((((_b621)._left7) == null) ? (-1) : (((_b621)._left7)._height10)) > ((((_b621)._right8) == null) ? (-1) : (((_b621)._right8)._height10))) ? ((((_b621)._left7) == null) ? (-1) : (((_b621)._left7)._height10)) : ((((_b621)._right8) == null) ? (-1) : (((_b621)._right8)._height10)));
                if (!(((_b621)._parent9) == null)) {
                    /* _min_ax12 is min of ax1 */
                    var _augval653 = ((_b621)._parent9).ax1;
                    var _child654 = ((_b621)._parent9)._left7;
                    if (!((_child654) == null)) {
                        var _val655 = (_child654)._min_ax12;
                        _augval653 = ((_augval653) < (_val655)) ? (_augval653) : (_val655);
                    }
                    var _child656 = ((_b621)._parent9)._right8;
                    if (!((_child656) == null)) {
                        var _val657 = (_child656)._min_ax12;
                        _augval653 = ((_augval653) < (_val657)) ? (_augval653) : (_val657);
                    }
                    ((_b621)._parent9)._min_ax12 = _augval653;
                    /* _min_ay13 is min of ay1 */
                    var _augval658 = ((_b621)._parent9).ay1;
                    var _child659 = ((_b621)._parent9)._left7;
                    if (!((_child659) == null)) {
                        var _val660 = (_child659)._min_ay13;
                        _augval658 = ((_augval658) < (_val660)) ? (_augval658) : (_val660);
                    }
                    var _child661 = ((_b621)._parent9)._right8;
                    if (!((_child661) == null)) {
                        var _val662 = (_child661)._min_ay13;
                        _augval658 = ((_augval658) < (_val662)) ? (_augval658) : (_val662);
                    }
                    ((_b621)._parent9)._min_ay13 = _augval658;
                    /* _max_ay24 is max of ay2 */
                    var _augval663 = ((_b621)._parent9).ay2;
                    var _child664 = ((_b621)._parent9)._left7;
                    if (!((_child664) == null)) {
                        var _val665 = (_child664)._max_ay24;
                        _augval663 = ((_augval663) < (_val665)) ? (_val665) : (_augval663);
                    }
                    var _child666 = ((_b621)._parent9)._right8;
                    if (!((_child666) == null)) {
                        var _val667 = (_child666)._max_ay24;
                        _augval663 = ((_augval663) < (_val667)) ? (_val667) : (_augval663);
                    }
                    ((_b621)._parent9)._max_ay24 = _augval663;
                    ((_b621)._parent9)._height10 = 1 + (((((((_b621)._parent9)._left7) == null) ? (-1) : ((((_b621)._parent9)._left7)._height10)) > (((((_b621)._parent9)._right8) == null) ? (-1) : ((((_b621)._parent9)._right8)._height10))) ? (((((_b621)._parent9)._left7) == null) ? (-1) : ((((_b621)._parent9)._left7)._height10)) : (((((_b621)._parent9)._right8) == null) ? (-1) : ((((_b621)._parent9)._right8)._height10)));
                } else {
                    (this)._root1 = _b621;
                }
                _cursor474 = (_cursor474)._parent9;
            }
        }
        (__x).ax2 = new_val;
    }
}
RectangleHolder.prototype.updateAy2 = function (__x, new_val) {
    if ((__x).ay2 != new_val) {
        /* _max_ay24 is max of ay2 */
        var _augval668 = new_val;
        var _child669 = (__x)._left7;
        if (!((_child669) == null)) {
            var _val670 = (_child669)._max_ay24;
            _augval668 = ((_augval668) < (_val670)) ? (_val670) : (_augval668);
        }
        var _child671 = (__x)._right8;
        if (!((_child671) == null)) {
            var _val672 = (_child671)._max_ay24;
            _augval668 = ((_augval668) < (_val672)) ? (_val672) : (_augval668);
        }
        (__x)._max_ay24 = _augval668;
        var _cursor673 = (__x)._parent9;
        var _changed674 = true;
        while ((_changed674) && (!((_cursor673) == (null)))) {
            var _old__max_ay24675 = (_cursor673)._max_ay24;
            var _old_height676 = (_cursor673)._height10;
            /* _max_ay24 is max of ay2 */
            var _augval677 = (_cursor673).ay2;
            var _child678 = (_cursor673)._left7;
            if (!((_child678) == null)) {
                var _val679 = (_child678)._max_ay24;
                _augval677 = ((_augval677) < (_val679)) ? (_val679) : (_augval677);
            }
            var _child680 = (_cursor673)._right8;
            if (!((_child680) == null)) {
                var _val681 = (_child680)._max_ay24;
                _augval677 = ((_augval677) < (_val681)) ? (_val681) : (_augval677);
            }
            (_cursor673)._max_ay24 = _augval677;
            (_cursor673)._height10 = 1 + ((((((_cursor673)._left7) == null) ? (-1) : (((_cursor673)._left7)._height10)) > ((((_cursor673)._right8) == null) ? (-1) : (((_cursor673)._right8)._height10))) ? ((((_cursor673)._left7) == null) ? (-1) : (((_cursor673)._left7)._height10)) : ((((_cursor673)._right8) == null) ? (-1) : (((_cursor673)._right8)._height10)));
            _changed674 = false;
            _changed674 = (_changed674) || (!((_old__max_ay24675) == ((_cursor673)._max_ay24)));
            _changed674 = (_changed674) || (!((_old_height676) == ((_cursor673)._height10)));
            _cursor673 = (_cursor673)._parent9;
        }
        (__x).ay2 = new_val;
    }
}
RectangleHolder.prototype.update = function (__x, ax1, ay1, ax2, ay2) {
    var _parent682 = (__x)._parent9;
    var _left683 = (__x)._left7;
    var _right684 = (__x)._right8;
    var _new_x685;
    if (((_left683) == null) && ((_right684) == null)) {
        _new_x685 = null;
        /* replace __x with _new_x685 in _parent682 */
        if (!((_parent682) == null)) {
            if (((_parent682)._left7) == (__x)) {
                (_parent682)._left7 = _new_x685;
            } else {
                (_parent682)._right8 = _new_x685;
            }
        }
        if (!((_new_x685) == null)) {
            (_new_x685)._parent9 = _parent682;
        }
    } else if ((!((_left683) == null)) && ((_right684) == null)) {
        _new_x685 = _left683;
        /* replace __x with _new_x685 in _parent682 */
        if (!((_parent682) == null)) {
            if (((_parent682)._left7) == (__x)) {
                (_parent682)._left7 = _new_x685;
            } else {
                (_parent682)._right8 = _new_x685;
            }
        }
        if (!((_new_x685) == null)) {
            (_new_x685)._parent9 = _parent682;
        }
    } else if (((_left683) == null) && (!((_right684) == null))) {
        _new_x685 = _right684;
        /* replace __x with _new_x685 in _parent682 */
        if (!((_parent682) == null)) {
            if (((_parent682)._left7) == (__x)) {
                (_parent682)._left7 = _new_x685;
            } else {
                (_parent682)._right8 = _new_x685;
            }
        }
        if (!((_new_x685) == null)) {
            (_new_x685)._parent9 = _parent682;
        }
    } else {
        var _root686 = (__x)._right8;
        var _x687 = _root686;
        var _descend688 = true;
        var _from_left689 = true;
        while (true) {
            if ((_x687) == null) {
                _x687 = null;
                break;
            }
            if (_descend688) {
                /* too small? */
                if (false) {
                    if ((!(((_x687)._right8) == null)) && (true)) {
                        if ((_x687) == (_root686)) {
                            _root686 = (_x687)._right8;
                        }
                        _x687 = (_x687)._right8;
                    } else if ((_x687) == (_root686)) {
                        _x687 = null;
                        break;
                    } else {
                        _descend688 = false;
                        _from_left689 = (!(((_x687)._parent9) == null)) && ((_x687) == (((_x687)._parent9)._left7));
                        _x687 = (_x687)._parent9;
                    }
                } else if ((!(((_x687)._left7) == null)) && (true)) {
                    _x687 = (_x687)._left7;
                    /* too large? */
                } else if (false) {
                    if ((_x687) == (_root686)) {
                        _x687 = null;
                        break;
                    } else {
                        _descend688 = false;
                        _from_left689 = (!(((_x687)._parent9) == null)) && ((_x687) == (((_x687)._parent9)._left7));
                        _x687 = (_x687)._parent9;
                    }
                    /* node ok? */
                } else if (true) {
                    break;
                } else if ((_x687) == (_root686)) {
                    _root686 = (_x687)._right8;
                    _x687 = (_x687)._right8;
                } else {
                    if ((!(((_x687)._right8) == null)) && (true)) {
                        if ((_x687) == (_root686)) {
                            _root686 = (_x687)._right8;
                        }
                        _x687 = (_x687)._right8;
                    } else {
                        _descend688 = false;
                        _from_left689 = (!(((_x687)._parent9) == null)) && ((_x687) == (((_x687)._parent9)._left7));
                        _x687 = (_x687)._parent9;
                    }
                }
            } else if (_from_left689) {
                if (false) {
                    _x687 = null;
                    break;
                } else if (true) {
                    break;
                } else if ((!(((_x687)._right8) == null)) && (true)) {
                    _descend688 = true;
                    if ((_x687) == (_root686)) {
                        _root686 = (_x687)._right8;
                    }
                    _x687 = (_x687)._right8;
                } else if ((_x687) == (_root686)) {
                    _x687 = null;
                    break;
                } else {
                    _descend688 = false;
                    _from_left689 = (!(((_x687)._parent9) == null)) && ((_x687) == (((_x687)._parent9)._left7));
                    _x687 = (_x687)._parent9;
                }
            } else {
                if ((_x687) == (_root686)) {
                    _x687 = null;
                    break;
                } else {
                    _descend688 = false;
                    _from_left689 = (!(((_x687)._parent9) == null)) && ((_x687) == (((_x687)._parent9)._left7));
                    _x687 = (_x687)._parent9;
                }
            }
        }
        _new_x685 = _x687;
        var _mp690 = (_x687)._parent9;
        var _mr691 = (_x687)._right8;
        /* replace _x687 with _mr691 in _mp690 */
        if (!((_mp690) == null)) {
            if (((_mp690)._left7) == (_x687)) {
                (_mp690)._left7 = _mr691;
            } else {
                (_mp690)._right8 = _mr691;
            }
        }
        if (!((_mr691) == null)) {
            (_mr691)._parent9 = _mp690;
        }
        /* replace __x with _x687 in _parent682 */
        if (!((_parent682) == null)) {
            if (((_parent682)._left7) == (__x)) {
                (_parent682)._left7 = _x687;
            } else {
                (_parent682)._right8 = _x687;
            }
        }
        if (!((_x687) == null)) {
            (_x687)._parent9 = _parent682;
        }
        /* replace null with _left683 in _x687 */
        (_x687)._left7 = _left683;
        if (!((_left683) == null)) {
            (_left683)._parent9 = _x687;
        }
        /* replace _mr691 with (__x)._right8 in _x687 */
        (_x687)._right8 = (__x)._right8;
        if (!(((__x)._right8) == null)) {
            ((__x)._right8)._parent9 = _x687;
        }
        /* _min_ax12 is min of ax1 */
        var _augval692 = (_x687).ax1;
        var _child693 = (_x687)._left7;
        if (!((_child693) == null)) {
            var _val694 = (_child693)._min_ax12;
            _augval692 = ((_augval692) < (_val694)) ? (_augval692) : (_val694);
        }
        var _child695 = (_x687)._right8;
        if (!((_child695) == null)) {
            var _val696 = (_child695)._min_ax12;
            _augval692 = ((_augval692) < (_val696)) ? (_augval692) : (_val696);
        }
        (_x687)._min_ax12 = _augval692;
        /* _min_ay13 is min of ay1 */
        var _augval697 = (_x687).ay1;
        var _child698 = (_x687)._left7;
        if (!((_child698) == null)) {
            var _val699 = (_child698)._min_ay13;
            _augval697 = ((_augval697) < (_val699)) ? (_augval697) : (_val699);
        }
        var _child700 = (_x687)._right8;
        if (!((_child700) == null)) {
            var _val701 = (_child700)._min_ay13;
            _augval697 = ((_augval697) < (_val701)) ? (_augval697) : (_val701);
        }
        (_x687)._min_ay13 = _augval697;
        /* _max_ay24 is max of ay2 */
        var _augval702 = (_x687).ay2;
        var _child703 = (_x687)._left7;
        if (!((_child703) == null)) {
            var _val704 = (_child703)._max_ay24;
            _augval702 = ((_augval702) < (_val704)) ? (_val704) : (_augval702);
        }
        var _child705 = (_x687)._right8;
        if (!((_child705) == null)) {
            var _val706 = (_child705)._max_ay24;
            _augval702 = ((_augval702) < (_val706)) ? (_val706) : (_augval702);
        }
        (_x687)._max_ay24 = _augval702;
        (_x687)._height10 = 1 + ((((((_x687)._left7) == null) ? (-1) : (((_x687)._left7)._height10)) > ((((_x687)._right8) == null) ? (-1) : (((_x687)._right8)._height10))) ? ((((_x687)._left7) == null) ? (-1) : (((_x687)._left7)._height10)) : ((((_x687)._right8) == null) ? (-1) : (((_x687)._right8)._height10)));
        var _cursor707 = _mp690;
        var _changed708 = true;
        while ((_changed708) && (!((_cursor707) == (_parent682)))) {
            var _old__min_ax12709 = (_cursor707)._min_ax12;
            var _old__min_ay13710 = (_cursor707)._min_ay13;
            var _old__max_ay24711 = (_cursor707)._max_ay24;
            var _old_height712 = (_cursor707)._height10;
            /* _min_ax12 is min of ax1 */
            var _augval713 = (_cursor707).ax1;
            var _child714 = (_cursor707)._left7;
            if (!((_child714) == null)) {
                var _val715 = (_child714)._min_ax12;
                _augval713 = ((_augval713) < (_val715)) ? (_augval713) : (_val715);
            }
            var _child716 = (_cursor707)._right8;
            if (!((_child716) == null)) {
                var _val717 = (_child716)._min_ax12;
                _augval713 = ((_augval713) < (_val717)) ? (_augval713) : (_val717);
            }
            (_cursor707)._min_ax12 = _augval713;
            /* _min_ay13 is min of ay1 */
            var _augval718 = (_cursor707).ay1;
            var _child719 = (_cursor707)._left7;
            if (!((_child719) == null)) {
                var _val720 = (_child719)._min_ay13;
                _augval718 = ((_augval718) < (_val720)) ? (_augval718) : (_val720);
            }
            var _child721 = (_cursor707)._right8;
            if (!((_child721) == null)) {
                var _val722 = (_child721)._min_ay13;
                _augval718 = ((_augval718) < (_val722)) ? (_augval718) : (_val722);
            }
            (_cursor707)._min_ay13 = _augval718;
            /* _max_ay24 is max of ay2 */
            var _augval723 = (_cursor707).ay2;
            var _child724 = (_cursor707)._left7;
            if (!((_child724) == null)) {
                var _val725 = (_child724)._max_ay24;
                _augval723 = ((_augval723) < (_val725)) ? (_val725) : (_augval723);
            }
            var _child726 = (_cursor707)._right8;
            if (!((_child726) == null)) {
                var _val727 = (_child726)._max_ay24;
                _augval723 = ((_augval723) < (_val727)) ? (_val727) : (_augval723);
            }
            (_cursor707)._max_ay24 = _augval723;
            (_cursor707)._height10 = 1 + ((((((_cursor707)._left7) == null) ? (-1) : (((_cursor707)._left7)._height10)) > ((((_cursor707)._right8) == null) ? (-1) : (((_cursor707)._right8)._height10))) ? ((((_cursor707)._left7) == null) ? (-1) : (((_cursor707)._left7)._height10)) : ((((_cursor707)._right8) == null) ? (-1) : (((_cursor707)._right8)._height10)));
            _changed708 = false;
            _changed708 = (_changed708) || (!((_old__min_ax12709) == ((_cursor707)._min_ax12)));
            _changed708 = (_changed708) || (!((_old__min_ay13710) == ((_cursor707)._min_ay13)));
            _changed708 = (_changed708) || (!((_old__max_ay24711) == ((_cursor707)._max_ay24)));
            _changed708 = (_changed708) || (!((_old_height712) == ((_cursor707)._height10)));
            _cursor707 = (_cursor707)._parent9;
        }
    }
    var _cursor728 = _parent682;
    var _changed729 = true;
    while ((_changed729) && (!((_cursor728) == (null)))) {
        var _old__min_ax12730 = (_cursor728)._min_ax12;
        var _old__min_ay13731 = (_cursor728)._min_ay13;
        var _old__max_ay24732 = (_cursor728)._max_ay24;
        var _old_height733 = (_cursor728)._height10;
        /* _min_ax12 is min of ax1 */
        var _augval734 = (_cursor728).ax1;
        var _child735 = (_cursor728)._left7;
        if (!((_child735) == null)) {
            var _val736 = (_child735)._min_ax12;
            _augval734 = ((_augval734) < (_val736)) ? (_augval734) : (_val736);
        }
        var _child737 = (_cursor728)._right8;
        if (!((_child737) == null)) {
            var _val738 = (_child737)._min_ax12;
            _augval734 = ((_augval734) < (_val738)) ? (_augval734) : (_val738);
        }
        (_cursor728)._min_ax12 = _augval734;
        /* _min_ay13 is min of ay1 */
        var _augval739 = (_cursor728).ay1;
        var _child740 = (_cursor728)._left7;
        if (!((_child740) == null)) {
            var _val741 = (_child740)._min_ay13;
            _augval739 = ((_augval739) < (_val741)) ? (_augval739) : (_val741);
        }
        var _child742 = (_cursor728)._right8;
        if (!((_child742) == null)) {
            var _val743 = (_child742)._min_ay13;
            _augval739 = ((_augval739) < (_val743)) ? (_augval739) : (_val743);
        }
        (_cursor728)._min_ay13 = _augval739;
        /* _max_ay24 is max of ay2 */
        var _augval744 = (_cursor728).ay2;
        var _child745 = (_cursor728)._left7;
        if (!((_child745) == null)) {
            var _val746 = (_child745)._max_ay24;
            _augval744 = ((_augval744) < (_val746)) ? (_val746) : (_augval744);
        }
        var _child747 = (_cursor728)._right8;
        if (!((_child747) == null)) {
            var _val748 = (_child747)._max_ay24;
            _augval744 = ((_augval744) < (_val748)) ? (_val748) : (_augval744);
        }
        (_cursor728)._max_ay24 = _augval744;
        (_cursor728)._height10 = 1 + ((((((_cursor728)._left7) == null) ? (-1) : (((_cursor728)._left7)._height10)) > ((((_cursor728)._right8) == null) ? (-1) : (((_cursor728)._right8)._height10))) ? ((((_cursor728)._left7) == null) ? (-1) : (((_cursor728)._left7)._height10)) : ((((_cursor728)._right8) == null) ? (-1) : (((_cursor728)._right8)._height10)));
        _changed729 = false;
        _changed729 = (_changed729) || (!((_old__min_ax12730) == ((_cursor728)._min_ax12)));
        _changed729 = (_changed729) || (!((_old__min_ay13731) == ((_cursor728)._min_ay13)));
        _changed729 = (_changed729) || (!((_old__max_ay24732) == ((_cursor728)._max_ay24)));
        _changed729 = (_changed729) || (!((_old_height733) == ((_cursor728)._height10)));
        _cursor728 = (_cursor728)._parent9;
    }
    if (((this)._root1) == (__x)) {
        (this)._root1 = _new_x685;
    }
    (__x)._left7 = null;
    (__x)._right8 = null;
    (__x)._min_ax12 = (__x).ax1;
    (__x)._min_ay13 = (__x).ay1;
    (__x)._max_ay24 = (__x).ay2;
    (__x)._height10 = 0;
    var _previous749 = null;
    var _current750 = (this)._root1;
    var _is_left751 = false;
    while (!((_current750) == null)) {
        _previous749 = _current750;
        if ((ax2) < ((_current750).ax2)) {
            _current750 = (_current750)._left7;
            _is_left751 = true;
        } else {
            _current750 = (_current750)._right8;
            _is_left751 = false;
        }
    }
    if ((_previous749) == null) {
        (this)._root1 = __x;
    } else {
        (__x)._parent9 = _previous749;
        if (_is_left751) {
            (_previous749)._left7 = __x;
        } else {
            (_previous749)._right8 = __x;
        }
    }
    var _cursor752 = (__x)._parent9;
    var _changed753 = true;
    while ((_changed753) && (!((_cursor752) == (null)))) {
        var _old__min_ax12754 = (_cursor752)._min_ax12;
        var _old__min_ay13755 = (_cursor752)._min_ay13;
        var _old__max_ay24756 = (_cursor752)._max_ay24;
        var _old_height757 = (_cursor752)._height10;
        /* _min_ax12 is min of ax1 */
        var _augval758 = (_cursor752).ax1;
        var _child759 = (_cursor752)._left7;
        if (!((_child759) == null)) {
            var _val760 = (_child759)._min_ax12;
            _augval758 = ((_augval758) < (_val760)) ? (_augval758) : (_val760);
        }
        var _child761 = (_cursor752)._right8;
        if (!((_child761) == null)) {
            var _val762 = (_child761)._min_ax12;
            _augval758 = ((_augval758) < (_val762)) ? (_augval758) : (_val762);
        }
        (_cursor752)._min_ax12 = _augval758;
        /* _min_ay13 is min of ay1 */
        var _augval763 = (_cursor752).ay1;
        var _child764 = (_cursor752)._left7;
        if (!((_child764) == null)) {
            var _val765 = (_child764)._min_ay13;
            _augval763 = ((_augval763) < (_val765)) ? (_augval763) : (_val765);
        }
        var _child766 = (_cursor752)._right8;
        if (!((_child766) == null)) {
            var _val767 = (_child766)._min_ay13;
            _augval763 = ((_augval763) < (_val767)) ? (_augval763) : (_val767);
        }
        (_cursor752)._min_ay13 = _augval763;
        /* _max_ay24 is max of ay2 */
        var _augval768 = (_cursor752).ay2;
        var _child769 = (_cursor752)._left7;
        if (!((_child769) == null)) {
            var _val770 = (_child769)._max_ay24;
            _augval768 = ((_augval768) < (_val770)) ? (_val770) : (_augval768);
        }
        var _child771 = (_cursor752)._right8;
        if (!((_child771) == null)) {
            var _val772 = (_child771)._max_ay24;
            _augval768 = ((_augval768) < (_val772)) ? (_val772) : (_augval768);
        }
        (_cursor752)._max_ay24 = _augval768;
        (_cursor752)._height10 = 1 + ((((((_cursor752)._left7) == null) ? (-1) : (((_cursor752)._left7)._height10)) > ((((_cursor752)._right8) == null) ? (-1) : (((_cursor752)._right8)._height10))) ? ((((_cursor752)._left7) == null) ? (-1) : (((_cursor752)._left7)._height10)) : ((((_cursor752)._right8) == null) ? (-1) : (((_cursor752)._right8)._height10)));
        _changed753 = false;
        _changed753 = (_changed753) || (!((_old__min_ax12754) == ((_cursor752)._min_ax12)));
        _changed753 = (_changed753) || (!((_old__min_ay13755) == ((_cursor752)._min_ay13)));
        _changed753 = (_changed753) || (!((_old__max_ay24756) == ((_cursor752)._max_ay24)));
        _changed753 = (_changed753) || (!((_old_height757) == ((_cursor752)._height10)));
        _cursor752 = (_cursor752)._parent9;
    }
    /* rebalance AVL tree */
    var _cursor773 = __x;
    var _imbalance774;
    while (!(((_cursor773)._parent9) == null)) {
        _cursor773 = (_cursor773)._parent9;
        (_cursor773)._height10 = 1 + ((((((_cursor773)._left7) == null) ? (-1) : (((_cursor773)._left7)._height10)) > ((((_cursor773)._right8) == null) ? (-1) : (((_cursor773)._right8)._height10))) ? ((((_cursor773)._left7) == null) ? (-1) : (((_cursor773)._left7)._height10)) : ((((_cursor773)._right8) == null) ? (-1) : (((_cursor773)._right8)._height10)));
        _imbalance774 = ((((_cursor773)._left7) == null) ? (-1) : (((_cursor773)._left7)._height10)) - ((((_cursor773)._right8) == null) ? (-1) : (((_cursor773)._right8)._height10));
        if ((_imbalance774) > (1)) {
            if ((((((_cursor773)._left7)._left7) == null) ? (-1) : ((((_cursor773)._left7)._left7)._height10)) < (((((_cursor773)._left7)._right8) == null) ? (-1) : ((((_cursor773)._left7)._right8)._height10))) {
                /* rotate ((_cursor773)._left7)._right8 */
                var _a775 = (_cursor773)._left7;
                var _b776 = (_a775)._right8;
                var _c777 = (_b776)._left7;
                /* replace _a775 with _b776 in (_a775)._parent9 */
                if (!(((_a775)._parent9) == null)) {
                    if ((((_a775)._parent9)._left7) == (_a775)) {
                        ((_a775)._parent9)._left7 = _b776;
                    } else {
                        ((_a775)._parent9)._right8 = _b776;
                    }
                }
                if (!((_b776) == null)) {
                    (_b776)._parent9 = (_a775)._parent9;
                }
                /* replace _c777 with _a775 in _b776 */
                (_b776)._left7 = _a775;
                if (!((_a775) == null)) {
                    (_a775)._parent9 = _b776;
                }
                /* replace _b776 with _c777 in _a775 */
                (_a775)._right8 = _c777;
                if (!((_c777) == null)) {
                    (_c777)._parent9 = _a775;
                }
                /* _min_ax12 is min of ax1 */
                var _augval778 = (_a775).ax1;
                var _child779 = (_a775)._left7;
                if (!((_child779) == null)) {
                    var _val780 = (_child779)._min_ax12;
                    _augval778 = ((_augval778) < (_val780)) ? (_augval778) : (_val780);
                }
                var _child781 = (_a775)._right8;
                if (!((_child781) == null)) {
                    var _val782 = (_child781)._min_ax12;
                    _augval778 = ((_augval778) < (_val782)) ? (_augval778) : (_val782);
                }
                (_a775)._min_ax12 = _augval778;
                /* _min_ay13 is min of ay1 */
                var _augval783 = (_a775).ay1;
                var _child784 = (_a775)._left7;
                if (!((_child784) == null)) {
                    var _val785 = (_child784)._min_ay13;
                    _augval783 = ((_augval783) < (_val785)) ? (_augval783) : (_val785);
                }
                var _child786 = (_a775)._right8;
                if (!((_child786) == null)) {
                    var _val787 = (_child786)._min_ay13;
                    _augval783 = ((_augval783) < (_val787)) ? (_augval783) : (_val787);
                }
                (_a775)._min_ay13 = _augval783;
                /* _max_ay24 is max of ay2 */
                var _augval788 = (_a775).ay2;
                var _child789 = (_a775)._left7;
                if (!((_child789) == null)) {
                    var _val790 = (_child789)._max_ay24;
                    _augval788 = ((_augval788) < (_val790)) ? (_val790) : (_augval788);
                }
                var _child791 = (_a775)._right8;
                if (!((_child791) == null)) {
                    var _val792 = (_child791)._max_ay24;
                    _augval788 = ((_augval788) < (_val792)) ? (_val792) : (_augval788);
                }
                (_a775)._max_ay24 = _augval788;
                (_a775)._height10 = 1 + ((((((_a775)._left7) == null) ? (-1) : (((_a775)._left7)._height10)) > ((((_a775)._right8) == null) ? (-1) : (((_a775)._right8)._height10))) ? ((((_a775)._left7) == null) ? (-1) : (((_a775)._left7)._height10)) : ((((_a775)._right8) == null) ? (-1) : (((_a775)._right8)._height10)));
                /* _min_ax12 is min of ax1 */
                var _augval793 = (_b776).ax1;
                var _child794 = (_b776)._left7;
                if (!((_child794) == null)) {
                    var _val795 = (_child794)._min_ax12;
                    _augval793 = ((_augval793) < (_val795)) ? (_augval793) : (_val795);
                }
                var _child796 = (_b776)._right8;
                if (!((_child796) == null)) {
                    var _val797 = (_child796)._min_ax12;
                    _augval793 = ((_augval793) < (_val797)) ? (_augval793) : (_val797);
                }
                (_b776)._min_ax12 = _augval793;
                /* _min_ay13 is min of ay1 */
                var _augval798 = (_b776).ay1;
                var _child799 = (_b776)._left7;
                if (!((_child799) == null)) {
                    var _val800 = (_child799)._min_ay13;
                    _augval798 = ((_augval798) < (_val800)) ? (_augval798) : (_val800);
                }
                var _child801 = (_b776)._right8;
                if (!((_child801) == null)) {
                    var _val802 = (_child801)._min_ay13;
                    _augval798 = ((_augval798) < (_val802)) ? (_augval798) : (_val802);
                }
                (_b776)._min_ay13 = _augval798;
                /* _max_ay24 is max of ay2 */
                var _augval803 = (_b776).ay2;
                var _child804 = (_b776)._left7;
                if (!((_child804) == null)) {
                    var _val805 = (_child804)._max_ay24;
                    _augval803 = ((_augval803) < (_val805)) ? (_val805) : (_augval803);
                }
                var _child806 = (_b776)._right8;
                if (!((_child806) == null)) {
                    var _val807 = (_child806)._max_ay24;
                    _augval803 = ((_augval803) < (_val807)) ? (_val807) : (_augval803);
                }
                (_b776)._max_ay24 = _augval803;
                (_b776)._height10 = 1 + ((((((_b776)._left7) == null) ? (-1) : (((_b776)._left7)._height10)) > ((((_b776)._right8) == null) ? (-1) : (((_b776)._right8)._height10))) ? ((((_b776)._left7) == null) ? (-1) : (((_b776)._left7)._height10)) : ((((_b776)._right8) == null) ? (-1) : (((_b776)._right8)._height10)));
                if (!(((_b776)._parent9) == null)) {
                    /* _min_ax12 is min of ax1 */
                    var _augval808 = ((_b776)._parent9).ax1;
                    var _child809 = ((_b776)._parent9)._left7;
                    if (!((_child809) == null)) {
                        var _val810 = (_child809)._min_ax12;
                        _augval808 = ((_augval808) < (_val810)) ? (_augval808) : (_val810);
                    }
                    var _child811 = ((_b776)._parent9)._right8;
                    if (!((_child811) == null)) {
                        var _val812 = (_child811)._min_ax12;
                        _augval808 = ((_augval808) < (_val812)) ? (_augval808) : (_val812);
                    }
                    ((_b776)._parent9)._min_ax12 = _augval808;
                    /* _min_ay13 is min of ay1 */
                    var _augval813 = ((_b776)._parent9).ay1;
                    var _child814 = ((_b776)._parent9)._left7;
                    if (!((_child814) == null)) {
                        var _val815 = (_child814)._min_ay13;
                        _augval813 = ((_augval813) < (_val815)) ? (_augval813) : (_val815);
                    }
                    var _child816 = ((_b776)._parent9)._right8;
                    if (!((_child816) == null)) {
                        var _val817 = (_child816)._min_ay13;
                        _augval813 = ((_augval813) < (_val817)) ? (_augval813) : (_val817);
                    }
                    ((_b776)._parent9)._min_ay13 = _augval813;
                    /* _max_ay24 is max of ay2 */
                    var _augval818 = ((_b776)._parent9).ay2;
                    var _child819 = ((_b776)._parent9)._left7;
                    if (!((_child819) == null)) {
                        var _val820 = (_child819)._max_ay24;
                        _augval818 = ((_augval818) < (_val820)) ? (_val820) : (_augval818);
                    }
                    var _child821 = ((_b776)._parent9)._right8;
                    if (!((_child821) == null)) {
                        var _val822 = (_child821)._max_ay24;
                        _augval818 = ((_augval818) < (_val822)) ? (_val822) : (_augval818);
                    }
                    ((_b776)._parent9)._max_ay24 = _augval818;
                    ((_b776)._parent9)._height10 = 1 + (((((((_b776)._parent9)._left7) == null) ? (-1) : ((((_b776)._parent9)._left7)._height10)) > (((((_b776)._parent9)._right8) == null) ? (-1) : ((((_b776)._parent9)._right8)._height10))) ? (((((_b776)._parent9)._left7) == null) ? (-1) : ((((_b776)._parent9)._left7)._height10)) : (((((_b776)._parent9)._right8) == null) ? (-1) : ((((_b776)._parent9)._right8)._height10)));
                } else {
                    (this)._root1 = _b776;
                }
            }
            /* rotate (_cursor773)._left7 */
            var _a823 = _cursor773;
            var _b824 = (_a823)._left7;
            var _c825 = (_b824)._right8;
            /* replace _a823 with _b824 in (_a823)._parent9 */
            if (!(((_a823)._parent9) == null)) {
                if ((((_a823)._parent9)._left7) == (_a823)) {
                    ((_a823)._parent9)._left7 = _b824;
                } else {
                    ((_a823)._parent9)._right8 = _b824;
                }
            }
            if (!((_b824) == null)) {
                (_b824)._parent9 = (_a823)._parent9;
            }
            /* replace _c825 with _a823 in _b824 */
            (_b824)._right8 = _a823;
            if (!((_a823) == null)) {
                (_a823)._parent9 = _b824;
            }
            /* replace _b824 with _c825 in _a823 */
            (_a823)._left7 = _c825;
            if (!((_c825) == null)) {
                (_c825)._parent9 = _a823;
            }
            /* _min_ax12 is min of ax1 */
            var _augval826 = (_a823).ax1;
            var _child827 = (_a823)._left7;
            if (!((_child827) == null)) {
                var _val828 = (_child827)._min_ax12;
                _augval826 = ((_augval826) < (_val828)) ? (_augval826) : (_val828);
            }
            var _child829 = (_a823)._right8;
            if (!((_child829) == null)) {
                var _val830 = (_child829)._min_ax12;
                _augval826 = ((_augval826) < (_val830)) ? (_augval826) : (_val830);
            }
            (_a823)._min_ax12 = _augval826;
            /* _min_ay13 is min of ay1 */
            var _augval831 = (_a823).ay1;
            var _child832 = (_a823)._left7;
            if (!((_child832) == null)) {
                var _val833 = (_child832)._min_ay13;
                _augval831 = ((_augval831) < (_val833)) ? (_augval831) : (_val833);
            }
            var _child834 = (_a823)._right8;
            if (!((_child834) == null)) {
                var _val835 = (_child834)._min_ay13;
                _augval831 = ((_augval831) < (_val835)) ? (_augval831) : (_val835);
            }
            (_a823)._min_ay13 = _augval831;
            /* _max_ay24 is max of ay2 */
            var _augval836 = (_a823).ay2;
            var _child837 = (_a823)._left7;
            if (!((_child837) == null)) {
                var _val838 = (_child837)._max_ay24;
                _augval836 = ((_augval836) < (_val838)) ? (_val838) : (_augval836);
            }
            var _child839 = (_a823)._right8;
            if (!((_child839) == null)) {
                var _val840 = (_child839)._max_ay24;
                _augval836 = ((_augval836) < (_val840)) ? (_val840) : (_augval836);
            }
            (_a823)._max_ay24 = _augval836;
            (_a823)._height10 = 1 + ((((((_a823)._left7) == null) ? (-1) : (((_a823)._left7)._height10)) > ((((_a823)._right8) == null) ? (-1) : (((_a823)._right8)._height10))) ? ((((_a823)._left7) == null) ? (-1) : (((_a823)._left7)._height10)) : ((((_a823)._right8) == null) ? (-1) : (((_a823)._right8)._height10)));
            /* _min_ax12 is min of ax1 */
            var _augval841 = (_b824).ax1;
            var _child842 = (_b824)._left7;
            if (!((_child842) == null)) {
                var _val843 = (_child842)._min_ax12;
                _augval841 = ((_augval841) < (_val843)) ? (_augval841) : (_val843);
            }
            var _child844 = (_b824)._right8;
            if (!((_child844) == null)) {
                var _val845 = (_child844)._min_ax12;
                _augval841 = ((_augval841) < (_val845)) ? (_augval841) : (_val845);
            }
            (_b824)._min_ax12 = _augval841;
            /* _min_ay13 is min of ay1 */
            var _augval846 = (_b824).ay1;
            var _child847 = (_b824)._left7;
            if (!((_child847) == null)) {
                var _val848 = (_child847)._min_ay13;
                _augval846 = ((_augval846) < (_val848)) ? (_augval846) : (_val848);
            }
            var _child849 = (_b824)._right8;
            if (!((_child849) == null)) {
                var _val850 = (_child849)._min_ay13;
                _augval846 = ((_augval846) < (_val850)) ? (_augval846) : (_val850);
            }
            (_b824)._min_ay13 = _augval846;
            /* _max_ay24 is max of ay2 */
            var _augval851 = (_b824).ay2;
            var _child852 = (_b824)._left7;
            if (!((_child852) == null)) {
                var _val853 = (_child852)._max_ay24;
                _augval851 = ((_augval851) < (_val853)) ? (_val853) : (_augval851);
            }
            var _child854 = (_b824)._right8;
            if (!((_child854) == null)) {
                var _val855 = (_child854)._max_ay24;
                _augval851 = ((_augval851) < (_val855)) ? (_val855) : (_augval851);
            }
            (_b824)._max_ay24 = _augval851;
            (_b824)._height10 = 1 + ((((((_b824)._left7) == null) ? (-1) : (((_b824)._left7)._height10)) > ((((_b824)._right8) == null) ? (-1) : (((_b824)._right8)._height10))) ? ((((_b824)._left7) == null) ? (-1) : (((_b824)._left7)._height10)) : ((((_b824)._right8) == null) ? (-1) : (((_b824)._right8)._height10)));
            if (!(((_b824)._parent9) == null)) {
                /* _min_ax12 is min of ax1 */
                var _augval856 = ((_b824)._parent9).ax1;
                var _child857 = ((_b824)._parent9)._left7;
                if (!((_child857) == null)) {
                    var _val858 = (_child857)._min_ax12;
                    _augval856 = ((_augval856) < (_val858)) ? (_augval856) : (_val858);
                }
                var _child859 = ((_b824)._parent9)._right8;
                if (!((_child859) == null)) {
                    var _val860 = (_child859)._min_ax12;
                    _augval856 = ((_augval856) < (_val860)) ? (_augval856) : (_val860);
                }
                ((_b824)._parent9)._min_ax12 = _augval856;
                /* _min_ay13 is min of ay1 */
                var _augval861 = ((_b824)._parent9).ay1;
                var _child862 = ((_b824)._parent9)._left7;
                if (!((_child862) == null)) {
                    var _val863 = (_child862)._min_ay13;
                    _augval861 = ((_augval861) < (_val863)) ? (_augval861) : (_val863);
                }
                var _child864 = ((_b824)._parent9)._right8;
                if (!((_child864) == null)) {
                    var _val865 = (_child864)._min_ay13;
                    _augval861 = ((_augval861) < (_val865)) ? (_augval861) : (_val865);
                }
                ((_b824)._parent9)._min_ay13 = _augval861;
                /* _max_ay24 is max of ay2 */
                var _augval866 = ((_b824)._parent9).ay2;
                var _child867 = ((_b824)._parent9)._left7;
                if (!((_child867) == null)) {
                    var _val868 = (_child867)._max_ay24;
                    _augval866 = ((_augval866) < (_val868)) ? (_val868) : (_augval866);
                }
                var _child869 = ((_b824)._parent9)._right8;
                if (!((_child869) == null)) {
                    var _val870 = (_child869)._max_ay24;
                    _augval866 = ((_augval866) < (_val870)) ? (_val870) : (_augval866);
                }
                ((_b824)._parent9)._max_ay24 = _augval866;
                ((_b824)._parent9)._height10 = 1 + (((((((_b824)._parent9)._left7) == null) ? (-1) : ((((_b824)._parent9)._left7)._height10)) > (((((_b824)._parent9)._right8) == null) ? (-1) : ((((_b824)._parent9)._right8)._height10))) ? (((((_b824)._parent9)._left7) == null) ? (-1) : ((((_b824)._parent9)._left7)._height10)) : (((((_b824)._parent9)._right8) == null) ? (-1) : ((((_b824)._parent9)._right8)._height10)));
            } else {
                (this)._root1 = _b824;
            }
            _cursor773 = (_cursor773)._parent9;
        } else if ((_imbalance774) < (-1)) {
            if ((((((_cursor773)._right8)._left7) == null) ? (-1) : ((((_cursor773)._right8)._left7)._height10)) > (((((_cursor773)._right8)._right8) == null) ? (-1) : ((((_cursor773)._right8)._right8)._height10))) {
                /* rotate ((_cursor773)._right8)._left7 */
                var _a871 = (_cursor773)._right8;
                var _b872 = (_a871)._left7;
                var _c873 = (_b872)._right8;
                /* replace _a871 with _b872 in (_a871)._parent9 */
                if (!(((_a871)._parent9) == null)) {
                    if ((((_a871)._parent9)._left7) == (_a871)) {
                        ((_a871)._parent9)._left7 = _b872;
                    } else {
                        ((_a871)._parent9)._right8 = _b872;
                    }
                }
                if (!((_b872) == null)) {
                    (_b872)._parent9 = (_a871)._parent9;
                }
                /* replace _c873 with _a871 in _b872 */
                (_b872)._right8 = _a871;
                if (!((_a871) == null)) {
                    (_a871)._parent9 = _b872;
                }
                /* replace _b872 with _c873 in _a871 */
                (_a871)._left7 = _c873;
                if (!((_c873) == null)) {
                    (_c873)._parent9 = _a871;
                }
                /* _min_ax12 is min of ax1 */
                var _augval874 = (_a871).ax1;
                var _child875 = (_a871)._left7;
                if (!((_child875) == null)) {
                    var _val876 = (_child875)._min_ax12;
                    _augval874 = ((_augval874) < (_val876)) ? (_augval874) : (_val876);
                }
                var _child877 = (_a871)._right8;
                if (!((_child877) == null)) {
                    var _val878 = (_child877)._min_ax12;
                    _augval874 = ((_augval874) < (_val878)) ? (_augval874) : (_val878);
                }
                (_a871)._min_ax12 = _augval874;
                /* _min_ay13 is min of ay1 */
                var _augval879 = (_a871).ay1;
                var _child880 = (_a871)._left7;
                if (!((_child880) == null)) {
                    var _val881 = (_child880)._min_ay13;
                    _augval879 = ((_augval879) < (_val881)) ? (_augval879) : (_val881);
                }
                var _child882 = (_a871)._right8;
                if (!((_child882) == null)) {
                    var _val883 = (_child882)._min_ay13;
                    _augval879 = ((_augval879) < (_val883)) ? (_augval879) : (_val883);
                }
                (_a871)._min_ay13 = _augval879;
                /* _max_ay24 is max of ay2 */
                var _augval884 = (_a871).ay2;
                var _child885 = (_a871)._left7;
                if (!((_child885) == null)) {
                    var _val886 = (_child885)._max_ay24;
                    _augval884 = ((_augval884) < (_val886)) ? (_val886) : (_augval884);
                }
                var _child887 = (_a871)._right8;
                if (!((_child887) == null)) {
                    var _val888 = (_child887)._max_ay24;
                    _augval884 = ((_augval884) < (_val888)) ? (_val888) : (_augval884);
                }
                (_a871)._max_ay24 = _augval884;
                (_a871)._height10 = 1 + ((((((_a871)._left7) == null) ? (-1) : (((_a871)._left7)._height10)) > ((((_a871)._right8) == null) ? (-1) : (((_a871)._right8)._height10))) ? ((((_a871)._left7) == null) ? (-1) : (((_a871)._left7)._height10)) : ((((_a871)._right8) == null) ? (-1) : (((_a871)._right8)._height10)));
                /* _min_ax12 is min of ax1 */
                var _augval889 = (_b872).ax1;
                var _child890 = (_b872)._left7;
                if (!((_child890) == null)) {
                    var _val891 = (_child890)._min_ax12;
                    _augval889 = ((_augval889) < (_val891)) ? (_augval889) : (_val891);
                }
                var _child892 = (_b872)._right8;
                if (!((_child892) == null)) {
                    var _val893 = (_child892)._min_ax12;
                    _augval889 = ((_augval889) < (_val893)) ? (_augval889) : (_val893);
                }
                (_b872)._min_ax12 = _augval889;
                /* _min_ay13 is min of ay1 */
                var _augval894 = (_b872).ay1;
                var _child895 = (_b872)._left7;
                if (!((_child895) == null)) {
                    var _val896 = (_child895)._min_ay13;
                    _augval894 = ((_augval894) < (_val896)) ? (_augval894) : (_val896);
                }
                var _child897 = (_b872)._right8;
                if (!((_child897) == null)) {
                    var _val898 = (_child897)._min_ay13;
                    _augval894 = ((_augval894) < (_val898)) ? (_augval894) : (_val898);
                }
                (_b872)._min_ay13 = _augval894;
                /* _max_ay24 is max of ay2 */
                var _augval899 = (_b872).ay2;
                var _child900 = (_b872)._left7;
                if (!((_child900) == null)) {
                    var _val901 = (_child900)._max_ay24;
                    _augval899 = ((_augval899) < (_val901)) ? (_val901) : (_augval899);
                }
                var _child902 = (_b872)._right8;
                if (!((_child902) == null)) {
                    var _val903 = (_child902)._max_ay24;
                    _augval899 = ((_augval899) < (_val903)) ? (_val903) : (_augval899);
                }
                (_b872)._max_ay24 = _augval899;
                (_b872)._height10 = 1 + ((((((_b872)._left7) == null) ? (-1) : (((_b872)._left7)._height10)) > ((((_b872)._right8) == null) ? (-1) : (((_b872)._right8)._height10))) ? ((((_b872)._left7) == null) ? (-1) : (((_b872)._left7)._height10)) : ((((_b872)._right8) == null) ? (-1) : (((_b872)._right8)._height10)));
                if (!(((_b872)._parent9) == null)) {
                    /* _min_ax12 is min of ax1 */
                    var _augval904 = ((_b872)._parent9).ax1;
                    var _child905 = ((_b872)._parent9)._left7;
                    if (!((_child905) == null)) {
                        var _val906 = (_child905)._min_ax12;
                        _augval904 = ((_augval904) < (_val906)) ? (_augval904) : (_val906);
                    }
                    var _child907 = ((_b872)._parent9)._right8;
                    if (!((_child907) == null)) {
                        var _val908 = (_child907)._min_ax12;
                        _augval904 = ((_augval904) < (_val908)) ? (_augval904) : (_val908);
                    }
                    ((_b872)._parent9)._min_ax12 = _augval904;
                    /* _min_ay13 is min of ay1 */
                    var _augval909 = ((_b872)._parent9).ay1;
                    var _child910 = ((_b872)._parent9)._left7;
                    if (!((_child910) == null)) {
                        var _val911 = (_child910)._min_ay13;
                        _augval909 = ((_augval909) < (_val911)) ? (_augval909) : (_val911);
                    }
                    var _child912 = ((_b872)._parent9)._right8;
                    if (!((_child912) == null)) {
                        var _val913 = (_child912)._min_ay13;
                        _augval909 = ((_augval909) < (_val913)) ? (_augval909) : (_val913);
                    }
                    ((_b872)._parent9)._min_ay13 = _augval909;
                    /* _max_ay24 is max of ay2 */
                    var _augval914 = ((_b872)._parent9).ay2;
                    var _child915 = ((_b872)._parent9)._left7;
                    if (!((_child915) == null)) {
                        var _val916 = (_child915)._max_ay24;
                        _augval914 = ((_augval914) < (_val916)) ? (_val916) : (_augval914);
                    }
                    var _child917 = ((_b872)._parent9)._right8;
                    if (!((_child917) == null)) {
                        var _val918 = (_child917)._max_ay24;
                        _augval914 = ((_augval914) < (_val918)) ? (_val918) : (_augval914);
                    }
                    ((_b872)._parent9)._max_ay24 = _augval914;
                    ((_b872)._parent9)._height10 = 1 + (((((((_b872)._parent9)._left7) == null) ? (-1) : ((((_b872)._parent9)._left7)._height10)) > (((((_b872)._parent9)._right8) == null) ? (-1) : ((((_b872)._parent9)._right8)._height10))) ? (((((_b872)._parent9)._left7) == null) ? (-1) : ((((_b872)._parent9)._left7)._height10)) : (((((_b872)._parent9)._right8) == null) ? (-1) : ((((_b872)._parent9)._right8)._height10)));
                } else {
                    (this)._root1 = _b872;
                }
            }
            /* rotate (_cursor773)._right8 */
            var _a919 = _cursor773;
            var _b920 = (_a919)._right8;
            var _c921 = (_b920)._left7;
            /* replace _a919 with _b920 in (_a919)._parent9 */
            if (!(((_a919)._parent9) == null)) {
                if ((((_a919)._parent9)._left7) == (_a919)) {
                    ((_a919)._parent9)._left7 = _b920;
                } else {
                    ((_a919)._parent9)._right8 = _b920;
                }
            }
            if (!((_b920) == null)) {
                (_b920)._parent9 = (_a919)._parent9;
            }
            /* replace _c921 with _a919 in _b920 */
            (_b920)._left7 = _a919;
            if (!((_a919) == null)) {
                (_a919)._parent9 = _b920;
            }
            /* replace _b920 with _c921 in _a919 */
            (_a919)._right8 = _c921;
            if (!((_c921) == null)) {
                (_c921)._parent9 = _a919;
            }
            /* _min_ax12 is min of ax1 */
            var _augval922 = (_a919).ax1;
            var _child923 = (_a919)._left7;
            if (!((_child923) == null)) {
                var _val924 = (_child923)._min_ax12;
                _augval922 = ((_augval922) < (_val924)) ? (_augval922) : (_val924);
            }
            var _child925 = (_a919)._right8;
            if (!((_child925) == null)) {
                var _val926 = (_child925)._min_ax12;
                _augval922 = ((_augval922) < (_val926)) ? (_augval922) : (_val926);
            }
            (_a919)._min_ax12 = _augval922;
            /* _min_ay13 is min of ay1 */
            var _augval927 = (_a919).ay1;
            var _child928 = (_a919)._left7;
            if (!((_child928) == null)) {
                var _val929 = (_child928)._min_ay13;
                _augval927 = ((_augval927) < (_val929)) ? (_augval927) : (_val929);
            }
            var _child930 = (_a919)._right8;
            if (!((_child930) == null)) {
                var _val931 = (_child930)._min_ay13;
                _augval927 = ((_augval927) < (_val931)) ? (_augval927) : (_val931);
            }
            (_a919)._min_ay13 = _augval927;
            /* _max_ay24 is max of ay2 */
            var _augval932 = (_a919).ay2;
            var _child933 = (_a919)._left7;
            if (!((_child933) == null)) {
                var _val934 = (_child933)._max_ay24;
                _augval932 = ((_augval932) < (_val934)) ? (_val934) : (_augval932);
            }
            var _child935 = (_a919)._right8;
            if (!((_child935) == null)) {
                var _val936 = (_child935)._max_ay24;
                _augval932 = ((_augval932) < (_val936)) ? (_val936) : (_augval932);
            }
            (_a919)._max_ay24 = _augval932;
            (_a919)._height10 = 1 + ((((((_a919)._left7) == null) ? (-1) : (((_a919)._left7)._height10)) > ((((_a919)._right8) == null) ? (-1) : (((_a919)._right8)._height10))) ? ((((_a919)._left7) == null) ? (-1) : (((_a919)._left7)._height10)) : ((((_a919)._right8) == null) ? (-1) : (((_a919)._right8)._height10)));
            /* _min_ax12 is min of ax1 */
            var _augval937 = (_b920).ax1;
            var _child938 = (_b920)._left7;
            if (!((_child938) == null)) {
                var _val939 = (_child938)._min_ax12;
                _augval937 = ((_augval937) < (_val939)) ? (_augval937) : (_val939);
            }
            var _child940 = (_b920)._right8;
            if (!((_child940) == null)) {
                var _val941 = (_child940)._min_ax12;
                _augval937 = ((_augval937) < (_val941)) ? (_augval937) : (_val941);
            }
            (_b920)._min_ax12 = _augval937;
            /* _min_ay13 is min of ay1 */
            var _augval942 = (_b920).ay1;
            var _child943 = (_b920)._left7;
            if (!((_child943) == null)) {
                var _val944 = (_child943)._min_ay13;
                _augval942 = ((_augval942) < (_val944)) ? (_augval942) : (_val944);
            }
            var _child945 = (_b920)._right8;
            if (!((_child945) == null)) {
                var _val946 = (_child945)._min_ay13;
                _augval942 = ((_augval942) < (_val946)) ? (_augval942) : (_val946);
            }
            (_b920)._min_ay13 = _augval942;
            /* _max_ay24 is max of ay2 */
            var _augval947 = (_b920).ay2;
            var _child948 = (_b920)._left7;
            if (!((_child948) == null)) {
                var _val949 = (_child948)._max_ay24;
                _augval947 = ((_augval947) < (_val949)) ? (_val949) : (_augval947);
            }
            var _child950 = (_b920)._right8;
            if (!((_child950) == null)) {
                var _val951 = (_child950)._max_ay24;
                _augval947 = ((_augval947) < (_val951)) ? (_val951) : (_augval947);
            }
            (_b920)._max_ay24 = _augval947;
            (_b920)._height10 = 1 + ((((((_b920)._left7) == null) ? (-1) : (((_b920)._left7)._height10)) > ((((_b920)._right8) == null) ? (-1) : (((_b920)._right8)._height10))) ? ((((_b920)._left7) == null) ? (-1) : (((_b920)._left7)._height10)) : ((((_b920)._right8) == null) ? (-1) : (((_b920)._right8)._height10)));
            if (!(((_b920)._parent9) == null)) {
                /* _min_ax12 is min of ax1 */
                var _augval952 = ((_b920)._parent9).ax1;
                var _child953 = ((_b920)._parent9)._left7;
                if (!((_child953) == null)) {
                    var _val954 = (_child953)._min_ax12;
                    _augval952 = ((_augval952) < (_val954)) ? (_augval952) : (_val954);
                }
                var _child955 = ((_b920)._parent9)._right8;
                if (!((_child955) == null)) {
                    var _val956 = (_child955)._min_ax12;
                    _augval952 = ((_augval952) < (_val956)) ? (_augval952) : (_val956);
                }
                ((_b920)._parent9)._min_ax12 = _augval952;
                /* _min_ay13 is min of ay1 */
                var _augval957 = ((_b920)._parent9).ay1;
                var _child958 = ((_b920)._parent9)._left7;
                if (!((_child958) == null)) {
                    var _val959 = (_child958)._min_ay13;
                    _augval957 = ((_augval957) < (_val959)) ? (_augval957) : (_val959);
                }
                var _child960 = ((_b920)._parent9)._right8;
                if (!((_child960) == null)) {
                    var _val961 = (_child960)._min_ay13;
                    _augval957 = ((_augval957) < (_val961)) ? (_augval957) : (_val961);
                }
                ((_b920)._parent9)._min_ay13 = _augval957;
                /* _max_ay24 is max of ay2 */
                var _augval962 = ((_b920)._parent9).ay2;
                var _child963 = ((_b920)._parent9)._left7;
                if (!((_child963) == null)) {
                    var _val964 = (_child963)._max_ay24;
                    _augval962 = ((_augval962) < (_val964)) ? (_val964) : (_augval962);
                }
                var _child965 = ((_b920)._parent9)._right8;
                if (!((_child965) == null)) {
                    var _val966 = (_child965)._max_ay24;
                    _augval962 = ((_augval962) < (_val966)) ? (_val966) : (_augval962);
                }
                ((_b920)._parent9)._max_ay24 = _augval962;
                ((_b920)._parent9)._height10 = 1 + (((((((_b920)._parent9)._left7) == null) ? (-1) : ((((_b920)._parent9)._left7)._height10)) > (((((_b920)._parent9)._right8) == null) ? (-1) : ((((_b920)._parent9)._right8)._height10))) ? (((((_b920)._parent9)._left7) == null) ? (-1) : ((((_b920)._parent9)._left7)._height10)) : (((((_b920)._parent9)._right8) == null) ? (-1) : ((((_b920)._parent9)._right8)._height10)));
            } else {
                (this)._root1 = _b920;
            }
            _cursor773 = (_cursor773)._parent9;
        }
    }
    (__x).ax1 = ax1;
    (__x).ay1 = ay1;
    (__x).ax2 = ax2;
    (__x).ay2 = ay2;
}
RectangleHolder.prototype.findMatchingRectangles = function (bx1, by1, bx2, by2, __callback) {
    var _root967 = (this)._root1;
    var _x968 = _root967;
    var _descend969 = true;
    var _from_left970 = true;
    while (true) {
        if ((_x968) == null) {
            _x968 = null;
            break;
        }
        if (_descend969) {
            /* too small? */
            if ((false) || (((_x968).ax2) <= (bx1))) {
                if ((!(((_x968)._right8) == null)) && ((((true) && ((((_x968)._right8)._min_ax12) < (bx2))) && ((((_x968)._right8)._min_ay13) < (by2))) && ((((_x968)._right8)._max_ay24) > (by1)))) {
                    if ((_x968) == (_root967)) {
                        _root967 = (_x968)._right8;
                    }
                    _x968 = (_x968)._right8;
                } else if ((_x968) == (_root967)) {
                    _x968 = null;
                    break;
                } else {
                    _descend969 = false;
                    _from_left970 = (!(((_x968)._parent9) == null)) && ((_x968) == (((_x968)._parent9)._left7));
                    _x968 = (_x968)._parent9;
                }
            } else if ((!(((_x968)._left7) == null)) && ((((true) && ((((_x968)._left7)._min_ax12) < (bx2))) && ((((_x968)._left7)._min_ay13) < (by2))) && ((((_x968)._left7)._max_ay24) > (by1)))) {
                _x968 = (_x968)._left7;
                /* too large? */
            } else if (false) {
                if ((_x968) == (_root967)) {
                    _x968 = null;
                    break;
                } else {
                    _descend969 = false;
                    _from_left970 = (!(((_x968)._parent9) == null)) && ((_x968) == (((_x968)._parent9)._left7));
                    _x968 = (_x968)._parent9;
                }
                /* node ok? */
            } else if ((((true) && (((_x968).ax1) < (bx2))) && (((_x968).ay1) < (by2))) && (((_x968).ay2) > (by1))) {
                break;
            } else if ((_x968) == (_root967)) {
                _root967 = (_x968)._right8;
                _x968 = (_x968)._right8;
            } else {
                if ((!(((_x968)._right8) == null)) && ((((true) && ((((_x968)._right8)._min_ax12) < (bx2))) && ((((_x968)._right8)._min_ay13) < (by2))) && ((((_x968)._right8)._max_ay24) > (by1)))) {
                    if ((_x968) == (_root967)) {
                        _root967 = (_x968)._right8;
                    }
                    _x968 = (_x968)._right8;
                } else {
                    _descend969 = false;
                    _from_left970 = (!(((_x968)._parent9) == null)) && ((_x968) == (((_x968)._parent9)._left7));
                    _x968 = (_x968)._parent9;
                }
            }
        } else if (_from_left970) {
            if (false) {
                _x968 = null;
                break;
            } else if ((((true) && (((_x968).ax1) < (bx2))) && (((_x968).ay1) < (by2))) && (((_x968).ay2) > (by1))) {
                break;
            } else if ((!(((_x968)._right8) == null)) && ((((true) && ((((_x968)._right8)._min_ax12) < (bx2))) && ((((_x968)._right8)._min_ay13) < (by2))) && ((((_x968)._right8)._max_ay24) > (by1)))) {
                _descend969 = true;
                if ((_x968) == (_root967)) {
                    _root967 = (_x968)._right8;
                }
                _x968 = (_x968)._right8;
            } else if ((_x968) == (_root967)) {
                _x968 = null;
                break;
            } else {
                _descend969 = false;
                _from_left970 = (!(((_x968)._parent9) == null)) && ((_x968) == (((_x968)._parent9)._left7));
                _x968 = (_x968)._parent9;
            }
        } else {
            if ((_x968) == (_root967)) {
                _x968 = null;
                break;
            } else {
                _descend969 = false;
                _from_left970 = (!(((_x968)._parent9) == null)) && ((_x968) == (((_x968)._parent9)._left7));
                _x968 = (_x968)._parent9;
            }
        }
    }
    var _prev_cursor5 = null;
    var _cursor6 = _x968;
    for (; ;) {
        if (!(!((_cursor6) == null))) break;
        var _name971 = _cursor6;
        /* ADVANCE */
        _prev_cursor5 = _cursor6;
        do {
            var _right_min972 = null;
            if ((!(((_cursor6)._right8) == null)) && ((((true) && ((((_cursor6)._right8)._min_ax12) < (bx2))) && ((((_cursor6)._right8)._min_ay13) < (by2))) && ((((_cursor6)._right8)._max_ay24) > (by1)))) {
                var _root973 = (_cursor6)._right8;
                var _x974 = _root973;
                var _descend975 = true;
                var _from_left976 = true;
                while (true) {
                    if ((_x974) == null) {
                        _x974 = null;
                        break;
                    }
                    if (_descend975) {
                        /* too small? */
                        if ((false) || (((_x974).ax2) <= (bx1))) {
                            if ((!(((_x974)._right8) == null)) && ((((true) && ((((_x974)._right8)._min_ax12) < (bx2))) && ((((_x974)._right8)._min_ay13) < (by2))) && ((((_x974)._right8)._max_ay24) > (by1)))) {
                                if ((_x974) == (_root973)) {
                                    _root973 = (_x974)._right8;
                                }
                                _x974 = (_x974)._right8;
                            } else if ((_x974) == (_root973)) {
                                _x974 = null;
                                break;
                            } else {
                                _descend975 = false;
                                _from_left976 = (!(((_x974)._parent9) == null)) && ((_x974) == (((_x974)._parent9)._left7));
                                _x974 = (_x974)._parent9;
                            }
                        } else if ((!(((_x974)._left7) == null)) && ((((true) && ((((_x974)._left7)._min_ax12) < (bx2))) && ((((_x974)._left7)._min_ay13) < (by2))) && ((((_x974)._left7)._max_ay24) > (by1)))) {
                            _x974 = (_x974)._left7;
                            /* too large? */
                        } else if (false) {
                            if ((_x974) == (_root973)) {
                                _x974 = null;
                                break;
                            } else {
                                _descend975 = false;
                                _from_left976 = (!(((_x974)._parent9) == null)) && ((_x974) == (((_x974)._parent9)._left7));
                                _x974 = (_x974)._parent9;
                            }
                            /* node ok? */
                        } else if ((((true) && (((_x974).ax1) < (bx2))) && (((_x974).ay1) < (by2))) && (((_x974).ay2) > (by1))) {
                            break;
                        } else if ((_x974) == (_root973)) {
                            _root973 = (_x974)._right8;
                            _x974 = (_x974)._right8;
                        } else {
                            if ((!(((_x974)._right8) == null)) && ((((true) && ((((_x974)._right8)._min_ax12) < (bx2))) && ((((_x974)._right8)._min_ay13) < (by2))) && ((((_x974)._right8)._max_ay24) > (by1)))) {
                                if ((_x974) == (_root973)) {
                                    _root973 = (_x974)._right8;
                                }
                                _x974 = (_x974)._right8;
                            } else {
                                _descend975 = false;
                                _from_left976 = (!(((_x974)._parent9) == null)) && ((_x974) == (((_x974)._parent9)._left7));
                                _x974 = (_x974)._parent9;
                            }
                        }
                    } else if (_from_left976) {
                        if (false) {
                            _x974 = null;
                            break;
                        } else if ((((true) && (((_x974).ax1) < (bx2))) && (((_x974).ay1) < (by2))) && (((_x974).ay2) > (by1))) {
                            break;
                        } else if ((!(((_x974)._right8) == null)) && ((((true) && ((((_x974)._right8)._min_ax12) < (bx2))) && ((((_x974)._right8)._min_ay13) < (by2))) && ((((_x974)._right8)._max_ay24) > (by1)))) {
                            _descend975 = true;
                            if ((_x974) == (_root973)) {
                                _root973 = (_x974)._right8;
                            }
                            _x974 = (_x974)._right8;
                        } else if ((_x974) == (_root973)) {
                            _x974 = null;
                            break;
                        } else {
                            _descend975 = false;
                            _from_left976 = (!(((_x974)._parent9) == null)) && ((_x974) == (((_x974)._parent9)._left7));
                            _x974 = (_x974)._parent9;
                        }
                    } else {
                        if ((_x974) == (_root973)) {
                            _x974 = null;
                            break;
                        } else {
                            _descend975 = false;
                            _from_left976 = (!(((_x974)._parent9) == null)) && ((_x974) == (((_x974)._parent9)._left7));
                            _x974 = (_x974)._parent9;
                        }
                    }
                }
                _right_min972 = _x974;
            }
            if (!((_right_min972) == null)) {
                _cursor6 = _right_min972;
                break;
            } else {
                while ((!(((_cursor6)._parent9) == null)) && ((_cursor6) == (((_cursor6)._parent9)._right8))) {
                    _cursor6 = (_cursor6)._parent9;
                }
                _cursor6 = (_cursor6)._parent9;
                if ((!((_cursor6) == null)) && (false)) {
                    _cursor6 = null;
                }
            }
        } while ((!((_cursor6) == null)) && (!((((true) && (((_cursor6).ax1) < (bx2))) && (((_cursor6).ay1) < (by2))) && (((_cursor6).ay2) > (by1)))));
        if (__callback(_name971)) {
            var _to_remove977 = _prev_cursor5;
            var _parent978 = (_to_remove977)._parent9;
            var _left979 = (_to_remove977)._left7;
            var _right980 = (_to_remove977)._right8;
            var _new_x981;
            if (((_left979) == null) && ((_right980) == null)) {
                _new_x981 = null;
                /* replace _to_remove977 with _new_x981 in _parent978 */
                if (!((_parent978) == null)) {
                    if (((_parent978)._left7) == (_to_remove977)) {
                        (_parent978)._left7 = _new_x981;
                    } else {
                        (_parent978)._right8 = _new_x981;
                    }
                }
                if (!((_new_x981) == null)) {
                    (_new_x981)._parent9 = _parent978;
                }
            } else if ((!((_left979) == null)) && ((_right980) == null)) {
                _new_x981 = _left979;
                /* replace _to_remove977 with _new_x981 in _parent978 */
                if (!((_parent978) == null)) {
                    if (((_parent978)._left7) == (_to_remove977)) {
                        (_parent978)._left7 = _new_x981;
                    } else {
                        (_parent978)._right8 = _new_x981;
                    }
                }
                if (!((_new_x981) == null)) {
                    (_new_x981)._parent9 = _parent978;
                }
            } else if (((_left979) == null) && (!((_right980) == null))) {
                _new_x981 = _right980;
                /* replace _to_remove977 with _new_x981 in _parent978 */
                if (!((_parent978) == null)) {
                    if (((_parent978)._left7) == (_to_remove977)) {
                        (_parent978)._left7 = _new_x981;
                    } else {
                        (_parent978)._right8 = _new_x981;
                    }
                }
                if (!((_new_x981) == null)) {
                    (_new_x981)._parent9 = _parent978;
                }
            } else {
                var _root982 = (_to_remove977)._right8;
                var _x983 = _root982;
                var _descend984 = true;
                var _from_left985 = true;
                while (true) {
                    if ((_x983) == null) {
                        _x983 = null;
                        break;
                    }
                    if (_descend984) {
                        /* too small? */
                        if (false) {
                            if ((!(((_x983)._right8) == null)) && (true)) {
                                if ((_x983) == (_root982)) {
                                    _root982 = (_x983)._right8;
                                }
                                _x983 = (_x983)._right8;
                            } else if ((_x983) == (_root982)) {
                                _x983 = null;
                                break;
                            } else {
                                _descend984 = false;
                                _from_left985 = (!(((_x983)._parent9) == null)) && ((_x983) == (((_x983)._parent9)._left7));
                                _x983 = (_x983)._parent9;
                            }
                        } else if ((!(((_x983)._left7) == null)) && (true)) {
                            _x983 = (_x983)._left7;
                            /* too large? */
                        } else if (false) {
                            if ((_x983) == (_root982)) {
                                _x983 = null;
                                break;
                            } else {
                                _descend984 = false;
                                _from_left985 = (!(((_x983)._parent9) == null)) && ((_x983) == (((_x983)._parent9)._left7));
                                _x983 = (_x983)._parent9;
                            }
                            /* node ok? */
                        } else if (true) {
                            break;
                        } else if ((_x983) == (_root982)) {
                            _root982 = (_x983)._right8;
                            _x983 = (_x983)._right8;
                        } else {
                            if ((!(((_x983)._right8) == null)) && (true)) {
                                if ((_x983) == (_root982)) {
                                    _root982 = (_x983)._right8;
                                }
                                _x983 = (_x983)._right8;
                            } else {
                                _descend984 = false;
                                _from_left985 = (!(((_x983)._parent9) == null)) && ((_x983) == (((_x983)._parent9)._left7));
                                _x983 = (_x983)._parent9;
                            }
                        }
                    } else if (_from_left985) {
                        if (false) {
                            _x983 = null;
                            break;
                        } else if (true) {
                            break;
                        } else if ((!(((_x983)._right8) == null)) && (true)) {
                            _descend984 = true;
                            if ((_x983) == (_root982)) {
                                _root982 = (_x983)._right8;
                            }
                            _x983 = (_x983)._right8;
                        } else if ((_x983) == (_root982)) {
                            _x983 = null;
                            break;
                        } else {
                            _descend984 = false;
                            _from_left985 = (!(((_x983)._parent9) == null)) && ((_x983) == (((_x983)._parent9)._left7));
                            _x983 = (_x983)._parent9;
                        }
                    } else {
                        if ((_x983) == (_root982)) {
                            _x983 = null;
                            break;
                        } else {
                            _descend984 = false;
                            _from_left985 = (!(((_x983)._parent9) == null)) && ((_x983) == (((_x983)._parent9)._left7));
                            _x983 = (_x983)._parent9;
                        }
                    }
                }
                _new_x981 = _x983;
                var _mp986 = (_x983)._parent9;
                var _mr987 = (_x983)._right8;
                /* replace _x983 with _mr987 in _mp986 */
                if (!((_mp986) == null)) {
                    if (((_mp986)._left7) == (_x983)) {
                        (_mp986)._left7 = _mr987;
                    } else {
                        (_mp986)._right8 = _mr987;
                    }
                }
                if (!((_mr987) == null)) {
                    (_mr987)._parent9 = _mp986;
                }
                /* replace _to_remove977 with _x983 in _parent978 */
                if (!((_parent978) == null)) {
                    if (((_parent978)._left7) == (_to_remove977)) {
                        (_parent978)._left7 = _x983;
                    } else {
                        (_parent978)._right8 = _x983;
                    }
                }
                if (!((_x983) == null)) {
                    (_x983)._parent9 = _parent978;
                }
                /* replace null with _left979 in _x983 */
                (_x983)._left7 = _left979;
                if (!((_left979) == null)) {
                    (_left979)._parent9 = _x983;
                }
                /* replace _mr987 with (_to_remove977)._right8 in _x983 */
                (_x983)._right8 = (_to_remove977)._right8;
                if (!(((_to_remove977)._right8) == null)) {
                    ((_to_remove977)._right8)._parent9 = _x983;
                }
                /* _min_ax12 is min of ax1 */
                var _augval988 = (_x983).ax1;
                var _child989 = (_x983)._left7;
                if (!((_child989) == null)) {
                    var _val990 = (_child989)._min_ax12;
                    _augval988 = ((_augval988) < (_val990)) ? (_augval988) : (_val990);
                }
                var _child991 = (_x983)._right8;
                if (!((_child991) == null)) {
                    var _val992 = (_child991)._min_ax12;
                    _augval988 = ((_augval988) < (_val992)) ? (_augval988) : (_val992);
                }
                (_x983)._min_ax12 = _augval988;
                /* _min_ay13 is min of ay1 */
                var _augval993 = (_x983).ay1;
                var _child994 = (_x983)._left7;
                if (!((_child994) == null)) {
                    var _val995 = (_child994)._min_ay13;
                    _augval993 = ((_augval993) < (_val995)) ? (_augval993) : (_val995);
                }
                var _child996 = (_x983)._right8;
                if (!((_child996) == null)) {
                    var _val997 = (_child996)._min_ay13;
                    _augval993 = ((_augval993) < (_val997)) ? (_augval993) : (_val997);
                }
                (_x983)._min_ay13 = _augval993;
                /* _max_ay24 is max of ay2 */
                var _augval998 = (_x983).ay2;
                var _child999 = (_x983)._left7;
                if (!((_child999) == null)) {
                    var _val1000 = (_child999)._max_ay24;
                    _augval998 = ((_augval998) < (_val1000)) ? (_val1000) : (_augval998);
                }
                var _child1001 = (_x983)._right8;
                if (!((_child1001) == null)) {
                    var _val1002 = (_child1001)._max_ay24;
                    _augval998 = ((_augval998) < (_val1002)) ? (_val1002) : (_augval998);
                }
                (_x983)._max_ay24 = _augval998;
                (_x983)._height10 = 1 + ((((((_x983)._left7) == null) ? (-1) : (((_x983)._left7)._height10)) > ((((_x983)._right8) == null) ? (-1) : (((_x983)._right8)._height10))) ? ((((_x983)._left7) == null) ? (-1) : (((_x983)._left7)._height10)) : ((((_x983)._right8) == null) ? (-1) : (((_x983)._right8)._height10)));
                var _cursor1003 = _mp986;
                var _changed1004 = true;
                while ((_changed1004) && (!((_cursor1003) == (_parent978)))) {
                    var _old__min_ax121005 = (_cursor1003)._min_ax12;
                    var _old__min_ay131006 = (_cursor1003)._min_ay13;
                    var _old__max_ay241007 = (_cursor1003)._max_ay24;
                    var _old_height1008 = (_cursor1003)._height10;
                    /* _min_ax12 is min of ax1 */
                    var _augval1009 = (_cursor1003).ax1;
                    var _child1010 = (_cursor1003)._left7;
                    if (!((_child1010) == null)) {
                        var _val1011 = (_child1010)._min_ax12;
                        _augval1009 = ((_augval1009) < (_val1011)) ? (_augval1009) : (_val1011);
                    }
                    var _child1012 = (_cursor1003)._right8;
                    if (!((_child1012) == null)) {
                        var _val1013 = (_child1012)._min_ax12;
                        _augval1009 = ((_augval1009) < (_val1013)) ? (_augval1009) : (_val1013);
                    }
                    (_cursor1003)._min_ax12 = _augval1009;
                    /* _min_ay13 is min of ay1 */
                    var _augval1014 = (_cursor1003).ay1;
                    var _child1015 = (_cursor1003)._left7;
                    if (!((_child1015) == null)) {
                        var _val1016 = (_child1015)._min_ay13;
                        _augval1014 = ((_augval1014) < (_val1016)) ? (_augval1014) : (_val1016);
                    }
                    var _child1017 = (_cursor1003)._right8;
                    if (!((_child1017) == null)) {
                        var _val1018 = (_child1017)._min_ay13;
                        _augval1014 = ((_augval1014) < (_val1018)) ? (_augval1014) : (_val1018);
                    }
                    (_cursor1003)._min_ay13 = _augval1014;
                    /* _max_ay24 is max of ay2 */
                    var _augval1019 = (_cursor1003).ay2;
                    var _child1020 = (_cursor1003)._left7;
                    if (!((_child1020) == null)) {
                        var _val1021 = (_child1020)._max_ay24;
                        _augval1019 = ((_augval1019) < (_val1021)) ? (_val1021) : (_augval1019);
                    }
                    var _child1022 = (_cursor1003)._right8;
                    if (!((_child1022) == null)) {
                        var _val1023 = (_child1022)._max_ay24;
                        _augval1019 = ((_augval1019) < (_val1023)) ? (_val1023) : (_augval1019);
                    }
                    (_cursor1003)._max_ay24 = _augval1019;
                    (_cursor1003)._height10 = 1 + ((((((_cursor1003)._left7) == null) ? (-1) : (((_cursor1003)._left7)._height10)) > ((((_cursor1003)._right8) == null) ? (-1) : (((_cursor1003)._right8)._height10))) ? ((((_cursor1003)._left7) == null) ? (-1) : (((_cursor1003)._left7)._height10)) : ((((_cursor1003)._right8) == null) ? (-1) : (((_cursor1003)._right8)._height10)));
                    _changed1004 = false;
                    _changed1004 = (_changed1004) || (!((_old__min_ax121005) == ((_cursor1003)._min_ax12)));
                    _changed1004 = (_changed1004) || (!((_old__min_ay131006) == ((_cursor1003)._min_ay13)));
                    _changed1004 = (_changed1004) || (!((_old__max_ay241007) == ((_cursor1003)._max_ay24)));
                    _changed1004 = (_changed1004) || (!((_old_height1008) == ((_cursor1003)._height10)));
                    _cursor1003 = (_cursor1003)._parent9;
                }
            }
            var _cursor1024 = _parent978;
            var _changed1025 = true;
            while ((_changed1025) && (!((_cursor1024) == (null)))) {
                var _old__min_ax121026 = (_cursor1024)._min_ax12;
                var _old__min_ay131027 = (_cursor1024)._min_ay13;
                var _old__max_ay241028 = (_cursor1024)._max_ay24;
                var _old_height1029 = (_cursor1024)._height10;
                /* _min_ax12 is min of ax1 */
                var _augval1030 = (_cursor1024).ax1;
                var _child1031 = (_cursor1024)._left7;
                if (!((_child1031) == null)) {
                    var _val1032 = (_child1031)._min_ax12;
                    _augval1030 = ((_augval1030) < (_val1032)) ? (_augval1030) : (_val1032);
                }
                var _child1033 = (_cursor1024)._right8;
                if (!((_child1033) == null)) {
                    var _val1034 = (_child1033)._min_ax12;
                    _augval1030 = ((_augval1030) < (_val1034)) ? (_augval1030) : (_val1034);
                }
                (_cursor1024)._min_ax12 = _augval1030;
                /* _min_ay13 is min of ay1 */
                var _augval1035 = (_cursor1024).ay1;
                var _child1036 = (_cursor1024)._left7;
                if (!((_child1036) == null)) {
                    var _val1037 = (_child1036)._min_ay13;
                    _augval1035 = ((_augval1035) < (_val1037)) ? (_augval1035) : (_val1037);
                }
                var _child1038 = (_cursor1024)._right8;
                if (!((_child1038) == null)) {
                    var _val1039 = (_child1038)._min_ay13;
                    _augval1035 = ((_augval1035) < (_val1039)) ? (_augval1035) : (_val1039);
                }
                (_cursor1024)._min_ay13 = _augval1035;
                /* _max_ay24 is max of ay2 */
                var _augval1040 = (_cursor1024).ay2;
                var _child1041 = (_cursor1024)._left7;
                if (!((_child1041) == null)) {
                    var _val1042 = (_child1041)._max_ay24;
                    _augval1040 = ((_augval1040) < (_val1042)) ? (_val1042) : (_augval1040);
                }
                var _child1043 = (_cursor1024)._right8;
                if (!((_child1043) == null)) {
                    var _val1044 = (_child1043)._max_ay24;
                    _augval1040 = ((_augval1040) < (_val1044)) ? (_val1044) : (_augval1040);
                }
                (_cursor1024)._max_ay24 = _augval1040;
                (_cursor1024)._height10 = 1 + ((((((_cursor1024)._left7) == null) ? (-1) : (((_cursor1024)._left7)._height10)) > ((((_cursor1024)._right8) == null) ? (-1) : (((_cursor1024)._right8)._height10))) ? ((((_cursor1024)._left7) == null) ? (-1) : (((_cursor1024)._left7)._height10)) : ((((_cursor1024)._right8) == null) ? (-1) : (((_cursor1024)._right8)._height10)));
                _changed1025 = false;
                _changed1025 = (_changed1025) || (!((_old__min_ax121026) == ((_cursor1024)._min_ax12)));
                _changed1025 = (_changed1025) || (!((_old__min_ay131027) == ((_cursor1024)._min_ay13)));
                _changed1025 = (_changed1025) || (!((_old__max_ay241028) == ((_cursor1024)._max_ay24)));
                _changed1025 = (_changed1025) || (!((_old_height1029) == ((_cursor1024)._height10)));
                _cursor1024 = (_cursor1024)._parent9;
            }
            if (((this)._root1) == (_to_remove977)) {
                (this)._root1 = _new_x981;
            }
            _prev_cursor5 = null;
        }
    };
}
; 
 
 buildViz = function (d3) {
    return function (widthInPixels = 800,
                     heightInPixels = 600,
                     max_snippets = null,
                     color = null,
                     sortByDist = true,
                     useFullDoc = false,
                     greyZeroScores = false,
                     asianMode = false,
                     nonTextFeaturesMode = false,
                     showCharacteristic = true,
                     wordVecMaxPValue = false,
                     saveSvgButton = false,
                     reverseSortScoresForNotCategory = false,
                     minPVal = 0.05,
                     pValueColors = false,
                     xLabelText = null,
                     yLabelText = null) {
        var divName = 'd3-div-1';

        // Set the dimensions of the canvas / graph
        var margin = {top: 30, right: 20, bottom: 30, left: 50},
            width = widthInPixels - margin.left - margin.right,
            height = heightInPixels - margin.top - margin.bottom;

        // Set the ranges
        var x = d3.scaleLinear().range([0, width]);
        var y = d3.scaleLinear().range([height, 0]);

        console.log('X Label');
        console.log(xLabelText);
        console.log('Y Label');
        console.log(yLabelText);
        console.log(yLabelText == null);
        console.log(yLabelText != null);
        console.log(yLabelText === undefined);
        console.log(yLabelText !== undefined);

        function axisLabelerFactory(axis) {
            if ((axis == "x" && xLabelText == null)
                || (axis == "y" && yLabelText == null))
                return function (d, i) {
                    return ["Infrequent", "Average", "Frequent"][i];
                };

            return function (d, i) {
                return ["Low", "Medium", "High"][i];
            }
        }

        var xAxis = d3.axisBottom(x).ticks(3).tickFormat(axisLabelerFactory('x'));
        var yAxis = d3.axisLeft(y).ticks(3).tickFormat(axisLabelerFactory('y'));

        // var label = d3.select("body").append("div")
        var label = d3.select('#' + divName).append("div")
            .attr("class", "label");

        var interpolateLightGreys = d3.interpolate(d3.rgb(230, 230, 230), d3.rgb(130, 130, 130));
        // setup fill color
        //var color = d3.interpolateRdYlBu;
        if (color == null) {
            color = d3.interpolateRdYlBu;
        }
        ;

        // Adds the svg canvas
        // var svg = d3.select("body")
        svg = d3.select('#' + divName)
            .append("svg")
            .attr("width", width + margin.left + margin.right + 200)
            .attr("height", height + margin.top + margin.bottom)
            .append("g")
            .attr("transform",
                "translate(" + margin.left + "," + margin.top + ")");

        var lastCircleSelected = null;

        function deselectLastCircle() {
            if (lastCircleSelected) {
                lastCircleSelected.style["stroke"] = null;
                lastCircleSelected = null;
            }
        }

        function getSentenceBoundaries(text) {
            // !!! need to use spacy's sentence splitter
            if (asianMode) {
                var sentenceRe = /\n/gmi;
            } else {
                var sentenceRe = /\(?[^\.\?\!\n\b]+[\n\.!\?]\)?/g;
            }
            var offsets = [];
            var match;
            while ((match = sentenceRe.exec(text)) != null) {
                offsets.push(match.index);
            }
            offsets.push(text.length);
            return offsets;
        }

        function getMatchingSnippet(text, boundaries, start, end) {
            var sentenceStart = null;
            var sentenceEnd = null;
            for (var i in boundaries) {
                var position = boundaries[i];
                if (position <= start && (sentenceStart == null || position > sentenceStart)) {
                    sentenceStart = position;
                }
                if (position >= end) {
                    sentenceEnd = position;
                    break;
                }
            }
            var snippet = (text.slice(sentenceStart, start) + "<b>" + text.slice(start, end)
            + "</b>" + text.slice(end, sentenceEnd)).trim();
            if (sentenceStart == null) {
                sentenceStart = 0;
            }
            return {'snippet': snippet, 'sentenceStart': sentenceStart};
        }

        function gatherTermContexts(d) {
            var category_name = fullData['info']['category_name'];
            var not_category_name = fullData['info']['not_category_name'];
            var matches = [[], []];
            if (fullData.docs === undefined) return matches;
            if (!nonTextFeaturesMode) {
                return searchInText(d);
            } else {
                return searchInExtraFeatures(d);
            }
        }

        function searchInExtraFeatures(d) {
            var matches = [[], []];
            var term = d.term;
            for (var i in fullData.docs.extra) {

                if (term in fullData.docs.extra[i]) {
                    var strength = fullData.docs.extra[i][term] /
                        Object.values(fullData.docs.extra[i]).reduce(
                            function (a, b) {
                                return a + b
                            });
                    var text = fullData.docs.texts[i];
                    if (!useFullDoc)
                        text = text.slice(0, 300);
                    var curMatch = {'id': i, 'snippets': [text], 'strength': strength};

                    curMatch['meta'] = fullData.docs.meta[i];
                    matches[fullData.docs.labels[i]].push(curMatch);
                }
            }
            for (var i in [0, 1]) {
                matches[i] = matches[i].sort(function (a, b) {
                    return a.strength < b.strength ? 1 : -1
                })
            }
            return {'contexts': matches, 'info': d};
        }

        // from https://medium.com/reactnative/emojis-in-javascript-f693d0eb79fb
        var emojiRE = /(?:[\u2700-\u27bf]|(?:\ud83c[\udde6-\uddff]){2}|[\ud800-\udbff][\udc00-\udfff])[\ufe0e\ufe0f]?(?:[\u0300-\u036f\ufe20-\ufe23\u20d0-\u20f0]|\ud83c[\udffb-\udfff])?(?:\u200d(?:[^\ud800-\udfff]|(?:\ud83c[\udde6-\uddff]){2}|[\ud800-\udbff][\udc00-\udfff])[\ufe0e\ufe0f]?(?:[\u0300-\u036f\ufe20-\ufe23\u20d0-\u20f0]|\ud83c[\udffb-\udfff])?)*/g;

        function isEmoji(str) {
            console.log(str);
            if (str.match(emojiRE)) return true;
            return false;
        }

        function searchInText(d) {
            function stripNonWordChars(term) {
                //d.term.replace(" ", "[^\\w]+")
            }

            function buildMatcher(term) {

                var boundary = '\\b';
                var wordSep = "[^\\w]+";
                if (asianMode) {
                    boundary = '( |$|^)';
                    wordSep = ' ';
                }
                if (isEmoji(term)) {
                    boundary = '';
                    wordSep = '';
                }
                var regexp = new RegExp(boundary + '('
                    + term.replace('$', '\\$').replace(' ', wordSep, 'gim')
                    + ')' + boundary, 'gim');
                try {
                    regexp.exec('X');
                } catch (err) {
                    console.log("Can't search " + term);
                    console.log(err);
                    return null;
                }
                return regexp;
            }

            var matches = [[], []];
            var pattern = buildMatcher(d.term);
            if (pattern !== null) {
                for (var i in fullData.docs.texts) {
                    if (fullData.docs.labels[i] > 1) continue;
                    var text = fullData.docs.texts[i];
                    //var pattern = new RegExp("\\b(" + stripNonWordChars(d.term) + ")\\b", "gim");
                    var match;
                    var sentenceOffsets = null;
                    var lastSentenceStart = null;
                    var matchFound = false;
                    var curMatch = {'id': i, 'snippets': []};
                    if (fullData.docs.meta) {
                        curMatch['meta'] = fullData.docs.meta[i];
                    }
                    while ((match = pattern.exec(text)) != null) {
                        if (sentenceOffsets == null) {
                            sentenceOffsets = getSentenceBoundaries(text);
                        }
                        var foundSnippet = getMatchingSnippet(text, sentenceOffsets,
                            match.index, pattern.lastIndex);
                        if (foundSnippet.sentenceStart == lastSentenceStart) continue; // ensure we don't duplicate sentences
                        lastSentenceStart = foundSnippet.sentenceStart;
                        curMatch.snippets.push(foundSnippet.snippet);
                        matchFound = true;
                    }
                    if (matchFound) {
                        if (useFullDoc) {
                            curMatch.snippets = [
                                text
                                    .replace(/\n$/g, '\n\n')
                                    .replace(
                                        //new RegExp("\\b(" + d.term.replace(" ", "[^\\w]+") + ")\\b",
                                        //    'gim'),
                                        pattern,
                                        '<b>$&</b>')
                            ];
                        }
                        matches[fullData.docs.labels[i]].push(curMatch);

                    }
                }
            }
            return {'contexts': matches, 'info': d};
        }

        function displayTermContexts(termInfo, jump=true) {
            var contexts = termInfo.contexts;
            var info = termInfo.info;
            if (contexts[0].length == 0 && contexts[1].length == 0) {
                return null;
            }
            //var categoryNames = [fullData.info.category_name,
            //    fullData.info.not_category_name];
            var catInternalName = fullData.info.category_internal_name;
            fullData.docs.categories
                .map(
                    function (catName, catIndex) {
                        if (max_snippets != null) {
                            var contextsToDisplay = contexts[catIndex].slice(0, max_snippets);
                        }
                        var divId = catName == catInternalName ? '#cat' : '#notcat';
                        var temp = d3.select(divId)
                            .selectAll("div").remove();
                        contexts[catIndex].forEach(function (context) {
                            var meta = context.meta ? context.meta : '&nbsp;';
                            d3.select(divId)
                                .append("div")
                                .attr('class', 'snippet_meta')
                                .html(meta);
                            context.snippets.forEach(function (snippet) {
                                d3.select(divId)
                                    .append("div")
                                    .attr('class', 'snippet')
                                    .html(snippet);
                            })

                        });
                    });
            d3.select('#termstats')
                .selectAll("div")
                .remove();
            d3.select('#termstats')
                .append('div')
                .attr("class", "snippet_header")
                .html('Term: <b>' + info.term + '</b>');
            var message = '';
            var cat_name = fullData.info.category_name;
            var ncat_name = fullData.info.not_category_name;

            function getFrequencyDescription(name, count25k, count) {
                var desc = name + ' frequency: <div class=text_subhead>' + count25k
                    + ' per 25,000 terms</div>';
                if (count == 0) {
                    desc += '<u>Not found in any ' + name + ' documents.</u>';
                } else {
                    desc += '<u>Some of the ' + count + ' mentions:</u>';
                }
                return desc;
            }

            d3.select('#cathead')
                .style('fill', color(1))
                .html(getFrequencyDescription(cat_name, info.cat25k, info.cat));
            d3.select('#notcathead')
                .style('fill', color(0))
                .html(getFrequencyDescription(ncat_name, info.ncat25k, info.ncat));
            console.log(info);
            if (jump) {
                if (window.location.hash == '#snippets') {
                    window.location.hash = '#snippetsalt';
                } else {
                    window.location.hash = '#snippets';
                }
            }
        }

        function showTooltip(d, pageX, pageY) {
            deselectLastCircle();
            var message = d.term + "<br/>" + d.cat25k + ":" + d.ncat25k + " per 25k words";
            if (!sortByDist) {
                message += '<br/>score: ' + d.os.toFixed(5);
            }
            /*
             if (d.p) {
             message += ';  (p:' + d.p.toFixed(5) +')';
             }*/

            tooltip.transition()
                .duration(0)
                .style("opacity", 1)
                .style("z-index", 10000000);
            tooltip.html(message)
                .style("left", (pageX) + "px")
                .style("top", (pageY - 28) + "px");

            tooltip.on('click', function () {
                tooltip.transition()
                    .style('opacity', 0)
            });
        }

        handleSearch = function (event) {
            deselectLastCircle();
            var searchTerm = document
                .getElementById("searchTerm")
                .value
                .toLowerCase()
                .replace("'", " '")
                .trim();
            showToolTipForTerm(searchTerm);
            var termInfo = termDict[searchTerm];
            if (termInfo != null) {
                displayTermContexts(gatherTermContexts(termInfo), false);
            }
            return false;
        };

        function showToolTipForTerm(searchTerm) {
            var searchTermInfo = termDict[searchTerm];
            if (searchTermInfo === undefined) {
                d3.select("#alertMessage")
                    .text(searchTerm + " didn't make it into the visualization.");
            } else {
                d3.select("#alertMessage").text("");
                var circle = mysvg._groups[0][searchTermInfo.i];
                var mySVGMatrix = circle.getScreenCTM()
                    .translate(circle.cx.baseVal.value, circle.cy.baseVal.value);
                var pageX = mySVGMatrix.e;
                var pageY = mySVGMatrix.f;
                circle.style["stroke"] = "black";
                showTooltip(searchTermInfo, pageX, pageY);
                lastCircleSelected = circle;

            }
        };

        function makeWordInteractive(domObj, term) {
            return domObj
                .on("mouseover", function (d) {
                    showToolTipForTerm(term);
                    d3.select(this).style("stroke", "black");
                })
                .on("mouseout", function (d) {
                    tooltip.transition()
                        .duration(0)
                        .style("opacity", 0);
                    d3.select(this).style("stroke", null);
                })
                .on("click", function (d) {
                    displayTermContexts(gatherTermContexts(termDict[term]));
                });
        }

        function processData(fullData) {
            var modelInfo = fullData['info'];
            /*
             categoryTermList.data(modelInfo['category_terms'])
             .enter()
             .append("li")
             .text(function(d) {return d;});
             */
            data = fullData['data'];
            termDict = Object();
            data.forEach(function (x, i) {
                termDict[x.term] = x;
                termDict[x.term].i = i;
            });

            console.log(data);
            // Scale the range of the data.  Add some space on either end.
            x.domain([-0.1, d3.max(data, function (d) {
                return d.x;
            }) + 0.1]);
            y.domain([-0.1, d3.max(data, function (d) {
                return d.y;
            }) + 0.1]);

            /*
             data.sort(function (a, b) {
             return Math.abs(b.os) - Math.abs(a.os)
             });
             */


            //var rangeTree = null; // keep boxes of all points and labels here
            var rectHolder = new RectangleHolder();
            // Add the scatterplot
            mysvg = svg
                .selectAll("dot")
                .data(data)
                .enter()
                .append("circle")
                .attr("r", function (d) {
                    if (pValueColors && d.p) {
                        return (d.p >= 1 - minPVal || d.p <= minPVal) ? 2 : 1.75;
                    }
                    return 2;
                })
                .attr("cx", function (d) {
                    return x(d.x);
                })
                .attr("cy", function (d) {
                    return y(d.y);
                })
                .style("fill", function (d) {
                    //.attr("fill", function (d) {
                    if (greyZeroScores && d.os == 0) {
                        return d3.rgb(230, 230, 230);
                    } else if (pValueColors && d.p) {
                        if (d.p >= 1 - minPVal) {
                            return d3.interpolateYlGnBu(d.s);
                        } else if (d.p <= minPVal) {
                            return d3.interpolateYlOrBr(d.s);
                        } else {
                            return interpolateLightGreys(d.s);
                        }
                    } else {
                        return color(d.s);
                    }
                })
                .on("mouseover", function (d) {
                    showTooltip(d, d3.event.pageX, d3.event.pageY);
                    d3.select(this).style("stroke", "black");
                })
                .on("click", function (d) {
                    displayTermContexts(gatherTermContexts(d));
                })
                .on("mouseout", function (d) {
                    tooltip.transition()
                        .duration(0)
                        .style("opacity", 0);
                    d3.select(this).style("stroke", null);
                });

            coords = Object();

            function censorPoints(datum) {
                var term = datum.term;
                var curLabel = svg.append("text")
                    .attr("x", x(datum.x))
                    .attr("y", y(datum.y) + 3)
                    .attr("text-anchor", "middle")
                    .text("x");
                var bbox = curLabel.node().getBBox();
                var borderToRemove = .5;
                var x1 = bbox.x + borderToRemove,
                    y1 = bbox.y + borderToRemove,
                    x2 = bbox.x + bbox.width - borderToRemove,
                    y2 = bbox.y + bbox.height - borderToRemove;
                //rangeTree = insertRangeTree(rangeTree, x1, y1, x2, y2, '~~' + term);
                rectHolder.add(new Rectangle(x1, y1, x2, y2));

                curLabel.remove();
            }

            function labelPointsIfPossible(i, useOffset) {
                var term = data[i].term;

                var configs = [
                    {'anchor': 'end', 'xoff': -5, 'yoff': -3, 'alignment-baseline': 'ideographic'},
                    {'anchor': 'end', 'xoff': -5, 'yoff': 10, 'alignment-baseline': 'ideographic'},
                    {'anchor': 'start', 'xoff': 3, 'yoff': 10, 'alignment-baseline': 'ideographic'},
                    {'anchor': 'start', 'xoff': 3, 'yoff': -3, 'alignment-baseline': 'ideographic'},
                    {'anchor': 'start', 'xoff': 5, 'yoff': 10, 'alignment-baseline': 'ideographic'},
                    {'anchor': 'start', 'xoff': 5, 'yoff': -3, 'alignment-baseline': 'ideographic'},
                    {'anchor': 'start', 'xoff': 10, 'yoff': 15, 'alignment-baseline': 'ideographic'},
                    {'anchor': 'start', 'xoff': -10, 'yoff': -15, 'alignment-baseline': 'ideographic'},
                    {'anchor': 'start', 'xoff': 10, 'yoff': -15, 'alignment-baseline': 'ideographic'},
                    {'anchor': 'start', 'xoff': -10, 'yoff': 15, 'alignment-baseline': 'ideographic'},
                ];
                /*if(!useOffset) {
                    configs = [{'anchor': 'middle', 'xoff': 0, 'yoff': 0,
                        'alignment-baseline': 'middle'}];
                }*/
                var matchedElement = null;
                for (var configI in configs) {
                    var config = configs[configI];
                    var curLabel = makeWordInteractive(
                        svg.append("text")
                            .attr("x", x(data[i].x) + config['xoff'])
                            .attr("y", y(data[i].y) + config['yoff'])
                            .attr('class', 'label')
                            .attr('font-family', 'Helvetica, Arial, Sans-Serif')
                            .attr('font-size', '10px')
                            .attr("text-anchor", config['anchor'])
                            .attr("alignment-baseline", config['alignment'])
                            .text(term),
                        term
                    );
                    var bbox = curLabel.node().getBBox();
                    var borderToRemove = .5;
                    var x1 = bbox.x + borderToRemove,
                        y1 = bbox.y + borderToRemove,
                        x2 = bbox.x + bbox.width - borderToRemove,
                        y2 = bbox.y + bbox.height - borderToRemove;
                    //matchedElement = searchRangeTree(rangeTree, x1, y1, x2, y2);
                    var matchedElement = false;
                    rectHolder.findMatchingRectangles(x1, y1, x2, y2, function (elem) {
                        matchedElement = true;
                        return false;
                    });
                    if (matchedElement) {
                        curLabel.remove();
                    } else {
                        break;
                    }
                }

                if (!matchedElement) {
                    coords[term] = [x1, y1, x2, y2];
                    //rangeTree = insertRangeTree(rangeTree, x1, y1, x2, y2, term);
                    rectHolder.add(new Rectangle(x1, y1, x2, y2));
                    return true;

                } else {
                    //curLabel.remove();
                    return false;
                }

            }

            var radius = 2;

            function euclideanDistanceSort(a, b) {
                var aCatDist = a.x * a.x + (1 - a.y) * (1 - a.y);
                var aNotCatDist = a.y * a.y + (1 - a.x) * (1 - a.x);
                var bCatDist = b.x * b.x + (1 - b.y) * (1 - b.y);
                var bNotCatDist = b.y * b.y + (1 - b.x) * (1 - b.x);
                return (Math.min(aCatDist, aNotCatDist) > Math.min(bCatDist, bNotCatDist)) * 2 - 1;
            }

            function euclideanDistanceSortForCategory(a, b) {
                var aCatDist = a.x * a.x + (1 - a.y) * (1 - a.y);
                var bCatDist = b.x * b.x + (1 - b.y) * (1 - b.y);
                return (aCatDist > bCatDist) * 2 - 1;
            }

            function euclideanDistanceSortForNotCategory(a, b) {
                var aNotCatDist = a.y * a.y + (1 - a.x) * (1 - a.x);
                var bNotCatDist = b.y * b.y + (1 - b.x) * (1 - b.x);
                return (aNotCatDist > bNotCatDist) * 2 - 1;
            }

            function scoreSort(a, b) {
                return a.s - b.s;
            }

            function scoreSortReverse(a, b) {
                return b.s - a.s;
            }

            function backgroundScoreSort(a, b) {
                return b.bg - a.bg;
            }

            function arePointsPredictiveOfDifferentCategories(a, b) {
                var aCatDist = a.x * a.x + (1 - a.y) * (1 - a.y);
                var bCatDist = b.x * b.x + (1 - b.y) * (1 - b.y);
                var aNotCatDist = a.y * a.y + (1 - a.x) * (1 - a.x);
                var bNotCatDist = b.y * b.y + (1 - b.x) * (1 - b.x);
                var aGood = aCatDist < aNotCatDist;
                var bGood = bCatDist < bNotCatDist;
                return {aGood: aGood, bGood: bGood};
            }

            function scoreSortForCategory(a, b) {
                var __ret = arePointsPredictiveOfDifferentCategories(a, b);
                if(sortByDist) {
                    var aGood = __ret.aGood;
                    var bGood = __ret.bGood;
                    if (aGood && !bGood) return -1;
                    if (!aGood && bGood) return 1;
                }
                return b.s - a.s;
            }

            function scoreSortForNotCategory(a, b) {
                var __ret = arePointsPredictiveOfDifferentCategories(a, b);
                if(sortByDist) {
                    var aGood = __ret.aGood;
                    var bGood = __ret.bGood;
                    if (aGood && !bGood) return 1;
                    if (!aGood && bGood) return -1;
                }
                if (reverseSortScoresForNotCategory)
                    return a.s - b.s;
                else
                    return b.s - a.s;
            }

            data = data.sort(sortByDist ? euclideanDistanceSort : scoreSort);
            console.log("Sorted Data:");
            console.log(data);
            data.forEach(censorPoints);

            var myXAxis = svg.append("g")
                .attr("class", "x axis")
                .attr("transform", "translate(0," + height + ")")
                .call(xAxis);

            function registerFigureBBox(curLabel) {
                var bbox = curLabel.node().getBBox();
                var borderToRemove = 1.5;
                var x1 = bbox.x + borderToRemove,
                    y1 = bbox.y + borderToRemove,
                    x2 = bbox.x + bbox.width - borderToRemove,
                    y2 = bbox.y + bbox.height - borderToRemove;
                rectHolder.add(new Rectangle(x1, y1, x2, y2));
                //return insertRangeTree(rangeTree, x1, y1, x2, y2, '~~_other_');
            }

            //rangeTree = registerFigureBBox(myXAxis);
            var xLabel = svg.append("text")
                .attr("class", "x label")
                .attr("text-anchor", "end")
                .attr("x", width)
                .attr("y", height - 6)
                .attr('font-family', 'Helvetica, Arial, Sans-Serif')
                .attr('font-size', '10px')
                .text(getLabelText('x'));

            //console.log('xLabel');
            //console.log(xLabel);

            //rangeTree = registerFigureBBox(xLabel);
            // Add the Y Axis
            var myYAxis = svg.append("g")
                .attr("class", "y axis")
                .call(yAxis)
                .selectAll("text")
                .style("text-anchor", "end")
                .attr("dx", "30px")
                .attr("dy", "-13px")
                .attr('font-family', 'Helvetica, Arial, Sans-Serif')
                .attr('font-size', '10px')
                .attr("transform", "rotate(-90)");
            registerFigureBBox(myYAxis);

            function getLabelText(axis) {
                if (axis == 'y') {
                    if (yLabelText == null)
                        return modelInfo['category_name'] + " Frequency";
                    else
                        return yLabelText;
                } else {
                    if (xLabelText == null)
                        return modelInfo['not_category_name'] + " Frequency";
                    else
                        return xLabelText;
                }
            }

            var yLabel = svg.append("text")
                .attr("class", "y label")
                .attr("text-anchor", "end")
                .attr("y", 6)
                .attr("dy", ".75em")
                .attr("transform", "rotate(-90)")
                .attr('font-family', 'Helvetica, Arial, Sans-Serif')
                .attr('font-size', '10px')
                .text(getLabelText('y'));
            registerFigureBBox(yLabel);

            var catHeader = svg.append("text")
                .attr("text-anchor", "start")
                .attr("x", width)
                .attr("dy", "6px")
                .attr('font-family', 'Helvetica, Arial, Sans-Serif')
                .attr('font-size', '12px')
                .attr('font-weight', 'bolder')
                .attr('font-decoration', 'underline')
                .text("Top " + fullData['info']['category_name']);
            registerFigureBBox(catHeader);
            console.log(catHeader);

            function showWordList(word, termDataList) {
                var maxWidth = word.node().getBBox().width;
                for (var i in termDataList) {
                    var curTerm = termDataList[i].term;
                    word = (function (word, curTerm) {
                        return makeWordInteractive(
                            svg.append("text")
                                .attr("text-anchor", "start")
                                .attr('font-family', 'Helvetica, Arial, Sans-Serif')
                                .attr('font-size', '12px')
                                .attr("x", word.node().getBBox().x)
                                .attr("y", word.node().getBBox().y
                                    + 2 * word.node().getBBox().height)
                                .text(curTerm)
                            ,
                            curTerm);
                    })(word, curTerm);
                    if (word.node().getBBox().width > maxWidth)
                        maxWidth = word.node().getBBox().width;
                    registerFigureBBox(word);
                }
                return {
                    'word': word,
                    'maxWidth': maxWidth
                };
            }

            function pickEuclideanDistanceSortAlgo(category) {
                if (category == true) return euclideanDistanceSortForCategory;
                return euclideanDistanceSortForNotCategory;
            }

            function pickScoreSortAlgo(category) {
                console.log("PICK SCORE ALGO")
                console.log(category)
                if (category == true) {
                    return scoreSortForCategory;
                } else {
                    return scoreSortForNotCategory;
                }
            }

            function pickTermSortingAlgorithm(category) {
                if (sortByDist) return pickEuclideanDistanceSortAlgo(category);
                return pickScoreSortAlgo(category);
            }

            function showAssociatedWordList(header, isAssociatedToCategory, length=14) {
                var sortedData = null;
                var sortingAlgo = pickTermSortingAlgorithm(isAssociatedToCategory);
                sortedData = data.sort(sortingAlgo);
                if (wordVecMaxPValue) {
                    function signifTest(x) {
                        if (isAssociatedToCategory)
                            return x.p >= 1 - minPVal;
                        return x.p <= minPVal;
                    }

                    sortedData = sortedData.filter(signifTest)
                }
                return showWordList(header, sortedData.slice(0, length));

            }

            var wordListData = showAssociatedWordList(catHeader, true);
            var word = wordListData.word;
            var maxWidth = wordListData.maxWidth;

            catHeader = svg.append("text")
                .attr('font-family', 'Helvetica, Arial, Sans-Serif')
                .attr('font-size', '12px')
                .attr('font-weight', 'bolder')
                .attr('font-decoration', 'underline')
                .attr("text-anchor", "start")
                .attr("x", width)
                .attr("y", word.node().getBBox().y + 4 * word.node().getBBox().height)
                .text("Top " + fullData['info']['not_category_name']);


            wordListData = showAssociatedWordList(catHeader, false);
            word = wordListData.word;
            if (wordListData.maxWidth > maxWidth) {
                maxWidth = wordListData.maxWidth;
            }


            if (!nonTextFeaturesMode && !asianMode && showCharacteristic) {
                var title = 'Characteristic';
                if (wordVecMaxPValue) {
                    title = 'Most similar';
                }
                word = svg.append("text")
                    .attr('font-family', 'Helvetica, Arial, Sans-Serif')
                    .attr("text-anchor", "start")
                    .attr('font-size', '12px')
                    .attr('font-weight', 'bolder')
                    .attr('font-decoration', 'underline')
                    .attr("x", catHeader.node().getBBox().x + maxWidth + 10)
                    .attr("dy", "6px")
                    .text(title);
                var sortMethod = backgroundScoreSort;
                if (wordVecMaxPValue) {
                    sortMethod = scoreSortReverse;
                }
                var wordListData = showWordList(word, data.sort(sortMethod).slice(0, 30));
                ;

                word = wordListData.word;
                maxWidth = wordListData.maxWidth;
                console.log(maxWidth);
                console.log(word.node().getBBox().x + maxWidth);

                svg.attr('width', word.node().getBBox().x + 3 * maxWidth + 10);
            }

            var numPointsLabeled = 0;
            for (var i = 0; i < data.length; i++) {
                if (labelPointsIfPossible(i), true) numPointsLabeled++;
            }
            console.log('numPointsLabeled');
            console.log(numPointsLabeled);


            function populateCorpusStats() {
                var wordCounts = {};
                var docCounts = {}
                fullData.docs.labels.forEach(function (x, i) {
                    var cnt = (
                        fullData.docs.texts[i]
                            .trim()
                            .replace(/['";:,.?¿\-!¡]+/g, '')
                            .match(/\S+/g) || []
                    ).length;
                    wordCounts[x] = wordCounts[x] ? wordCounts[x] + cnt : cnt
                });
                fullData.docs.labels.forEach(function (x) {
                    docCounts[x] = docCounts[x] ? docCounts[x] + 1 : 1
                });
                var messages = [];
                fullData.docs.categories.forEach(function (x, i) {
                    var name = fullData.info.not_category_name;
                    if (x == fullData.info.category_internal_name) {
                        name = fullData.info.category_name;
                    }

                    messages.push('<b>' + name + '</b> document count: '
                        + Number(docCounts[i]).toLocaleString('en')
                        + '; word count: '
                        + Number(wordCounts[i]).toLocaleString('en'));
                });

                d3.select('#corpus-stats')
                    .style('width', width + margin.left + margin.right + 200)
                    .append('div')
                    .html(messages.join('<br />'));
            };

            if (fullData.docs) {
                populateCorpusStats();
            }

            if (saveSvgButton) {
                // from https://stackoverflow.com/questions/23218174/how-do-i-save-export-an-svg-file-after-creating-an-svg-with-d3-js-ie-safari-an
                var svgElement = document.getElementById("d3-div-1");

                var serializer = new XMLSerializer();
                var source = serializer.serializeToString(svgElement);

                if (!source.match(/^<svg[^>]+xmlns="http\:\/\/www\.w3\.org\/2000\/svg"/)) {
                    source = source.replace(/^<svg/, '<svg xmlns="https://www.w3.org/2000/svg"');
                }
                if (!source.match(/^<svg[^>]+"http\:\/\/www\.w3\.org\/1999\/xlink"/)) {
                    source = source.replace(/^<svg/, '<svg xmlns:xlink="https://www.w3.org/1999/xlink"');
                }

                source = '<?xml version="1.0" standalone="no"?>\r\n' + source;

                var url = "data:image/svg+xml;charset=utf-8," + encodeURIComponent(source);

                var downloadLink = document.createElement("a");
                downloadLink.href = url;
                downloadLink.download = fullData['info']['category_name'] + ".svg";
                downloadLink.innerText = 'Download SVG';
                document.body.appendChild(downloadLink);

            }

        };

        fullData = getDataAndInfo();
        processData(fullData);

        // The tool tip is down here in order to make sure it has the highest z-index
        var tooltip = d3.select('#' + divName)
            .append("div")
            .attr("class", sortByDist ? "tooltip" : "tooltipscore")
            .style("opacity", 0);
    };
}(d3);

function getDataAndInfo() { return{"data": [{"cat25k": 12, "ncat25k": 1, "os": 0.9002535732075494, "cat": 4, "y": 0.6178489702517163, "term": "larger", "s": 1.0, "bg": 1.630757708086151e-07, "x": 0.0, "ncat": 1}, {"cat25k": 12, "ncat25k": 1, "os": 0.9002535732075494, "cat": 4, "y": 0.6498855835240275, "term": "rate", "s": 1.0, "bg": 4.814877354721788e-08, "x": 0.0007627765064836003, "ncat": 1}, {"cat25k": 12, "ncat25k": 1, "os": 0.9002535732075494, "cat": 4, "y": 0.6636155606407322, "term": "restricted", "s": 1.0, "bg": 7.086071391318938e-07, "x": 0.0015255530129672007, "ncat": 1}, {"cat25k": 12, "ncat25k": 1, "os": 0.9002535732075494, "cat": 4, "y": 0.6742944317315027, "term": "matrix", "s": 1.0, "bg": 7.76737859163586e-07, "x": 0.002288329519450801, "ncat": 1}, {"cat25k": 19, "ncat25k": 2, "os": 0.8979649262823572, "cat": 6, "y": 0.7467581998474447, "term": "individual", "s": 0.9992354740061161, "bg": 1.8973228532105502e-07, "x": 0.0030511060259344014, "ncat": 2}, {"cat25k": 12, "ncat25k": 2, "os": 0.8451055395299674, "cat": 4, "y": 0.5781845919145691, "term": "variation", "s": 0.9900611620795106, "bg": 1.6217183403190353e-06, "x": 0.0038138825324180014, "ncat": 2}, {"cat25k": 9, "ncat25k": 2, "os": 0.7935922478010495, "cat": 3, "y": 0.4233409610983982, "term": "typical", "s": 0.9717125382262997, "bg": 4.8196396847011e-07, "x": 0.004576659038901602, "ncat": 2}, {"cat25k": 9, "ncat25k": 2, "os": 0.7935922478010495, "cat": 3, "y": 0.4286803966437834, "term": "who", "s": 0.9717125382262997, "bg": 1.584829482229124e-08, "x": 0.005339435545385202, "ncat": 2}, {"cat25k": 12, "ncat25k": 2, "os": 0.8451055395299674, "cat": 4, "y": 0.5873379099923722, "term": "distinguish", "s": 0.9900611620795106, "bg": 2.4480817953089447e-06, "x": 0.006102212051868803, "ncat": 2}, {"cat25k": 9, "ncat25k": 2, "os": 0.7935922478010495, "cat": 3, "y": 0.43401983218916856, "term": "issues", "s": 0.9717125382262997, "bg": 1.0655179814550325e-07, "x": 0.006864988558352402, "ncat": 2}, {"cat25k": 9, "ncat25k": 2, "os": 0.7935922478010495, "cat": 3, "y": 0.4401220442410374, "term": "signal", "s": 0.9717125382262997, "bg": 3.560445867515097e-07, "x": 0.007627765064836003, "ncat": 2}, {"cat25k": 16, "ncat25k": 2, "os": 0.8773622566301508, "cat": 5, "y": 0.7139588100686499, "term": "recognizing", "s": 0.9977064220183486, "bg": 3.58172328475749e-06, "x": 0.008390541571319604, "ncat": 2}, {"cat25k": 12, "ncat25k": 2, "os": 0.8451055395299674, "cat": 4, "y": 0.6216628527841342, "term": "predefined", "s": 0.9900611620795106, "bg": 7.47145437462993e-06, "x": 0.009153318077803204, "ncat": 2}, {"cat25k": 9, "ncat25k": 2, "os": 0.7935922478010495, "cat": 3, "y": 0.4973302822273074, "term": "resolution", "s": 0.9717125382262997, "bg": 4.685964839619789e-07, "x": 0.009916094584286803, "ncat": 2}, {"cat25k": 9, "ncat25k": 2, "os": 0.7935922478010495, "cat": 3, "y": 0.4996186117467582, "term": "validation", "s": 0.9717125382262997, "bg": 1.1512366987550871e-06, "x": 0.010678871090770405, "ncat": 2}, {"cat25k": 9, "ncat25k": 2, "os": 0.7935922478010495, "cat": 3, "y": 0.501906941266209, "term": "expected", "s": 0.9717125382262997, "bg": 2.2057949320979116e-07, "x": 0.011441647597254004, "ncat": 2}, {"cat25k": 9, "ncat25k": 2, "os": 0.7935922478010495, "cat": 3, "y": 0.5087719298245614, "term": "currently", "s": 0.9717125382262997, "bg": 1.1219388053961352e-07, "x": 0.012204424103737605, "ncat": 2}, {"cat25k": 9, "ncat25k": 2, "os": 0.7935922478010495, "cat": 3, "y": 0.5110602593440122, "term": "selecting", "s": 0.9717125382262997, "bg": 9.494170531822609e-07, "x": 0.012967200610221205, "ncat": 2}, {"cat25k": 12, "ncat25k": 2, "os": 0.8451055395299674, "cat": 4, "y": 0.6468344774980931, "term": "extend", "s": 0.9900611620795106, "bg": 7.920031965249012e-07, "x": 0.013729977116704805, "ncat": 2}, {"cat25k": 9, "ncat25k": 2, "os": 0.7935922478010495, "cat": 3, "y": 0.5240274599542334, "term": "toward", "s": 0.9717125382262997, "bg": 3.324468969273662e-07, "x": 0.014492753623188406, "ncat": 2}, {"cat25k": 9, "ncat25k": 2, "os": 0.7935922478010495, "cat": 3, "y": 0.5339435545385202, "term": "integration", "s": 0.9717125382262997, "bg": 3.075211461534532e-07, "x": 0.015255530129672006, "ncat": 2}, {"cat25k": 9, "ncat25k": 2, "os": 0.7935922478010495, "cat": 3, "y": 0.5347063310450039, "term": "disorder", "s": 0.9717125382262997, "bg": 1.1205924796558437e-06, "x": 0.016018306636155607, "ncat": 2}, {"cat25k": 9, "ncat25k": 2, "os": 0.7935922478010495, "cat": 3, "y": 0.5369946605644547, "term": "affective", "s": 0.9717125382262997, "bg": 1.6530105454559116e-05, "x": 0.016781083142639208, "ncat": 2}, {"cat25k": 12, "ncat25k": 2, "os": 0.8451055395299674, "cat": 4, "y": 0.6575133485888635, "term": "kernel", "s": 0.9900611620795106, "bg": 1.2074433682357221e-06, "x": 0.017543859649122806, "ncat": 2}, {"cat25k": 9, "ncat25k": 2, "os": 0.7935922478010495, "cat": 3, "y": 0.5484363081617086, "term": "interpretable", "s": 0.9717125382262997, "bg": 7.768197001475959e-05, "x": 0.018306636155606407, "ncat": 2}, {"cat25k": 9, "ncat25k": 2, "os": 0.7935922478010495, "cat": 3, "y": 0.5491990846681922, "term": "feedback", "s": 0.9717125382262997, "bg": 1.0591571506747626e-07, "x": 0.01906941266209001, "ncat": 2}, {"cat25k": 12, "ncat25k": 2, "os": 0.8451055395299674, "cat": 4, "y": 0.6605644546147978, "term": "carefully", "s": 0.9900611620795106, "bg": 7.172246275811121e-07, "x": 0.019832189168573607, "ncat": 2}, {"cat25k": 9, "ncat25k": 2, "os": 0.7935922478010495, "cat": 3, "y": 0.562929061784897, "term": "probabilistic", "s": 0.9717125382262997, "bg": 8.0789855487146e-06, "x": 0.020594965675057208, "ncat": 2}, {"cat25k": 12, "ncat25k": 2, "os": 0.8451055395299674, "cat": 4, "y": 0.6704805491990846, "term": "frames", "s": 0.9900611620795106, "bg": 1.0346316334483401e-06, "x": 0.02135774218154081, "ncat": 2}, {"cat25k": 9, "ncat25k": 2, "os": 0.7935922478010495, "cat": 3, "y": 0.5682684973302822, "term": "usage", "s": 0.9717125382262997, "bg": 3.92220894728814e-07, "x": 0.02212051868802441, "ncat": 2}, {"cat25k": 9, "ncat25k": 2, "os": 0.7935922478010495, "cat": 3, "y": 0.5697940503432495, "term": "incorporate", "s": 0.9717125382262997, "bg": 1.363124324571897e-06, "x": 0.02288329519450801, "ncat": 2}, {"cat25k": 12, "ncat25k": 2, "os": 0.8451055395299674, "cat": 4, "y": 0.6735316552250191, "term": "motivated", "s": 0.9900611620795106, "bg": 2.1950840726346002e-06, "x": 0.02364607170099161, "ncat": 2}, {"cat25k": 9, "ncat25k": 2, "os": 0.7935922478010495, "cat": 3, "y": 0.5766590389016019, "term": "involves", "s": 0.9717125382262997, "bg": 7.731851353920626e-07, "x": 0.02440884820747521, "ncat": 2}, {"cat25k": 12, "ncat25k": 3, "os": 0.7914838226498992, "cat": 4, "y": 0.581998474446987, "term": "arguments", "s": 0.9640672782874617, "bg": 1.996152131601747e-06, "x": 0.02517162471395881, "ncat": 3}, {"cat25k": 25, "ncat25k": 3, "os": 0.8920986241664888, "cat": 8, "y": 0.820747520976354, "term": "posts", "s": 0.9984709480122324, "bg": 1.3832689170358603e-07, "x": 0.02593440122044241, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.2494279176201373, "term": "environments", "s": 0.7798165137614679, "bg": 1.045790692462837e-06, "x": 0.02669717772692601, "ncat": 3}, {"cat25k": 9, "ncat25k": 3, "os": 0.7303054896577338, "cat": 3, "y": 0.4416475972540046, "term": "preliminary", "s": 0.9304281345565748, "bg": 9.116971888956802e-07, "x": 0.02745995423340961, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.2601067887109077, "term": "purpose", "s": 0.7798165137614679, "bg": 1.8642113429057683e-07, "x": 0.02822273073989321, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.26926010678871093, "term": "beneficial", "s": 0.7798165137614679, "bg": 1.3832092779038956e-06, "x": 0.028985507246376812, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.2715484363081617, "term": "utility", "s": 0.7798165137614679, "bg": 3.526512515046306e-07, "x": 0.029748283752860413, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.2784134248665141, "term": "always", "s": 0.7798165137614679, "bg": 7.831454690045982e-08, "x": 0.03051106025934401, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.2829900839054157, "term": "facilitate", "s": 0.7798165137614679, "bg": 8.782400911683473e-07, "x": 0.031273836765827616, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.2898550724637681, "term": "digital", "s": 0.7798165137614679, "bg": 5.928789340870749e-08, "x": 0.032036613272311214, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.2906178489702517, "term": "estimated", "s": 0.7798165137614679, "bg": 3.0499940692865326e-07, "x": 0.03279938977879481, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.2913806254767353, "term": "established", "s": 0.7798165137614679, "bg": 1.9656562119178678e-07, "x": 0.033562166285278416, "ncat": 3}, {"cat25k": 19, "ncat25k": 3, "os": 0.8596107167225104, "cat": 6, "y": 0.7681159420289855, "term": "health", "s": 0.9969418960244648, "bg": 7.71899456172768e-08, "x": 0.034324942791762014, "ncat": 3}, {"cat25k": 9, "ncat25k": 3, "os": 0.7303054896577338, "cat": 3, "y": 0.4874141876430206, "term": "growing", "s": 0.9304281345565748, "bg": 3.0939991757070536e-07, "x": 0.03508771929824561, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.2982456140350877, "term": "product", "s": 0.7798165137614679, "bg": 2.5051870775255646e-08, "x": 0.03585049580472922, "ncat": 3}, {"cat25k": 9, "ncat25k": 3, "os": 0.7303054896577338, "cat": 3, "y": 0.4897025171624714, "term": "considered", "s": 0.9304281345565748, "bg": 2.0893645598152862e-07, "x": 0.036613272311212815, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.2997711670480549, "term": "co occurrence", "s": 0.7798165137614679, "bg": 0.0, "x": 0.03737604881769641, "ncat": 3}, {"cat25k": 12, "ncat25k": 3, "os": 0.7914838226498992, "cat": 4, "y": 0.6270022883295194, "term": "here", "s": 0.9640672782874617, "bg": 2.1882979389089145e-08, "x": 0.03813882532418002, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.30739893211289093, "term": "machines", "s": 0.7798165137614679, "bg": 3.6996239385118273e-07, "x": 0.038901601830663615, "ncat": 3}, {"cat25k": 12, "ncat25k": 3, "os": 0.7914838226498992, "cat": 4, "y": 0.6346300533943554, "term": "whose", "s": 0.9640672782874617, "bg": 3.66219065332497e-07, "x": 0.03966437833714721, "ncat": 3}, {"cat25k": 9, "ncat25k": 3, "os": 0.7303054896577338, "cat": 3, "y": 0.5041952707856598, "term": "linguistics", "s": 0.9304281345565748, "bg": 3.3872478345203624e-06, "x": 0.04042715484363082, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.3096872616323417, "term": "contain", "s": 0.7798165137614679, "bg": 4.05296673618743e-07, "x": 0.041189931350114416, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.3104500381388253, "term": "e", "s": 0.7798165137614679, "bg": 3.0346884872458074e-08, "x": 0.041952707856598014, "ncat": 3}, {"cat25k": 12, "ncat25k": 3, "os": 0.7914838226498992, "cat": 4, "y": 0.6361556064073226, "term": "year", "s": 0.9640672782874617, "bg": 3.9898213627971655e-08, "x": 0.04271548436308162, "ncat": 3}, {"cat25k": 9, "ncat25k": 3, "os": 0.7303054896577338, "cat": 3, "y": 0.5072463768115942, "term": "investigated", "s": 0.9304281345565748, "bg": 1.956719963370202e-06, "x": 0.043478260869565216, "ncat": 3}, {"cat25k": 9, "ncat25k": 3, "os": 0.7303054896577338, "cat": 3, "y": 0.509534706331045, "term": "reliable", "s": 0.9304281345565748, "bg": 6.860311368952103e-07, "x": 0.04424103737604882, "ncat": 3}, {"cat25k": 12, "ncat25k": 3, "os": 0.7914838226498992, "cat": 4, "y": 0.6399694889397407, "term": "integrates", "s": 0.9640672782874617, "bg": 5.069820481278058e-06, "x": 0.04500381388253242, "ncat": 3}, {"cat25k": 9, "ncat25k": 3, "os": 0.7303054896577338, "cat": 3, "y": 0.5102974828375286, "term": "intuitive", "s": 0.9304281345565748, "bg": 3.2582106326118488e-06, "x": 0.04576659038901602, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.32112890922959575, "term": "informed", "s": 0.7798165137614679, "bg": 2.6135003339138704e-07, "x": 0.04652936689549962, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.32646834477498093, "term": "efforts", "s": 0.7798165137614679, "bg": 2.6124677830472995e-07, "x": 0.04729214340198322, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.3310450038138825, "term": "matrices", "s": 0.7798165137614679, "bg": 3.4115150231181317e-06, "x": 0.04805491990846682, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.3333333333333333, "term": "narratives", "s": 0.7798165137614679, "bg": 7.80062639029914e-06, "x": 0.04881769641495042, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.3348588863463005, "term": "done", "s": 0.7798165137614679, "bg": 9.721190520373289e-08, "x": 0.04958047292143402, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.33714721586575136, "term": "easily", "s": 0.7798165137614679, "bg": 2.380684950676255e-07, "x": 0.05034324942791762, "ncat": 3}, {"cat25k": 9, "ncat25k": 3, "os": 0.7303054896577338, "cat": 3, "y": 0.5194508009153318, "term": "upon", "s": 0.9304281345565748, "bg": 1.3464561126044322e-07, "x": 0.05110602593440122, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.33790999237223496, "term": "string", "s": 0.7798165137614679, "bg": 1.8962099976724022e-07, "x": 0.05186880244088482, "ncat": 3}, {"cat25k": 9, "ncat25k": 3, "os": 0.7303054896577338, "cat": 3, "y": 0.520976353928299, "term": "classifying", "s": 0.9304281345565748, "bg": 1.4394029356622872e-05, "x": 0.05263157894736842, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.34630053394355453, "term": "reranking", "s": 0.7798165137614679, "bg": 0.00025255714105316333, "x": 0.05339435545385202, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.34706331045003813, "term": "adopted", "s": 0.7798165137614679, "bg": 4.3424614478443886e-07, "x": 0.05415713196033562, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.34782608695652173, "term": "argue", "s": 0.7798165137614679, "bg": 1.1891969543238964e-06, "x": 0.05491990846681922, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.3493516399694889, "term": "leads", "s": 0.7798165137614679, "bg": 3.2719589096929854e-07, "x": 0.05568268497330282, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.3524027459954233, "term": "behind", "s": 0.7798165137614679, "bg": 1.8559637050707382e-07, "x": 0.05644546147978642, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.35392829900839057, "term": "stories", "s": 0.7798165137614679, "bg": 1.7307011226876457e-07, "x": 0.057208237986270026, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.35469107551487417, "term": "illustrate", "s": 0.7798165137614679, "bg": 2.0419064545479793e-06, "x": 0.057971014492753624, "ncat": 3}, {"cat25k": 12, "ncat25k": 3, "os": 0.7914838226498992, "cat": 4, "y": 0.6559877955758963, "term": "phenomena", "s": 0.9640672782874617, "bg": 3.205431282765518e-06, "x": 0.05873379099923722, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.35545385202135776, "term": "style", "s": 0.7798165137614679, "bg": 1.582909327985738e-07, "x": 0.059496567505720827, "ncat": 3}, {"cat25k": 9, "ncat25k": 3, "os": 0.7303054896577338, "cat": 3, "y": 0.5377574370709383, "term": "unique", "s": 0.9304281345565748, "bg": 1.899565808328333e-07, "x": 0.060259344012204424, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.35774218154080856, "term": "reveal", "s": 0.7798165137614679, "bg": 1.4399152177919764e-06, "x": 0.06102212051868802, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.36003051106025935, "term": "predictive", "s": 0.7798165137614679, "bg": 6.948862548410409e-06, "x": 0.06178489702517163, "ncat": 3}, {"cat25k": 16, "ncat25k": 3, "os": 0.8321629577072732, "cat": 5, "y": 0.7345537757437071, "term": "steps", "s": 0.9877675840978594, "bg": 4.6985456200196884e-07, "x": 0.06254767353165523, "ncat": 3}, {"cat25k": 9, "ncat25k": 3, "os": 0.7303054896577338, "cat": 3, "y": 0.5408085430968727, "term": "characterize", "s": 0.9304281345565748, "bg": 5.54746806623122e-06, "x": 0.06331045003813883, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.36155606407322655, "term": "sparse", "s": 0.7798165137614679, "bg": 6.66411209036536e-06, "x": 0.06407322654462243, "ncat": 3}, {"cat25k": 9, "ncat25k": 3, "os": 0.7303054896577338, "cat": 3, "y": 0.543859649122807, "term": "processes", "s": 0.9304281345565748, "bg": 3.0375231307386406e-07, "x": 0.06483600305110603, "ncat": 3}, {"cat25k": 9, "ncat25k": 3, "os": 0.7303054896577338, "cat": 3, "y": 0.5461479786422578, "term": "coreference", "s": 0.9304281345565748, "bg": 0.0005253149262983159, "x": 0.06559877955758962, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.36613272311212813, "term": "crf", "s": 0.7798165137614679, "bg": 3.4057496622631584e-05, "x": 0.06636155606407322, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.36765827612509533, "term": "structural", "s": 0.7798165137614679, "bg": 6.141868565241078e-07, "x": 0.06712433257055683, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.3684210526315789, "term": "advantages", "s": 0.7798165137614679, "bg": 7.921021082985766e-07, "x": 0.06788710907704043, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.3714721586575134, "term": "infer", "s": 0.7798165137614679, "bg": 1.0345077294969189e-05, "x": 0.06864988558352403, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.37223493516399697, "term": "clustering", "s": 0.7798165137614679, "bg": 7.322742938404383e-06, "x": 0.06941266209000763, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.37376048817696417, "term": "utterance", "s": 0.7798165137614679, "bg": 1.5731680458106537e-05, "x": 0.07017543859649122, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.37757437070938216, "term": "morphology", "s": 0.7798165137614679, "bg": 5.32354747007279e-06, "x": 0.07093821510297482, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.38672768878718533, "term": "whole", "s": 0.7798165137614679, "bg": 1.4074931793466986e-07, "x": 0.07170099160945843, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.3897787948131198, "term": "factual", "s": 0.7798165137614679, "bg": 5.222741776221836e-06, "x": 0.07246376811594203, "ncat": 3}, {"cat25k": 16, "ncat25k": 3, "os": 0.8321629577072732, "cat": 5, "y": 0.7414187643020596, "term": "diverse", "s": 0.9877675840978594, "bg": 1.186260288491088e-06, "x": 0.07322654462242563, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.39359267734553777, "term": "clauses", "s": 0.7798165137614679, "bg": 2.8088065072182115e-06, "x": 0.07398932112890923, "ncat": 3}, {"cat25k": 12, "ncat25k": 3, "os": 0.7914838226498992, "cat": 4, "y": 0.6689549961861174, "term": "benefit", "s": 0.9640672782874617, "bg": 2.931387545283918e-07, "x": 0.07475209763539283, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.39511823035850496, "term": "claim", "s": 0.7798165137614679, "bg": 2.491232543030499e-07, "x": 0.07551487414187644, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.39588100686498856, "term": "run", "s": 0.7798165137614679, "bg": 8.527403099792889e-08, "x": 0.07627765064836003, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.39816933638443935, "term": "manual", "s": 0.7798165137614679, "bg": 2.4118771442844e-07, "x": 0.07704042715484363, "ncat": 3}, {"cat25k": 12, "ncat25k": 3, "os": 0.7914838226498992, "cat": 4, "y": 0.669717772692601, "term": "interesting", "s": 0.9640672782874617, "bg": 2.9762741839018986e-07, "x": 0.07780320366132723, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.39969488939740655, "term": "compositional", "s": 0.7798165137614679, "bg": 5.5733765992494514e-05, "x": 0.07856598016781083, "ncat": 3}, {"cat25k": 9, "ncat25k": 3, "os": 0.7303054896577338, "cat": 3, "y": 0.5659801678108314, "term": "namely", "s": 0.9304281345565748, "bg": 1.820958780321809e-06, "x": 0.07932875667429443, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.40122044241037375, "term": "annotator", "s": 0.7798165137614679, "bg": 6.792601498447891e-05, "x": 0.08009153318077804, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.40198321891685734, "term": "physical", "s": 0.7798165137614679, "bg": 3.1179122060775344e-07, "x": 0.08085430968726164, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.40274599542334094, "term": "dependent", "s": 0.7798165137614679, "bg": 6.212250869326856e-07, "x": 0.08161708619374523, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.40350877192982454, "term": "aware", "s": 0.7798165137614679, "bg": 4.6591519722190297e-07, "x": 0.08237986270022883, "ncat": 3}, {"cat25k": 12, "ncat25k": 3, "os": 0.7914838226498992, "cat": 4, "y": 0.6712433257055682, "term": "statements", "s": 0.9640672782874617, "bg": 4.0612276481996363e-07, "x": 0.08314263920671243, "ncat": 3}, {"cat25k": 9, "ncat25k": 3, "os": 0.7303054896577338, "cat": 3, "y": 0.5690312738367659, "term": "active", "s": 0.9304281345565748, "bg": 1.66388961509087e-07, "x": 0.08390541571319603, "ncat": 3}, {"cat25k": 16, "ncat25k": 3, "os": 0.8321629577072732, "cat": 5, "y": 0.7421815408085431, "term": "entailment", "s": 0.9877675840978594, "bg": 0.00019278748015422997, "x": 0.08466819221967964, "ncat": 3}, {"cat25k": 12, "ncat25k": 3, "os": 0.7914838226498992, "cat": 4, "y": 0.6727688787185355, "term": "coverage", "s": 0.9640672782874617, "bg": 3.6632559311776783e-07, "x": 0.08543096872616324, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.40503432494279173, "term": "hybrid", "s": 0.7798165137614679, "bg": 1.0581829019260213e-06, "x": 0.08619374523264683, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.406559877955759, "term": "call", "s": 0.7798165137614679, "bg": 5.008406610495717e-08, "x": 0.08695652173913043, "ncat": 3}, {"cat25k": 9, "ncat25k": 3, "os": 0.7303054896577338, "cat": 3, "y": 0.5713196033562167, "term": "responses", "s": 0.9304281345565748, "bg": 1.084425621040126e-06, "x": 0.08771929824561403, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.4073226544622426, "term": "demonstrates", "s": 0.7798165137614679, "bg": 1.6784902316064745e-06, "x": 0.08848207475209764, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.4088482074752098, "term": "partial", "s": 0.7798165137614679, "bg": 6.80383701027427e-07, "x": 0.08924485125858124, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.41189931350114417, "term": "implemented", "s": 0.7798165137614679, "bg": 5.203033285156714e-07, "x": 0.09000762776506484, "ncat": 3}, {"cat25k": 9, "ncat25k": 3, "os": 0.7303054896577338, "cat": 3, "y": 0.5751334858886347, "term": "get", "s": 0.9304281345565748, "bg": 1.9800675183223075e-08, "x": 0.09077040427154844, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.41266209000762777, "term": "gap", "s": 0.7798165137614679, "bg": 5.771895164837245e-07, "x": 0.09153318077803203, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.41342486651411137, "term": "third", "s": 0.7798165137614679, "bg": 1.0466308476796156e-07, "x": 0.09229595728451563, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.41495041952707856, "term": "relied", "s": 0.7798165137614679, "bg": 2.967527239674415e-06, "x": 0.09305873379099924, "ncat": 3}, {"cat25k": 6, "ncat25k": 3, "os": 0.6371522655702668, "cat": 2, "y": 0.41647597254004576, "term": "rumour veracity", "s": 0.7798165137614679, "bg": 0.0, "x": 0.09382151029748284, "ncat": 3}, {"cat25k": 9, "ncat25k": 5, "os": 0.6773350476619996, "cat": 3, "y": 0.41952707856598015, "term": "degree", "s": 0.8715596330275229, "bg": 2.0869009712869404e-07, "x": 0.09458428680396644, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.2379862700228833, "term": "communication", "s": 0.632262996941896, "bg": 2.483161526491267e-07, "x": 0.09534706331045004, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.07627765064836003, "term": "side", "s": 0.24388379204892963, "bg": 7.081611120916783e-08, "x": 0.09610983981693363, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.2395118230358505, "term": "initial", "s": 0.632262996941896, "bg": 2.8965700724111143e-07, "x": 0.09687261632341723, "ncat": 4}, {"cat25k": 12, "ncat25k": 5, "os": 0.7432196939732622, "cat": 4, "y": 0.5850495804729214, "term": "others", "s": 0.948012232415902, "bg": 1.4355808056673282e-07, "x": 0.09763539282990084, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.07704042715484363, "term": "neutral", "s": 0.24388379204892963, "bg": 9.356930013719131e-07, "x": 0.09839816933638444, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.24561403508771928, "term": "comment", "s": 0.632262996941896, "bg": 9.415932276633471e-08, "x": 0.09916094584286804, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.08085430968726164, "term": "availability", "s": 0.24388379204892963, "bg": 1.240089545377964e-07, "x": 0.09992372234935164, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.08237986270022883, "term": "providing", "s": 0.24388379204892963, "bg": 1.7237491661578874e-07, "x": 0.10068649885583524, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.2479023646071701, "term": "unseen", "s": 0.632262996941896, "bg": 6.7624340028706535e-06, "x": 0.10144927536231885, "ncat": 4}, {"cat25k": 9, "ncat25k": 5, "os": 0.6773350476619996, "cat": 3, "y": 0.43478260869565216, "term": "deal", "s": 0.8715596330275229, "bg": 2.1914831233023733e-07, "x": 0.10221205186880244, "ncat": 4}, {"cat25k": 22, "ncat25k": 5, "os": 0.8456662300318669, "cat": 7, "y": 0.7925247902364607, "term": "class", "s": 0.9961773700305809, "bg": 2.7204731187356826e-07, "x": 0.10297482837528604, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.08390541571319603, "term": "seen", "s": 0.24388379204892963, "bg": 1.2751731615018797e-07, "x": 0.10373760488176964, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.09077040427154844, "term": "demonstrating", "s": 0.24388379204892963, "bg": 2.940723253239795e-06, "x": 0.10450038138825324, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.09229595728451563, "term": "cosine", "s": 0.24388379204892963, "bg": 3.239502493404575e-05, "x": 0.10526315789473684, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.2669717772692601, "term": "noisy", "s": 0.632262996941896, "bg": 5.822655157218305e-06, "x": 0.10602593440122045, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.09534706331045004, "term": "shelf", "s": 0.24388379204892963, "bg": 8.816434256643226e-07, "x": 0.10678871090770405, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.26849733028222733, "term": "free", "s": 0.632262996941896, "bg": 1.972070060802233e-08, "x": 0.10755148741418764, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.2738367658276125, "term": "examine", "s": 0.632262996941896, "bg": 1.0698426116325363e-06, "x": 0.10831426392067124, "ncat": 4}, {"cat25k": 9, "ncat25k": 5, "os": 0.6773350476619996, "cat": 3, "y": 0.45232646834477497, "term": "importance", "s": 0.8715596330275229, "bg": 5.281539040476395e-07, "x": 0.10907704042715484, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.10068649885583524, "term": "crafted", "s": 0.24388379204892963, "bg": 2.5571834158983927e-06, "x": 0.10983981693363844, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.10144927536231885, "term": "relying", "s": 0.24388379204892963, "bg": 1.582738276499312e-06, "x": 0.11060259344012205, "ncat": 4}, {"cat25k": 9, "ncat25k": 5, "os": 0.6773350476619996, "cat": 3, "y": 0.4569031273836766, "term": "interactions", "s": 0.8715596330275229, "bg": 1.654757514729617e-06, "x": 0.11136536994660565, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.10297482837528604, "term": "insights", "s": 0.24388379204892963, "bg": 1.3097369380262604e-06, "x": 0.11212814645308924, "ncat": 4}, {"cat25k": 9, "ncat25k": 5, "os": 0.6773350476619996, "cat": 3, "y": 0.4607170099160946, "term": "map", "s": 0.8715596330275229, "bg": 6.45719489825942e-08, "x": 0.11289092295957284, "ncat": 4}, {"cat25k": 9, "ncat25k": 5, "os": 0.6773350476619996, "cat": 3, "y": 0.463768115942029, "term": "introduced", "s": 0.8715596330275229, "bg": 5.362048533107733e-07, "x": 0.11365369946605644, "ncat": 4}, {"cat25k": 16, "ncat25k": 5, "os": 0.7894542749459637, "cat": 5, "y": 0.7048054919908466, "term": "reasoning", "s": 0.9617737003058103, "bg": 3.9654490424927606e-06, "x": 0.11441647597254005, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.2837528604118993, "term": "signals", "s": 0.632262996941896, "bg": 1.2484637068869397e-06, "x": 0.11517925247902365, "ncat": 4}, {"cat25k": 9, "ncat25k": 5, "os": 0.6773350476619996, "cat": 3, "y": 0.467581998474447, "term": "supporting", "s": 0.8715596330275229, "bg": 8.151027785508802e-07, "x": 0.11594202898550725, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.10678871090770405, "term": "phase", "s": 0.24388379204892963, "bg": 2.4522804012941077e-07, "x": 0.11670480549199085, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.10831426392067124, "term": "employing", "s": 0.24388379204892963, "bg": 3.0633406955621384e-06, "x": 0.11746758199847444, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.11136536994660565, "term": "action", "s": 0.24388379204892963, "bg": 1.1105704552498535e-07, "x": 0.11823035850495804, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.11289092295957284, "term": "factors", "s": 0.24388379204892963, "bg": 2.3718072006311476e-07, "x": 0.11899313501144165, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.11517925247902365, "term": "variable", "s": 0.24388379204892963, "bg": 2.875942399590282e-07, "x": 0.11975591151792525, "ncat": 4}, {"cat25k": 9, "ncat25k": 5, "os": 0.6773350476619996, "cat": 3, "y": 0.479023646071701, "term": "prior", "s": 0.8715596330275229, "bg": 3.809251901495222e-07, "x": 0.12051868802440885, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.11594202898550725, "term": "minimal", "s": 0.24388379204892963, "bg": 1.3509703640164315e-06, "x": 0.12128146453089245, "ncat": 4}, {"cat25k": 9, "ncat25k": 5, "os": 0.6773350476619996, "cat": 3, "y": 0.4851258581235698, "term": "roles", "s": 0.8715596330275229, "bg": 1.5120651839204268e-06, "x": 0.12204424103737604, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.11746758199847444, "term": "record", "s": 0.24388379204892963, "bg": 1.368655382898158e-07, "x": 0.12280701754385964, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.2951945080091533, "term": "electronic", "s": 0.632262996941896, "bg": 2.605423987289282e-07, "x": 0.12356979405034325, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.11975591151792525, "term": "superior", "s": 0.24388379204892963, "bg": 5.075258470225742e-07, "x": 0.12433257055682685, "ncat": 4}, {"cat25k": 9, "ncat25k": 5, "os": 0.6773350476619996, "cat": 3, "y": 0.4889397406559878, "term": "explicit", "s": 0.8715596330275229, "bg": 1.4546483756409154e-06, "x": 0.12509534706331046, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.12204424103737604, "term": "exact", "s": 0.24388379204892963, "bg": 6.261077075200454e-07, "x": 0.12585812356979406, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.12585812356979406, "term": "taxonomy", "s": 0.24388379204892963, "bg": 3.2332725298471467e-06, "x": 0.12662090007627766, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.12662090007627766, "term": "labels", "s": 0.24388379204892963, "bg": 8.656670340521489e-07, "x": 0.12738367658276126, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.3005339435545385, "term": "co", "s": 0.632262996941896, "bg": 1.7466001423933228e-07, "x": 0.12814645308924486, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.3012967200610221, "term": "classes", "s": 0.632262996941896, "bg": 3.681553101627699e-07, "x": 0.12890922959572845, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.12890922959572845, "term": "setup", "s": 0.24388379204892963, "bg": 5.934647408396704e-07, "x": 0.12967200610221205, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.13119755911517925, "term": "weakly", "s": 0.24388379204892963, "bg": 1.1165083434575056e-05, "x": 0.13043478260869565, "ncat": 4}, {"cat25k": 9, "ncat25k": 5, "os": 0.6773350476619996, "cat": 3, "y": 0.4950419527078566, "term": "group", "s": 0.8715596330275229, "bg": 5.5918261592953026e-08, "x": 0.13119755911517925, "ncat": 4}, {"cat25k": 9, "ncat25k": 5, "os": 0.6773350476619996, "cat": 3, "y": 0.4988558352402746, "term": "mentions", "s": 0.8715596330275229, "bg": 8.424132612695589e-06, "x": 0.13196033562166284, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.30511060259344014, "term": "creation", "s": 0.632262996941896, "bg": 6.112994630413439e-07, "x": 0.13272311212814644, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.13577421815408086, "term": "complicated", "s": 0.24388379204892963, "bg": 1.1794021657597852e-06, "x": 0.13348588863463004, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.30587337909992374, "term": "dictionary", "s": 0.632262996941896, "bg": 4.890724584322646e-07, "x": 0.13424866514111367, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.13806254767353165, "term": "identifies", "s": 0.24388379204892963, "bg": 1.5161972317877421e-06, "x": 0.13501144164759726, "ncat": 4}, {"cat25k": 12, "ncat25k": 5, "os": 0.7432196939732622, "cat": 4, "y": 0.635392829900839, "term": "increasing", "s": 0.948012232415902, "bg": 6.313048060252853e-07, "x": 0.13577421815408086, "ncat": 4}, {"cat25k": 16, "ncat25k": 5, "os": 0.7894542749459637, "cat": 5, "y": 0.7223493516399695, "term": "attempt", "s": 0.9617737003058103, "bg": 7.902844953057497e-07, "x": 0.13653699466056446, "ncat": 4}, {"cat25k": 9, "ncat25k": 5, "os": 0.6773350476619996, "cat": 3, "y": 0.5049580472921434, "term": "own", "s": 0.8715596330275229, "bg": 6.032736489432395e-08, "x": 0.13729977116704806, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.30892448512585813, "term": "extrinsic", "s": 0.632262996941896, "bg": 3.010642621667595e-05, "x": 0.13806254767353165, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.3112128146453089, "term": "investigating", "s": 0.632262996941896, "bg": 2.4290912830237495e-06, "x": 0.13882532418001525, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.13958810068649885, "term": "identified", "s": 0.24388379204892963, "bg": 3.0050324376723967e-07, "x": 0.13958810068649885, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.3127383676582761, "term": "million", "s": 0.632262996941896, "bg": 1.1777171771253238e-07, "x": 0.14035087719298245, "ncat": 4}, {"cat25k": 9, "ncat25k": 5, "os": 0.6773350476619996, "cat": 3, "y": 0.5080091533180778, "term": "summarization", "s": 0.8715596330275229, "bg": 0.00011982744847419715, "x": 0.14111365369946605, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.14035087719298245, "term": "assessing", "s": 0.24388379204892963, "bg": 1.5281878839763082e-06, "x": 0.14187643020594964, "ncat": 4}, {"cat25k": 16, "ncat25k": 5, "os": 0.7894542749459637, "cat": 5, "y": 0.7254004576659039, "term": "extension", "s": 0.9617737003058103, "bg": 5.793804019074941e-07, "x": 0.14263920671243327, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.3142639206712433, "term": "discuss", "s": 0.632262996941896, "bg": 2.7736852437240687e-07, "x": 0.14340198321891687, "ncat": 4}, {"cat25k": 12, "ncat25k": 5, "os": 0.7432196939732622, "cat": 4, "y": 0.6384439359267735, "term": "total", "s": 0.948012232415902, "bg": 7.184395360365971e-08, "x": 0.14416475972540047, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.3150266971777269, "term": "certain", "s": 0.632262996941896, "bg": 1.6401588521184258e-07, "x": 0.14492753623188406, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.14569031273836766, "term": "substantially", "s": 0.24388379204892963, "bg": 1.245552133331872e-06, "x": 0.14569031273836766, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.14797864225781845, "term": "looking", "s": 0.24388379204892963, "bg": 7.964657733966732e-08, "x": 0.14645308924485126, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.14874141876430205, "term": "summary", "s": 0.24388379204892963, "bg": 1.489165317131281e-07, "x": 0.14721586575133486, "ncat": 4}, {"cat25k": 9, "ncat25k": 5, "os": 0.6773350476619996, "cat": 3, "y": 0.5148741418764302, "term": "writing", "s": 0.8715596330275229, "bg": 3.1241680400589476e-07, "x": 0.14797864225781845, "ncat": 4}, {"cat25k": 9, "ncat25k": 5, "os": 0.6773350476619996, "cat": 3, "y": 0.5156369183829138, "term": "translations", "s": 0.8715596330275229, "bg": 2.6668859439553915e-06, "x": 0.14874141876430205, "ncat": 4}, {"cat25k": 12, "ncat25k": 5, "os": 0.7432196939732622, "cat": 4, "y": 0.6475972540045767, "term": "relatedness", "s": 0.948012232415902, "bg": 9.258237160427445e-05, "x": 0.14950419527078565, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.15713196033562166, "term": "conducted", "s": 0.24388379204892963, "bg": 4.038687068067466e-07, "x": 0.15026697177726925, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.3356216628527841, "term": "embedded", "s": 0.632262996941896, "bg": 9.826811455998527e-07, "x": 0.15102974828375287, "ncat": 4}, {"cat25k": 9, "ncat25k": 5, "os": 0.6773350476619996, "cat": 3, "y": 0.5217391304347826, "term": "working", "s": 0.8715596330275229, "bg": 1.0830468257055045e-07, "x": 0.15179252479023647, "ncat": 4}, {"cat25k": 12, "ncat25k": 5, "os": 0.7432196939732622, "cat": 4, "y": 0.6506483600305111, "term": "affect", "s": 0.948012232415902, "bg": 1.226412911478906e-06, "x": 0.15255530129672007, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.16323417238749047, "term": "potentially", "s": 0.24388379204892963, "bg": 9.436445117493649e-07, "x": 0.15331807780320367, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.16399694889397406, "term": "inducing", "s": 0.24388379204892963, "bg": 1.2584700936380403e-05, "x": 0.15408085430968727, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.16552250190694126, "term": "switching", "s": 0.24388379204892963, "bg": 2.8080684229998054e-06, "x": 0.15484363081617086, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.34248665141113654, "term": "influence", "s": 0.632262996941896, "bg": 6.034067818924714e-07, "x": 0.15560640732265446, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.34401220442410374, "term": "conduct", "s": 0.632262996941896, "bg": 3.998537468278686e-07, "x": 0.15636918382913806, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.34477498093058734, "term": "basic", "s": 0.632262996941896, "bg": 1.4134998517827614e-07, "x": 0.15713196033562166, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.16933638443935928, "term": "produced", "s": 0.24388379204892963, "bg": 2.5584563788816006e-07, "x": 0.15789473684210525, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.17086193745232647, "term": "article", "s": 0.24388379204892963, "bg": 7.691260159577828e-08, "x": 0.15865751334858885, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.17238749046529367, "term": "obtains", "s": 0.24388379204892963, "bg": 6.342079060357566e-06, "x": 0.15942028985507245, "ncat": 4}, {"cat25k": 9, "ncat25k": 5, "os": 0.6773350476619996, "cat": 3, "y": 0.5316552250190694, "term": "findings", "s": 0.8715596330275229, "bg": 6.726596477194939e-07, "x": 0.16018306636155608, "ncat": 4}, {"cat25k": 9, "ncat25k": 5, "os": 0.6773350476619996, "cat": 3, "y": 0.532418001525553, "term": "encode", "s": 0.8715596330275229, "bg": 9.611461055670455e-06, "x": 0.16094584286803967, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.17543859649122806, "term": "measured", "s": 0.24388379204892963, "bg": 5.625371415147686e-07, "x": 0.16170861937452327, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.17620137299771166, "term": "hence", "s": 0.24388379204892963, "bg": 7.974605665718087e-07, "x": 0.16247139588100687, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.17696414950419528, "term": "augment", "s": 0.24388379204892963, "bg": 9.290874038975215e-06, "x": 0.16323417238749047, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.3531655225019069, "term": "population", "s": 0.632262996941896, "bg": 2.559693737763664e-07, "x": 0.16399694889397406, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.18077803203661327, "term": "emotional", "s": 0.24388379204892963, "bg": 9.079725895181526e-07, "x": 0.16475972540045766, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.18230358504958047, "term": "post", "s": 0.24388379204892963, "bg": 2.5444524299822225e-08, "x": 0.16552250190694126, "ncat": 4}, {"cat25k": 9, "ncat25k": 5, "os": 0.6773350476619996, "cat": 3, "y": 0.5392829900839055, "term": "presented", "s": 0.8715596330275229, "bg": 2.992406917068285e-07, "x": 0.16628527841342486, "ncat": 4}, {"cat25k": 9, "ncat25k": 5, "os": 0.6773350476619996, "cat": 3, "y": 0.5430968726163234, "term": "contexts", "s": 0.8715596330275229, "bg": 5.699594085272145e-06, "x": 0.16704805491990846, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.36231884057971014, "term": "furthermore", "s": 0.632262996941896, "bg": 1.0418928623306155e-06, "x": 0.16781083142639205, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.18611746758199849, "term": "entropy", "s": 0.24388379204892963, "bg": 7.759513284529229e-06, "x": 0.16857360793287568, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.18688024408848208, "term": "papers", "s": 0.24388379204892963, "bg": 1.9577090598840297e-07, "x": 0.16933638443935928, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.36536994660564454, "term": "arbitrary", "s": 0.632262996941896, "bg": 1.8468624730781318e-06, "x": 0.17009916094584288, "ncat": 4}, {"cat25k": 9, "ncat25k": 5, "os": 0.6773350476619996, "cat": 3, "y": 0.547673531655225, "term": "solution", "s": 0.8715596330275229, "bg": 2.1605264976219427e-07, "x": 0.17086193745232647, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.36689549961861173, "term": "captures", "s": 0.632262996941896, "bg": 3.24523687119141e-06, "x": 0.17162471395881007, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.3691838291380625, "term": "extensive", "s": 0.632262996941896, "bg": 5.527530464293211e-07, "x": 0.17238749046529367, "ncat": 4}, {"cat25k": 9, "ncat25k": 5, "os": 0.6773350476619996, "cat": 3, "y": 0.5522501906941266, "term": "leveraging", "s": 0.8715596330275229, "bg": 6.401679800779725e-06, "x": 0.17315026697177727, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.19374523264683446, "term": "theoretical", "s": 0.24388379204892963, "bg": 9.611411590535796e-07, "x": 0.17391304347826086, "ncat": 4}, {"cat25k": 9, "ncat25k": 5, "os": 0.6773350476619996, "cat": 3, "y": 0.5530129672006102, "term": "dictionaries", "s": 0.8715596330275229, "bg": 2.566649470115217e-06, "x": 0.17467581998474446, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.19603356216628529, "term": "lower", "s": 0.24388379204892963, "bg": 1.3762283904962182e-07, "x": 0.17543859649122806, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.37452326468344777, "term": "grounded", "s": 0.632262996941896, "bg": 4.742629361144112e-06, "x": 0.17620137299771166, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.19832189168573608, "term": "beam", "s": 0.24388379204892963, "bg": 1.514742611148657e-06, "x": 0.17696414950419528, "ncat": 4}, {"cat25k": 9, "ncat25k": 5, "os": 0.6773350476619996, "cat": 3, "y": 0.5560640732265446, "term": "efficiently", "s": 0.8715596330275229, "bg": 2.190854060638459e-06, "x": 0.17772692601067888, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.19984744469870327, "term": "yield", "s": 0.24388379204892963, "bg": 6.632212323645329e-07, "x": 0.17848970251716248, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.37681159420289856, "term": "distinct", "s": 0.632262996941896, "bg": 1.1561373067203372e-06, "x": 0.17925247902364608, "ncat": 4}, {"cat25k": 9, "ncat25k": 5, "os": 0.6773350476619996, "cat": 3, "y": 0.5568268497330282, "term": "units", "s": 0.8715596330275229, "bg": 2.828467150058774e-07, "x": 0.18001525553012968, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.20061022120518687, "term": "supports", "s": 0.24388379204892963, "bg": 3.4519271677886865e-07, "x": 0.18077803203661327, "ncat": 4}, {"cat25k": 9, "ncat25k": 5, "os": 0.6773350476619996, "cat": 3, "y": 0.5583524027459954, "term": "extent", "s": 0.8715596330275229, "bg": 5.606102130046512e-07, "x": 0.18154080854309687, "ncat": 4}, {"cat25k": 9, "ncat25k": 5, "os": 0.6773350476619996, "cat": 3, "y": 0.559115179252479, "term": "political", "s": 0.8715596330275229, "bg": 5.848150933465405e-07, "x": 0.18230358504958047, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.20137299771167047, "term": "version", "s": 0.24388379204892963, "bg": 4.3010496660097294e-08, "x": 0.18306636155606407, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.2028985507246377, "term": "majority", "s": 0.24388379204892963, "bg": 3.507292836750705e-07, "x": 0.18382913806254766, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.38062547673531655, "term": "sts", "s": 0.632262996941896, "bg": 8.267027182536511e-06, "x": 0.18459191456903126, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.2051868802440885, "term": "exploring", "s": 0.24388379204892963, "bg": 1.2098067418416382e-06, "x": 0.1853546910755149, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.38138825324180015, "term": "conversational", "s": 0.632262996941896, "bg": 1.6232662755271304e-05, "x": 0.18611746758199849, "ncat": 4}, {"cat25k": 12, "ncat25k": 5, "os": 0.7432196939732622, "cat": 4, "y": 0.6643783371472158, "term": "necessary", "s": 0.948012232415902, "bg": 2.2020417634010997e-07, "x": 0.18688024408848208, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.38443935926773454, "term": "complexity", "s": 0.632262996941896, "bg": 1.5234952485039753e-06, "x": 0.18764302059496568, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.20594965675057209, "term": "view", "s": 0.24388379204892963, "bg": 1.660206347212916e-08, "x": 0.18840579710144928, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.20671243325705568, "term": "representing", "s": 0.24388379204892963, "bg": 9.776258909226947e-07, "x": 0.18916857360793288, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.38596491228070173, "term": "poetry", "s": 0.632262996941896, "bg": 1.261494382013613e-06, "x": 0.18993135011441648, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.20900076277650648, "term": "interface", "s": 0.24388379204892963, "bg": 1.6845414766538973e-07, "x": 0.19069412662090007, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.38749046529366893, "term": "practical", "s": 0.632262996941896, "bg": 4.795448927150178e-07, "x": 0.19145690312738367, "ncat": 4}, {"cat25k": 12, "ncat25k": 5, "os": 0.7432196939732622, "cat": 4, "y": 0.665903890160183, "term": "fields", "s": 0.948012232415902, "bg": 5.398326567839666e-07, "x": 0.19221967963386727, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.20976353928299007, "term": "helps", "s": 0.24388379204892963, "bg": 3.37115499545838e-07, "x": 0.19298245614035087, "ncat": 4}, {"cat25k": 12, "ncat25k": 5, "os": 0.7432196939732622, "cat": 4, "y": 0.6674294431731502, "term": "access", "s": 0.948012232415902, "bg": 7.338021723828067e-08, "x": 0.19374523264683446, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.21052631578947367, "term": "phrases", "s": 0.24388379204892963, "bg": 1.8039540869632146e-06, "x": 0.1945080091533181, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.2135774218154081, "term": "enabling", "s": 0.24388379204892963, "bg": 1.091289415191098e-06, "x": 0.1952707856598017, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.2151029748283753, "term": "likely", "s": 0.24388379204892963, "bg": 1.7945308156113843e-07, "x": 0.19603356216628529, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.39740655987795576, "term": "overcome", "s": 0.632262996941896, "bg": 1.5643119947272257e-06, "x": 0.19679633867276888, "ncat": 4}, {"cat25k": 9, "ncat25k": 5, "os": 0.6773350476619996, "cat": 3, "y": 0.5636918382913806, "term": "additionally", "s": 0.8715596330275229, "bg": 1.5922056529214585e-06, "x": 0.19755911517925248, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.40045766590389015, "term": "quantitative", "s": 0.632262996941896, "bg": 1.7361766698655723e-06, "x": 0.19832189168573608, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.21891685736079328, "term": "cognitive", "s": 0.24388379204892963, "bg": 2.177231744183979e-06, "x": 0.19908466819221968, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.21967963386727687, "term": "robot", "s": 0.24388379204892963, "bg": 2.2026861442860123e-06, "x": 0.19984744469870327, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.40427154843630814, "term": "simultaneously", "s": 0.632262996941896, "bg": 1.577798689454112e-06, "x": 0.20061022120518687, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.2234935163996949, "term": "distributed", "s": 0.24388379204892963, "bg": 3.5523554674445094e-07, "x": 0.20137299771167047, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.2250190694126621, "term": "token", "s": 0.24388379204892963, "bg": 2.444225395292352e-06, "x": 0.20213577421815407, "ncat": 4}, {"cat25k": 9, "ncat25k": 5, "os": 0.6773350476619996, "cat": 3, "y": 0.5705568268497331, "term": "keyphrase", "s": 0.8715596330275229, "bg": 0.00039677291363576247, "x": 0.2028985507246377, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.22654462242562928, "term": "faster", "s": 0.24388379204892963, "bg": 3.1648907778785656e-07, "x": 0.2036613272311213, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.2303585049580473, "term": "optimization", "s": 0.24388379204892963, "bg": 1.2404388523807059e-06, "x": 0.2044241037376049, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.410373760488177, "term": "quantification", "s": 0.632262996941896, "bg": 2.1319688732544504e-05, "x": 0.2051868802440885, "ncat": 4}, {"cat25k": 9, "ncat25k": 5, "os": 0.6773350476619996, "cat": 3, "y": 0.5736079328756675, "term": "submissions", "s": 0.8715596330275229, "bg": 1.8639256025279306e-06, "x": 0.20594965675057209, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.4111365369946606, "term": "having", "s": 0.632262996941896, "bg": 1.096736470530947e-07, "x": 0.20671243325705568, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.2311212814645309, "term": "evaluations", "s": 0.24388379204892963, "bg": 1.7885414587487222e-06, "x": 0.20747520976353928, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.2318840579710145, "term": "microblog", "s": 0.24388379204892963, "bg": 0.00025255714105316333, "x": 0.20823798627002288, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.2326468344774981, "term": "must", "s": 0.24388379204892963, "bg": 3.41494893966638e-08, "x": 0.20900076277650648, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.2334096109839817, "term": "fourth", "s": 0.24388379204892963, "bg": 3.8731411488441557e-07, "x": 0.20976353928299007, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.2349351639969489, "term": "b.", "s": 0.24388379204892963, "bg": 0.0, "x": 0.21052631578947367, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.41723874904652936, "term": "rumour", "s": 0.632262996941896, "bg": 2.6106776716771592e-05, "x": 0.2112890922959573, "ncat": 4}, {"cat25k": 6, "ncat25k": 5, "os": 0.5835599150872166, "cat": 2, "y": 0.41800152555301295, "term": "rumours", "s": 0.632262996941896, "bg": 1.4550152922107213e-05, "x": 0.2120518688024409, "ncat": 4}, {"cat25k": 3, "ncat25k": 5, "os": 0.4517558576810476, "cat": 1, "y": 0.23646071700991608, "term": "determining rumour", "s": 0.24388379204892963, "bg": 0.0, "x": 0.2128146453089245, "ncat": 4}, {"cat25k": 9, "ncat25k": 5, "os": 0.6773350476619996, "cat": 3, "y": 0.5758962623951183, "term": "veracity", "s": 0.8715596330275229, "bg": 4.3266630611141155e-05, "x": 0.2135774218154081, "ncat": 4}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.07398932112890923, "term": "difference", "s": 0.1720183486238532, "bg": 4.035668131763668e-07, "x": 0.2143401983218917, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.2387490465293669, "term": "computer", "s": 0.481651376146789, "bg": 6.24352011804891e-08, "x": 0.2151029748283753, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.0007627765064836003, "term": "individuals", "s": 0.0, "bg": 2.6380739316701917e-07, "x": 0.21586575133485889, "ncat": 5}, {"cat25k": 9, "ncat25k": 6, "os": 0.6338270477912181, "cat": 3, "y": 0.4241037376048818, "term": "occurrence", "s": 0.7652905198776758, "bg": 3.560635395386307e-06, "x": 0.21662852784134248, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.07780320366132723, "term": "determine", "s": 0.1720183486238532, "bg": 2.806170703900561e-07, "x": 0.21739130434782608, "ncat": 5}, {"cat25k": 9, "ncat25k": 6, "os": 0.6338270477912181, "cat": 3, "y": 0.4271548436308162, "term": "successfully", "s": 0.7652905198776758, "bg": 8.84876563590714e-07, "x": 0.21815408085430968, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.2418001525553013, "term": "response", "s": 0.481651376146789, "bg": 2.3775352683878904e-07, "x": 0.21891685736079328, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.002288329519450801, "term": "companies", "s": 0.0, "bg": 1.1848189520051256e-07, "x": 0.21967963386727687, "ncat": 5}, {"cat25k": 12, "ncat25k": 6, "os": 0.7011342931621475, "cat": 4, "y": 0.5926773455377574, "term": "fast", "s": 0.9097859327217125, "bg": 1.9149566272430645e-07, "x": 0.2204424103737605, "ncat": 5}, {"cat25k": 9, "ncat25k": 6, "os": 0.6338270477912181, "cat": 3, "y": 0.43554538520213576, "term": "outperforming", "s": 0.7652905198776758, "bg": 9.442926362879857e-05, "x": 0.2212051868802441, "ncat": 5}, {"cat25k": 9, "ncat25k": 6, "os": 0.6338270477912181, "cat": 3, "y": 0.43630816170861936, "term": "vocabulary", "s": 0.7652905198776758, "bg": 3.9656973282181945e-06, "x": 0.2219679633867277, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.2501906941266209, "term": "behavior", "s": 0.481651376146789, "bg": 6.214334188311789e-07, "x": 0.2227307398932113, "ncat": 5}, {"cat25k": 9, "ncat25k": 6, "os": 0.6338270477912181, "cat": 3, "y": 0.440884820747521, "term": "strategies", "s": 0.7652905198776758, "bg": 5.959426813660805e-07, "x": 0.2234935163996949, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.2517162471395881, "term": "considering", "s": 0.481651376146789, "bg": 7.885230248441639e-07, "x": 0.2242562929061785, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.2578184591914569, "term": "inspired", "s": 0.481651376146789, "bg": 1.3808975437026023e-06, "x": 0.2250190694126621, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.2616323417238749, "term": "conditions", "s": 0.481651376146789, "bg": 1.1833448332756472e-07, "x": 0.22578184591914569, "ncat": 5}, {"cat25k": 19, "ncat25k": 6, "os": 0.7868932600914886, "cat": 6, "y": 0.7543859649122807, "term": "relatively", "s": 0.9610091743119266, "bg": 1.1139604870113727e-06, "x": 0.22654462242562928, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.2654462242562929, "term": "off", "s": 0.481651376146789, "bg": 4.9279962373763124e-08, "x": 0.22730739893211288, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.2662090007627765, "term": "candidates", "s": 0.481651376146789, "bg": 1.2922910316940836e-06, "x": 0.22807017543859648, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.005339435545385202, "term": "ranks", "s": 0.0, "bg": 1.6488202485019436e-06, "x": 0.2288329519450801, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.09382151029748284, "term": "sensitive", "s": 0.1720183486238532, "bg": 8.403297790184781e-07, "x": 0.2295957284515637, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.09458428680396644, "term": "weighted", "s": 0.1720183486238532, "bg": 2.2643305029741175e-06, "x": 0.2303585049580473, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.09610983981693363, "term": "frequency", "s": 0.1720183486238532, "bg": 4.687931279213556e-07, "x": 0.2311212814645309, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.009153318077803204, "term": "direct", "s": 0.0, "bg": 1.1731406859052486e-07, "x": 0.2318840579710145, "ncat": 5}, {"cat25k": 9, "ncat25k": 6, "os": 0.6338270477912181, "cat": 3, "y": 0.45308924485125857, "term": "performed", "s": 0.7652905198776758, "bg": 5.374528196202526e-07, "x": 0.2326468344774981, "ncat": 5}, {"cat25k": 9, "ncat25k": 6, "os": 0.6338270477912181, "cat": 3, "y": 0.45461479786422576, "term": "category", "s": 0.7652905198776758, "bg": 9.588452703117257e-08, "x": 0.2334096109839817, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.011441647597254004, "term": "analogies", "s": 0.0, "bg": 3.9333546688025975e-05, "x": 0.2341723874904653, "ncat": 5}, {"cat25k": 9, "ncat25k": 6, "os": 0.6338270477912181, "cat": 3, "y": 0.459954233409611, "term": "makes", "s": 0.7652905198776758, "bg": 1.820560297457706e-07, "x": 0.2349351639969489, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.2768878718535469, "term": "completion", "s": 0.481651376146789, "bg": 1.1602270374456948e-06, "x": 0.23569794050343248, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.012204424103737605, "term": "relationship", "s": 0.0, "bg": 2.0826743838360976e-07, "x": 0.23646071700991608, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.2776506483600305, "term": "regularities", "s": 0.481651376146789, "bg": 7.634243398765161e-05, "x": 0.2372234935163997, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.012967200610221205, "term": "modifying", "s": 0.0, "bg": 3.058450974101343e-06, "x": 0.2379862700228833, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.10373760488176964, "term": "informative", "s": 0.1720183486238532, "bg": 1.864933438971452e-06, "x": 0.2387490465293669, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.013729977116704805, "term": "allowing", "s": 0.0, "bg": 5.161275138442174e-07, "x": 0.2395118230358505, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.10450038138825324, "term": "critical", "s": 0.1720183486238532, "bg": 2.5978808998903567e-07, "x": 0.2402745995423341, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.2814645308924485, "term": "relevance", "s": 0.481651376146789, "bg": 2.43937690995589e-06, "x": 0.2410373760488177, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.2822273073989321, "term": "selection", "s": 0.481651376146789, "bg": 2.923504355769006e-07, "x": 0.2418001525553013, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.28451563691838294, "term": "tuned", "s": 0.481651376146789, "bg": 3.668146938630067e-06, "x": 0.2425629290617849, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.28604118993135014, "term": "bioasq", "s": 0.481651376146789, "bg": 0.0005411157807398856, "x": 0.2433257055682685, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.11365369946605644, "term": "compute", "s": 0.1720183486238532, "bg": 2.327129658162107e-06, "x": 0.2440884820747521, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.11441647597254005, "term": "produces", "s": 0.1720183486238532, "bg": 1.2021950880111996e-06, "x": 0.2448512585812357, "ncat": 5}, {"cat25k": 12, "ncat25k": 6, "os": 0.7011342931621475, "cat": 4, "y": 0.6140350877192983, "term": "similarities", "s": 0.9097859327217125, "bg": 7.753049855987098e-06, "x": 0.24561403508771928, "ncat": 5}, {"cat25k": 9, "ncat25k": 6, "os": 0.6338270477912181, "cat": 3, "y": 0.4774980930587338, "term": "retrieval", "s": 0.7652905198776758, "bg": 2.7280021578497067e-06, "x": 0.2463768115942029, "ncat": 5}, {"cat25k": 9, "ncat25k": 6, "os": 0.6338270477912181, "cat": 3, "y": 0.4813119755911518, "term": "construction", "s": 0.7652905198776758, "bg": 2.476766020859684e-07, "x": 0.2471395881006865, "ncat": 5}, {"cat25k": 22, "ncat25k": 6, "os": 0.8139616201954708, "cat": 7, "y": 0.8085430968726163, "term": "increase", "s": 0.9870030581039755, "bg": 2.9254557668101656e-07, "x": 0.2479023646071701, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.2936689549961861, "term": "far", "s": 0.481651376146789, "bg": 1.503481036491665e-07, "x": 0.2486651411136537, "ncat": 5}, {"cat25k": 9, "ncat25k": 6, "os": 0.6338270477912181, "cat": 3, "y": 0.4836003051106026, "term": "built", "s": 0.7652905198776758, "bg": 2.599160912882494e-07, "x": 0.2494279176201373, "ncat": 5}, {"cat25k": 12, "ncat25k": 6, "os": 0.7011342931621475, "cat": 4, "y": 0.6186117467581999, "term": "defined", "s": 0.9097859327217125, "bg": 3.9147669884689953e-07, "x": 0.2501906941266209, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.11899313501144165, "term": "procedure", "s": 0.1720183486238532, "bg": 4.4216926250422883e-07, "x": 0.2509534706331045, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.2967200610221205, "term": "date", "s": 0.481651376146789, "bg": 2.8628521614125863e-08, "x": 0.2517162471395881, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.2974828375286041, "term": "name", "s": 0.481651376146789, "bg": 3.013421769800471e-08, "x": 0.2524790236460717, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.12356979405034325, "term": "commands", "s": 0.1720183486238532, "bg": 1.6302455260386017e-06, "x": 0.2532418001525553, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.02288329519450801, "term": "rest", "s": 0.0, "bg": 1.873801738921742e-07, "x": 0.2540045766590389, "ncat": 5}, {"cat25k": 12, "ncat25k": 6, "os": 0.7011342931621475, "cat": 4, "y": 0.623951182303585, "term": "label", "s": 0.9097859327217125, "bg": 7.243700141913744e-07, "x": 0.2547673531655225, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.02364607170099161, "term": "leverages", "s": 0.0, "bg": 1.867842660405658e-05, "x": 0.2555301296720061, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.12967200610221205, "term": "sentiments", "s": 0.1720183486238532, "bg": 1.1099048603427525e-05, "x": 0.2562929061784897, "ncat": 5}, {"cat25k": 9, "ncat25k": 6, "os": 0.6338270477912181, "cat": 3, "y": 0.4927536231884058, "term": "distant", "s": 0.7652905198776758, "bg": 3.3907040457880678e-06, "x": 0.2570556826849733, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.02517162471395881, "term": "9", "s": 0.0, "bg": 0.0, "x": 0.2578184591914569, "ncat": 5}, {"cat25k": 9, "ncat25k": 6, "os": 0.6338270477912181, "cat": 3, "y": 0.4965675057208238, "term": "pipeline", "s": 0.7652905198776758, "bg": 1.255905582023068e-06, "x": 0.2585812356979405, "ncat": 5}, {"cat25k": 12, "ncat25k": 6, "os": 0.7011342931621475, "cat": 4, "y": 0.6262395118230358, "term": "downstream", "s": 0.9097859327217125, "bg": 4.804314915369323e-06, "x": 0.2593440122044241, "ncat": 5}, {"cat25k": 9, "ncat25k": 6, "os": 0.6338270477912181, "cat": 3, "y": 0.498093058733791, "term": "paraphrase", "s": 0.7652905198776758, "bg": 4.0350177463184344e-05, "x": 0.2601067887109077, "ncat": 5}, {"cat25k": 16, "ncat25k": 6, "os": 0.7505502795270482, "cat": 5, "y": 0.7208237986270023, "term": "key", "s": 0.9541284403669724, "bg": 1.4607254279452592e-07, "x": 0.2608695652173913, "ncat": 5}, {"cat25k": 12, "ncat25k": 6, "os": 0.7011342931621475, "cat": 4, "y": 0.6323417238749046, "term": "incorporating", "s": 0.9097859327217125, "bg": 4.443712713084356e-06, "x": 0.2616323417238749, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.13882532418001525, "term": "offer", "s": 0.1720183486238532, "bg": 9.502361336792193e-08, "x": 0.2623951182303585, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.3119755911517925, "term": "per", "s": 0.481651376146789, "bg": 6.392662304947086e-08, "x": 0.2631578947368421, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.3157894736842105, "term": "derived", "s": 0.481651376146789, "bg": 8.303694580623387e-07, "x": 0.2639206712433257, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.14111365369946605, "term": "facts", "s": 0.1720183486238532, "bg": 3.3243727635801663e-07, "x": 0.2646834477498093, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.3165522501906941, "term": "cases", "s": 0.481651376146789, "bg": 2.0854789629163372e-07, "x": 0.2654462242562929, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.3180778032036613, "term": "runs", "s": 0.481651376146789, "bg": 1.0024308562714254e-06, "x": 0.2662090007627765, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.14187643020594964, "term": "trivial", "s": 0.1720183486238532, "bg": 5.0547215732989386e-06, "x": 0.2669717772692601, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.02745995423340961, "term": "university", "s": 0.0, "bg": 4.495401331272646e-08, "x": 0.26773455377574373, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.028985507246376812, "term": "appears", "s": 0.0, "bg": 3.0189439335619807e-07, "x": 0.26849733028222733, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.14492753623188406, "term": "predicate", "s": 0.1720183486238532, "bg": 1.0765693824744192e-05, "x": 0.26926010678871093, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.32265446224256294, "term": "great", "s": 0.481651376146789, "bg": 4.642789373529294e-08, "x": 0.2700228832951945, "ncat": 5}, {"cat25k": 16, "ncat25k": 6, "os": 0.7505502795270482, "cat": 5, "y": 0.7276887871853547, "term": "participating", "s": 0.9541284403669724, "bg": 1.244138707033825e-06, "x": 0.2707856598016781, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.32570556826849734, "term": "metric", "s": 0.481651376146789, "bg": 1.9764676119075958e-06, "x": 0.2715484363081617, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.15179252479023647, "term": "collect", "s": 0.1720183486238532, "bg": 7.500587858573416e-07, "x": 0.2723112128146453, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.031273836765827616, "term": "normalization", "s": 0.0, "bg": 2.049146412299292e-05, "x": 0.2730739893211289, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.33638443935926776, "term": "allow", "s": 0.481651376146789, "bg": 2.0861894259998808e-07, "x": 0.2738367658276125, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.15942028985507245, "term": "successful", "s": 0.1720183486238532, "bg": 2.784408278899699e-07, "x": 0.2745995423340961, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.33867276887871856, "term": "represented", "s": 0.481651376146789, "bg": 8.34469254606166e-07, "x": 0.2753623188405797, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.034324942791762014, "term": "consisted", "s": 0.0, "bg": 2.904993916942738e-06, "x": 0.2761250953470633, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.03508771929824561, "term": "heavily", "s": 0.0, "bg": 1.2207040190703265e-06, "x": 0.2768878718535469, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.34019832189168575, "term": "acquisition", "s": 0.481651376146789, "bg": 9.360644573985364e-07, "x": 0.2776506483600305, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.16247139588100687, "term": "french", "s": 0.1720183486238532, "bg": 2.455427996753188e-07, "x": 0.2784134248665141, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.03585049580472922, "term": "lexicons", "s": 0.0, "bg": 4.637161438911195e-05, "x": 0.2791762013729977, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.34172387490465295, "term": "success", "s": 0.481651376146789, "bg": 2.3711919419580994e-07, "x": 0.2799389778794813, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.03737604881769641, "term": "carry", "s": 0.0, "bg": 3.0200615440221684e-07, "x": 0.2807017543859649, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.16628527841342486, "term": "lead", "s": 0.1720183486238532, "bg": 1.7548767403094354e-07, "x": 0.2814645308924485, "ncat": 5}, {"cat25k": 12, "ncat25k": 6, "os": 0.7011342931621475, "cat": 4, "y": 0.6521739130434783, "term": "interest", "s": 0.9097859327217125, "bg": 1.4959064146985172e-07, "x": 0.2822273073989321, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.03813882532418002, "term": "inherent", "s": 0.0, "bg": 2.164346631367616e-06, "x": 0.2829900839054157, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.16857360793287568, "term": "introduces", "s": 0.1720183486238532, "bg": 2.1407372668565095e-06, "x": 0.2837528604118993, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.03966437833714721, "term": "publicly", "s": 0.0, "bg": 1.2150965047870548e-06, "x": 0.28451563691838294, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.17315026697177727, "term": "translating", "s": 0.1720183486238532, "bg": 9.769197286768274e-06, "x": 0.28527841342486654, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.3485888634630053, "term": "covering", "s": 0.481651376146789, "bg": 1.0269598132011446e-06, "x": 0.28604118993135014, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.3508771929824561, "term": "+", "s": 0.481651376146789, "bg": 0.0, "x": 0.28680396643783374, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.043478260869565216, "term": "tracking", "s": 0.0, "bg": 6.31169036298768e-07, "x": 0.28756674294431733, "ncat": 5}, {"cat25k": 12, "ncat25k": 6, "os": 0.7011342931621475, "cat": 4, "y": 0.6544622425629291, "term": "mental", "s": 0.9097859327217125, "bg": 7.836615522488149e-07, "x": 0.28832951945080093, "ncat": 5}, {"cat25k": 12, "ncat25k": 6, "os": 0.7011342931621475, "cat": 4, "y": 0.6552250190694127, "term": "around", "s": 0.9097859327217125, "bg": 1.0063429347916391e-07, "x": 0.28909229595728453, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.18001525553012968, "term": "exploration", "s": 0.1720183486238532, "bg": 1.290126505197505e-06, "x": 0.2898550724637681, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.35697940503432496, "term": "accurately", "s": 0.481651376146789, "bg": 2.107397492046456e-06, "x": 0.2906178489702517, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.18154080854309687, "term": "artificial", "s": 0.1720183486238532, "bg": 1.313460303664517e-06, "x": 0.2913806254767353, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.35926773455377575, "term": "count", "s": 0.481651376146789, "bg": 4.950343230810323e-07, "x": 0.2921434019832189, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.18306636155606407, "term": "distributions", "s": 0.1720183486238532, "bg": 2.4901765991741193e-06, "x": 0.2929061784897025, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.04424103737604882, "term": "discriminative", "s": 0.0, "bg": 6.0021487692593944e-05, "x": 0.2936689549961861, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.04500381388253242, "term": "unlabeled", "s": 0.0, "bg": 2.520420658207855e-05, "x": 0.2944317315026697, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.1853546910755149, "term": "explores", "s": 0.1720183486238532, "bg": 2.77528195130074e-06, "x": 0.2951945080091533, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.04576659038901602, "term": "diachronic", "s": 0.0, "bg": 0.00020106098334287086, "x": 0.2959572845156369, "ncat": 5}, {"cat25k": 9, "ncat25k": 6, "os": 0.6338270477912181, "cat": 3, "y": 0.5453852021357742, "term": "exploiting", "s": 0.7652905198776758, "bg": 1.0636133871698977e-05, "x": 0.2967200610221205, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.04729214340198322, "term": "area", "s": 0.0, "bg": 3.8472342087078704e-08, "x": 0.2974828375286041, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.18840579710144928, "term": "showed", "s": 0.1720183486238532, "bg": 5.399146529912285e-07, "x": 0.2982456140350877, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.04881769641495042, "term": "dialect", "s": 0.0, "bg": 1.0733973793769693e-05, "x": 0.2990083905415713, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.18993135011441648, "term": "unified", "s": 0.1720183486238532, "bg": 2.0580858720894486e-06, "x": 0.2997711670480549, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.04958047292143402, "term": "substantial", "s": 0.0, "bg": 6.380395749150656e-07, "x": 0.3005339435545385, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.19221967963386727, "term": "define", "s": 0.1720183486238532, "bg": 3.3201966065487893e-07, "x": 0.3012967200610221, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.05034324942791762, "term": "engineering", "s": 0.0, "bg": 1.1625196818941592e-07, "x": 0.30205949656750575, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.05110602593440122, "term": "mixture", "s": 0.0, "bg": 1.104792679025025e-06, "x": 0.30282227307398935, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.19298245614035087, "term": "comparing", "s": 0.1720183486238532, "bg": 1.7702906286124992e-06, "x": 0.30358504958047294, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.3707093821510298, "term": "modeled", "s": 0.481651376146789, "bg": 5.925855693562151e-06, "x": 0.30434782608695654, "ncat": 5}, {"cat25k": 12, "ncat25k": 6, "os": 0.7011342931621475, "cat": 4, "y": 0.6613272311212814, "term": "analyses", "s": 0.9097859327217125, "bg": 1.9937193851927656e-06, "x": 0.30511060259344014, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.1952707856598017, "term": "meanings", "s": 0.1720183486238532, "bg": 3.763835455867685e-06, "x": 0.30587337909992374, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.05186880244088482, "term": "massive", "s": 0.0, "bg": 5.125531703438172e-07, "x": 0.30663615560640733, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.05263157894736842, "term": "enhanced", "s": 0.0, "bg": 5.495178502905658e-07, "x": 0.30739893211289093, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.05415713196033562, "term": "6", "s": 0.0, "bg": 0.0, "x": 0.30816170861937453, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.37528604118993136, "term": "construct", "s": 0.481651376146789, "bg": 1.6418422079400194e-06, "x": 0.30892448512585813, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.05568268497330282, "term": "variants", "s": 0.0, "bg": 3.141094181311495e-06, "x": 0.3096872616323417, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.37909992372234935, "term": "linguistically", "s": 0.481651376146789, "bg": 3.690046626374871e-05, "x": 0.3104500381388253, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.37986270022883295, "term": "loss", "s": 0.481651376146789, "bg": 2.4075688571915863e-07, "x": 0.3112128146453089, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.38215102974828374, "term": "focuses", "s": 0.481651376146789, "bg": 1.7485115795179355e-06, "x": 0.3119755911517925, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.3890160183066362, "term": "implementation", "s": 0.481651376146789, "bg": 2.9806205375187207e-07, "x": 0.3127383676582761, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.2112890922959573, "term": "schemes", "s": 0.1720183486238532, "bg": 1.309731350711909e-06, "x": 0.3135011441647597, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.060259344012204424, "term": "exists", "s": 0.0, "bg": 5.349454449261628e-07, "x": 0.3142639206712433, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.06102212051868802, "term": "margin", "s": 0.0, "bg": 9.846813128165136e-07, "x": 0.3150266971777269, "ncat": 5}, {"cat25k": 12, "ncat25k": 6, "os": 0.7011342931621475, "cat": 4, "y": 0.6681922196796338, "term": "trees", "s": 0.9097859327217125, "bg": 8.019376855779491e-07, "x": 0.3157894736842105, "ncat": 5}, {"cat25k": 9, "ncat25k": 6, "os": 0.6338270477912181, "cat": 3, "y": 0.5621662852784134, "term": "pos", "s": 0.7652905198776758, "bg": 2.736641610256764e-06, "x": 0.3165522501906941, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.2120518688024409, "term": "practice", "s": 0.1720183486238532, "bg": 2.1404810814471484e-07, "x": 0.3173150266971777, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.06178489702517163, "term": "span", "s": 0.0, "bg": 2.1971708130026375e-06, "x": 0.3180778032036613, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.21586575133485889, "term": "induction", "s": 0.1720183486238532, "bg": 3.4796373205653843e-06, "x": 0.3188405797101449, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.06331045003813883, "term": "release", "s": 0.0, "bg": 7.974718420069201e-08, "x": 0.31960335621662855, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.21739130434782608, "term": "instance", "s": 0.1720183486238532, "bg": 4.5696967869090984e-07, "x": 0.32036613272311215, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.06636155606407322, "term": "attempts", "s": 0.0, "bg": 7.897525499925211e-07, "x": 0.32112890922959575, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.21815408085430968, "term": "believe", "s": 0.1720183486238532, "bg": 1.5794984263259742e-07, "x": 0.32189168573607935, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.06712433257055683, "term": "until", "s": 0.0, "bg": 1.0605811182021369e-07, "x": 0.32265446224256294, "ncat": 5}, {"cat25k": 9, "ncat25k": 6, "os": 0.6338270477912181, "cat": 3, "y": 0.5675057208237986, "term": "aspects", "s": 0.7652905198776758, "bg": 6.330640044590213e-07, "x": 0.32341723874904654, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.2204424103737605, "term": "positive", "s": 0.1720183486238532, "bg": 2.8475981150609035e-07, "x": 0.32418001525553014, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.2212051868802441, "term": "six", "s": 0.1720183486238532, "bg": 1.960186676417942e-07, "x": 0.32494279176201374, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.2219679633867277, "term": "perception", "s": 0.1720183486238532, "bg": 1.6700608665611827e-06, "x": 0.32570556826849734, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.06864988558352403, "term": "reducing", "s": 0.0, "bg": 7.990067281027379e-07, "x": 0.32646834477498093, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.2242562929061785, "term": "re", "s": 0.1720183486238532, "bg": 3.248991094856553e-08, "x": 0.32723112128146453, "ncat": 5}, {"cat25k": 12, "ncat25k": 6, "os": 0.7011342931621475, "cat": 4, "y": 0.6720061022120518, "term": "keyphrases", "s": 0.9097859327217125, "bg": 0.00040084700715424765, "x": 0.32799389778794813, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.07017543859649122, "term": "almost", "s": 0.0, "bg": 1.5048783943886578e-07, "x": 0.3287566742944317, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.22730739893211288, "term": "separate", "s": 0.1720183486238532, "bg": 3.3154777358900934e-07, "x": 0.3295194508009153, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.07093821510297482, "term": "heuristics", "s": 0.0, "bg": 1.5891071998474458e-05, "x": 0.3302822273073989, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.22807017543859648, "term": "max", "s": 0.1720183486238532, "bg": 2.7808238420049903e-07, "x": 0.3310450038138825, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.2288329519450801, "term": "compositionality", "s": 0.1720183486238532, "bg": 0.00020748844666603793, "x": 0.3318077803203661, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.2295957284515637, "term": "requiring", "s": 0.1720183486238532, "bg": 1.0315032259833599e-06, "x": 0.3325705568268497, "ncat": 5}, {"cat25k": 9, "ncat25k": 6, "os": 0.6338270477912181, "cat": 3, "y": 0.5720823798627003, "term": "should", "s": 0.7652905198776758, "bg": 3.979273060925729e-08, "x": 0.3333333333333333, "ncat": 5}, {"cat25k": 9, "ncat25k": 6, "os": 0.6338270477912181, "cat": 3, "y": 0.5743707093821511, "term": "tracks", "s": 0.7652905198776758, "bg": 8.313333185633114e-07, "x": 0.3340961098398169, "ncat": 5}, {"cat25k": 0, "ncat25k": 6, "os": 0.27488233814366553, "cat": 0, "y": 0.07322654462242563, "term": "objects", "s": 0.0, "bg": 4.719680616852818e-07, "x": 0.3348588863463005, "ncat": 5}, {"cat25k": 3, "ncat25k": 6, "os": 0.4235367220655553, "cat": 1, "y": 0.23569794050343248, "term": "puns", "s": 0.1720183486238532, "bg": 7.430782263218122e-05, "x": 0.3356216628527841, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.41571319603356216, "term": "c", "s": 0.481651376146789, "bg": 3.0166990684168475e-08, "x": 0.33638443935926776, "ncat": 5}, {"cat25k": 6, "ncat25k": 6, "os": 0.5430280830127496, "cat": 2, "y": 0.41876430205949655, "term": "microblogs", "s": 0.481651376146789, "bg": 0.00039684687122319023, "x": 0.33714721586575136, "ncat": 5}, {"cat25k": 6, "ncat25k": 7, "os": 0.5117059143088374, "cat": 2, "y": 0.2372234935163997, "term": "wide", "s": 0.41437308868501527, "bg": 1.8240496823708184e-07, "x": 0.33790999237223496, "ncat": 6}, {"cat25k": 9, "ncat25k": 7, "os": 0.598080078710294, "cat": 3, "y": 0.42028985507246375, "term": "parts", "s": 0.6873088685015291, "bg": 2.1848601861290335e-07, "x": 0.33867276887871856, "ncat": 6}, {"cat25k": 0, "ncat25k": 7, "os": 0.27488233814366553, "cat": 0, "y": 0.0, "term": "change", "s": 0.0, "bg": 9.494120955480738e-08, "x": 0.33943554538520215, "ncat": 6}, {"cat25k": 9, "ncat25k": 7, "os": 0.598080078710294, "cat": 3, "y": 0.42181540808543094, "term": "groups", "s": 0.6873088685015291, "bg": 3.336783620561814e-07, "x": 0.34019832189168575, "ncat": 6}, {"cat25k": 9, "ncat25k": 7, "os": 0.598080078710294, "cat": 3, "y": 0.4225781845919146, "term": "easy", "s": 0.6873088685015291, "bg": 2.0699983311036534e-07, "x": 0.34096109839816935, "ncat": 6}, {"cat25k": 12, "ncat25k": 7, "os": 0.6648549218294989, "cat": 4, "y": 0.585812356979405, "term": "improved", "s": 0.8493883792048929, "bg": 8.013720947301954e-07, "x": 0.34172387490465295, "ncat": 6}, {"cat25k": 9, "ncat25k": 7, "os": 0.598080078710294, "cat": 3, "y": 0.425629290617849, "term": "made", "s": 0.6873088685015291, "bg": 6.958737473754991e-08, "x": 0.34248665141113654, "ncat": 6}, {"cat25k": 9, "ncat25k": 7, "os": 0.598080078710294, "cat": 3, "y": 0.4263920671243326, "term": "basis", "s": 0.6873088685015291, "bg": 3.002158551998887e-07, "x": 0.34324942791762014, "ncat": 6}, {"cat25k": 12, "ncat25k": 7, "os": 0.6648549218294989, "cat": 4, "y": 0.5888634630053394, "term": "pair", "s": 0.8493883792048929, "bg": 8.431657962896106e-07, "x": 0.34401220442410374, "ncat": 6}, {"cat25k": 9, "ncat25k": 7, "os": 0.598080078710294, "cat": 3, "y": 0.4302059496567506, "term": "limited", "s": 0.6873088685015291, "bg": 1.8830546781174592e-07, "x": 0.34477498093058734, "ncat": 6}, {"cat25k": 12, "ncat25k": 7, "os": 0.6648549218294989, "cat": 4, "y": 0.589626239511823, "term": "public", "s": 0.8493883792048929, "bg": 6.297561618491657e-08, "x": 0.34553775743707094, "ncat": 6}, {"cat25k": 6, "ncat25k": 7, "os": 0.5117059143088374, "cat": 2, "y": 0.2463768115942029, "term": "forms", "s": 0.41437308868501527, "bg": 3.14381178376108e-07, "x": 0.34630053394355453, "ncat": 6}, {"cat25k": 3, "ncat25k": 7, "os": 0.403306146092218, "cat": 1, "y": 0.08161708619374523, "term": "requirements", "s": 0.13990825688073394, "bg": 1.4390106431796831e-07, "x": 0.34706331045003813, "ncat": 6}, {"cat25k": 3, "ncat25k": 7, "os": 0.403306146092218, "cat": 1, "y": 0.08314263920671243, "term": "dynamic", "s": 0.13990825688073394, "bg": 5.459451764583526e-07, "x": 0.34782608695652173, "ncat": 6}, {"cat25k": 9, "ncat25k": 7, "os": 0.598080078710294, "cat": 3, "y": 0.43707093821510296, "term": "exploit", "s": 0.6873088685015291, "bg": 3.6682701762501923e-06, "x": 0.3485888634630053, "ncat": 6}, {"cat25k": 16, "ncat25k": 7, "os": 0.7157357487535015, "cat": 5, "y": 0.6864988558352403, "term": "tweet", "s": 0.9212538226299694, "bg": 0.00015165031222123107, "x": 0.3493516399694889, "ncat": 6}, {"cat25k": 6, "ncat25k": 7, "os": 0.5117059143088374, "cat": 2, "y": 0.2532418001525553, "term": "rnn", "s": 0.41437308868501527, "bg": 0.00023896939019356518, "x": 0.3501144164759725, "ncat": 6}, {"cat25k": 6, "ncat25k": 7, "os": 0.5117059143088374, "cat": 2, "y": 0.2555301296720061, "term": "rather", "s": 0.41437308868501527, "bg": 2.1703636143097822e-07, "x": 0.3508771929824561, "ncat": 6}, {"cat25k": 3, "ncat25k": 7, "os": 0.403306146092218, "cat": 1, "y": 0.09000762776506484, "term": "power", "s": 0.13990825688073394, "bg": 6.1768756913606e-08, "x": 0.3516399694889397, "ncat": 6}, {"cat25k": 9, "ncat25k": 7, "os": 0.598080078710294, "cat": 3, "y": 0.4462242562929062, "term": "capable", "s": 0.6873088685015291, "bg": 1.095166967330561e-06, "x": 0.3524027459954233, "ncat": 6}, {"cat25k": 6, "ncat25k": 7, "os": 0.5117059143088374, "cat": 2, "y": 0.2646834477498093, "term": "mechanisms", "s": 0.41437308868501527, "bg": 1.4428976501473883e-06, "x": 0.3531655225019069, "ncat": 6}, {"cat25k": 3, "ncat25k": 7, "os": 0.403306146092218, "cat": 1, "y": 0.09153318077803203, "term": "spanish", "s": 0.13990825688073394, "bg": 3.8678165943256036e-07, "x": 0.35392829900839057, "ncat": 6}, {"cat25k": 16, "ncat25k": 7, "os": 0.7157357487535015, "cat": 5, "y": 0.6964149504195271, "term": "among", "s": 0.9212538226299694, "bg": 2.8746980908219657e-07, "x": 0.35469107551487417, "ncat": 6}, {"cat25k": 3, "ncat25k": 7, "os": 0.403306146092218, "cat": 1, "y": 0.09305873379099924, "term": "showing", "s": 0.13990825688073394, "bg": 2.9288261766768365e-07, "x": 0.35545385202135776, "ncat": 6}, {"cat25k": 0, "ncat25k": 7, "os": 0.27488233814366553, "cat": 0, "y": 0.006102212051868803, "term": "correction", "s": 0.0, "bg": 1.6838806468459119e-06, "x": 0.35621662852784136, "ncat": 6}, {"cat25k": 0, "ncat25k": 7, "os": 0.27488233814366553, "cat": 0, "y": 0.006864988558352402, "term": "added", "s": 0.0, "bg": 1.0129501797505419e-07, "x": 0.35697940503432496, "ncat": 6}, {"cat25k": 9, "ncat25k": 7, "os": 0.598080078710294, "cat": 3, "y": 0.4492753623188406, "term": "word2vec", "s": 0.6873088685015291, "bg": 0.0, "x": 0.35774218154080856, "ncat": 6}, {"cat25k": 3, "ncat25k": 7, "os": 0.403306146092218, "cat": 1, "y": 0.09916094584286804, "term": "ones", "s": 0.13990825688073394, "bg": 3.823724341375773e-07, "x": 0.35850495804729215, "ncat": 6}, {"cat25k": 6, "ncat25k": 7, "os": 0.5117059143088374, "cat": 2, "y": 0.2723112128146453, "term": "medical", "s": 0.41437308868501527, "bg": 3.734467704941407e-07, "x": 0.35926773455377575, "ncat": 6}, {"cat25k": 0, "ncat25k": 7, "os": 0.27488233814366553, "cat": 0, "y": 0.009916094584286803, "term": "gains", "s": 0.0, "bg": 1.3734917466390412e-06, "x": 0.36003051106025935, "ncat": 6}, {"cat25k": 9, "ncat25k": 7, "os": 0.598080078710294, "cat": 3, "y": 0.45614035087719296, "term": "advantage", "s": 0.6873088685015291, "bg": 5.451422615359977e-07, "x": 0.36079328756674295, "ncat": 6}, {"cat25k": 6, "ncat25k": 7, "os": 0.5117059143088374, "cat": 2, "y": 0.2753623188405797, "term": "takes", "s": 0.41437308868501527, "bg": 2.7662676550333533e-07, "x": 0.36155606407322655, "ncat": 6}, {"cat25k": 3, "ncat25k": 7, "os": 0.403306146092218, "cat": 1, "y": 0.10221205186880244, "term": "hidden", "s": 0.13990825688073394, "bg": 7.523934198982027e-07, "x": 0.36231884057971014, "ncat": 6}, {"cat25k": 6, "ncat25k": 7, "os": 0.5117059143088374, "cat": 2, "y": 0.2761250953470633, "term": "f1-score", "s": 0.41437308868501527, "bg": 0.0, "x": 0.36308161708619374, "ncat": 6}, {"cat25k": 0, "ncat25k": 7, "os": 0.27488233814366553, "cat": 0, "y": 0.014492753623188406, "term": "benchmarks", "s": 0.0, "bg": 3.3431612988961715e-06, "x": 0.36384439359267734, "ncat": 6}, {"cat25k": 9, "ncat25k": 7, "os": 0.598080078710294, "cat": 3, "y": 0.4645308924485126, "term": "scoring", "s": 0.6873088685015291, "bg": 2.554079188635841e-06, "x": 0.36460717009916094, "ncat": 6}, {"cat25k": 9, "ncat25k": 7, "os": 0.598080078710294, "cat": 3, "y": 0.4767353165522502, "term": "mapping", "s": 0.6873088685015291, "bg": 1.1130573875187207e-06, "x": 0.36536994660564454, "ncat": 6}, {"cat25k": 0, "ncat25k": 7, "os": 0.27488233814366553, "cat": 0, "y": 0.019832189168573607, "term": "probability", "s": 0.0, "bg": 1.2322420443758087e-06, "x": 0.36613272311212813, "ncat": 6}, {"cat25k": 12, "ncat25k": 7, "os": 0.6648549218294989, "cat": 4, "y": 0.6155606407322655, "term": "patient", "s": 0.8493883792048929, "bg": 8.91685046329139e-07, "x": 0.36689549961861173, "ncat": 6}, {"cat25k": 6, "ncat25k": 7, "os": 0.5117059143088374, "cat": 2, "y": 0.2921434019832189, "term": "constructed", "s": 0.41437308868501527, "bg": 1.3749668718919305e-06, "x": 0.36765827612509533, "ncat": 6}, {"cat25k": 9, "ncat25k": 7, "os": 0.598080078710294, "cat": 3, "y": 0.486651411136537, "term": "ontology", "s": 0.6873088685015291, "bg": 2.2508021999715833e-05, "x": 0.3684210526315789, "ncat": 6}, {"cat25k": 3, "ncat25k": 7, "os": 0.403306146092218, "cat": 1, "y": 0.11823035850495804, "term": "before", "s": 0.13990825688073394, "bg": 5.0432012870019134e-08, "x": 0.3691838291380625, "ncat": 6}, {"cat25k": 12, "ncat25k": 7, "os": 0.6648549218294989, "cat": 4, "y": 0.620137299771167, "term": "usually", "s": 0.8493883792048929, "bg": 2.1156676550995428e-07, "x": 0.3699466056445461, "ncat": 6}, {"cat25k": 3, "ncat25k": 7, "os": 0.403306146092218, "cat": 1, "y": 0.12128146453089245, "term": "utterances", "s": 0.13990825688073394, "bg": 3.7256436049327516e-05, "x": 0.3707093821510298, "ncat": 6}, {"cat25k": 6, "ncat25k": 7, "os": 0.5117059143088374, "cat": 2, "y": 0.2990083905415713, "term": "reduction", "s": 0.41437308868501527, "bg": 6.204823498797247e-07, "x": 0.3714721586575134, "ncat": 6}, {"cat25k": 0, "ncat25k": 7, "os": 0.27488233814366553, "cat": 0, "y": 0.02212051868802441, "term": "means", "s": 0.0, "bg": 1.1320531083093509e-07, "x": 0.37223493516399697, "ncat": 6}, {"cat25k": 3, "ncat25k": 7, "os": 0.403306146092218, "cat": 1, "y": 0.12738367658276126, "term": "hierarchical", "s": 0.13990825688073394, "bg": 7.399783388159001e-06, "x": 0.37299771167048057, "ncat": 6}, {"cat25k": 3, "ncat25k": 7, "os": 0.403306146092218, "cat": 1, "y": 0.12814645308924486, "term": "itself", "s": 0.13990825688073394, "bg": 2.738003442804643e-07, "x": 0.37376048817696417, "ncat": 6}, {"cat25k": 12, "ncat25k": 7, "os": 0.6648549218294989, "cat": 4, "y": 0.6254767353165522, "term": "contribution", "s": 0.8493883792048929, "bg": 9.744608429963305e-07, "x": 0.37452326468344777, "ncat": 6}, {"cat25k": 3, "ncat25k": 7, "os": 0.403306146092218, "cat": 1, "y": 0.13272311212814644, "term": "series", "s": 0.13990825688073394, "bg": 9.902583888021929e-08, "x": 0.37528604118993136, "ncat": 6}, {"cat25k": 3, "ncat25k": 7, "os": 0.403306146092218, "cat": 1, "y": 0.13348588863463004, "term": "plays", "s": 0.13990825688073394, "bg": 6.419261305339363e-07, "x": 0.37604881769641496, "ncat": 6}, {"cat25k": 12, "ncat25k": 7, "os": 0.6648549218294989, "cat": 4, "y": 0.627765064836003, "term": "precision", "s": 0.8493883792048929, "bg": 1.7750334445884852e-06, "x": 0.37681159420289856, "ncat": 6}, {"cat25k": 12, "ncat25k": 7, "os": 0.6648549218294989, "cat": 4, "y": 0.631578947368421, "term": "little", "s": 0.8493883792048929, "bg": 1.0683877395989715e-07, "x": 0.37757437070938216, "ncat": 6}, {"cat25k": 3, "ncat25k": 7, "os": 0.403306146092218, "cat": 1, "y": 0.13653699466056446, "term": "impact", "s": 0.13990825688073394, "bg": 2.61981726054158e-07, "x": 0.37833714721586575, "ncat": 6}, {"cat25k": 12, "ncat25k": 7, "os": 0.6648549218294989, "cat": 4, "y": 0.6338672768878718, "term": "generative", "s": 0.8493883792048929, "bg": 5.2481041223857886e-05, "x": 0.37909992372234935, "ncat": 6}, {"cat25k": 9, "ncat25k": 7, "os": 0.598080078710294, "cat": 3, "y": 0.5064836003051106, "term": "distribution", "s": 0.6873088685015291, "bg": 2.721928797457755e-07, "x": 0.37986270022883295, "ncat": 6}, {"cat25k": 6, "ncat25k": 7, "os": 0.5117059143088374, "cat": 2, "y": 0.3135011441647597, "term": "qualitative", "s": 0.41437308868501527, "bg": 4.66367010316971e-06, "x": 0.38062547673531655, "ncat": 6}, {"cat25k": 0, "ncat25k": 7, "os": 0.27488233814366553, "cat": 0, "y": 0.02669717772692601, "term": "indicate", "s": 0.0, "bg": 4.940745230719214e-07, "x": 0.38138825324180015, "ncat": 6}, {"cat25k": 9, "ncat25k": 7, "os": 0.598080078710294, "cat": 3, "y": 0.5118230358504958, "term": "argument", "s": 0.6873088685015291, "bg": 6.16054377066349e-07, "x": 0.38215102974828374, "ncat": 6}, {"cat25k": 3, "ncat25k": 7, "os": 0.403306146092218, "cat": 1, "y": 0.14340198321891687, "term": "predicted", "s": 0.13990825688073394, "bg": 1.6984183963945976e-06, "x": 0.38291380625476734, "ncat": 6}, {"cat25k": 3, "ncat25k": 7, "os": 0.403306146092218, "cat": 1, "y": 0.14645308924485126, "term": "interaction", "s": 0.13990825688073394, "bg": 8.175440873423226e-07, "x": 0.38367658276125094, "ncat": 6}, {"cat25k": 9, "ncat25k": 7, "os": 0.598080078710294, "cat": 3, "y": 0.5141113653699466, "term": "disambiguation", "s": 0.6873088685015291, "bg": 3.2512436006772587e-05, "x": 0.38443935926773454, "ncat": 6}, {"cat25k": 3, "ncat25k": 7, "os": 0.403306146092218, "cat": 1, "y": 0.15408085430968727, "term": "meaningful", "s": 0.13990825688073394, "bg": 2.3445222728150592e-06, "x": 0.38520213577421814, "ncat": 6}, {"cat25k": 12, "ncat25k": 7, "os": 0.6648549218294989, "cat": 4, "y": 0.6453089244851259, "term": "combines", "s": 0.8493883792048929, "bg": 3.0022078236334997e-06, "x": 0.38596491228070173, "ncat": 6}, {"cat25k": 9, "ncat25k": 7, "os": 0.598080078710294, "cat": 3, "y": 0.5163996948893974, "term": "scenarios", "s": 0.6873088685015291, "bg": 3.1223625793587475e-06, "x": 0.38672768878718533, "ncat": 6}, {"cat25k": 3, "ncat25k": 7, "os": 0.403306146092218, "cat": 1, "y": 0.15484363081617086, "term": "commonly", "s": 0.13990825688073394, "bg": 1.1971978046128716e-06, "x": 0.38749046529366893, "ncat": 6}, {"cat25k": 19, "ncat25k": 7, "os": 0.7544150477067272, "cat": 6, "y": 0.7780320366132724, "term": "measures", "s": 0.95565749235474, "bg": 8.501595749522185e-07, "x": 0.3882532418001526, "ncat": 6}, {"cat25k": 12, "ncat25k": 7, "os": 0.6648549218294989, "cat": 4, "y": 0.6483600305110603, "term": "correlation", "s": 0.8493883792048929, "bg": 3.0080770629235828e-06, "x": 0.3890160183066362, "ncat": 6}, {"cat25k": 6, "ncat25k": 7, "os": 0.5117059143088374, "cat": 2, "y": 0.3318077803203661, "term": "integrating", "s": 0.41437308868501527, "bg": 2.969757964725875e-06, "x": 0.3897787948131198, "ncat": 6}, {"cat25k": 6, "ncat25k": 7, "os": 0.5117059143088374, "cat": 2, "y": 0.3325705568268497, "term": "curated", "s": 0.41437308868501527, "bg": 2.0419909922672355e-05, "x": 0.3905415713196034, "ncat": 6}, {"cat25k": 9, "ncat25k": 7, "os": 0.598080078710294, "cat": 3, "y": 0.5202135774218154, "term": "spoken", "s": 0.6873088685015291, "bg": 3.2863313841844144e-06, "x": 0.391304347826087, "ncat": 6}, {"cat25k": 0, "ncat25k": 7, "os": 0.27488233814366553, "cat": 0, "y": 0.033562166285278416, "term": "suggests", "s": 0.0, "bg": 8.076426143741405e-07, "x": 0.39206712433257057, "ncat": 6}, {"cat25k": 3, "ncat25k": 7, "os": 0.403306146092218, "cat": 1, "y": 0.16094584286803967, "term": "corresponding", "s": 0.13990825688073394, "bg": 8.085011353377192e-07, "x": 0.39282990083905417, "ncat": 6}, {"cat25k": 3, "ncat25k": 7, "os": 0.403306146092218, "cat": 1, "y": 0.16170861937452327, "term": "lexicon", "s": 0.13990825688073394, "bg": 1.160270849407919e-05, "x": 0.39359267734553777, "ncat": 6}, {"cat25k": 9, "ncat25k": 7, "os": 0.598080078710294, "cat": 3, "y": 0.5255530129672006, "term": "effect", "s": 0.6873088685015291, "bg": 2.643744869895697e-07, "x": 0.39435545385202136, "ncat": 6}, {"cat25k": 9, "ncat25k": 7, "os": 0.598080078710294, "cat": 3, "y": 0.5263157894736842, "term": "associated", "s": 0.6873088685015291, "bg": 2.7576078762796166e-07, "x": 0.39511823035850496, "ncat": 6}, {"cat25k": 6, "ncat25k": 7, "os": 0.5117059143088374, "cat": 2, "y": 0.34324942791762014, "term": "demonstrated", "s": 0.41437308868501527, "bg": 1.3586421187208654e-06, "x": 0.39588100686498856, "ncat": 6}, {"cat25k": 9, "ncat25k": 7, "os": 0.598080078710294, "cat": 3, "y": 0.5308924485125858, "term": "after", "s": 0.6873088685015291, "bg": 4.825691608939175e-08, "x": 0.39664378337147216, "ncat": 6}, {"cat25k": 19, "ncat25k": 7, "os": 0.7544150477067272, "cat": 6, "y": 0.7803203661327232, "term": "frame", "s": 0.95565749235474, "bg": 1.1704666806718063e-06, "x": 0.39740655987795576, "ncat": 6}, {"cat25k": 0, "ncat25k": 7, "os": 0.27488233814366553, "cat": 0, "y": 0.04042715484363082, "term": "bilingual", "s": 0.0, "bg": 9.119376052290502e-06, "x": 0.39816933638443935, "ncat": 6}, {"cat25k": 12, "ncat25k": 7, "os": 0.6648549218294989, "cat": 4, "y": 0.6536994660564455, "term": "gold", "s": 0.8493883792048929, "bg": 2.4174079330421147e-07, "x": 0.39893211289092295, "ncat": 6}, {"cat25k": 0, "ncat25k": 7, "os": 0.27488233814366553, "cat": 0, "y": 0.04271548436308162, "term": "self", "s": 0.0, "bg": 1.593518120704589e-07, "x": 0.39969488939740655, "ncat": 6}, {"cat25k": 16, "ncat25k": 7, "os": 0.7157357487535015, "cat": 5, "y": 0.7322654462242563, "term": "enables", "s": 0.9212538226299694, "bg": 1.5645982062023802e-06, "x": 0.40045766590389015, "ncat": 6}, {"cat25k": 3, "ncat25k": 7, "os": 0.403306146092218, "cat": 1, "y": 0.17772692601067888, "term": "inputs", "s": 0.13990825688073394, "bg": 1.793477021588083e-06, "x": 0.40122044241037375, "ncat": 6}, {"cat25k": 9, "ncat25k": 7, "os": 0.598080078710294, "cat": 3, "y": 0.5354691075514875, "term": "scenario", "s": 0.6873088685015291, "bg": 3.390437947855663e-06, "x": 0.40198321891685734, "ncat": 6}, {"cat25k": 6, "ncat25k": 7, "os": 0.5117059143088374, "cat": 2, "y": 0.35850495804729215, "term": "grammar", "s": 0.41437308868501527, "bg": 3.219983315532605e-06, "x": 0.40274599542334094, "ncat": 6}, {"cat25k": 9, "ncat25k": 7, "os": 0.598080078710294, "cat": 3, "y": 0.5385202135774219, "term": "underlying", "s": 0.6873088685015291, "bg": 1.628106177848892e-06, "x": 0.40350877192982454, "ncat": 6}, {"cat25k": 6, "ncat25k": 7, "os": 0.5117059143088374, "cat": 2, "y": 0.36079328756674295, "term": "empirically", "s": 0.41437308868501527, "bg": 2.0850410036344873e-05, "x": 0.40427154843630814, "ncat": 6}, {"cat25k": 3, "ncat25k": 7, "os": 0.403306146092218, "cat": 1, "y": 0.18459191456903126, "term": "match", "s": 0.13990825688073394, "bg": 2.6125293848907794e-07, "x": 0.40503432494279173, "ncat": 6}, {"cat25k": 0, "ncat25k": 7, "os": 0.27488233814366553, "cat": 0, "y": 0.04805491990846682, "term": "just", "s": 0.0, "bg": 2.5923995972439344e-08, "x": 0.4057971014492754, "ncat": 6}, {"cat25k": 16, "ncat25k": 7, "os": 0.7157357487535015, "cat": 5, "y": 0.7391304347826086, "term": "images", "s": 0.9212538226299694, "bg": 2.459516490328996e-07, "x": 0.406559877955759, "ncat": 6}, {"cat25k": 12, "ncat25k": 7, "os": 0.6648549218294989, "cat": 4, "y": 0.6628527841342486, "term": "rules", "s": 0.8493883792048929, "bg": 2.4561455468459155e-07, "x": 0.4073226544622426, "ncat": 6}, {"cat25k": 3, "ncat25k": 7, "os": 0.403306146092218, "cat": 1, "y": 0.2044241037376049, "term": "sub", "s": 0.13990825688073394, "bg": 3.7780238064194325e-07, "x": 0.4080854309687262, "ncat": 6}, {"cat25k": 16, "ncat25k": 7, "os": 0.7157357487535015, "cat": 5, "y": 0.7406559877955758, "term": "tool", "s": 0.9212538226299694, "bg": 5.840297734689904e-07, "x": 0.4088482074752098, "ncat": 6}, {"cat25k": 3, "ncat25k": 7, "os": 0.403306146092218, "cat": 1, "y": 0.20823798627002288, "term": "speed", "s": 0.13990825688073394, "bg": 1.92328073997938e-07, "x": 0.4096109839816934, "ncat": 6}, {"cat25k": 12, "ncat25k": 7, "os": 0.6648549218294989, "cat": 4, "y": 0.6666666666666666, "term": "primary", "s": 0.8493883792048929, "bg": 3.374504227808976e-07, "x": 0.410373760488177, "ncat": 6}, {"cat25k": 0, "ncat25k": 7, "os": 0.27488233814366553, "cat": 0, "y": 0.059496567505720827, "term": "treebank", "s": 0.0, "bg": 0.00012412337863836653, "x": 0.4111365369946606, "ncat": 6}, {"cat25k": 6, "ncat25k": 7, "os": 0.5117059143088374, "cat": 2, "y": 0.3905415713196034, "term": "characters", "s": 0.41437308868501527, "bg": 8.240122738688224e-07, "x": 0.41189931350114417, "ncat": 6}, {"cat25k": 6, "ncat25k": 7, "os": 0.5117059143088374, "cat": 2, "y": 0.391304347826087, "term": "relational", "s": 0.41437308868501527, "bg": 6.424563418792876e-06, "x": 0.41266209000762777, "ncat": 6}, {"cat25k": 6, "ncat25k": 7, "os": 0.5117059143088374, "cat": 2, "y": 0.39206712433257057, "term": "remains", "s": 0.41437308868501527, "bg": 6.246008654079216e-07, "x": 0.41342486651411137, "ncat": 6}, {"cat25k": 6, "ncat25k": 7, "os": 0.5117059143088374, "cat": 2, "y": 0.39282990083905417, "term": "assessment", "s": 0.41437308868501527, "bg": 3.693224831088264e-07, "x": 0.41418764302059496, "ncat": 6}, {"cat25k": 6, "ncat25k": 7, "os": 0.5117059143088374, "cat": 2, "y": 0.39435545385202136, "term": "expressions", "s": 0.41437308868501527, "bg": 2.5994505470484597e-06, "x": 0.41495041952707856, "ncat": 6}, {"cat25k": 3, "ncat25k": 7, "os": 0.403306146092218, "cat": 1, "y": 0.21662852784134248, "term": "expression", "s": 0.13990825688073394, "bg": 6.403044160867137e-07, "x": 0.41571319603356216, "ncat": 6}, {"cat25k": 0, "ncat25k": 7, "os": 0.27488233814366553, "cat": 0, "y": 0.06483600305110603, "term": "attributes", "s": 0.0, "bg": 9.75232643488591e-07, "x": 0.41647597254004576, "ncat": 6}, {"cat25k": 22, "ncat25k": 7, "os": 0.784074160603953, "cat": 7, "y": 0.8184591914569032, "term": "called", "s": 0.9602446483180428, "bg": 2.802858403582853e-07, "x": 0.41723874904652936, "ncat": 6}, {"cat25k": 0, "ncat25k": 7, "os": 0.27488233814366553, "cat": 0, "y": 0.06941266209000763, "term": "2nd", "s": 0.0, "bg": 0.0, "x": 0.41800152555301295, "ncat": 6}, {"cat25k": 6, "ncat25k": 7, "os": 0.5117059143088374, "cat": 2, "y": 0.4057971014492754, "term": "determining", "s": 0.41437308868501527, "bg": 1.5919474205238158e-06, "x": 0.41876430205949655, "ncat": 6}, {"cat25k": 0, "ncat25k": 7, "os": 0.27488233814366553, "cat": 0, "y": 0.07170099160945843, "term": "grounding", "s": 0.0, "bg": 1.6786658996454785e-05, "x": 0.41952707856598015, "ncat": 6}, {"cat25k": 0, "ncat25k": 7, "os": 0.27488233814366553, "cat": 0, "y": 0.07246376811594203, "term": "3rd", "s": 0.0, "bg": 0.0, "x": 0.42028985507246375, "ncat": 6}, {"cat25k": 12, "ncat25k": 8, "os": 0.6336409119141577, "cat": 4, "y": 0.5774218154080855, "term": "interactive", "s": 0.7545871559633027, "bg": 1.1016612749068747e-06, "x": 0.42105263157894735, "ncat": 7}, {"cat25k": 9, "ncat25k": 8, "os": 0.5684878449741124, "cat": 3, "y": 0.42105263157894735, "term": "grammatical", "s": 0.5902140672782875, "bg": 1.82981919099119e-05, "x": 0.42181540808543094, "ncat": 7}, {"cat25k": 12, "ncat25k": 8, "os": 0.6336409119141577, "cat": 4, "y": 0.5797101449275363, "term": "discourse", "s": 0.7545871559633027, "bg": 7.484522241895081e-06, "x": 0.4225781845919146, "ncat": 7}, {"cat25k": 12, "ncat25k": 8, "os": 0.6336409119141577, "cat": 4, "y": 0.5827612509534706, "term": "take", "s": 0.7545871559633027, "bg": 8.320561334719097e-08, "x": 0.4233409610983982, "ncat": 7}, {"cat25k": 16, "ncat25k": 8, "os": 0.6848224865652851, "cat": 5, "y": 0.6788710907704043, "term": "lack", "s": 0.8975535168195719, "bg": 8.140934862376243e-07, "x": 0.4241037376048818, "ncat": 7}, {"cat25k": 22, "ncat25k": 8, "os": 0.7562727199486876, "cat": 7, "y": 0.7848970251716247, "term": "detect", "s": 0.9571865443425076, "bg": 4.713086166526531e-06, "x": 0.4248665141113654, "ncat": 7}, {"cat25k": 19, "ncat25k": 8, "os": 0.724827101820251, "cat": 6, "y": 0.7482837528604119, "term": "containing", "s": 0.9258409785932722, "bg": 9.890635708600112e-07, "x": 0.425629290617849, "ncat": 7}, {"cat25k": 9, "ncat25k": 8, "os": 0.5684878449741124, "cat": 3, "y": 0.4279176201372998, "term": "contains", "s": 0.5902140672782875, "bg": 3.623098615961836e-07, "x": 0.4263920671243326, "ncat": 7}, {"cat25k": 3, "ncat25k": 8, "os": 0.38814197039065573, "cat": 1, "y": 0.07856598016781083, "term": "methodology", "s": 0.1154434250764526, "bg": 1.614952739753865e-06, "x": 0.4271548436308162, "ncat": 7}, {"cat25k": 9, "ncat25k": 8, "os": 0.5684878449741124, "cat": 3, "y": 0.43325705568268497, "term": "major", "s": 0.5902140672782875, "bg": 1.7937557714601538e-07, "x": 0.4279176201372998, "ncat": 7}, {"cat25k": 22, "ncat25k": 8, "os": 0.7562727199486876, "cat": 7, "y": 0.7894736842105263, "term": "ability", "s": 0.9571865443425076, "bg": 5.762611523340594e-07, "x": 0.4286803966437834, "ncat": 7}, {"cat25k": 12, "ncat25k": 8, "os": 0.6336409119141577, "cat": 4, "y": 0.5942028985507246, "term": "algorithms", "s": 0.7545871559633027, "bg": 2.165093070462167e-06, "x": 0.429443173150267, "ncat": 7}, {"cat25k": 3, "ncat25k": 8, "os": 0.38814197039065573, "cat": 1, "y": 0.08771929824561403, "term": "settings", "s": 0.1154434250764526, "bg": 4.748530863907343e-07, "x": 0.4302059496567506, "ncat": 7}, {"cat25k": 3, "ncat25k": 8, "os": 0.38814197039065573, "cat": 1, "y": 0.08924485125858124, "term": "finding", "s": 0.1154434250764526, "bg": 4.305943299769223e-07, "x": 0.4309687261632342, "ncat": 7}, {"cat25k": 6, "ncat25k": 8, "os": 0.48695224568159834, "cat": 2, "y": 0.2608695652173913, "term": "matching", "s": 0.34938837920489296, "bg": 5.737425571246777e-07, "x": 0.43173150266971777, "ncat": 7}, {"cat25k": 6, "ncat25k": 8, "os": 0.48695224568159834, "cat": 2, "y": 0.2631578947368421, "term": "image", "s": 0.34938837920489296, "bg": 1.7177813907548177e-07, "x": 0.43249427917620137, "ncat": 7}, {"cat25k": 3, "ncat25k": 8, "os": 0.38814197039065573, "cat": 1, "y": 0.09839816933638444, "term": "adding", "s": 0.1154434250764526, "bg": 6.703109237219684e-07, "x": 0.43325705568268497, "ncat": 7}, {"cat25k": 12, "ncat25k": 8, "os": 0.6336409119141577, "cat": 4, "y": 0.6033562166285278, "term": "crucial", "s": 0.7545871559633027, "bg": 2.214078661987983e-06, "x": 0.43401983218916856, "ncat": 7}, {"cat25k": 16, "ncat25k": 8, "os": 0.6848224865652851, "cat": 5, "y": 0.6994660564454614, "term": "thus", "s": 0.8975535168195719, "bg": 4.033421874786249e-07, "x": 0.43478260869565216, "ncat": 7}, {"cat25k": 12, "ncat25k": 8, "os": 0.6336409119141577, "cat": 4, "y": 0.6086956521739131, "term": "answers", "s": 0.7545871559633027, "bg": 7.472044672130317e-07, "x": 0.43554538520213576, "ncat": 7}, {"cat25k": 6, "ncat25k": 8, "os": 0.48695224568159834, "cat": 2, "y": 0.2799389778794813, "term": "proposes", "s": 0.34938837920489296, "bg": 4.412574759435004e-06, "x": 0.43630816170861936, "ncat": 7}, {"cat25k": 3, "ncat25k": 8, "os": 0.38814197039065573, "cat": 1, "y": 0.10526315789473684, "term": "bases", "s": 0.1154434250764526, "bg": 2.0645047631565727e-06, "x": 0.43707093821510296, "ncat": 7}, {"cat25k": 0, "ncat25k": 8, "os": 0.27488233814366553, "cat": 0, "y": 0.017543859649122806, "term": "factoid", "s": 0.0, "bg": 9.755145839430299e-05, "x": 0.43783371472158655, "ncat": 7}, {"cat25k": 3, "ncat25k": 8, "os": 0.38814197039065573, "cat": 1, "y": 0.10602593440122045, "term": "extractive", "s": 0.1154434250764526, "bg": 5.748319414948824e-05, "x": 0.43859649122807015, "ncat": 7}, {"cat25k": 6, "ncat25k": 8, "os": 0.48695224568159834, "cat": 2, "y": 0.28756674294431733, "term": "fact", "s": 0.34938837920489296, "bg": 1.9176804146809173e-07, "x": 0.43935926773455375, "ncat": 7}, {"cat25k": 3, "ncat25k": 8, "os": 0.38814197039065573, "cat": 1, "y": 0.10983981693363844, "term": "expensive", "s": 0.1154434250764526, "bg": 8.940816655310898e-07, "x": 0.4401220442410374, "ncat": 7}, {"cat25k": 9, "ncat25k": 8, "os": 0.5684878449741124, "cat": 3, "y": 0.4805491990846682, "term": "aim", "s": 0.5902140672782875, "bg": 6.894964455768734e-07, "x": 0.440884820747521, "ncat": 7}, {"cat25k": 9, "ncat25k": 8, "os": 0.5684878449741124, "cat": 3, "y": 0.4820747520976354, "term": "creating", "s": 0.5902140672782875, "bg": 7.194383981642398e-07, "x": 0.4416475972540046, "ncat": 7}, {"cat25k": 9, "ncat25k": 8, "os": 0.5684878449741124, "cat": 3, "y": 0.482837528604119, "term": "analyzing", "s": 0.5902140672782875, "bg": 4.5404012852059875e-06, "x": 0.4424103737604882, "ncat": 7}, {"cat25k": 16, "ncat25k": 8, "os": 0.6848224865652851, "cat": 5, "y": 0.7131960335621663, "term": "if", "s": 0.8975535168195719, "bg": 2.2906614176125044e-08, "x": 0.4431731502669718, "ncat": 7}, {"cat25k": 12, "ncat25k": 8, "os": 0.6336409119141577, "cat": 4, "y": 0.6163234172387491, "term": "written", "s": 0.7545871559633027, "bg": 2.2423287309570102e-07, "x": 0.4439359267734554, "ncat": 7}, {"cat25k": 19, "ncat25k": 8, "os": 0.724827101820251, "cat": 6, "y": 0.7696414950419527, "term": "resource", "s": 0.9258409785932722, "bg": 3.799258080881965e-07, "x": 0.444698703279939, "ncat": 7}, {"cat25k": 0, "ncat25k": 8, "os": 0.27488233814366553, "cat": 0, "y": 0.020594965675057208, "term": "project", "s": 0.0, "bg": 7.649222661133202e-08, "x": 0.4454614797864226, "ncat": 7}, {"cat25k": 12, "ncat25k": 8, "os": 0.6336409119141577, "cat": 4, "y": 0.6193745232646835, "term": "employ", "s": 0.7545871559633027, "bg": 4.073442124788881e-06, "x": 0.4462242562929062, "ncat": 7}, {"cat25k": 0, "ncat25k": 8, "os": 0.27488233814366553, "cat": 0, "y": 0.02135774218154081, "term": "latter", "s": 0.0, "bg": 1.1347969234804306e-06, "x": 0.4469870327993898, "ncat": 7}, {"cat25k": 12, "ncat25k": 8, "os": 0.6336409119141577, "cat": 4, "y": 0.6224256292906178, "term": "cost", "s": 0.7545871559633027, "bg": 1.5099781811927763e-07, "x": 0.4477498093058734, "ncat": 7}, {"cat25k": 9, "ncat25k": 8, "os": 0.5684878449741124, "cat": 3, "y": 0.4935163996948894, "term": "leverage", "s": 0.5902140672782875, "bg": 5.367457350061909e-06, "x": 0.448512585812357, "ncat": 7}, {"cat25k": 6, "ncat25k": 8, "os": 0.48695224568159834, "cat": 2, "y": 0.30282227307398935, "term": "message", "s": 0.34938837920489296, "bg": 5.8959628570848697e-08, "x": 0.4492753623188406, "ncat": 7}, {"cat25k": 6, "ncat25k": 8, "os": 0.48695224568159834, "cat": 2, "y": 0.30358504958047294, "term": "graphs", "s": 0.34938837920489296, "bg": 6.254051173327009e-06, "x": 0.4500381388253242, "ncat": 7}, {"cat25k": 6, "ncat25k": 8, "os": 0.48695224568159834, "cat": 2, "y": 0.30434782608695654, "term": "rule", "s": 0.34938837920489296, "bg": 3.450187861003938e-07, "x": 0.45080091533180777, "ncat": 7}, {"cat25k": 3, "ncat25k": 8, "os": 0.38814197039065573, "cat": 1, "y": 0.13196033562166284, "term": "amr", "s": 0.1154434250764526, "bg": 3.119109290877284e-05, "x": 0.45156369183829137, "ncat": 7}, {"cat25k": 0, "ncat25k": 8, "os": 0.27488233814366553, "cat": 0, "y": 0.02593440122044241, "term": "exploits", "s": 0.0, "bg": 6.904677475117269e-06, "x": 0.45232646834477497, "ncat": 7}, {"cat25k": 3, "ncat25k": 8, "os": 0.38814197039065573, "cat": 1, "y": 0.13501144164759726, "term": "making", "s": 0.1154434250764526, "bg": 1.2876835666362443e-07, "x": 0.45308924485125857, "ncat": 7}, {"cat25k": 19, "ncat25k": 8, "os": 0.724827101820251, "cat": 6, "y": 0.7734553775743707, "term": "towards", "s": 0.9258409785932722, "bg": 9.76824671856102e-07, "x": 0.45385202135774216, "ncat": 7}, {"cat25k": 12, "ncat25k": 8, "os": 0.6336409119141577, "cat": 4, "y": 0.6300533943554538, "term": "mining", "s": 0.7545871559633027, "bg": 1.642103342020451e-06, "x": 0.45461479786422576, "ncat": 7}, {"cat25k": 12, "ncat25k": 8, "os": 0.6336409119141577, "cat": 4, "y": 0.6308161708619374, "term": "recall", "s": 0.7545871559633027, "bg": 2.3000685913312054e-06, "x": 0.45537757437070936, "ncat": 7}, {"cat25k": 9, "ncat25k": 8, "os": 0.5684878449741124, "cat": 3, "y": 0.5026697177726926, "term": "value", "s": 0.5902140672782875, "bg": 1.2080167240470948e-07, "x": 0.45614035087719296, "ncat": 7}, {"cat25k": 6, "ncat25k": 8, "os": 0.48695224568159834, "cat": 2, "y": 0.30816170861937453, "term": "past", "s": 0.34938837920489296, "bg": 1.7032381708618701e-07, "x": 0.4569031273836766, "ncat": 7}, {"cat25k": 19, "ncat25k": 8, "os": 0.724827101820251, "cat": 6, "y": 0.7757437070938215, "term": "researchers", "s": 0.9258409785932722, "bg": 1.6193593328671377e-06, "x": 0.4576659038901602, "ncat": 7}, {"cat25k": 16, "ncat25k": 8, "os": 0.6848224865652851, "cat": 5, "y": 0.7246376811594203, "term": "real", "s": 0.8975535168195719, "bg": 9.404496120986264e-08, "x": 0.4584286803966438, "ncat": 7}, {"cat25k": 19, "ncat25k": 8, "os": 0.724827101820251, "cat": 6, "y": 0.7765064836003052, "term": "top", "s": 0.9258409785932722, "bg": 6.194901359948524e-08, "x": 0.4591914569031274, "ncat": 7}, {"cat25k": 6, "ncat25k": 8, "os": 0.48695224568159834, "cat": 2, "y": 0.32189168573607935, "term": "encoder", "s": 0.34938837920489296, "bg": 9.28426196187882e-06, "x": 0.459954233409611, "ncat": 7}, {"cat25k": 16, "ncat25k": 8, "os": 0.6848224865652851, "cat": 5, "y": 0.7269260106788711, "term": "accurate", "s": 0.8975535168195719, "bg": 1.1111147707351575e-06, "x": 0.4607170099160946, "ncat": 7}, {"cat25k": 12, "ncat25k": 8, "os": 0.6336409119141577, "cat": 4, "y": 0.6437833714721587, "term": "classify", "s": 0.7545871559633027, "bg": 1.349923898040248e-05, "x": 0.4614797864225782, "ncat": 7}, {"cat25k": 6, "ncat25k": 8, "os": 0.48695224568159834, "cat": 2, "y": 0.32341723874904654, "term": "svm", "s": 0.34938837920489296, "bg": 4.267475906542278e-05, "x": 0.4622425629290618, "ncat": 7}, {"cat25k": 6, "ncat25k": 8, "os": 0.48695224568159834, "cat": 2, "y": 0.32723112128146453, "term": "size", "s": 0.34938837920489296, "bg": 1.2098673505159562e-07, "x": 0.4630053394355454, "ncat": 7}, {"cat25k": 0, "ncat25k": 8, "os": 0.27488233814366553, "cat": 0, "y": 0.029748283752860413, "term": "effects", "s": 0.0, "bg": 2.1830130176098205e-07, "x": 0.463768115942029, "ncat": 7}, {"cat25k": 6, "ncat25k": 8, "os": 0.48695224568159834, "cat": 2, "y": 0.32799389778794813, "term": "performs", "s": 0.34938837920489296, "bg": 3.559152384624009e-06, "x": 0.4645308924485126, "ncat": 7}, {"cat25k": 3, "ncat25k": 8, "os": 0.38814197039065573, "cat": 1, "y": 0.15255530129672007, "term": "particularly", "s": 0.1154434250764526, "bg": 3.790064804659941e-07, "x": 0.4652936689549962, "ncat": 7}, {"cat25k": 0, "ncat25k": 8, "os": 0.27488233814366553, "cat": 0, "y": 0.03051106025934401, "term": "suggest", "s": 0.0, "bg": 3.806233463105051e-07, "x": 0.4660564454614798, "ncat": 7}, {"cat25k": 3, "ncat25k": 8, "os": 0.38814197039065573, "cat": 1, "y": 0.15636918382913806, "term": "applying", "s": 0.1154434250764526, "bg": 1.1037578609117468e-06, "x": 0.4668192219679634, "ncat": 7}, {"cat25k": 0, "ncat25k": 8, "os": 0.27488233814366553, "cat": 0, "y": 0.032036613272311214, "term": "published", "s": 0.0, "bg": 1.882816645690128e-07, "x": 0.467581998474447, "ncat": 7}, {"cat25k": 3, "ncat25k": 8, "os": 0.38814197039065573, "cat": 1, "y": 0.15865751334858885, "term": "essential", "s": 0.1154434250764526, "bg": 6.834387261564329e-07, "x": 0.4683447749809306, "ncat": 7}, {"cat25k": 3, "ncat25k": 8, "os": 0.38814197039065573, "cat": 1, "y": 0.16018306636155608, "term": "builds", "s": 0.1154434250764526, "bg": 2.4661794318169207e-06, "x": 0.4691075514874142, "ncat": 7}, {"cat25k": 6, "ncat25k": 8, "os": 0.48695224568159834, "cat": 2, "y": 0.34096109839816935, "term": "amounts", "s": 0.34938837920489296, "bg": 6.072900924568802e-07, "x": 0.4698703279938978, "ncat": 7}, {"cat25k": 3, "ncat25k": 8, "os": 0.38814197039065573, "cat": 1, "y": 0.16475972540045766, "term": "choice", "s": 0.1154434250764526, "bg": 3.222132087145433e-07, "x": 0.47063310450038137, "ncat": 7}, {"cat25k": 0, "ncat25k": 8, "os": 0.27488233814366553, "cat": 0, "y": 0.036613272311212815, "term": "constraints", "s": 0.0, "bg": 1.8895272761765188e-06, "x": 0.47139588100686497, "ncat": 7}, {"cat25k": 3, "ncat25k": 8, "os": 0.38814197039065573, "cat": 1, "y": 0.17009916094584288, "term": "scheme", "s": 0.1154434250764526, "bg": 6.345955250297873e-07, "x": 0.47215865751334857, "ncat": 7}, {"cat25k": 3, "ncat25k": 8, "os": 0.38814197039065573, "cat": 1, "y": 0.17391304347826086, "term": "i", "s": 0.1154434250764526, "bg": 5.832262739423815e-09, "x": 0.47292143401983217, "ncat": 7}, {"cat25k": 0, "ncat25k": 8, "os": 0.27488233814366553, "cat": 0, "y": 0.041952707856598014, "term": "values", "s": 0.0, "bg": 1.9999509440604148e-07, "x": 0.47368421052631576, "ncat": 7}, {"cat25k": 3, "ncat25k": 8, "os": 0.38814197039065573, "cat": 1, "y": 0.17925247902364608, "term": "handle", "s": 0.1154434250764526, "bg": 5.560000123555558e-07, "x": 0.4744469870327994, "ncat": 7}, {"cat25k": 16, "ncat25k": 8, "os": 0.6848224865652851, "cat": 5, "y": 0.7337909992372235, "term": "therefore", "s": 0.8975535168195719, "bg": 4.184240746020513e-07, "x": 0.475209763539283, "ncat": 7}, {"cat25k": 6, "ncat25k": 8, "os": 0.48695224568159834, "cat": 2, "y": 0.35621662852784136, "term": "nature", "s": 0.34938837920489296, "bg": 2.2300833762510813e-07, "x": 0.4759725400457666, "ncat": 7}, {"cat25k": 9, "ncat25k": 8, "os": 0.5684878449741124, "cat": 3, "y": 0.540045766590389, "term": "characteristics", "s": 0.5902140672782875, "bg": 9.081782649906485e-07, "x": 0.4767353165522502, "ncat": 7}, {"cat25k": 16, "ncat25k": 8, "os": 0.6848224865652851, "cat": 5, "y": 0.7353165522501907, "term": "become", "s": 0.8975535168195719, "bg": 1.9908673274897286e-07, "x": 0.4774980930587338, "ncat": 7}, {"cat25k": 16, "ncat25k": 8, "os": 0.6848224865652851, "cat": 5, "y": 0.7368421052631579, "term": "explicitly", "s": 0.8975535168195719, "bg": 3.7212602419935535e-06, "x": 0.4782608695652174, "ncat": 7}, {"cat25k": 9, "ncat25k": 8, "os": 0.5684878449741124, "cat": 3, "y": 0.5423340961098398, "term": "interpretation", "s": 0.5902140672782875, "bg": 1.6088557360100402e-06, "x": 0.479023646071701, "ncat": 7}, {"cat25k": 6, "ncat25k": 8, "os": 0.48695224568159834, "cat": 2, "y": 0.36384439359267734, "term": "encoding", "s": 0.34938837920489296, "bg": 2.4208286608236552e-06, "x": 0.4797864225781846, "ncat": 7}, {"cat25k": 0, "ncat25k": 8, "os": 0.27488233814366553, "cat": 0, "y": 0.04652936689549962, "term": "extending", "s": 0.0, "bg": 2.0587653995651887e-06, "x": 0.4805491990846682, "ncat": 7}, {"cat25k": 3, "ncat25k": 8, "os": 0.38814197039065573, "cat": 1, "y": 0.18764302059496568, "term": "reduce", "s": 0.1154434250764526, "bg": 4.512840950461467e-07, "x": 0.4813119755911518, "ncat": 7}, {"cat25k": 6, "ncat25k": 8, "os": 0.48695224568159834, "cat": 2, "y": 0.36460717009916094, "term": "outputs", "s": 0.34938837920489296, "bg": 3.279460004115722e-06, "x": 0.4820747520976354, "ncat": 7}, {"cat25k": 9, "ncat25k": 8, "os": 0.5684878449741124, "cat": 3, "y": 0.5469107551487414, "term": "yields", "s": 0.5902140672782875, "bg": 3.4972677595628415e-06, "x": 0.482837528604119, "ncat": 7}, {"cat25k": 12, "ncat25k": 8, "os": 0.6336409119141577, "cat": 4, "y": 0.6590389016018307, "term": "functions", "s": 0.7545871559633027, "bg": 6.554612229044139e-07, "x": 0.4836003051106026, "ncat": 7}, {"cat25k": 3, "ncat25k": 8, "os": 0.38814197039065573, "cat": 1, "y": 0.19069412662090007, "term": "decisions", "s": 0.1154434250764526, "bg": 5.736757961114152e-07, "x": 0.4843630816170862, "ncat": 7}, {"cat25k": 6, "ncat25k": 8, "os": 0.48695224568159834, "cat": 2, "y": 0.3699466056445461, "term": "decoder", "s": 0.34938837920489296, "bg": 1.1242168248884743e-05, "x": 0.4851258581235698, "ncat": 7}, {"cat25k": 3, "ncat25k": 8, "os": 0.38814197039065573, "cat": 1, "y": 0.1945080091533181, "term": "solve", "s": 0.1154434250764526, "bg": 1.3325846181978496e-06, "x": 0.4858886346300534, "ncat": 7}, {"cat25k": 3, "ncat25k": 8, "os": 0.38814197039065573, "cat": 1, "y": 0.19679633867276888, "term": "sampling", "s": 0.1154434250764526, "bg": 2.0665384035164217e-06, "x": 0.486651411136537, "ncat": 7}, {"cat25k": 9, "ncat25k": 8, "os": 0.5684878449741124, "cat": 3, "y": 0.555301296720061, "term": "descriptions", "s": 0.5902140672782875, "bg": 1.3862515613380215e-06, "x": 0.4874141876430206, "ncat": 7}, {"cat25k": 0, "ncat25k": 8, "os": 0.27488233814366553, "cat": 0, "y": 0.05491990846681922, "term": "spaces", "s": 0.0, "bg": 1.1453654568468294e-06, "x": 0.4881769641495042, "ncat": 7}, {"cat25k": 3, "ncat25k": 8, "os": 0.38814197039065573, "cat": 1, "y": 0.2036613272311213, "term": "full", "s": 0.1154434250764526, "bg": 6.451933106422072e-08, "x": 0.4889397406559878, "ncat": 7}, {"cat25k": 0, "ncat25k": 8, "os": 0.27488233814366553, "cat": 0, "y": 0.057971014492753624, "term": "effort", "s": 0.0, "bg": 3.9231489449242606e-07, "x": 0.4897025171624714, "ncat": 7}, {"cat25k": 6, "ncat25k": 8, "os": 0.48695224568159834, "cat": 2, "y": 0.38520213577421814, "term": "computation", "s": 0.34938837920489296, "bg": 3.4804429559750076e-06, "x": 0.49046529366895497, "ncat": 7}, {"cat25k": 6, "ncat25k": 8, "os": 0.48695224568159834, "cat": 2, "y": 0.3882532418001526, "term": "conditional", "s": 0.34938837920489296, "bg": 4.256811914893947e-06, "x": 0.49122807017543857, "ncat": 7}, {"cat25k": 9, "ncat25k": 8, "os": 0.5684878449741124, "cat": 3, "y": 0.5614035087719298, "term": "understand", "s": 0.5902140672782875, "bg": 3.2375344200495325e-07, "x": 0.4919908466819222, "ncat": 7}, {"cat25k": 3, "ncat25k": 8, "os": 0.38814197039065573, "cat": 1, "y": 0.2128146453089245, "term": "changes", "s": 0.1154434250764526, "bg": 1.8373108830070937e-07, "x": 0.4927536231884058, "ncat": 7}, {"cat25k": 3, "ncat25k": 8, "os": 0.38814197039065573, "cat": 1, "y": 0.2143401983218917, "term": "semantically", "s": 0.1154434250764526, "bg": 3.7622272385252076e-05, "x": 0.4935163996948894, "ncat": 7}, {"cat25k": 0, "ncat25k": 8, "os": 0.27488233814366553, "cat": 0, "y": 0.06407322654462243, "term": "decision", "s": 0.0, "bg": 2.251557990177719e-07, "x": 0.494279176201373, "ncat": 7}, {"cat25k": 9, "ncat25k": 8, "os": 0.5684878449741124, "cat": 3, "y": 0.5652173913043478, "term": "created", "s": 0.5902140672782875, "bg": 2.912681769091546e-07, "x": 0.4950419527078566, "ncat": 7}, {"cat25k": 6, "ncat25k": 8, "os": 0.48695224568159834, "cat": 2, "y": 0.39893211289092295, "term": "experiment", "s": 0.34938837920489296, "bg": 1.2131935608538565e-06, "x": 0.4958047292143402, "ncat": 7}, {"cat25k": 0, "ncat25k": 8, "os": 0.27488233814366553, "cat": 0, "y": 0.06559877955758962, "term": "programming", "s": 0.0, "bg": 3.156700984675657e-07, "x": 0.4965675057208238, "ncat": 7}, {"cat25k": 3, "ncat25k": 8, "os": 0.38814197039065573, "cat": 1, "y": 0.2227307398932113, "term": "solving", "s": 0.1154434250764526, "bg": 2.0017781795569006e-06, "x": 0.4973302822273074, "ncat": 7}, {"cat25k": 3, "ncat25k": 8, "os": 0.38814197039065573, "cat": 1, "y": 0.22578184591914569, "term": "official", "s": 0.1154434250764526, "bg": 1.7378464097522072e-07, "x": 0.498093058733791, "ncat": 7}, {"cat25k": 6, "ncat25k": 8, "os": 0.48695224568159834, "cat": 2, "y": 0.4080854309687262, "term": "pairwise", "s": 0.34938837920489296, "bg": 2.902907423056826e-05, "x": 0.4988558352402746, "ncat": 7}, {"cat25k": 6, "ncat25k": 8, "os": 0.48695224568159834, "cat": 2, "y": 0.4096109839816934, "term": "account", "s": 0.34938837920489296, "bg": 9.819961561233464e-08, "x": 0.4996186117467582, "ncat": 7}, {"cat25k": 6, "ncat25k": 8, "os": 0.48695224568159834, "cat": 2, "y": 0.41418764302059496, "term": "respectively", "s": 0.34938837920489296, "bg": 1.0650927278604647e-06, "x": 0.5003813882532419, "ncat": 7}, {"cat25k": 3, "ncat25k": 9, "os": 0.37637475362311695, "cat": 1, "y": 0.07475209763539283, "term": "consisting", "s": 0.10397553516819572, "bg": 2.7903311676643032e-06, "x": 0.5011441647597255, "ncat": 8}, {"cat25k": 12, "ncat25k": 9, "os": 0.606713619791769, "cat": 4, "y": 0.5789473684210527, "term": "whether", "s": 0.7140672782874617, "bg": 2.2841828172747304e-07, "x": 0.501906941266209, "ncat": 8}, {"cat25k": 16, "ncat25k": 9, "os": 0.6574374502292555, "cat": 5, "y": 0.6796338672768879, "term": "people", "s": 0.8386850152905199, "bg": 7.494397625508365e-08, "x": 0.5026697177726926, "ncat": 8}, {"cat25k": 6, "ncat25k": 9, "os": 0.4669837332201837, "cat": 2, "y": 0.2448512585812357, "term": "help", "s": 0.31651376146788995, "bg": 3.272736061511205e-08, "x": 0.5034324942791762, "ncat": 8}, {"cat25k": 6, "ncat25k": 9, "os": 0.4669837332201837, "cat": 2, "y": 0.2471395881006865, "term": "needed", "s": 0.31651376146788995, "bg": 2.872680852103996e-07, "x": 0.5041952707856598, "ncat": 8}, {"cat25k": 16, "ncat25k": 9, "os": 0.6574374502292555, "cat": 5, "y": 0.6849733028222731, "term": "highly", "s": 0.8386850152905199, "bg": 6.524872943829024e-07, "x": 0.5049580472921434, "ncat": 8}, {"cat25k": 9, "ncat25k": 9, "os": 0.5437442859831727, "cat": 3, "y": 0.43859649122807015, "term": "errors", "s": 0.5122324159021406, "bg": 5.744306954457489e-07, "x": 0.505720823798627, "ncat": 8}, {"cat25k": 28, "ncat25k": 9, "os": 0.7788846723121688, "cat": 9, "y": 0.8520213577421816, "term": "documents", "s": 0.959480122324159, "bg": 7.132582237277691e-07, "x": 0.5064836003051106, "ncat": 8}, {"cat25k": 12, "ncat25k": 9, "os": 0.606713619791769, "cat": 4, "y": 0.5957284515636918, "term": "rely", "s": 0.7140672782874617, "bg": 2.829748096912777e-06, "x": 0.5072463768115942, "ncat": 8}, {"cat25k": 16, "ncat25k": 9, "os": 0.6574374502292555, "cat": 5, "y": 0.6872616323417239, "term": "n", "s": 0.8386850152905199, "bg": 7.305655572580447e-08, "x": 0.5080091533180778, "ncat": 8}, {"cat25k": 6, "ncat25k": 9, "os": 0.4669837332201837, "cat": 2, "y": 0.2585812356979405, "term": "sequences", "s": 0.31651376146788995, "bg": 2.397117337326316e-06, "x": 0.5087719298245614, "ncat": 8}, {"cat25k": 6, "ncat25k": 9, "os": 0.4669837332201837, "cat": 2, "y": 0.2593440122044241, "term": "lstms", "s": 0.31651376146788995, "bg": 0.0005050505050505052, "x": 0.509534706331045, "ncat": 8}, {"cat25k": 6, "ncat25k": 9, "os": 0.4669837332201837, "cat": 2, "y": 0.2623951182303585, "term": "ranging", "s": 0.31651376146788995, "bg": 1.9477054714844716e-06, "x": 0.5102974828375286, "ncat": 8}, {"cat25k": 9, "ncat25k": 9, "os": 0.5437442859831727, "cat": 3, "y": 0.4477498093058734, "term": "bag", "s": 0.5122324159021406, "bg": 5.892859129066358e-07, "x": 0.5110602593440122, "ncat": 8}, {"cat25k": 9, "ncat25k": 9, "os": 0.5437442859831727, "cat": 3, "y": 0.448512585812357, "term": "submitted", "s": 0.5122324159021406, "bg": 5.054142108557762e-07, "x": 0.5118230358504958, "ncat": 8}, {"cat25k": 9, "ncat25k": 9, "os": 0.5437442859831727, "cat": 3, "y": 0.4576659038901602, "term": "typically", "s": 0.5122324159021406, "bg": 1.1753165781982728e-06, "x": 0.5125858123569794, "ncat": 8}, {"cat25k": 16, "ncat25k": 9, "os": 0.6574374502292555, "cat": 5, "y": 0.7009916094584286, "term": "challenges", "s": 0.8386850152905199, "bg": 1.6201830158734732e-06, "x": 0.513348588863463, "ncat": 8}, {"cat25k": 9, "ncat25k": 9, "os": 0.5437442859831727, "cat": 3, "y": 0.4614797864225782, "term": "relationships", "s": 0.5122324159021406, "bg": 9.362744209627561e-07, "x": 0.5141113653699466, "ncat": 8}, {"cat25k": 0, "ncat25k": 9, "os": 0.27488233814366553, "cat": 0, "y": 0.015255530129672006, "term": "unstructured", "s": 0.0, "bg": 2.1948917552549365e-05, "x": 0.5148741418764302, "ncat": 8}, {"cat25k": 0, "ncat25k": 9, "os": 0.27488233814366553, "cat": 0, "y": 0.016781083142639208, "term": "extended", "s": 0.0, "bg": 4.4809108437090223e-07, "x": 0.5156369183829138, "ncat": 8}, {"cat25k": 19, "ncat25k": 9, "os": 0.6980244784665887, "cat": 6, "y": 0.7635392829900839, "term": "effectiveness", "s": 0.9082568807339448, "bg": 1.8799331039233063e-06, "x": 0.5163996948893974, "ncat": 8}, {"cat25k": 9, "ncat25k": 9, "os": 0.5437442859831727, "cat": 3, "y": 0.47063310450038137, "term": "because", "s": 0.5122324159021406, "bg": 8.106731069289656e-08, "x": 0.517162471395881, "ncat": 8}, {"cat25k": 9, "ncat25k": 9, "os": 0.5437442859831727, "cat": 3, "y": 0.47139588100686497, "term": "less", "s": 0.5122324159021406, "bg": 1.5121773164824355e-07, "x": 0.5179252479023646, "ncat": 8}, {"cat25k": 3, "ncat25k": 9, "os": 0.37637475362311695, "cat": 1, "y": 0.11060259344012205, "term": "will", "s": 0.10397553516819572, "bg": 2.0643653165862244e-08, "x": 0.5186880244088482, "ncat": 8}, {"cat25k": 31, "ncat25k": 9, "os": 0.7971318951493415, "cat": 10, "y": 0.8764302059496567, "term": "much", "s": 0.9862385321100917, "bg": 1.5677748338679548e-07, "x": 0.5194508009153318, "ncat": 8}, {"cat25k": 6, "ncat25k": 9, "os": 0.4669837332201837, "cat": 2, "y": 0.2944317315026697, "term": "enable", "s": 0.31651376146788995, "bg": 5.026585232299741e-07, "x": 0.5202135774218154, "ncat": 8}, {"cat25k": 3, "ncat25k": 9, "os": 0.37637475362311695, "cat": 1, "y": 0.12051868802440885, "term": "reports", "s": 0.10397553516819572, "bg": 1.7456364217263828e-07, "x": 0.520976353928299, "ncat": 8}, {"cat25k": 3, "ncat25k": 9, "os": 0.37637475362311695, "cat": 1, "y": 0.12509534706331046, "term": "binary", "s": 0.10397553516819572, "bg": 1.7824712586637217e-06, "x": 0.5217391304347826, "ncat": 8}, {"cat25k": 16, "ncat25k": 9, "os": 0.6574374502292555, "cat": 5, "y": 0.7200610221205187, "term": "focused", "s": 0.8386850152905199, "bg": 1.300989011846806e-06, "x": 0.5225019069412662, "ncat": 8}, {"cat25k": 3, "ncat25k": 9, "os": 0.37637475362311695, "cat": 1, "y": 0.13729977116704806, "term": "abstract", "s": 0.10397553516819572, "bg": 4.999346513991385e-07, "x": 0.5232646834477498, "ncat": 8}, {"cat25k": 6, "ncat25k": 9, "os": 0.4669837332201837, "cat": 2, "y": 0.30663615560640733, "term": "empirical", "s": 0.31651376146788995, "bg": 3.4250129379863737e-06, "x": 0.5240274599542334, "ncat": 8}, {"cat25k": 12, "ncat25k": 9, "os": 0.606713619791769, "cat": 4, "y": 0.6369183829138062, "term": "labeling", "s": 0.7140672782874617, "bg": 7.731102588107391e-06, "x": 0.524790236460717, "ncat": 8}, {"cat25k": 12, "ncat25k": 9, "os": 0.606713619791769, "cat": 4, "y": 0.6392067124332571, "term": "still", "s": 0.7140672782874617, "bg": 1.259915766756519e-07, "x": 0.5255530129672006, "ncat": 8}, {"cat25k": 3, "ncat25k": 9, "os": 0.37637475362311695, "cat": 1, "y": 0.15102974828375287, "term": "skip", "s": 0.10397553516819572, "bg": 7.15294662954049e-07, "x": 0.5263157894736842, "ncat": 8}, {"cat25k": 9, "ncat25k": 9, "os": 0.5437442859831727, "cat": 3, "y": 0.517162471395881, "term": "structures", "s": 0.5122324159021406, "bg": 1.2538923070297945e-06, "x": 0.5270785659801678, "ncat": 8}, {"cat25k": 9, "ncat25k": 9, "os": 0.5437442859831727, "cat": 3, "y": 0.5179252479023646, "term": "relies", "s": 0.5122324159021406, "bg": 6.430364414597162e-06, "x": 0.5278413424866514, "ncat": 8}, {"cat25k": 0, "ncat25k": 9, "os": 0.27488233814366553, "cat": 0, "y": 0.03279938977879481, "term": "predictions", "s": 0.0, "bg": 2.788685119279906e-06, "x": 0.528604118993135, "ncat": 8}, {"cat25k": 9, "ncat25k": 9, "os": 0.5437442859831727, "cat": 3, "y": 0.5225019069412662, "term": "aims", "s": 0.5122324159021406, "bg": 1.9030551965300962e-06, "x": 0.5293668954996186, "ncat": 8}, {"cat25k": 12, "ncat25k": 9, "os": 0.606713619791769, "cat": 4, "y": 0.6514111365369947, "term": "relative", "s": 0.7140672782874617, "bg": 1.048619858972613e-06, "x": 0.5301296720061022, "ncat": 8}, {"cat25k": 6, "ncat25k": 9, "os": 0.4669837332201837, "cat": 2, "y": 0.3516399694889397, "term": "science", "s": 0.31651376146788995, "bg": 1.377029169385128e-07, "x": 0.5308924485125858, "ncat": 8}, {"cat25k": 3, "ncat25k": 9, "os": 0.37637475362311695, "cat": 1, "y": 0.17848970251716248, "term": "reading", "s": 0.10397553516819572, "bg": 3.775765944800001e-07, "x": 0.5316552250190694, "ncat": 8}, {"cat25k": 9, "ncat25k": 9, "os": 0.5437442859831727, "cat": 3, "y": 0.5362318840579711, "term": "collected", "s": 0.5122324159021406, "bg": 1.0524503459906593e-06, "x": 0.532418001525553, "ncat": 8}, {"cat25k": 9, "ncat25k": 9, "os": 0.5437442859831727, "cat": 3, "y": 0.5446224256292906, "term": "publications", "s": 0.5122324159021406, "bg": 4.5485761535209435e-07, "x": 0.5331807780320366, "ncat": 8}, {"cat25k": 3, "ncat25k": 9, "os": 0.37637475362311695, "cat": 1, "y": 0.18916857360793288, "term": "metrics", "s": 0.10397553516819572, "bg": 7.616855898988304e-06, "x": 0.5339435545385202, "ncat": 8}, {"cat25k": 9, "ncat25k": 9, "os": 0.5437442859831727, "cat": 3, "y": 0.5545385202135774, "term": "web", "s": 0.5122324159021406, "bg": 5.164397148938391e-08, "x": 0.5347063310450039, "ncat": 8}, {"cat25k": 6, "ncat25k": 9, "os": 0.4669837332201837, "cat": 2, "y": 0.37604881769641496, "term": "difficulty", "s": 0.31651376146788995, "bg": 1.6210286318234668e-06, "x": 0.5354691075514875, "ncat": 8}, {"cat25k": 3, "ncat25k": 9, "os": 0.37637475362311695, "cat": 1, "y": 0.19908466819221968, "term": "dialogue", "s": 0.10397553516819572, "bg": 4.585658963014367e-06, "x": 0.5362318840579711, "ncat": 8}, {"cat25k": 16, "ncat25k": 9, "os": 0.6574374502292555, "cat": 5, "y": 0.7398932112890922, "term": "building", "s": 0.8386850152905199, "bg": 2.4940220046158577e-07, "x": 0.5369946605644547, "ncat": 8}, {"cat25k": 0, "ncat25k": 9, "os": 0.27488233814366553, "cat": 0, "y": 0.05644546147978642, "term": "transition", "s": 0.0, "bg": 1.7921369989172504e-06, "x": 0.5377574370709383, "ncat": 8}, {"cat25k": 3, "ncat25k": 9, "os": 0.37637475362311695, "cat": 1, "y": 0.20213577421815407, "term": "actions", "s": 0.10397553516819572, "bg": 6.002692669407819e-07, "x": 0.5385202135774219, "ncat": 8}, {"cat25k": 9, "ncat25k": 9, "os": 0.5437442859831727, "cat": 3, "y": 0.5598779557589626, "term": "track", "s": 0.5122324159021406, "bg": 2.8459449531101666e-07, "x": 0.5392829900839055, "ncat": 8}, {"cat25k": 12, "ncat25k": 9, "os": 0.606713619791769, "cat": 4, "y": 0.6651411136536994, "term": "rank", "s": 0.7140672782874617, "bg": 9.32435734129553e-07, "x": 0.540045766590389, "ncat": 8}, {"cat25k": 19, "ncat25k": 9, "os": 0.6980244784665887, "cat": 6, "y": 0.782608695652174, "term": "10", "s": 0.9082568807339448, "bg": 0.0, "x": 0.5408085430968727, "ncat": 8}, {"cat25k": 0, "ncat25k": 9, "os": 0.27488233814366553, "cat": 0, "y": 0.05873379099923722, "term": "weights", "s": 0.0, "bg": 3.3591868569065795e-06, "x": 0.5415713196033562, "ncat": 8}, {"cat25k": 0, "ncat25k": 9, "os": 0.27488233814366553, "cat": 0, "y": 0.06254767353165523, "term": "sources", "s": 0.0, "bg": 2.874791521715952e-07, "x": 0.5423340961098398, "ncat": 8}, {"cat25k": 0, "ncat25k": 9, "os": 0.27488233814366553, "cat": 0, "y": 0.06788710907704043, "term": "concept", "s": 0.0, "bg": 6.301834757133118e-07, "x": 0.5430968726163234, "ncat": 8}, {"cat25k": 19, "ncat25k": 10, "os": 0.673799666511757, "cat": 6, "y": 0.7429443173150267, "term": "being", "s": 0.8623853211009175, "bg": 1.2353887891234659e-07, "x": 0.543859649122807, "ncat": 9}, {"cat25k": 12, "ncat25k": 10, "os": 0.5833720786881543, "cat": 4, "y": 0.5812356979405034, "term": "according", "s": 0.6238532110091742, "bg": 3.580846788732408e-07, "x": 0.5446224256292906, "ncat": 9}, {"cat25k": 12, "ncat25k": 10, "os": 0.5833720786881543, "cat": 4, "y": 0.5835240274599542, "term": "since", "s": 0.6238532110091742, "bg": 1.212922108264821e-07, "x": 0.5453852021357742, "ncat": 9}, {"cat25k": 12, "ncat25k": 10, "os": 0.5833720786881543, "cat": 4, "y": 0.5842868039664378, "term": "works", "s": 0.6238532110091742, "bg": 2.635924033358754e-07, "x": 0.5461479786422578, "ncat": 9}, {"cat25k": 16, "ncat25k": 10, "os": 0.6331612260516191, "cat": 5, "y": 0.6811594202898551, "term": "instances", "s": 0.7492354740061162, "bg": 3.911689243441334e-06, "x": 0.5469107551487414, "ncat": 9}, {"cat25k": 12, "ncat25k": 10, "os": 0.5833720786881543, "cat": 4, "y": 0.5865751334858886, "term": "annotations", "s": 0.6238532110091742, "bg": 2.0623707795808423e-05, "x": 0.547673531655225, "ncat": 9}, {"cat25k": 19, "ncat25k": 10, "os": 0.673799666511757, "cat": 6, "y": 0.7490465293668955, "term": "although", "s": 0.8623853211009175, "bg": 3.767194984788569e-07, "x": 0.5484363081617086, "ncat": 9}, {"cat25k": 6, "ncat25k": 10, "os": 0.45058111172325954, "cat": 2, "y": 0.2402745995423341, "term": "participants", "s": 0.2308868501529052, "bg": 1.3066255158026724e-06, "x": 0.5491990846681922, "ncat": 9}, {"cat25k": 19, "ncat25k": 10, "os": 0.673799666511757, "cat": 6, "y": 0.7505720823798627, "term": "either", "s": 0.8623853211009175, "bg": 3.0242407411760823e-07, "x": 0.5499618611746758, "ncat": 9}, {"cat25k": 12, "ncat25k": 10, "os": 0.5833720786881543, "cat": 4, "y": 0.593440122044241, "term": "example", "s": 0.6238532110091742, "bg": 1.963380076907259e-07, "x": 0.5507246376811594, "ncat": 9}, {"cat25k": 9, "ncat25k": 10, "os": 0.522836370084893, "cat": 3, "y": 0.43783371472158655, "term": "error", "s": 0.4487767584097859, "bg": 4.695259650206286e-07, "x": 0.551487414187643, "ncat": 9}, {"cat25k": 3, "ncat25k": 10, "os": 0.3669888006584705, "cat": 1, "y": 0.08543096872616324, "term": "list", "s": 0.09327217125382262, "bg": 7.193543150142761e-08, "x": 0.5522501906941266, "ncat": 9}, {"cat25k": 6, "ncat25k": 10, "os": 0.45058111172325954, "cat": 2, "y": 0.2540045766590389, "term": "overall", "s": 0.2308868501529052, "bg": 3.0361268352611873e-07, "x": 0.5530129672006102, "ncat": 9}, {"cat25k": 3, "ncat25k": 10, "os": 0.3669888006584705, "cat": 1, "y": 0.08619374523264683, "term": "states", "s": 0.09327217125382262, "bg": 1.1494585115517669e-07, "x": 0.5537757437070938, "ncat": 9}, {"cat25k": 9, "ncat25k": 10, "os": 0.522836370084893, "cat": 3, "y": 0.444698703279939, "term": "analyze", "s": 0.4487767584097859, "bg": 2.7272240711160042e-06, "x": 0.5545385202135774, "ncat": 9}, {"cat25k": 12, "ncat25k": 10, "os": 0.5833720786881543, "cat": 4, "y": 0.5995423340961098, "term": "include", "s": 0.6238532110091742, "bg": 1.4236066862951367e-07, "x": 0.555301296720061, "ncat": 9}, {"cat25k": 16, "ncat25k": 10, "os": 0.6331612260516191, "cat": 5, "y": 0.6933638443935927, "term": "alignment", "s": 0.7492354740061162, "bg": 5.858945357877699e-06, "x": 0.5560640732265446, "ncat": 9}, {"cat25k": 0, "ncat25k": 10, "os": 0.27488233814366553, "cat": 0, "y": 0.004576659038901602, "term": "architectures", "s": 0.0, "bg": 6.414914325903307e-06, "x": 0.5568268497330282, "ncat": 9}, {"cat25k": 6, "ncat25k": 10, "os": 0.45058111172325954, "cat": 2, "y": 0.26773455377574373, "term": "generates", "s": 0.2308868501529052, "bg": 4.5724040176189965e-06, "x": 0.5575896262395118, "ncat": 9}, {"cat25k": 16, "ncat25k": 10, "os": 0.6331612260516191, "cat": 5, "y": 0.6987032799389779, "term": "automated", "s": 0.7492354740061162, "bg": 2.17519806537884e-06, "x": 0.5583524027459954, "ncat": 9}, {"cat25k": 25, "ncat25k": 10, "os": 0.734459742737951, "cat": 8, "y": 0.8314263920671243, "term": "events", "s": 0.9441896024464832, "bg": 2.8814018620185173e-07, "x": 0.559115179252479, "ncat": 9}, {"cat25k": 12, "ncat25k": 10, "os": 0.5833720786881543, "cat": 4, "y": 0.6056445461479787, "term": "years", "s": 0.6238532110091742, "bg": 8.286555015064675e-08, "x": 0.5598779557589626, "ncat": 9}, {"cat25k": 12, "ncat25k": 10, "os": 0.5833720786881543, "cat": 4, "y": 0.6064073226544623, "term": "properties", "s": 0.6238532110091742, "bg": 4.933995475526149e-07, "x": 0.5606407322654462, "ncat": 9}, {"cat25k": 19, "ncat25k": 10, "os": 0.673799666511757, "cat": 6, "y": 0.7612509534706331, "term": "respect", "s": 0.8623853211009175, "bg": 6.200253429158663e-07, "x": 0.5614035087719298, "ncat": 9}, {"cat25k": 16, "ncat25k": 10, "os": 0.6331612260516191, "cat": 5, "y": 0.7032799389778794, "term": "evaluating", "s": 0.7492354740061162, "bg": 4.89770688074973e-06, "x": 0.5621662852784134, "ncat": 9}, {"cat25k": 6, "ncat25k": 10, "os": 0.45058111172325954, "cat": 2, "y": 0.2807017543859649, "term": "could", "s": 0.2308868501529052, "bg": 7.275929451370975e-08, "x": 0.562929061784897, "ncat": 9}, {"cat25k": 9, "ncat25k": 10, "os": 0.522836370084893, "cat": 3, "y": 0.4683447749809306, "term": "output", "s": 0.4487767584097859, "bg": 5.727055206557163e-07, "x": 0.5636918382913806, "ncat": 9}, {"cat25k": 19, "ncat25k": 10, "os": 0.673799666511757, "cat": 6, "y": 0.7643020594965675, "term": "submission", "s": 0.8623853211009175, "bg": 1.5369508757048841e-06, "x": 0.5644546147978642, "ncat": 9}, {"cat25k": 3, "ncat25k": 10, "os": 0.3669888006584705, "cat": 1, "y": 0.10755148741418764, "term": "parameters", "s": 0.09327217125382262, "bg": 7.338750309561831e-07, "x": 0.5652173913043478, "ncat": 9}, {"cat25k": 0, "ncat25k": 10, "os": 0.27488233814366553, "cat": 0, "y": 0.018306636155606407, "term": "parsers", "s": 0.0, "bg": 4.966651007919738e-05, "x": 0.5659801678108314, "ncat": 9}, {"cat25k": 6, "ncat25k": 10, "os": 0.45058111172325954, "cat": 2, "y": 0.28680396643783374, "term": "contrast", "s": 0.2308868501529052, "bg": 1.2214606415122393e-06, "x": 0.566742944317315, "ncat": 9}, {"cat25k": 6, "ncat25k": 10, "os": 0.45058111172325954, "cat": 2, "y": 0.28832951945080093, "term": "despite", "s": 0.2308868501529052, "bg": 8.509302458085746e-07, "x": 0.5675057208237986, "ncat": 9}, {"cat25k": 3, "ncat25k": 10, "os": 0.3669888006584705, "cat": 1, "y": 0.10907704042715484, "term": "wikipedia", "s": 0.09327217125382262, "bg": 1.5023930868283547e-06, "x": 0.5682684973302822, "ncat": 9}, {"cat25k": 3, "ncat25k": 10, "os": 0.3669888006584705, "cat": 1, "y": 0.11212814645308924, "term": "robust", "s": 0.09327217125382262, "bg": 2.7710667928241006e-06, "x": 0.5690312738367659, "ncat": 9}, {"cat25k": 19, "ncat25k": 10, "os": 0.673799666511757, "cat": 6, "y": 0.7665903890160183, "term": "literature", "s": 0.8623853211009175, "bg": 8.572201845265027e-07, "x": 0.5697940503432495, "ncat": 9}, {"cat25k": 19, "ncat25k": 10, "os": 0.673799666511757, "cat": 6, "y": 0.7673531655225019, "term": "supervision", "s": 0.8623853211009175, "bg": 3.815152258710695e-06, "x": 0.5705568268497331, "ncat": 9}, {"cat25k": 9, "ncat25k": 10, "os": 0.522836370084893, "cat": 3, "y": 0.4858886346300534, "term": "driven", "s": 0.4487767584097859, "bg": 1.7998612756921762e-06, "x": 0.5713196033562167, "ncat": 9}, {"cat25k": 16, "ncat25k": 10, "os": 0.6331612260516191, "cat": 5, "y": 0.7147215865751335, "term": "performing", "s": 0.7492354740061162, "bg": 1.5265081721853515e-06, "x": 0.5720823798627003, "ncat": 9}, {"cat25k": 6, "ncat25k": 10, "os": 0.45058111172325954, "cat": 2, "y": 0.2959572845156369, "term": "bi", "s": 0.2308868501529052, "bg": 1.82850497547632e-06, "x": 0.5728451563691839, "ncat": 9}, {"cat25k": 22, "ncat25k": 10, "os": 0.7070330645748554, "cat": 7, "y": 0.8100686498855835, "term": "need", "s": 0.9204892966360856, "bg": 1.0017769833185412e-07, "x": 0.5736079328756675, "ncat": 9}, {"cat25k": 3, "ncat25k": 10, "os": 0.3669888006584705, "cat": 1, "y": 0.12433257055682685, "term": "require", "s": 0.09327217125382262, "bg": 4.108253219283244e-07, "x": 0.5743707093821511, "ncat": 9}, {"cat25k": 9, "ncat25k": 10, "os": 0.522836370084893, "cat": 3, "y": 0.49046529366895497, "term": "examples", "s": 0.4487767584097859, "bg": 6.472325213846299e-07, "x": 0.5751334858886347, "ncat": 9}, {"cat25k": 9, "ncat25k": 10, "os": 0.522836370084893, "cat": 3, "y": 0.4919908466819222, "term": "messages", "s": 0.4487767584097859, "bg": 3.097863992709523e-07, "x": 0.5758962623951183, "ncat": 9}, {"cat25k": 3, "ncat25k": 10, "os": 0.3669888006584705, "cat": 1, "y": 0.13043478260869565, "term": "place", "s": 0.09327217125382262, "bg": 1.0858467106669551e-07, "x": 0.5766590389016019, "ncat": 9}, {"cat25k": 19, "ncat25k": 10, "os": 0.673799666511757, "cat": 6, "y": 0.7719298245614035, "term": "morphological", "s": 0.8623853211009175, "bg": 2.9511278472850362e-05, "x": 0.5774218154080855, "ncat": 9}, {"cat25k": 25, "ncat25k": 10, "os": 0.734459742737951, "cat": 8, "y": 0.8382913806254767, "term": "relevant", "s": 0.9441896024464832, "bg": 7.947447415658985e-07, "x": 0.5781845919145691, "ncat": 9}, {"cat25k": 19, "ncat25k": 10, "os": 0.673799666511757, "cat": 6, "y": 0.7742181540808543, "term": "especially", "s": 0.8623853211009175, "bg": 5.051200568509258e-07, "x": 0.5789473684210527, "ncat": 9}, {"cat25k": 9, "ncat25k": 10, "os": 0.522836370084893, "cat": 3, "y": 0.5011441647597255, "term": "good", "s": 0.4487767584097859, "bg": 8.746710191462808e-08, "x": 0.5797101449275363, "ncat": 9}, {"cat25k": 6, "ncat25k": 10, "os": 0.45058111172325954, "cat": 2, "y": 0.3173150266971777, "term": "external", "s": 0.2308868501529052, "bg": 4.73744955849931e-07, "x": 0.5804729214340199, "ncat": 9}, {"cat25k": 6, "ncat25k": 10, "os": 0.45058111172325954, "cat": 2, "y": 0.31960335621662855, "term": "selected", "s": 0.2308868501529052, "bg": 3.746358326845038e-07, "x": 0.5812356979405034, "ncat": 9}, {"cat25k": 0, "ncat25k": 10, "os": 0.27488233814366553, "cat": 0, "y": 0.02822273073989321, "term": "syntax", "s": 0.0, "bg": 1.8868828808022118e-06, "x": 0.581998474446987, "ncat": 9}, {"cat25k": 3, "ncat25k": 10, "os": 0.3669888006584705, "cat": 1, "y": 0.14263920671243327, "term": "local", "s": 0.09327217125382262, "bg": 8.862682494772596e-08, "x": 0.5827612509534706, "ncat": 9}, {"cat25k": 6, "ncat25k": 10, "os": 0.45058111172325954, "cat": 2, "y": 0.32036613272311215, "term": "inference", "s": 0.2308868501529052, "bg": 1.572044475996489e-05, "x": 0.5835240274599542, "ncat": 9}, {"cat25k": 3, "ncat25k": 10, "os": 0.3669888006584705, "cat": 1, "y": 0.14721586575133486, "term": "progress", "s": 0.09327217125382262, "bg": 4.1902176101521264e-07, "x": 0.5842868039664378, "ncat": 9}, {"cat25k": 6, "ncat25k": 10, "os": 0.45058111172325954, "cat": 2, "y": 0.32494279176201374, "term": "requires", "s": 0.2308868501529052, "bg": 4.5151945326412444e-07, "x": 0.5850495804729214, "ncat": 9}, {"cat25k": 6, "ncat25k": 10, "os": 0.45058111172325954, "cat": 2, "y": 0.3340961098398169, "term": "topics", "s": 0.2308868501529052, "bg": 2.31122116259152e-07, "x": 0.585812356979405, "ncat": 9}, {"cat25k": 9, "ncat25k": 10, "os": 0.522836370084893, "cat": 3, "y": 0.524790236460717, "term": "close", "s": 0.4487767584097859, "bg": 2.5947907647838115e-07, "x": 0.5865751334858886, "ncat": 9}, {"cat25k": 25, "ncat25k": 10, "os": 0.734459742737951, "cat": 8, "y": 0.8421052631578947, "term": "capture", "s": 0.9441896024464832, "bg": 2.237348813251459e-06, "x": 0.5873379099923722, "ncat": 9}, {"cat25k": 3, "ncat25k": 10, "os": 0.3669888006584705, "cat": 1, "y": 0.16781083142639205, "term": "bleu", "s": 0.09327217125382262, "bg": 1.9673437334773863e-05, "x": 0.5881006864988558, "ncat": 9}, {"cat25k": 6, "ncat25k": 10, "os": 0.45058111172325954, "cat": 2, "y": 0.34553775743707094, "term": "levels", "s": 0.2308868501529052, "bg": 3.8566351078215795e-07, "x": 0.5888634630053394, "ncat": 9}, {"cat25k": 9, "ncat25k": 10, "os": 0.522836370084893, "cat": 3, "y": 0.5301296720061022, "term": "global", "s": 0.4487767584097859, "bg": 3.208349031072176e-07, "x": 0.589626239511823, "ncat": 9}, {"cat25k": 12, "ncat25k": 10, "os": 0.5833720786881543, "cat": 4, "y": 0.6529366895499619, "term": "another", "s": 0.6238532110091742, "bg": 1.350009838715934e-07, "x": 0.5903890160183066, "ncat": 9}, {"cat25k": 19, "ncat25k": 10, "os": 0.673799666511757, "cat": 6, "y": 0.7810831426392068, "term": "2016", "s": 0.8623853211009175, "bg": 0.0, "x": 0.5911517925247902, "ncat": 9}, {"cat25k": 9, "ncat25k": 10, "os": 0.522836370084893, "cat": 3, "y": 0.5331807780320366, "term": "design", "s": 0.4487767584097859, "bg": 9.829727271419164e-08, "x": 0.5919145690312738, "ncat": 9}, {"cat25k": 28, "ncat25k": 10, "os": 0.757382266199998, "cat": 9, "y": 0.8680396643783371, "term": "patterns", "s": 0.9587155963302751, "bg": 2.087741673979884e-06, "x": 0.5926773455377574, "ncat": 9}, {"cat25k": 3, "ncat25k": 10, "os": 0.3669888006584705, "cat": 1, "y": 0.18382913806254766, "term": "field", "s": 0.09327217125382262, "bg": 1.6254807165269728e-07, "x": 0.593440122044241, "ncat": 9}, {"cat25k": 12, "ncat25k": 10, "os": 0.5833720786881543, "cat": 4, "y": 0.6567505720823799, "term": "average", "s": 0.6238532110091742, "bg": 2.7212724452252075e-07, "x": 0.5942028985507246, "ncat": 9}, {"cat25k": 16, "ncat25k": 10, "os": 0.6331612260516191, "cat": 5, "y": 0.7376048817696415, "term": "moreover", "s": 0.7492354740061162, "bg": 2.3622293032857768e-06, "x": 0.5949656750572082, "ncat": 9}, {"cat25k": 12, "ncat25k": 10, "os": 0.5833720786881543, "cat": 4, "y": 0.658276125095347, "term": "obtain", "s": 0.6238532110091742, "bg": 8.46147835500139e-07, "x": 0.5957284515636918, "ncat": 9}, {"cat25k": 3, "ncat25k": 10, "os": 0.3669888006584705, "cat": 1, "y": 0.19145690312738367, "term": "sequential", "s": 0.09327217125382262, "bg": 8.96841950439916e-06, "x": 0.5964912280701754, "ncat": 9}, {"cat25k": 9, "ncat25k": 10, "os": 0.522836370084893, "cat": 3, "y": 0.5537757437070938, "term": "jointly", "s": 0.4487767584097859, "bg": 5.319054626691015e-06, "x": 0.597254004576659, "ncat": 9}, {"cat25k": 0, "ncat25k": 10, "os": 0.27488233814366553, "cat": 0, "y": 0.05339435545385202, "term": "comprehension", "s": 0.0, "bg": 1.093653664491663e-05, "x": 0.5980167810831426, "ncat": 9}, {"cat25k": 16, "ncat25k": 10, "os": 0.6331612260516191, "cat": 5, "y": 0.738367658276125, "term": "visual", "s": 0.7492354740061162, "bg": 1.119449141466467e-06, "x": 0.5987795575896262, "ncat": 9}, {"cat25k": 6, "ncat25k": 10, "os": 0.45058111172325954, "cat": 2, "y": 0.37299771167048057, "term": "layers", "s": 0.2308868501529052, "bg": 3.5266002086204437e-06, "x": 0.5995423340961098, "ncat": 9}, {"cat25k": 6, "ncat25k": 10, "os": 0.45058111172325954, "cat": 2, "y": 0.37833714721586575, "term": "differences", "s": 0.2308868501529052, "bg": 1.4367782833197463e-06, "x": 0.6003051106025934, "ncat": 9}, {"cat25k": 6, "ncat25k": 10, "os": 0.45058111172325954, "cat": 2, "y": 0.38291380625476734, "term": "f1", "s": 0.2308868501529052, "bg": 0.0, "x": 0.601067887109077, "ncat": 9}, {"cat25k": 6, "ncat25k": 10, "os": 0.45058111172325954, "cat": 2, "y": 0.39664378337147216, "term": "8", "s": 0.2308868501529052, "bg": 0.0, "x": 0.6018306636155606, "ncat": 9}, {"cat25k": 3, "ncat25k": 10, "os": 0.3669888006584705, "cat": 1, "y": 0.2341723874904653, "term": "headlines", "s": 0.09327217125382262, "bg": 9.221461938300581e-07, "x": 0.6025934401220442, "ncat": 9}, {"cat25k": 22, "ncat25k": 11, "os": 0.6854076088828636, "cat": 7, "y": 0.7864225781845919, "term": "monolingual", "s": 0.9036697247706422, "bg": 0.00016557074601447562, "x": 0.6033562166285278, "ncat": 10}, {"cat25k": 9, "ncat25k": 11, "os": 0.5049887625144037, "cat": 3, "y": 0.429443173150267, "term": "few", "s": 0.3967889908256881, "bg": 1.923246160203905e-07, "x": 0.6041189931350115, "ncat": 10}, {"cat25k": 16, "ncat25k": 11, "os": 0.6115898667441237, "cat": 5, "y": 0.6834477498093059, "term": "create", "s": 0.7224770642201834, "bg": 2.479461218911157e-07, "x": 0.6048817696414951, "ncat": 10}, {"cat25k": 6, "ncat25k": 11, "os": 0.4368934594627166, "cat": 2, "y": 0.2433257055682685, "term": "tools", "s": 0.2163608562691131, "bg": 1.5085287311742214e-07, "x": 0.6056445461479787, "ncat": 10}, {"cat25k": 12, "ncat25k": 11, "os": 0.5630220507835795, "cat": 4, "y": 0.5903890160183066, "term": "humans", "s": 0.5741590214067278, "bg": 2.1901565915030994e-06, "x": 0.6064073226544623, "ncat": 10}, {"cat25k": 9, "ncat25k": 11, "os": 0.5049887625144037, "cat": 3, "y": 0.43173150266971777, "term": "reported", "s": 0.3967889908256881, "bg": 5.6343599043173e-07, "x": 0.6071700991609459, "ncat": 10}, {"cat25k": 3, "ncat25k": 11, "os": 0.3593334151923075, "cat": 1, "y": 0.08009153318077804, "term": "though", "s": 0.0871559633027523, "bg": 2.392309950112943e-07, "x": 0.6079328756674295, "ncat": 10}, {"cat25k": 9, "ncat25k": 11, "os": 0.5049887625144037, "cat": 3, "y": 0.43935926773455375, "term": "studies", "s": 0.3967889908256881, "bg": 2.4056188520651456e-07, "x": 0.6086956521739131, "ncat": 10}, {"cat25k": 6, "ncat25k": 11, "os": 0.4368934594627166, "cat": 2, "y": 0.2509534706331045, "term": "gram", "s": 0.2163608562691131, "bg": 8.654080604539455e-06, "x": 0.6094584286803967, "ncat": 10}, {"cat25k": 16, "ncat25k": 11, "os": 0.6115898667441237, "cat": 5, "y": 0.6887871853546911, "term": "against", "s": 0.7224770642201834, "bg": 2.0364488226223612e-07, "x": 0.6102212051868803, "ncat": 10}, {"cat25k": 0, "ncat25k": 11, "os": 0.27488233814366553, "cat": 0, "y": 0.0030511060259344014, "term": "fully", "s": 0.0, "bg": 4.1091160987197063e-07, "x": 0.6109839816933639, "ncat": 10}, {"cat25k": 28, "ncat25k": 11, "os": 0.7371834671687619, "cat": 9, "y": 0.855072463768116, "term": "learned", "s": 0.9464831804281345, "bg": 1.8984525497533717e-06, "x": 0.6117467581998475, "ncat": 10}, {"cat25k": 9, "ncat25k": 11, "os": 0.5049887625144037, "cat": 3, "y": 0.4439359267734554, "term": "phrase", "s": 0.3967889908256881, "bg": 2.717513969908968e-06, "x": 0.6125095347063311, "ncat": 10}, {"cat25k": 3, "ncat25k": 11, "os": 0.3593334151923075, "cat": 1, "y": 0.08848207475209764, "term": "transfer", "s": 0.0871559633027523, "bg": 5.240153620343534e-07, "x": 0.6132723112128147, "ncat": 10}, {"cat25k": 0, "ncat25k": 11, "os": 0.27488233814366553, "cat": 0, "y": 0.007627765064836003, "term": "f", "s": 0.0, "bg": 1.0089420108964928e-07, "x": 0.6140350877192983, "ncat": 10}, {"cat25k": 16, "ncat25k": 11, "os": 0.6115898667441237, "cat": 5, "y": 0.6979405034324943, "term": "original", "s": 0.7224770642201834, "bg": 2.6429709869445686e-07, "x": 0.6147978642257819, "ncat": 10}, {"cat25k": 3, "ncat25k": 11, "os": 0.3593334151923075, "cat": 1, "y": 0.09992372234935164, "term": "component", "s": 0.0871559633027523, "bg": 7.03379845665399e-07, "x": 0.6155606407322655, "ncat": 10}, {"cat25k": 9, "ncat25k": 11, "os": 0.5049887625144037, "cat": 3, "y": 0.45156369183829137, "term": "within", "s": 0.3967889908256881, "bg": 1.0709654280579203e-07, "x": 0.6163234172387491, "ncat": 10}, {"cat25k": 0, "ncat25k": 11, "os": 0.27488233814366553, "cat": 0, "y": 0.010678871090770405, "term": "bidirectional", "s": 0.0, "bg": 2.916275068366767e-05, "x": 0.6170861937452327, "ncat": 10}, {"cat25k": 12, "ncat25k": 11, "os": 0.5630220507835795, "cat": 4, "y": 0.6048817696414951, "term": "higher", "s": 0.5741590214067278, "bg": 3.633235222660459e-07, "x": 0.6178489702517163, "ncat": 10}, {"cat25k": 12, "ncat25k": 11, "os": 0.5630220507835795, "cat": 4, "y": 0.6071700991609459, "term": "popular", "s": 0.5741590214067278, "bg": 2.5739769115300624e-07, "x": 0.6186117467581999, "ncat": 10}, {"cat25k": 19, "ncat25k": 11, "os": 0.6519084334533752, "cat": 6, "y": 0.7604881769641495, "term": "number", "s": 0.8340978593272171, "bg": 9.378828491523111e-08, "x": 0.6193745232646835, "ncat": 10}, {"cat25k": 12, "ncat25k": 11, "os": 0.5630220507835795, "cat": 4, "y": 0.6079328756674295, "term": "correct", "s": 0.5741590214067278, "bg": 8.534839202394121e-07, "x": 0.620137299771167, "ncat": 10}, {"cat25k": 19, "ncat25k": 11, "os": 0.6519084334533752, "cat": 6, "y": 0.7627765064836003, "term": "combining", "s": 0.8340978593272171, "bg": 5.3096123452026765e-06, "x": 0.6209000762776506, "ncat": 10}, {"cat25k": 16, "ncat25k": 11, "os": 0.6115898667441237, "cat": 5, "y": 0.704042715484363, "term": "components", "s": 0.7224770642201834, "bg": 6.543053839518518e-07, "x": 0.6216628527841342, "ncat": 10}, {"cat25k": 9, "ncat25k": 11, "os": 0.5049887625144037, "cat": 3, "y": 0.4652936689549962, "term": "qa", "s": 0.3967889908256881, "bg": 1.5238007379313952e-05, "x": 0.6224256292906178, "ncat": 10}, {"cat25k": 16, "ncat25k": 11, "os": 0.6115898667441237, "cat": 5, "y": 0.7070938215102975, "term": "articles", "s": 0.7224770642201834, "bg": 2.7706921357835466e-07, "x": 0.6231884057971014, "ncat": 10}, {"cat25k": 9, "ncat25k": 11, "os": 0.5049887625144037, "cat": 3, "y": 0.47368421052631576, "term": "consists", "s": 0.3967889908256881, "bg": 1.59970604786099e-06, "x": 0.623951182303585, "ncat": 10}, {"cat25k": 12, "ncat25k": 11, "os": 0.5630220507835795, "cat": 4, "y": 0.6132723112128147, "term": "case", "s": 0.5741590214067278, "bg": 1.4430109785590937e-07, "x": 0.6247139588100686, "ncat": 10}, {"cat25k": 9, "ncat25k": 11, "os": 0.5049887625144037, "cat": 3, "y": 0.4782608695652174, "term": "instead", "s": 0.3967889908256881, "bg": 4.597271745546243e-07, "x": 0.6254767353165522, "ncat": 10}, {"cat25k": 3, "ncat25k": 11, "os": 0.3593334151923075, "cat": 1, "y": 0.11670480549199085, "term": "achieving", "s": 0.0871559633027523, "bg": 2.4917920934757293e-06, "x": 0.6262395118230358, "ncat": 10}, {"cat25k": 12, "ncat25k": 11, "os": 0.5630220507835795, "cat": 4, "y": 0.6231884057971014, "term": "negative", "s": 0.5741590214067278, "bg": 1.2434582642395933e-06, "x": 0.6270022883295194, "ncat": 10}, {"cat25k": 19, "ncat25k": 11, "os": 0.6519084334533752, "cat": 6, "y": 0.7726926010678871, "term": "statistical", "s": 0.8340978593272171, "bg": 2.7229487836206573e-06, "x": 0.627765064836003, "ncat": 10}, {"cat25k": 12, "ncat25k": 11, "os": 0.5630220507835795, "cat": 4, "y": 0.6331045003813882, "term": "/", "s": 0.5741590214067278, "bg": 0.0, "x": 0.6285278413424866, "ncat": 10}, {"cat25k": 16, "ncat25k": 11, "os": 0.6115898667441237, "cat": 5, "y": 0.7238749046529367, "term": "scientific", "s": 0.7224770642201834, "bg": 1.1772766210616387e-06, "x": 0.6292906178489702, "ncat": 10}, {"cat25k": 9, "ncat25k": 11, "os": 0.5049887625144037, "cat": 3, "y": 0.5125858123569794, "term": "base", "s": 0.3967889908256881, "bg": 4.3929158667288895e-07, "x": 0.6300533943554538, "ncat": 10}, {"cat25k": 9, "ncat25k": 11, "os": 0.5049887625144037, "cat": 3, "y": 0.513348588863463, "term": "widely", "s": 0.3967889908256881, "bg": 1.9618568250471164e-06, "x": 0.6308161708619374, "ncat": 10}, {"cat25k": 16, "ncat25k": 11, "os": 0.6115898667441237, "cat": 5, "y": 0.7284515636918383, "term": "points", "s": 0.7224770642201834, "bg": 4.007316558572642e-07, "x": 0.631578947368421, "ncat": 10}, {"cat25k": 3, "ncat25k": 11, "os": 0.3593334151923075, "cat": 1, "y": 0.15560640732265446, "term": "range", "s": 0.0871559633027523, "bg": 1.7137912387735669e-07, "x": 0.6323417238749046, "ncat": 10}, {"cat25k": 12, "ncat25k": 11, "os": 0.5630220507835795, "cat": 4, "y": 0.6460717009916095, "term": "comparison", "s": 0.5741590214067278, "bg": 1.0073114019256436e-06, "x": 0.6331045003813882, "ncat": 10}, {"cat25k": 6, "ncat25k": 11, "os": 0.4368934594627166, "cat": 2, "y": 0.33943554538520215, "term": "baselines", "s": 0.2163608562691131, "bg": 6.973201450425903e-05, "x": 0.6338672768878718, "ncat": 10}, {"cat25k": 9, "ncat25k": 11, "os": 0.5049887625144037, "cat": 3, "y": 0.528604118993135, "term": "difficult", "s": 0.3967889908256881, "bg": 6.118834832643984e-07, "x": 0.6346300533943554, "ncat": 10}, {"cat25k": 16, "ncat25k": 11, "os": 0.6115898667441237, "cat": 5, "y": 0.7315026697177727, "term": "world", "s": 0.7224770642201834, "bg": 7.870558170633387e-08, "x": 0.635392829900839, "ncat": 10}, {"cat25k": 0, "ncat25k": 11, "os": 0.27488233814366553, "cat": 0, "y": 0.038901601830663615, "term": "nmt", "s": 0.0, "bg": 0.0002626464253821505, "x": 0.6361556064073226, "ncat": 10}, {"cat25k": 3, "ncat25k": 11, "os": 0.3593334151923075, "cat": 1, "y": 0.17467581998474446, "term": "mainly", "s": 0.0871559633027523, "bg": 1.3453561698981817e-06, "x": 0.6369183829138062, "ncat": 10}, {"cat25k": 6, "ncat25k": 11, "os": 0.4368934594627166, "cat": 2, "y": 0.36308161708619374, "term": "independent", "s": 0.2163608562691131, "bg": 4.671073513121395e-07, "x": 0.6376811594202898, "ncat": 10}, {"cat25k": 22, "ncat25k": 11, "os": 0.6854076088828636, "cat": 7, "y": 0.816933638443936, "term": "during", "s": 0.9036697247706422, "bg": 1.8409074239630143e-07, "x": 0.6384439359267735, "ncat": 10}, {"cat25k": 9, "ncat25k": 11, "os": 0.5049887625144037, "cat": 3, "y": 0.5499618611746758, "term": "tree", "s": 0.3967889908256881, "bg": 5.697204155708275e-07, "x": 0.6392067124332571, "ncat": 10}, {"cat25k": 9, "ncat25k": 11, "os": 0.5049887625144037, "cat": 3, "y": 0.5575896262395118, "term": "point", "s": 0.3967889908256881, "bg": 2.0503088496973997e-07, "x": 0.6399694889397407, "ncat": 10}, {"cat25k": 9, "ncat25k": 11, "os": 0.5049887625144037, "cat": 3, "y": 0.5606407322654462, "term": "composition", "s": 0.3967889908256881, "bg": 2.2505198700899906e-06, "x": 0.6407322654462243, "ncat": 10}, {"cat25k": 9, "ncat25k": 11, "os": 0.5049887625144037, "cat": 3, "y": 0.566742944317315, "term": "tagging", "s": 0.3967889908256881, "bg": 1.8108188193461296e-05, "x": 0.6414950419527079, "ncat": 10}, {"cat25k": 19, "ncat25k": 12, "os": 0.6321039973300391, "cat": 6, "y": 0.7437070938215103, "term": "main", "s": 0.7477064220183486, "bg": 1.7027908998266793e-07, "x": 0.6422578184591915, "ncat": 11}, {"cat25k": 3, "ncat25k": 12, "os": 0.3529735972384664, "cat": 1, "y": 0.07551487414187644, "term": "variety", "s": 0.08256880733944953, "bg": 5.21041770916771e-07, "x": 0.6430205949656751, "ncat": 11}, {"cat25k": 9, "ncat25k": 12, "os": 0.4896078143484769, "cat": 3, "y": 0.4309687261632342, "term": "labeled", "s": 0.3685015290519878, "bg": 5.497278675265785e-06, "x": 0.6437833714721587, "ncat": 11}, {"cat25k": 25, "ncat25k": 12, "os": 0.6939712091687207, "cat": 8, "y": 0.8237986270022883, "term": "online", "s": 0.9059633027522936, "bg": 1.0309749506410766e-07, "x": 0.6445461479786423, "ncat": 11}, {"cat25k": 6, "ncat25k": 12, "os": 0.42531364780070635, "cat": 2, "y": 0.2486651411136537, "term": "effectively", "s": 0.20642201834862384, "bg": 1.737952183210421e-06, "x": 0.6453089244851259, "ncat": 11}, {"cat25k": 12, "ncat25k": 12, "os": 0.545172590499608, "cat": 4, "y": 0.5987795575896262, "term": "et", "s": 0.5244648318042814, "bg": 3.2596241241138315e-07, "x": 0.6460717009916095, "ncat": 11}, {"cat25k": 16, "ncat25k": 12, "os": 0.5923591678505704, "cat": 5, "y": 0.6941266209000763, "term": "ensemble", "s": 0.6773700305810397, "bg": 1.0169666116739238e-05, "x": 0.6468344774980931, "ncat": 11}, {"cat25k": 12, "ncat25k": 12, "os": 0.545172590499608, "cat": 4, "y": 0.6025934401220442, "term": "arabic", "s": 0.5244648318042814, "bg": 6.7934999792198816e-06, "x": 0.6475972540045767, "ncat": 11}, {"cat25k": 3, "ncat25k": 12, "os": 0.3529735972384664, "cat": 1, "y": 0.09763539282990084, "term": "candidate", "s": 0.08256880733944953, "bg": 1.5674716079026939e-06, "x": 0.6483600305110603, "ncat": 11}, {"cat25k": 9, "ncat25k": 12, "os": 0.4896078143484769, "cat": 3, "y": 0.45080091533180777, "term": "hand", "s": 0.3685015290519878, "bg": 2.6369547135083437e-07, "x": 0.6491228070175439, "ncat": 11}, {"cat25k": 6, "ncat25k": 12, "os": 0.42531364780070635, "cat": 2, "y": 0.2730739893211289, "term": "adaptation", "s": 0.20642201834862384, "bg": 7.449239022987606e-06, "x": 0.6498855835240275, "ncat": 11}, {"cat25k": 19, "ncat25k": 12, "os": 0.6321039973300391, "cat": 6, "y": 0.7566742944317315, "term": "entities", "s": 0.7477064220183486, "bg": 5.424894824851583e-06, "x": 0.6506483600305111, "ncat": 11}, {"cat25k": 9, "ncat25k": 12, "os": 0.4896078143484769, "cat": 3, "y": 0.4584286803966438, "term": "shown", "s": 0.3685015290519878, "bg": 4.650404328677731e-07, "x": 0.6514111365369947, "ncat": 11}, {"cat25k": 9, "ncat25k": 12, "os": 0.4896078143484769, "cat": 3, "y": 0.4630053394355454, "term": "final", "s": 0.3685015290519878, "bg": 3.275180926623604e-07, "x": 0.6521739130434783, "ncat": 11}, {"cat25k": 31, "ncat25k": 12, "os": 0.7392444939733781, "cat": 10, "y": 0.8749046529366895, "term": "identifying", "s": 0.9472477064220184, "bg": 4.076863831728804e-06, "x": 0.6529366895499619, "ncat": 11}, {"cat25k": 16, "ncat25k": 12, "os": 0.5923591678505704, "cat": 5, "y": 0.7093821510297483, "term": "collection", "s": 0.6773700305810397, "bg": 2.985706109278131e-07, "x": 0.6536994660564455, "ncat": 11}, {"cat25k": 3, "ncat25k": 12, "os": 0.3529735972384664, "cat": 1, "y": 0.12280701754385964, "term": "technique", "s": 0.08256880733944953, "bg": 1.3766720277452363e-06, "x": 0.6544622425629291, "ncat": 11}, {"cat25k": 12, "ncat25k": 12, "os": 0.545172590499608, "cat": 4, "y": 0.6292906178489702, "term": "provides", "s": 0.5244648318042814, "bg": 2.745514625301499e-07, "x": 0.6552250190694127, "ncat": 11}, {"cat25k": 16, "ncat25k": 12, "os": 0.5923591678505704, "cat": 5, "y": 0.7231121281464531, "term": "random", "s": 0.6773700305810397, "bg": 8.164388511226702e-07, "x": 0.6559877955758963, "ncat": 11}, {"cat25k": 16, "ncat25k": 12, "os": 0.5923591678505704, "cat": 5, "y": 0.7261632341723875, "term": "memory", "s": 0.6773700305810397, "bg": 2.988573403062918e-07, "x": 0.6567505720823799, "ncat": 11}, {"cat25k": 12, "ncat25k": 12, "os": 0.545172590499608, "cat": 4, "y": 0.6407322654462243, "term": "extracted", "s": 0.5244648318042814, "bg": 6.342277494935691e-06, "x": 0.6575133485888635, "ncat": 11}, {"cat25k": 6, "ncat25k": 12, "os": 0.42531364780070635, "cat": 2, "y": 0.32418001525553014, "term": "strategy", "s": 0.20642201834862384, "bg": 4.892915486505645e-07, "x": 0.658276125095347, "ncat": 11}, {"cat25k": 6, "ncat25k": 12, "os": 0.42531364780070635, "cat": 2, "y": 0.3287566742944317, "term": "japanese", "s": 0.20642201834862384, "bg": 9.546283475284022e-07, "x": 0.6590389016018307, "ncat": 11}, {"cat25k": 9, "ncat25k": 12, "os": 0.4896078143484769, "cat": 3, "y": 0.5232646834477498, "term": "teams", "s": 0.3685015290519878, "bg": 8.711122875643871e-07, "x": 0.6598016781083142, "ncat": 11}, {"cat25k": 9, "ncat25k": 12, "os": 0.4896078143484769, "cat": 3, "y": 0.5270785659801678, "term": "directly", "s": 0.3685015290519878, "bg": 4.811019130725476e-07, "x": 0.6605644546147978, "ncat": 11}, {"cat25k": 3, "ncat25k": 12, "os": 0.3529735972384664, "cat": 1, "y": 0.16704805491990846, "term": "beyond", "s": 0.08256880733944953, "bg": 5.488626910627969e-07, "x": 0.6613272311212814, "ncat": 11}, {"cat25k": 3, "ncat25k": 12, "os": 0.3529735972384664, "cat": 1, "y": 0.17162471395881007, "term": "efficient", "s": 0.08256880733944953, "bg": 1.0426113974889486e-06, "x": 0.662090007627765, "ncat": 11}, {"cat25k": 6, "ncat25k": 12, "os": 0.42531364780070635, "cat": 2, "y": 0.3501144164759725, "term": "7", "s": 0.20642201834862384, "bg": 0.0, "x": 0.6628527841342486, "ncat": 11}, {"cat25k": 16, "ncat25k": 12, "os": 0.5923591678505704, "cat": 5, "y": 0.7360793287566743, "term": "address", "s": 0.6773700305810397, "bg": 1.2217083462395366e-07, "x": 0.6636155606407322, "ncat": 11}, {"cat25k": 3, "ncat25k": 12, "os": 0.3529735972384664, "cat": 1, "y": 0.19755911517925248, "term": "decoding", "s": 0.08256880733944953, "bg": 1.5051570443231118e-05, "x": 0.6643783371472158, "ncat": 11}, {"cat25k": 9, "ncat25k": 12, "os": 0.4896078143484769, "cat": 3, "y": 0.5728451563691839, "term": "financial", "s": 0.3685015290519878, "bg": 4.1782998058694514e-07, "x": 0.6651411136536994, "ncat": 11}, {"cat25k": 16, "ncat25k": 14, "os": 0.5751512240588168, "cat": 5, "y": 0.6781083142639207, "term": "vectors", "s": 0.6077981651376146, "bg": 1.528247627694044e-05, "x": 0.665903890160183, "ncat": 12}, {"cat25k": 9, "ncat25k": 14, "os": 0.4762360553779016, "cat": 3, "y": 0.43249427917620137, "term": "amount", "s": 0.32874617737003053, "bg": 3.2575015918324447e-07, "x": 0.6666666666666666, "ncat": 12}, {"cat25k": 12, "ncat25k": 14, "os": 0.5294222507875513, "cat": 4, "y": 0.5919145690312738, "term": "apply", "s": 0.4610091743119266, "bg": 4.18865053722061e-07, "x": 0.6674294431731502, "ncat": 12}, {"cat25k": 9, "ncat25k": 14, "os": 0.4762360553779016, "cat": 3, "y": 0.4424103737604882, "term": "cnn", "s": 0.32874617737003053, "bg": 4.105987642922137e-06, "x": 0.6681922196796338, "ncat": 12}, {"cat25k": 9, "ncat25k": 14, "os": 0.4762360553779016, "cat": 3, "y": 0.4431731502669718, "term": "mechanism", "s": 0.32874617737003053, "bg": 1.907213609158305e-06, "x": 0.6689549961861174, "ncat": 12}, {"cat25k": 16, "ncat25k": 14, "os": 0.5751512240588168, "cat": 5, "y": 0.6903127383676583, "term": "al", "s": 0.6077981651376146, "bg": 3.0196358656073875e-07, "x": 0.669717772692601, "ncat": 12}, {"cat25k": 6, "ncat25k": 14, "os": 0.4153991506885369, "cat": 2, "y": 0.2570556826849733, "term": "together", "s": 0.16590214067278286, "bg": 2.973371177976919e-07, "x": 0.6704805491990846, "ncat": 12}, {"cat25k": 16, "ncat25k": 14, "os": 0.5751512240588168, "cat": 5, "y": 0.6971777269260107, "term": "clinical", "s": 0.6077981651376146, "bg": 1.4416298713894087e-06, "x": 0.6712433257055682, "ncat": 12}, {"cat25k": 9, "ncat25k": 14, "os": 0.4762360553779016, "cat": 3, "y": 0.45537757437070936, "term": "result", "s": 0.32874617737003053, "bg": 3.1377350123322007e-07, "x": 0.6720061022120518, "ncat": 12}, {"cat25k": 9, "ncat25k": 14, "os": 0.4762360553779016, "cat": 3, "y": 0.4591914569031274, "term": "along", "s": 0.32874617737003053, "bg": 3.59280589481723e-07, "x": 0.6727688787185355, "ncat": 12}, {"cat25k": 9, "ncat25k": 14, "os": 0.4762360553779016, "cat": 3, "y": 0.4622425629290618, "term": "combine", "s": 0.32874617737003053, "bg": 2.273670329170622e-06, "x": 0.6735316552250191, "ncat": 12}, {"cat25k": 9, "ncat25k": 14, "os": 0.4762360553779016, "cat": 3, "y": 0.4744469870327994, "term": "generating", "s": 0.32874617737003053, "bg": 3.817783053804241e-06, "x": 0.6742944317315027, "ncat": 12}, {"cat25k": 6, "ncat25k": 14, "os": 0.4153991506885369, "cat": 2, "y": 0.2929061784897025, "term": "develop", "s": 0.16590214067278286, "bg": 5.029957348117384e-07, "x": 0.6750572082379863, "ncat": 12}, {"cat25k": 22, "ncat25k": 14, "os": 0.6474094464413922, "cat": 7, "y": 0.8108314263920672, "term": "shows", "s": 0.8318042813455657, "bg": 4.71364133931331e-07, "x": 0.6758199847444699, "ncat": 12}, {"cat25k": 16, "ncat25k": 14, "os": 0.5751512240588168, "cat": 5, "y": 0.7170099160945843, "term": "topic", "s": 0.6077981651376146, "bg": 4.6961849126297946e-07, "x": 0.6765827612509535, "ncat": 12}, {"cat25k": 6, "ncat25k": 14, "os": 0.4153991506885369, "cat": 2, "y": 0.30205949656750575, "term": "polarity", "s": 0.16590214067278286, "bg": 2.6604903875004247e-05, "x": 0.6773455377574371, "ncat": 12}, {"cat25k": 9, "ncat25k": 14, "os": 0.4762360553779016, "cat": 3, "y": 0.494279176201373, "term": "predicting", "s": 0.32874617737003053, "bg": 1.4307680783858915e-05, "x": 0.6781083142639207, "ncat": 12}, {"cat25k": 3, "ncat25k": 14, "os": 0.34760802965575754, "cat": 1, "y": 0.13424866514111367, "term": "temporal", "s": 0.08103975535168195, "bg": 1.0220515185887512e-05, "x": 0.6788710907704043, "ncat": 12}, {"cat25k": 12, "ncat25k": 14, "os": 0.5294222507875513, "cat": 4, "y": 0.6285278413424866, "term": "named", "s": 0.4610091743119266, "bg": 1.1711319488016247e-06, "x": 0.6796338672768879, "ncat": 12}, {"cat25k": 9, "ncat25k": 14, "os": 0.4762360553779016, "cat": 3, "y": 0.505720823798627, "term": "combined", "s": 0.32874617737003053, "bg": 1.0703800290634936e-06, "x": 0.6803966437833715, "ncat": 12}, {"cat25k": 6, "ncat25k": 14, "os": 0.4153991506885369, "cat": 2, "y": 0.3302822273073989, "term": "make", "s": 0.16590214067278286, "bg": 7.898502583121348e-08, "x": 0.6811594202898551, "ncat": 12}, {"cat25k": 25, "ncat25k": 14, "os": 0.6759204151848388, "cat": 8, "y": 0.8405797101449275, "term": "annotation", "s": 0.8700305810397553, "bg": 3.107287836876312e-06, "x": 0.6819221967963387, "ncat": 12}, {"cat25k": 19, "ncat25k": 14, "os": 0.6141535867299875, "cat": 6, "y": 0.7795575896262396, "term": "generate", "s": 0.7293577981651376, "bg": 1.9787900094849997e-06, "x": 0.6826849733028223, "ncat": 12}, {"cat25k": 22, "ncat25k": 14, "os": 0.6474094464413922, "cat": 7, "y": 0.8154080854309688, "term": "community", "s": 0.8318042813455657, "bg": 1.9091652179666437e-07, "x": 0.6834477498093059, "ncat": 12}, {"cat25k": 19, "ncat25k": 14, "os": 0.6141535867299875, "cat": 6, "y": 0.7818459191456903, "term": "learns", "s": 0.7293577981651376, "bg": 1.44683142015261e-05, "x": 0.6842105263157895, "ncat": 12}, {"cat25k": 0, "ncat25k": 14, "os": 0.27488233814366553, "cat": 0, "y": 0.057208237986270026, "term": "us", "s": 0.0, "bg": 2.115251837803814e-08, "x": 0.6849733028222731, "ncat": 12}, {"cat25k": 6, "ncat25k": 14, "os": 0.4153991506885369, "cat": 2, "y": 0.38367658276125094, "term": "function", "s": 0.16590214067278286, "bg": 3.406635288787766e-07, "x": 0.6857360793287567, "ncat": 12}, {"cat25k": 3, "ncat25k": 14, "os": 0.34760802965575754, "cat": 1, "y": 0.20747520976353928, "term": "categories", "s": 0.08103975535168195, "bg": 1.7251844537027167e-07, "x": 0.6864988558352403, "ncat": 12}, {"cat25k": 25, "ncat25k": 15, "os": 0.6591933595266825, "cat": 8, "y": 0.8192219679633868, "term": "media", "s": 0.8440366972477064, "bg": 3.3258198751106594e-07, "x": 0.6872616323417239, "ncat": 13}, {"cat25k": 28, "ncat25k": 15, "os": 0.6840241519876519, "cat": 9, "y": 0.8459191456903128, "term": "detecting", "s": 0.8967889908256881, "bg": 1.872774408270172e-05, "x": 0.6880244088482075, "ncat": 13}, {"cat25k": 3, "ncat25k": 15, "os": 0.34302164573120236, "cat": 1, "y": 0.07932875667429443, "term": "what", "s": 0.07798165137614678, "bg": 3.692530275760389e-08, "x": 0.6887871853546911, "ncat": 13}, {"cat25k": 16, "ncat25k": 15, "os": 0.5596930853319246, "cat": 5, "y": 0.6880244088482075, "term": "promising", "s": 0.5672782874617737, "bg": 7.185686264239242e-06, "x": 0.6895499618611747, "ncat": 13}, {"cat25k": 3, "ncat25k": 15, "os": 0.34302164573120236, "cat": 1, "y": 0.08695652173913043, "term": "evidence", "s": 0.07798165137614678, "bg": 7.089030571041552e-07, "x": 0.6903127383676583, "ncat": 13}, {"cat25k": 9, "ncat25k": 15, "os": 0.4645177499525405, "cat": 3, "y": 0.4454614797864226, "term": "setting", "s": 0.3103975535168196, "bg": 7.758161052053187e-07, "x": 0.6910755148741419, "ncat": 13}, {"cat25k": 0, "ncat25k": 15, "os": 0.27488233814366553, "cat": 0, "y": 0.0038138825324180014, "term": "classifiers", "s": 0.0, "bg": 7.77682247674514e-05, "x": 0.6918382913806255, "ncat": 13}, {"cat25k": 6, "ncat25k": 15, "os": 0.40682097304859305, "cat": 2, "y": 0.2745995423340961, "term": "concepts", "s": 0.15978593272171251, "bg": 1.834397975698158e-06, "x": 0.6926010678871091, "ncat": 13}, {"cat25k": 22, "ncat25k": 15, "os": 0.6307239361258317, "cat": 7, "y": 0.7978642257818459, "term": "biomedical", "s": 0.7469418960244648, "bg": 1.7880723060679126e-05, "x": 0.6933638443935927, "ncat": 13}, {"cat25k": 25, "ncat25k": 15, "os": 0.6591933595266825, "cat": 8, "y": 0.8321891685736079, "term": "event", "s": 0.8440366972477064, "bg": 1.0512002030536538e-06, "x": 0.6941266209000763, "ncat": 13}, {"cat25k": 6, "ncat25k": 15, "os": 0.40682097304859305, "cat": 2, "y": 0.2791762013729977, "term": "domains", "s": 0.15978593272171251, "bg": 1.8850421462158445e-06, "x": 0.6948893974065599, "ncat": 13}, {"cat25k": 12, "ncat25k": 15, "os": 0.5154436027796554, "cat": 4, "y": 0.6109839816933639, "term": "structured", "s": 0.43501529051987764, "bg": 6.043068484235726e-06, "x": 0.6956521739130435, "ncat": 13}, {"cat25k": 9, "ncat25k": 15, "os": 0.4645177499525405, "cat": 3, "y": 0.4668192219679634, "term": "future", "s": 0.3103975535168196, "bg": 3.1173139752729404e-07, "x": 0.6964149504195271, "ncat": 13}, {"cat25k": 6, "ncat25k": 15, "os": 0.40682097304859305, "cat": 2, "y": 0.28527841342486654, "term": "b", "s": 0.15978593272171251, "bg": 9.527867034042164e-08, "x": 0.6971777269260107, "ncat": 13}, {"cat25k": 0, "ncat25k": 15, "os": 0.27488233814366553, "cat": 0, "y": 0.01906941266209001, "term": "development", "s": 0.0, "bg": 1.0476804543323564e-07, "x": 0.6979405034324943, "ncat": 13}, {"cat25k": 6, "ncat25k": 15, "os": 0.40682097304859305, "cat": 2, "y": 0.28909229595728453, "term": "yet", "s": 0.15978593272171251, "bg": 2.4347493267309425e-07, "x": 0.6987032799389779, "ncat": 13}, {"cat25k": 9, "ncat25k": 15, "os": 0.4645177499525405, "cat": 3, "y": 0.4759725400457666, "term": "query", "s": 0.3103975535168196, "bg": 1.978317007431771e-06, "x": 0.6994660564454614, "ncat": 13}, {"cat25k": 31, "ncat25k": 15, "os": 0.705838955821486, "cat": 10, "y": 0.8756674294431731, "term": "users", "s": 0.9197247706422018, "bg": 4.820061223346535e-07, "x": 0.700228832951945, "ncat": 13}, {"cat25k": 19, "ncat25k": 15, "os": 0.5978454488211579, "cat": 6, "y": 0.7704042715484363, "term": "role", "s": 0.6842507645259939, "bg": 7.051377721231756e-07, "x": 0.7009916094584286, "ncat": 13}, {"cat25k": 16, "ncat25k": 15, "os": 0.5596930853319246, "cat": 5, "y": 0.7162471395881007, "term": "additional", "s": 0.5672782874617737, "bg": 2.873494835993278e-07, "x": 0.7017543859649122, "ncat": 13}, {"cat25k": 0, "ncat25k": 15, "os": 0.27488233814366553, "cat": 0, "y": 0.02440884820747521, "term": "dependencies", "s": 0.0, "bg": 9.956700797407275e-06, "x": 0.7025171624713958, "ncat": 13}, {"cat25k": 9, "ncat25k": 15, "os": 0.4645177499525405, "cat": 3, "y": 0.5034324942791762, "term": "segmentation", "s": 0.3103975535168196, "bg": 3.3279185325543226e-05, "x": 0.7032799389778794, "ncat": 13}, {"cat25k": 6, "ncat25k": 15, "os": 0.40682097304859305, "cat": 2, "y": 0.3188405797101449, "term": "four", "s": 0.15978593272171251, "bg": 2.3215762084746338e-07, "x": 0.704042715484363, "ncat": 13}, {"cat25k": 3, "ncat25k": 15, "os": 0.34302164573120236, "cat": 1, "y": 0.14416475972540047, "term": "chinese", "s": 0.07798165137614678, "bg": 9.62342984385985e-07, "x": 0.7048054919908466, "ncat": 13}, {"cat25k": 9, "ncat25k": 15, "os": 0.4645177499525405, "cat": 3, "y": 0.5186880244088482, "term": "finally", "s": 0.3103975535168196, "bg": 6.523352286321838e-07, "x": 0.7055682684973302, "ncat": 13}, {"cat25k": 3, "ncat25k": 15, "os": 0.34302164573120236, "cat": 1, "y": 0.15789473684210525, "term": "comparable", "s": 0.07798165137614678, "bg": 4.854896098835464e-06, "x": 0.7063310450038138, "ncat": 13}, {"cat25k": 19, "ncat25k": 15, "os": 0.5978454488211579, "cat": 6, "y": 0.778794813119756, "term": "strong", "s": 0.6842507645259939, "bg": 6.554727971988632e-07, "x": 0.7070938215102975, "ncat": 13}, {"cat25k": 9, "ncat25k": 15, "os": 0.4645177499525405, "cat": 3, "y": 0.5278413424866514, "term": "previously", "s": 0.3103975535168196, "bg": 1.225045242902511e-06, "x": 0.7078565980167811, "ncat": 13}, {"cat25k": 9, "ncat25k": 15, "os": 0.4645177499525405, "cat": 3, "y": 0.5293668954996186, "term": "experimental", "s": 0.3103975535168196, "bg": 1.8537336203324921e-06, "x": 0.7086193745232647, "ncat": 13}, {"cat25k": 12, "ncat25k": 15, "os": 0.5154436027796554, "cat": 4, "y": 0.6598016781083142, "term": "problems", "s": 0.43501529051987764, "bg": 3.136787070725015e-07, "x": 0.7093821510297483, "ncat": 13}, {"cat25k": 19, "ncat25k": 15, "os": 0.5978454488211579, "cat": 6, "y": 0.7833714721586575, "term": "team", "s": 0.6842507645259939, "bg": 2.329057771352218e-07, "x": 0.7101449275362319, "ncat": 13}, {"cat25k": 16, "ncat25k": 16, "os": 0.5457522770629377, "cat": 5, "y": 0.6750572082379863, "term": "form", "s": 0.5313455657492354, "bg": 2.481997538225778e-07, "x": 0.7109077040427155, "ncat": 14}, {"cat25k": 16, "ncat25k": 16, "os": 0.5457522770629377, "cat": 5, "y": 0.6803966437833715, "term": "way", "s": 0.5313455657492354, "bg": 1.3744757516313282e-07, "x": 0.7116704805491991, "ncat": 14}, {"cat25k": 9, "ncat25k": 16, "os": 0.4541734800785694, "cat": 3, "y": 0.4248665141113654, "term": "sets", "s": 0.2996941896024465, "bg": 6.639112656818038e-07, "x": 0.7124332570556827, "ncat": 14}, {"cat25k": 22, "ncat25k": 16, "os": 0.6153841490493973, "cat": 7, "y": 0.7856598016781083, "term": "step", "s": 0.7308868501529052, "bg": 5.568269319368517e-07, "x": 0.7131960335621663, "ncat": 14}, {"cat25k": 6, "ncat25k": 16, "os": 0.39933007184163694, "cat": 2, "y": 0.2440884820747521, "term": "under", "s": 0.13685015290519878, "bg": 1.0212162038430261e-07, "x": 0.7139588100686499, "ncat": 14}, {"cat25k": 28, "ncat25k": 16, "os": 0.6685688389651465, "cat": 9, "y": 0.8497330282227308, "term": "particular", "s": 0.8616207951070336, "bg": 6.656278250180933e-07, "x": 0.7147215865751335, "ncat": 14}, {"cat25k": 16, "ncat25k": 16, "os": 0.5457522770629377, "cat": 5, "y": 0.6857360793287567, "term": "character", "s": 0.5313455657492354, "bg": 1.3055911345139602e-06, "x": 0.7154843630816171, "ncat": 14}, {"cat25k": 22, "ncat25k": 16, "os": 0.6153841490493973, "cat": 7, "y": 0.7909992372234935, "term": "content", "s": 0.7308868501529052, "bg": 3.069823397823442e-07, "x": 0.7162471395881007, "ncat": 14}, {"cat25k": 3, "ncat25k": 16, "os": 0.3390569639684724, "cat": 1, "y": 0.08466819221967964, "term": "semi", "s": 0.0756880733944954, "bg": 2.1810122647407197e-06, "x": 0.7170099160945843, "ncat": 14}, {"cat25k": 6, "ncat25k": 16, "os": 0.39933007184163694, "cat": 2, "y": 0.2524790236460717, "term": "compare", "s": 0.13685015290519878, "bg": 1.7461689476189533e-07, "x": 0.7177726926010679, "ncat": 14}, {"cat25k": 16, "ncat25k": 16, "os": 0.5457522770629377, "cat": 5, "y": 0.6918382913806255, "term": "represent", "s": 0.5313455657492354, "bg": 1.6861835385488958e-06, "x": 0.7185354691075515, "ncat": 14}, {"cat25k": 37, "ncat25k": 16, "os": 0.727698163520174, "cat": 12, "y": 0.9016018306636155, "term": "unsupervised", "s": 0.929663608562691, "bg": 0.0001306506401881369, "x": 0.7192982456140351, "ncat": 14}, {"cat25k": 6, "ncat25k": 16, "os": 0.39933007184163694, "cat": 2, "y": 0.2700228832951945, "term": "five", "s": 0.13685015290519878, "bg": 4.0298896531777186e-07, "x": 0.7200610221205187, "ncat": 14}, {"cat25k": 22, "ncat25k": 16, "os": 0.6153841490493973, "cat": 7, "y": 0.7948131197559115, "term": "possible", "s": 0.7308868501529052, "bg": 3.5665937236104993e-07, "x": 0.7208237986270023, "ncat": 14}, {"cat25k": 9, "ncat25k": 16, "os": 0.4541734800785694, "cat": 3, "y": 0.4500381388253242, "term": "improvement", "s": 0.2996941896024465, "bg": 9.142443873663149e-07, "x": 0.7215865751334859, "ncat": 14}, {"cat25k": 9, "ncat25k": 16, "os": 0.4541734800785694, "cat": 3, "y": 0.45385202135774216, "term": "generated", "s": 0.2996941896024465, "bg": 1.0391441712519986e-06, "x": 0.7223493516399695, "ncat": 14}, {"cat25k": 9, "ncat25k": 16, "os": 0.4541734800785694, "cat": 3, "y": 0.4698703279938978, "term": "layer", "s": 0.2996941896024465, "bg": 1.6315803954936048e-06, "x": 0.7231121281464531, "ncat": 14}, {"cat25k": 22, "ncat25k": 16, "os": 0.6153841490493973, "cat": 7, "y": 0.8062547673531655, "term": "document", "s": 0.7308868501529052, "bg": 7.492970151095236e-07, "x": 0.7238749046529367, "ncat": 14}, {"cat25k": 16, "ncat25k": 16, "os": 0.5457522770629377, "cat": 5, "y": 0.7109077040427155, "term": "application", "s": 0.5313455657492354, "bg": 3.14070259283647e-07, "x": 0.7246376811594203, "ncat": 14}, {"cat25k": 16, "ncat25k": 16, "os": 0.5457522770629377, "cat": 5, "y": 0.7116704805491991, "term": "extracting", "s": 0.5313455657492354, "bg": 2.3548464613347594e-05, "x": 0.7254004576659039, "ncat": 14}, {"cat25k": 31, "ncat25k": 16, "os": 0.690592399550882, "cat": 10, "y": 0.8771929824561403, "term": "so", "s": 0.9051987767584098, "bg": 7.252234118332126e-08, "x": 0.7261632341723875, "ncat": 14}, {"cat25k": 19, "ncat25k": 16, "os": 0.5829908248740711, "cat": 6, "y": 0.7688787185354691, "term": "useful", "s": 0.6223241590214067, "bg": 7.216491001525411e-07, "x": 0.7269260106788711, "ncat": 14}, {"cat25k": 16, "ncat25k": 16, "os": 0.5457522770629377, "cat": 5, "y": 0.7185354691075515, "term": "rich", "s": 0.5313455657492354, "bg": 1.2883691774637818e-06, "x": 0.7276887871853547, "ncat": 14}, {"cat25k": 16, "ncat25k": 16, "os": 0.5457522770629377, "cat": 5, "y": 0.7215865751334859, "term": "build", "s": 0.5313455657492354, "bg": 5.436293487467958e-07, "x": 0.7284515636918383, "ncat": 14}, {"cat25k": 3, "ncat25k": 16, "os": 0.3390569639684724, "cat": 1, "y": 0.15026697177726925, "term": "continuous", "s": 0.0756880733944954, "bg": 1.7329118587673187e-06, "x": 0.7292143401983219, "ncat": 14}, {"cat25k": 12, "ncat25k": 16, "os": 0.5029691665060196, "cat": 4, "y": 0.6445461479786423, "term": "sense", "s": 0.39449541284403666, "bg": 1.480494541359684e-06, "x": 0.7299771167048055, "ncat": 14}, {"cat25k": 3, "ncat25k": 16, "os": 0.3390569639684724, "cat": 1, "y": 0.15331807780320367, "term": "challenging", "s": 0.0756880733944954, "bg": 3.999841784036097e-06, "x": 0.7307398932112891, "ncat": 14}, {"cat25k": 16, "ncat25k": 16, "os": 0.5457522770629377, "cat": 5, "y": 0.7292143401983219, "term": "distributional", "s": 0.5313455657492354, "bg": 0.00012253963391284367, "x": 0.7315026697177727, "ncat": 14}, {"cat25k": 12, "ncat25k": 16, "os": 0.5029691665060196, "cat": 4, "y": 0.6491228070175439, "term": "may", "s": 0.39449541284403666, "bg": 5.3147960976061345e-08, "x": 0.7322654462242563, "ncat": 14}, {"cat25k": 25, "ncat25k": 16, "os": 0.6436839291090987, "cat": 8, "y": 0.8428680396643783, "term": "3", "s": 0.8295107033639143, "bg": 0.0, "x": 0.7330282227307399, "ncat": 14}, {"cat25k": 0, "ncat25k": 16, "os": 0.27488233814366553, "cat": 0, "y": 0.041189931350114416, "term": "known", "s": 0.0, "bg": 3.2388290818534936e-07, "x": 0.7337909992372235, "ncat": 14}, {"cat25k": 16, "ncat25k": 16, "os": 0.5457522770629377, "cat": 5, "y": 0.7330282227307399, "term": "designed", "s": 0.5313455657492354, "bg": 5.023026209923531e-07, "x": 0.7345537757437071, "ncat": 14}, {"cat25k": 9, "ncat25k": 16, "os": 0.4541734800785694, "cat": 3, "y": 0.5415713196033562, "term": "objective", "s": 0.2996941896024465, "bg": 2.041896883142064e-06, "x": 0.7353165522501907, "ncat": 14}, {"cat25k": 16, "ncat25k": 17, "os": 0.5331314328026017, "cat": 5, "y": 0.6765827612509535, "term": "some", "s": 0.46559633027522934, "bg": 7.287502352496853e-08, "x": 0.7360793287566743, "ncat": 15}, {"cat25k": 16, "ncat25k": 17, "os": 0.5331314328026017, "cat": 5, "y": 0.6773455377574371, "term": "found", "s": 0.46559633027522934, "bg": 1.7236821954057492e-07, "x": 0.7368421052631579, "ncat": 15}, {"cat25k": 19, "ncat25k": 17, "os": 0.5694233919972365, "cat": 6, "y": 0.7498093058733791, "term": "combination", "s": 0.6009174311926605, "bg": 1.9079318982788228e-06, "x": 0.7376048817696415, "ncat": 15}, {"cat25k": 12, "ncat25k": 17, "os": 0.4917795995425828, "cat": 4, "y": 0.5911517925247902, "term": "due", "s": 0.3753822629969419, "bg": 3.6202973112004235e-07, "x": 0.738367658276125, "ncat": 15}, {"cat25k": 19, "ncat25k": 17, "os": 0.5694233919972365, "cat": 6, "y": 0.7536231884057971, "term": "identification", "s": 0.6009174311926605, "bg": 2.924548324400927e-06, "x": 0.7391304347826086, "ncat": 15}, {"cat25k": 16, "ncat25k": 17, "os": 0.5331314328026017, "cat": 5, "y": 0.6948893974065599, "term": "resulting", "s": 0.46559633027522934, "bg": 1.917901574569794e-06, "x": 0.7398932112890922, "ncat": 15}, {"cat25k": 12, "ncat25k": 17, "os": 0.4917795995425828, "cat": 4, "y": 0.6018306636155606, "term": "lingual", "s": 0.3753822629969419, "bg": 7.081651441116069e-05, "x": 0.7406559877955758, "ncat": 15}, {"cat25k": 22, "ncat25k": 17, "os": 0.6012568035789748, "cat": 7, "y": 0.8009153318077803, "term": "benchmark", "s": 0.7056574923547401, "bg": 8.026312929219625e-06, "x": 0.7414187643020596, "ncat": 15}, {"cat25k": 16, "ncat25k": 17, "os": 0.5331314328026017, "cat": 5, "y": 0.7055682684973302, "term": "e.g.", "s": 0.46559633027522934, "bg": 0.0, "x": 0.7421815408085431, "ncat": 15}, {"cat25k": 9, "ncat25k": 17, "os": 0.44498151708204425, "cat": 3, "y": 0.4691075514874142, "term": "provided", "s": 0.22629969418960244, "bg": 2.5024822277622313e-07, "x": 0.7429443173150267, "ncat": 15}, {"cat25k": 12, "ncat25k": 17, "os": 0.4917795995425828, "cat": 4, "y": 0.6117467581998475, "term": "participated", "s": 0.3753822629969419, "bg": 7.350745411526888e-06, "x": 0.7437070938215103, "ncat": 15}, {"cat25k": 19, "ncat25k": 17, "os": 0.5694233919972365, "cat": 6, "y": 0.7658276125095347, "term": "small", "s": 0.6009174311926605, "bg": 2.494874352610092e-07, "x": 0.7444698703279939, "ncat": 15}, {"cat25k": 28, "ncat25k": 17, "os": 0.6541229045106408, "cat": 9, "y": 0.8642257818459191, "term": "recently", "s": 0.8371559633027523, "bg": 8.104929267228645e-07, "x": 0.7452326468344775, "ncat": 15}, {"cat25k": 9, "ncat25k": 17, "os": 0.44498151708204425, "cat": 3, "y": 0.47215865751334857, "term": "traditional", "s": 0.22629969418960244, "bg": 7.515180821826355e-07, "x": 0.7459954233409611, "ncat": 15}, {"cat25k": 25, "ncat25k": 17, "os": 0.6292898649997938, "cat": 8, "y": 0.8352402745995423, "term": "explore", "s": 0.7446483180428134, "bg": 1.509640469686891e-06, "x": 0.7467581998474447, "ncat": 15}, {"cat25k": 9, "ncat25k": 17, "os": 0.44498151708204425, "cat": 3, "y": 0.475209763539283, "term": "improving", "s": 0.22629969418960244, "bg": 2.2332136033080146e-06, "x": 0.7475209763539283, "ncat": 15}, {"cat25k": 34, "ncat25k": 17, "os": 0.6960555742338718, "cat": 11, "y": 0.8909229595728452, "term": "order", "s": 0.9067278287461773, "bg": 1.9008772979397504e-07, "x": 0.7482837528604119, "ncat": 15}, {"cat25k": 9, "ncat25k": 17, "os": 0.44498151708204425, "cat": 3, "y": 0.4797864225781846, "term": "perform", "s": 0.22629969418960244, "bg": 1.3143026687901418e-06, "x": 0.7490465293668955, "ncat": 15}, {"cat25k": 16, "ncat25k": 17, "os": 0.5331314328026017, "cat": 5, "y": 0.7124332570556827, "term": "investigate", "s": 0.46559633027522934, "bg": 4.169261287307071e-06, "x": 0.7498093058733791, "ncat": 15}, {"cat25k": 25, "ncat25k": 17, "os": 0.6292898649997938, "cat": 8, "y": 0.8367658276125095, "term": "up", "s": 0.7446483180428134, "bg": 6.023916212385574e-08, "x": 0.7505720823798627, "ncat": 15}, {"cat25k": 9, "ncat25k": 17, "os": 0.44498151708204425, "cat": 3, "y": 0.4958047292143402, "term": "graph", "s": 0.22629969418960244, "bg": 4.235600802325473e-06, "x": 0.7513348588863463, "ncat": 15}, {"cat25k": 6, "ncat25k": 17, "os": 0.3927348207114813, "cat": 2, "y": 0.3295194508009153, "term": "parser", "s": 0.1353211009174312, "bg": 1.5350788544422877e-05, "x": 0.7520976353928299, "ncat": 15}, {"cat25k": 16, "ncat25k": 17, "os": 0.5331314328026017, "cat": 5, "y": 0.7307398932112891, "term": "recognition", "s": 0.46559633027522934, "bg": 2.7090430838084916e-06, "x": 0.7528604118993135, "ncat": 15}, {"cat25k": 22, "ncat25k": 17, "os": 0.6012568035789748, "cat": 7, "y": 0.8146453089244852, "term": "low", "s": 0.7056574923547401, "bg": 3.245507484697405e-07, "x": 0.7536231884057971, "ncat": 15}, {"cat25k": 22, "ncat25k": 17, "os": 0.6012568035789748, "cat": 7, "y": 0.8176964149504196, "term": "grained", "s": 0.7056574923547401, "bg": 6.173982836327716e-05, "x": 0.7543859649122807, "ncat": 15}, {"cat25k": 12, "ncat25k": 17, "os": 0.4917795995425828, "cat": 4, "y": 0.662090007627765, "term": "5", "s": 0.3753822629969419, "bg": 0.0, "x": 0.7551487414187643, "ncat": 15}, {"cat25k": 44, "ncat25k": 18, "os": 0.7317848844520297, "cat": 14, "y": 0.9183829138062548, "term": "social", "s": 0.9434250764525994, "bg": 7.448690714626169e-07, "x": 0.7559115179252479, "ncat": 16}, {"cat25k": 28, "ncat25k": 18, "os": 0.6406124593790287, "cat": 9, "y": 0.84744469870328, "term": "challenge", "s": 0.8272171253822629, "bg": 1.6768640737768266e-06, "x": 0.7566742944317315, "ncat": 16}, {"cat25k": 16, "ncat25k": 18, "os": 0.521663047998784, "cat": 5, "y": 0.6819221967963387, "term": "measure", "s": 0.44418960244648314, "bg": 1.7424184650058746e-06, "x": 0.7574370709382151, "ncat": 16}, {"cat25k": 31, "ncat25k": 18, "os": 0.6627533382097034, "cat": 10, "y": 0.8703279938977879, "term": "extract", "s": 0.8455657492354739, "bg": 4.901267594869934e-06, "x": 0.7581998474446987, "ncat": 16}, {"cat25k": 28, "ncat25k": 18, "os": 0.6406124593790287, "cat": 9, "y": 0.8489702517162472, "term": "terms", "s": 0.8272171253822629, "bg": 2.808165822191801e-07, "x": 0.7589626239511823, "ncat": 16}, {"cat25k": 34, "ncat25k": 18, "os": 0.6826853798686696, "cat": 11, "y": 0.88558352402746, "term": "out", "s": 0.8960244648318042, "bg": 9.168654970396893e-08, "x": 0.7597254004576659, "ncat": 16}, {"cat25k": 22, "ncat25k": 18, "os": 0.5882212146270054, "cat": 7, "y": 0.7902364607170099, "term": "predict", "s": 0.6704892966360856, "bg": 7.303635797532419e-06, "x": 0.7604881769641495, "ncat": 16}, {"cat25k": 19, "ncat25k": 18, "os": 0.556997533848218, "cat": 6, "y": 0.7520976353928299, "term": "common", "s": 0.5603975535168195, "bg": 4.448780976085717e-07, "x": 0.7612509534706331, "ncat": 16}, {"cat25k": 12, "ncat25k": 18, "os": 0.48169413045802517, "cat": 4, "y": 0.597254004576659, "term": "consider", "s": 0.33868501529051986, "bg": 7.391312823733727e-07, "x": 0.7620137299771167, "ncat": 16}, {"cat25k": 3, "ncat25k": 18, "os": 0.3325490911537743, "cat": 1, "y": 0.09687261632341723, "term": "outperform", "s": 0.0749235474006116, "bg": 5.131611582617521e-05, "x": 0.7627765064836003, "ncat": 16}, {"cat25k": 22, "ncat25k": 18, "os": 0.5882212146270054, "cat": 7, "y": 0.7955758962623951, "term": "short", "s": 0.6704892966360856, "bg": 4.6811792523432084e-07, "x": 0.7635392829900839, "ncat": 16}, {"cat25k": 22, "ncat25k": 18, "os": 0.5882212146270054, "cat": 7, "y": 0.7971014492753623, "term": "current", "s": 0.6704892966360856, "bg": 2.487990951453353e-07, "x": 0.7643020594965675, "ncat": 16}, {"cat25k": 0, "ncat25k": 18, "os": 0.27488233814366553, "cat": 0, "y": 0.016018306636155607, "term": "allows", "s": 0.0, "bg": 6.366037534269645e-07, "x": 0.7650648360030511, "ncat": 16}, {"cat25k": 12, "ncat25k": 18, "os": 0.48169413045802517, "cat": 4, "y": 0.6102212051868803, "term": "joint", "s": 0.33868501529051986, "bg": 1.4916731717333487e-06, "x": 0.7658276125095347, "ncat": 16}, {"cat25k": 22, "ncat25k": 18, "os": 0.5882212146270054, "cat": 7, "y": 0.8032036613272311, "term": "able", "s": 0.6704892966360856, "bg": 4.75126705784823e-07, "x": 0.7665903890160183, "ncat": 16}, {"cat25k": 9, "ncat25k": 18, "os": 0.43676414341872366, "cat": 3, "y": 0.47292143401983217, "term": "does", "s": 0.21559633027522934, "bg": 1.273584184162922e-07, "x": 0.7673531655225019, "ncat": 16}, {"cat25k": 16, "ncat25k": 18, "os": 0.521663047998784, "cat": 5, "y": 0.7086193745232647, "term": "german", "s": 0.44418960244648314, "bg": 1.0415458117043635e-06, "x": 0.7681159420289855, "ncat": 16}, {"cat25k": 16, "ncat25k": 18, "os": 0.521663047998784, "cat": 5, "y": 0.7101449275362319, "term": "search", "s": 0.44418960244648314, "bg": 7.420798245073389e-08, "x": 0.7688787185354691, "ncat": 16}, {"cat25k": 41, "ncat25k": 18, "os": 0.7169877358578377, "cat": 13, "y": 0.9130434782608695, "term": "structure", "s": 0.9250764525993884, "bg": 1.1896444484357016e-06, "x": 0.7696414950419527, "ncat": 16}, {"cat25k": 19, "ncat25k": 18, "os": 0.556997533848218, "cat": 6, "y": 0.7711670480549199, "term": "computational", "s": 0.5603975535168195, "bg": 7.656000581856045e-06, "x": 0.7704042715484363, "ncat": 16}, {"cat25k": 19, "ncat25k": 18, "os": 0.556997533848218, "cat": 6, "y": 0.7749809305873379, "term": "term", "s": 0.5603975535168195, "bg": 3.953986836301068e-07, "x": 0.7711670480549199, "ncat": 16}, {"cat25k": 12, "ncat25k": 18, "os": 0.48169413045802517, "cat": 4, "y": 0.6376811594202898, "term": "compared", "s": 0.33868501529051986, "bg": 1.2682435026372117e-06, "x": 0.7719298245614035, "ncat": 16}, {"cat25k": 31, "ncat25k": 18, "os": 0.6627533382097034, "cat": 10, "y": 0.881769641495042, "term": "applications", "s": 0.8455657492354739, "bg": 5.433708827769392e-07, "x": 0.7726926010678871, "ncat": 16}, {"cat25k": 12, "ncat25k": 18, "os": 0.48169413045802517, "cat": 4, "y": 0.6422578184591915, "term": "effective", "s": 0.33868501529051986, "bg": 6.840640466013896e-07, "x": 0.7734553775743707, "ncat": 16}, {"cat25k": 19, "ncat25k": 19, "os": 0.5455861695401745, "cat": 6, "y": 0.7444698703279939, "term": "speech", "s": 0.5290519877675841, "bg": 2.8869163124340156e-06, "x": 0.7742181540808543, "ncat": 17}, {"cat25k": 25, "ncat25k": 19, "os": 0.6034702844404055, "cat": 8, "y": 0.8215102974828375, "term": "ranked", "s": 0.7102446483180428, "bg": 5.7870131158518696e-06, "x": 0.7749809305873379, "ncat": 17}, {"cat25k": 41, "ncat25k": 19, "os": 0.7046684872485067, "cat": 13, "y": 0.9077040427154843, "term": "further", "s": 0.918960244648318, "bg": 5.657781012081754e-07, "x": 0.7757437070938215, "ncat": 17}, {"cat25k": 6, "ncat25k": 19, "os": 0.3816639181868222, "cat": 2, "y": 0.2425629290617849, "term": "like", "s": 0.11238532110091742, "bg": 9.987693260400047e-08, "x": 0.7765064836003052, "ncat": 17}, {"cat25k": 19, "ncat25k": 19, "os": 0.5455861695401745, "cat": 6, "y": 0.7513348588863463, "term": "any", "s": 0.5290519877675841, "bg": 7.034359740961335e-08, "x": 0.7772692601067888, "ncat": 17}, {"cat25k": 6, "ncat25k": 19, "os": 0.3816639181868222, "cat": 2, "y": 0.2547673531655225, "term": "general", "s": 0.11238532110091742, "bg": 1.2828191685600623e-07, "x": 0.7780320366132724, "ncat": 17}, {"cat25k": 9, "ncat25k": 19, "os": 0.42937754771690845, "cat": 3, "y": 0.4469870327993898, "term": "linear", "s": 0.21177370030581036, "bg": 2.0869327488530347e-06, "x": 0.778794813119756, "ncat": 17}, {"cat25k": 6, "ncat25k": 19, "os": 0.3816639181868222, "cat": 2, "y": 0.2639206712433257, "term": "regression", "s": 0.11238532110091742, "bg": 8.163583134790805e-06, "x": 0.7795575896262396, "ncat": 17}, {"cat25k": 28, "ncat25k": 19, "os": 0.6279666367506945, "cat": 9, "y": 0.8558352402745996, "term": "manually", "s": 0.7415902140672782, "bg": 8.837620117278618e-06, "x": 0.7803203661327232, "ncat": 17}, {"cat25k": 6, "ncat25k": 19, "os": 0.3816639181868222, "cat": 2, "y": 0.2707856598016781, "term": "code", "s": 0.11238532110091742, "bg": 2.876541442174747e-07, "x": 0.7810831426392068, "ncat": 17}, {"cat25k": 28, "ncat25k": 19, "os": 0.6279666367506945, "cat": 9, "y": 0.8649885583524027, "term": "modeling", "s": 0.7415902140672782, "bg": 4.507412278513006e-06, "x": 0.7818459191456903, "ncat": 17}, {"cat25k": 22, "ncat25k": 19, "os": 0.5761690430753356, "cat": 7, "y": 0.8070175438596491, "term": "'", "s": 0.613914373088685, "bg": 0.0, "x": 0.782608695652174, "ncat": 17}, {"cat25k": 16, "ncat25k": 19, "os": 0.5112047597165329, "cat": 5, "y": 0.7192982456140351, "term": "understanding", "s": 0.4128440366972477, "bg": 1.1729773285121807e-06, "x": 0.7833714721586575, "ncat": 17}, {"cat25k": 28, "ncat25k": 19, "os": 0.6279666367506945, "cat": 9, "y": 0.8665141113653699, "term": "developed", "s": 0.7415902140672782, "bg": 8.845943238583541e-07, "x": 0.7841342486651411, "ncat": 17}, {"cat25k": 3, "ncat25k": 19, "os": 0.3298461327265457, "cat": 1, "y": 0.14950419527078565, "term": "no", "s": 0.07415902140672782, "bg": 4.481588193589675e-08, "x": 0.7848970251716247, "ncat": 17}, {"cat25k": 25, "ncat25k": 19, "os": 0.6034702844404055, "cat": 8, "y": 0.8398169336384439, "term": "via", "s": 0.7102446483180428, "bg": 5.965692147882967e-07, "x": 0.7856598016781083, "ncat": 17}, {"cat25k": 28, "ncat25k": 19, "os": 0.6279666367506945, "cat": 9, "y": 0.8672768878718535, "term": "specifically", "s": 0.7415902140672782, "bg": 1.98704484970394e-06, "x": 0.7864225781845919, "ncat": 17}, {"cat25k": 25, "ncat25k": 19, "os": 0.6034702844404055, "cat": 8, "y": 0.8436308161708619, "term": "long", "s": 0.7102446483180428, "bg": 1.9796097111559782e-07, "x": 0.7871853546910755, "ncat": 17}, {"cat25k": 34, "ncat25k": 20, "os": 0.6580690214829872, "cat": 11, "y": 0.8825324180015256, "term": "tweets", "s": 0.8432721712538227, "bg": 0.002234717416378316, "x": 0.7879481311975591, "ncat": 18}, {"cat25k": 19, "ncat25k": 20, "os": 0.5350785187406797, "cat": 6, "y": 0.7452326468344775, "term": "identify", "s": 0.4709480122324159, "bg": 1.503777321545353e-06, "x": 0.7887109077040427, "ncat": 18}, {"cat25k": 25, "ncat25k": 20, "os": 0.5918741221567427, "cat": 8, "y": 0.8199847444698704, "term": "those", "s": 0.6758409785932722, "bg": 1.9994846217305007e-07, "x": 0.7894736842105263, "ncat": 18}, {"cat25k": 31, "ncat25k": 20, "os": 0.6380903066061674, "cat": 10, "y": 0.8695652173913043, "term": "applied", "s": 0.8249235474006116, "bg": 1.2440114731623854e-06, "x": 0.7902364607170099, "ncat": 18}, {"cat25k": 28, "ncat25k": 20, "os": 0.6161185994440739, "cat": 9, "y": 0.8466819221967964, "term": "resources", "s": 0.7339449541284404, "bg": 3.220995842370777e-07, "x": 0.7909992372234935, "ncat": 18}, {"cat25k": 0, "ncat25k": 20, "os": 0.27488233814366553, "cat": 0, "y": 0.0015255530129672007, "term": "report", "s": 0.0, "bg": 1.327312378920076e-07, "x": 0.7917620137299771, "ncat": 18}, {"cat25k": 31, "ncat25k": 20, "os": 0.6380903066061674, "cat": 10, "y": 0.8726163234172387, "term": "important", "s": 0.8249235474006116, "bg": 4.4066157374011316e-07, "x": 0.7925247902364607, "ncat": 18}, {"cat25k": 28, "ncat25k": 20, "os": 0.6161185994440739, "cat": 9, "y": 0.8527841342486652, "term": "user", "s": 0.7339449541284404, "bg": 2.590823399568766e-07, "x": 0.7932875667429443, "ncat": 18}, {"cat25k": 16, "ncat25k": 20, "os": 0.5016352707469923, "cat": 5, "y": 0.6895499618611747, "term": "improves", "s": 0.3914373088685015, "bg": 1.0402837894177532e-05, "x": 0.7940503432494279, "ncat": 18}, {"cat25k": 6, "ncat25k": 20, "os": 0.3769749740955056, "cat": 2, "y": 0.2562929061784897, "term": "produce", "s": 0.11162079510703363, "bg": 1.1851511397852474e-06, "x": 0.7948131197559115, "ncat": 18}, {"cat25k": 0, "ncat25k": 20, "os": 0.27488233814366553, "cat": 0, "y": 0.008390541571319604, "term": "pre", "s": 0.0, "bg": 6.489148120011264e-07, "x": 0.7955758962623951, "ncat": 18}, {"cat25k": 28, "ncat25k": 20, "os": 0.6161185994440739, "cat": 9, "y": 0.8596491228070176, "term": "texts", "s": 0.7339449541284404, "bg": 5.760755495102371e-06, "x": 0.7963386727688787, "ncat": 18}, {"cat25k": 19, "ncat25k": 20, "os": 0.5350785187406797, "cat": 6, "y": 0.7581998474446987, "term": "complex", "s": 0.4709480122324159, "bg": 1.449230915530958e-06, "x": 0.7971014492753623, "ncat": 18}, {"cat25k": 12, "ncat25k": 20, "os": 0.4642611274733404, "cat": 4, "y": 0.6094584286803967, "term": "single", "s": 0.308868501529052, "bg": 4.0056477853485504e-07, "x": 0.7978642257818459, "ncat": 18}, {"cat25k": 16, "ncat25k": 20, "os": 0.5016352707469923, "cat": 5, "y": 0.7063310450038138, "term": "open", "s": 0.3914373088685015, "bg": 2.6697169406333664e-07, "x": 0.7986270022883295, "ncat": 18}, {"cat25k": 22, "ncat25k": 20, "os": 0.5650035402311301, "cat": 7, "y": 0.8024408848207475, "term": "fine", "s": 0.5848623853211009, "bg": 9.7184582093663e-07, "x": 0.7993897787948131, "ncat": 18}, {"cat25k": 28, "ncat25k": 20, "os": 0.6161185994440739, "cat": 9, "y": 0.8627002288329519, "term": "focus", "s": 0.7339449541284404, "bg": 8.525903812032078e-07, "x": 0.8001525553012967, "ncat": 18}, {"cat25k": 28, "ncat25k": 20, "os": 0.6161185994440739, "cat": 9, "y": 0.8634630053394355, "term": "questions", "s": 0.7339449541284404, "bg": 8.292974033556423e-07, "x": 0.8009153318077803, "ncat": 18}, {"cat25k": 12, "ncat25k": 20, "os": 0.4642611274733404, "cat": 4, "y": 0.6170861937452327, "term": "process", "s": 0.308868501529052, "bg": 2.600565184223529e-07, "x": 0.8016781083142639, "ncat": 18}, {"cat25k": 16, "ncat25k": 20, "os": 0.5016352707469923, "cat": 5, "y": 0.7154843630816171, "term": "often", "s": 0.3914373088685015, "bg": 4.967231980499425e-07, "x": 0.8024408848207475, "ncat": 18}, {"cat25k": 25, "ncat25k": 20, "os": 0.5918741221567427, "cat": 8, "y": 0.8390541571319603, "term": "obtained", "s": 0.6758409785932722, "bg": 1.6695629608888181e-06, "x": 0.8032036613272311, "ncat": 18}, {"cat25k": 22, "ncat25k": 20, "os": 0.5650035402311301, "cat": 7, "y": 0.8161708619374524, "term": "ranking", "s": 0.5848623853211009, "bg": 4.632303737976191e-06, "x": 0.8039664378337147, "ncat": 18}, {"cat25k": 44, "ncat25k": 22, "os": 0.6970481178428832, "cat": 14, "y": 0.916094584286804, "term": "various", "s": 0.9074923547400611, "bg": 7.893732728142773e-07, "x": 0.8047292143401983, "ncat": 19}, {"cat25k": 28, "ncat25k": 22, "os": 0.6050060231885037, "cat": 9, "y": 0.8504958047292144, "term": "presents", "s": 0.7125382262996942, "bg": 2.6187496878947035e-06, "x": 0.8054919908466819, "ncat": 19}, {"cat25k": 12, "ncat25k": 22, "os": 0.4566839631314704, "cat": 4, "y": 0.601067887109077, "term": "participation", "s": 0.30428134556574926, "bg": 1.8999668842808985e-06, "x": 0.8062547673531655, "ncat": 19}, {"cat25k": 16, "ncat25k": 22, "os": 0.4928509069887488, "cat": 5, "y": 0.6956521739130435, "term": "meaning", "s": 0.37996941896024466, "bg": 2.3548404489974284e-06, "x": 0.8070175438596491, "ncat": 19}, {"cat25k": 34, "ncat25k": 22, "os": 0.6467408830051873, "cat": 11, "y": 0.8886346300533944, "term": "textual", "s": 0.831039755351682, "bg": 4.358775237531011e-05, "x": 0.8077803203661327, "ncat": 19}, {"cat25k": 22, "ncat25k": 22, "os": 0.5546385641901191, "cat": 7, "y": 0.7993897787948131, "term": "type", "s": 0.5558103975535168, "bg": 2.4229758197512747e-07, "x": 0.8085430968726163, "ncat": 19}, {"cat25k": 16, "ncat25k": 22, "os": 0.4928509069887488, "cat": 5, "y": 0.7078565980167811, "term": "goal", "s": 0.37996941896024466, "bg": 1.391133863363064e-06, "x": 0.8093058733790999, "ncat": 19}, {"cat25k": 12, "ncat25k": 22, "os": 0.4566839631314704, "cat": 4, "y": 0.6247139588100686, "term": "convolutional", "s": 0.30428134556574926, "bg": 0.0004665959703075292, "x": 0.8100686498855835, "ncat": 19}, {"cat25k": 25, "ncat25k": 22, "os": 0.5810522233983725, "cat": 8, "y": 0.8375286041189931, "term": "generation", "s": 0.6200305810397553, "bg": 2.4019393859086676e-06, "x": 0.8108314263920672, "ncat": 19}, {"cat25k": 9, "ncat25k": 22, "os": 0.41664768503551824, "cat": 3, "y": 0.551487414187643, "term": "multilingual", "s": 0.16972477064220182, "bg": 3.4917604603601957e-05, "x": 0.8115942028985508, "ncat": 19}, {"cat25k": 9, "ncat25k": 22, "os": 0.41664768503551824, "cat": 3, "y": 0.5644546147978642, "term": "subtasks", "s": 0.16972477064220182, "bg": 0.00037664783427495297, "x": 0.8123569794050344, "ncat": 19}, {"cat25k": 16, "ncat25k": 23, "os": 0.4847627444175645, "cat": 5, "y": 0.6826849733028223, "term": "addition", "s": 0.34480122324159024, "bg": 7.075798979490169e-07, "x": 0.813119755911518, "ncat": 20}, {"cat25k": 16, "ncat25k": 23, "os": 0.4847627444175645, "cat": 5, "y": 0.6842105263157895, "term": "4", "s": 0.34480122324159024, "bg": 0.0, "x": 0.8138825324180016, "ncat": 20}, {"cat25k": 16, "ncat25k": 23, "os": 0.4847627444175645, "cat": 5, "y": 0.6926010678871091, "term": "dependency", "s": 0.34480122324159024, "bg": 2.1234843053736617e-05, "x": 0.8146453089244852, "ncat": 20}, {"cat25k": 19, "ncat25k": 23, "os": 0.5164002564832593, "cat": 6, "y": 0.7528604118993135, "term": "improve", "s": 0.4380733944954128, "bg": 9.126307905853267e-07, "x": 0.8154080854309688, "ncat": 20}, {"cat25k": 19, "ncat25k": 23, "os": 0.5164002564832593, "cat": 6, "y": 0.7620137299771167, "term": "answer", "s": 0.4380733944954128, "bg": 1.5145653352807965e-06, "x": 0.8161708619374524, "ncat": 20}, {"cat25k": 19, "ncat25k": 23, "os": 0.5164002564832593, "cat": 6, "y": 0.7650648360030511, "term": "scale", "s": 0.4380733944954128, "bg": 1.4666872405500369e-06, "x": 0.816933638443936, "ncat": 20}, {"cat25k": 12, "ncat25k": 23, "os": 0.4497431111769313, "cat": 4, "y": 0.6125095347063311, "term": "target", "s": 0.2301223241590214, "bg": 1.2247556100648349e-06, "x": 0.8176964149504196, "ncat": 20}, {"cat25k": 9, "ncat25k": 23, "os": 0.4111274273644157, "cat": 3, "y": 0.4843630816170862, "term": "semantics", "s": 0.1636085626911315, "bg": 1.2885417802769354e-05, "x": 0.8184591914569032, "ncat": 20}, {"cat25k": 16, "ncat25k": 23, "os": 0.4847627444175645, "cat": 5, "y": 0.7299771167048055, "term": "second", "s": 0.34480122324159024, "bg": 3.387728288030581e-07, "x": 0.8192219679633868, "ncat": 20}, {"cat25k": 22, "ncat25k": 24, "os": 0.5360123590882652, "cat": 7, "y": 0.7841342486651411, "term": "related", "s": 0.4724770642201835, "bg": 2.595347351946334e-07, "x": 0.8199847444698704, "ncat": 21}, {"cat25k": 28, "ncat25k": 24, "os": 0.5847611960017467, "cat": 9, "y": 0.8443935926773455, "term": "there", "s": 0.6643730886850152, "bg": 8.841661587678746e-08, "x": 0.820747520976354, "ncat": 21}, {"cat25k": 16, "ncat25k": 24, "os": 0.47729422621362855, "cat": 5, "y": 0.6758199847444699, "term": "significant", "s": 0.3363914373088685, "bg": 9.590012577301494e-07, "x": 0.8215102974828375, "ncat": 21}, {"cat25k": 12, "ncat25k": 24, "os": 0.44336364872681266, "cat": 4, "y": 0.5804729214340199, "term": "part", "s": 0.22247706422018346, "bg": 1.7173916170251041e-07, "x": 0.8222730739893211, "ncat": 21}, {"cat25k": 6, "ncat25k": 24, "os": 0.36540297947513, "cat": 2, "y": 0.2410373760488177, "term": "2", "s": 0.09250764525993882, "bg": 0.0, "x": 0.8230358504958047, "ncat": 21}, {"cat25k": 25, "ncat25k": 24, "os": 0.5614683503154493, "cat": 8, "y": 0.8245614035087719, "term": "train", "s": 0.5703363914373089, "bg": 1.8197547936890653e-06, "x": 0.8237986270022883, "ncat": 21}, {"cat25k": 12, "ncat25k": 24, "os": 0.44336364872681266, "cat": 4, "y": 0.5980167810831426, "term": "lstm", "s": 0.22247706422018346, "bg": 0.0012261089073205915, "x": 0.8245614035087719, "ncat": 21}, {"cat25k": 16, "ncat25k": 24, "os": 0.47729422621362855, "cat": 5, "y": 0.6910755148741419, "term": "architecture", "s": 0.3363914373088685, "bg": 1.5892169415245458e-06, "x": 0.8253241800152555, "ncat": 21}, {"cat25k": 12, "ncat25k": 24, "os": 0.44336364872681266, "cat": 4, "y": 0.6003051106025934, "term": "similar", "s": 0.22247706422018346, "bg": 4.1944103140616737e-07, "x": 0.8260869565217391, "ncat": 21}, {"cat25k": 25, "ncat25k": 24, "os": 0.5614683503154493, "cat": 8, "y": 0.8329519450800915, "term": "multi", "s": 0.5703363914373089, "bg": 1.8482633753565608e-06, "x": 0.8268497330282227, "ncat": 21}, {"cat25k": 19, "ncat25k": 24, "os": 0.5080715904812593, "cat": 6, "y": 0.7589626239511823, "term": "same", "s": 0.40978593272171254, "bg": 2.4693666551372796e-07, "x": 0.8276125095347063, "ncat": 21}, {"cat25k": 28, "ncat25k": 24, "os": 0.5847611960017467, "cat": 9, "y": 0.8619374523264683, "term": "answering", "s": 0.6643730886850152, "bg": 1.7768881082835614e-05, "x": 0.8283752860411899, "ncat": 21}, {"cat25k": 12, "ncat25k": 24, "os": 0.44336364872681266, "cat": 4, "y": 0.6147978642257819, "term": "improvements", "s": 0.22247706422018346, "bg": 3.087887617075529e-06, "x": 0.8291380625476735, "ncat": 21}, {"cat25k": 34, "ncat25k": 24, "os": 0.6258473958480526, "cat": 11, "y": 0.8916857360793288, "term": "achieved", "s": 0.7400611620795107, "bg": 3.966913607038704e-06, "x": 0.8299008390541571, "ncat": 21}, {"cat25k": 22, "ncat25k": 24, "os": 0.5360123590882652, "cat": 7, "y": 0.8093058733790999, "term": "including", "s": 0.4724770642201835, "bg": 2.707106329610396e-07, "x": 0.8306636155606407, "ncat": 21}, {"cat25k": 9, "ncat25k": 24, "os": 0.40607638459937373, "cat": 3, "y": 0.4881769641495042, "term": "very", "s": 0.15902140672782872, "bg": 1.7911579986918814e-07, "x": 0.8314263920671243, "ncat": 21}, {"cat25k": 34, "ncat25k": 24, "os": 0.6258473958480526, "cat": 11, "y": 0.893211289092296, "term": "was", "s": 0.7400611620795107, "bg": 5.7971633990100204e-08, "x": 0.8321891685736079, "ncat": 21}, {"cat25k": 12, "ncat25k": 24, "os": 0.44336364872681266, "cat": 4, "y": 0.6414950419527079, "term": "relation", "s": 0.22247706422018346, "bg": 5.979092985872473e-06, "x": 0.8329519450800915, "ncat": 21}, {"cat25k": 25, "ncat25k": 24, "os": 0.5614683503154493, "cat": 8, "y": 0.8413424866514111, "term": "significantly", "s": 0.5703363914373089, "bg": 3.1858963265891286e-06, "x": 0.8337147215865751, "ncat": 21}, {"cat25k": 22, "ncat25k": 25, "os": 0.5276225405012401, "cat": 7, "y": 0.7871853546910755, "term": "classifier", "s": 0.459480122324159, "bg": 9.073846785709168e-05, "x": 0.8344774980930587, "ncat": 22}, {"cat25k": 28, "ncat25k": 25, "os": 0.5755272227524665, "cat": 9, "y": 0.8535469107551488, "term": "attention", "s": 0.6116207951070337, "bg": 3.213711837171933e-06, "x": 0.8352402745995423, "ncat": 22}, {"cat25k": 28, "ncat25k": 25, "os": 0.5755272227524665, "cat": 9, "y": 0.8565980167810832, "term": "annotated", "s": 0.6116207951070337, "bg": 1.1912575593151128e-05, "x": 0.8360030511060259, "ncat": 22}, {"cat25k": 28, "ncat25k": 25, "os": 0.5755272227524665, "cat": 9, "y": 0.8581235697940504, "term": "algorithm", "s": 0.6116207951070337, "bg": 4.603062199241366e-06, "x": 0.8367658276125095, "ncat": 22}, {"cat25k": 12, "ncat25k": 25, "os": 0.4374816838401849, "cat": 4, "y": 0.6041189931350115, "term": "were", "s": 0.2194189602446483, "bg": 1.296528235009605e-07, "x": 0.8375286041189931, "ncat": 22}, {"cat25k": 19, "ncat25k": 25, "os": 0.5003273740495183, "cat": 6, "y": 0.7597254004576659, "term": "do", "s": 0.38914373088685017, "bg": 6.52077533377564e-08, "x": 0.8382913806254767, "ncat": 22}, {"cat25k": 9, "ncat25k": 25, "os": 0.4014380141216716, "cat": 3, "y": 0.4660564454614798, "term": "scores", "s": 0.13914373088685014, "bg": 2.9471068858458954e-06, "x": 0.8390541571319603, "ncat": 22}, {"cat25k": 12, "ncat25k": 25, "os": 0.4374816838401849, "cat": 4, "y": 0.6430205949656751, "term": "shared", "s": 0.2194189602446483, "bg": 2.4481125760702667e-06, "x": 0.8398169336384439, "ncat": 22}, {"cat25k": 19, "ncat25k": 26, "os": 0.4931108470024541, "cat": 6, "y": 0.7475209763539283, "term": "nlp", "s": 0.3837920489296636, "bg": 5.70811231886187e-05, "x": 0.8405797101449275, "ncat": 23}, {"cat25k": 41, "ncat25k": 26, "os": 0.6417245015184483, "cat": 13, "y": 0.9069412662090007, "term": "given", "s": 0.8287461773700305, "bg": 6.051031051900889e-07, "x": 0.8413424866514111, "ncat": 23}, {"cat25k": 12, "ncat25k": 26, "os": 0.4320424486760224, "cat": 4, "y": 0.5949656750572082, "term": "competitive", "s": 0.21253822629969416, "bg": 2.204048963892325e-06, "x": 0.8421052631578947, "ncat": 23}, {"cat25k": 28, "ncat25k": 26, "os": 0.5668248190067547, "cat": 9, "y": 0.8543096872616324, "term": "outperforms", "s": 0.5879204892966361, "bg": 0.00020242979007398175, "x": 0.8428680396643783, "ncat": 23}, {"cat25k": 12, "ncat25k": 26, "os": 0.4320424486760224, "cat": 4, "y": 0.5964912280701754, "term": "news", "s": 0.21253822629969416, "bg": 1.244241320254617e-07, "x": 0.8436308161708619, "ncat": 23}, {"cat25k": 34, "ncat25k": 26, "os": 0.6070613851263471, "cat": 11, "y": 0.8871090770404272, "term": "relations", "s": 0.7186544342507646, "bg": 2.208700549412451e-06, "x": 0.8443935926773455, "ncat": 23}, {"cat25k": 22, "ncat25k": 26, "os": 0.5197742130715316, "cat": 7, "y": 0.7940503432494279, "term": "recurrent", "s": 0.4426605504587156, "bg": 3.524479048954573e-05, "x": 0.8451563691838292, "ncat": 23}, {"cat25k": 25, "ncat25k": 26, "os": 0.5442543723043243, "cat": 8, "y": 0.8283752860411899, "term": "1", "s": 0.5229357798165137, "bg": 0.0, "x": 0.8459191456903128, "ncat": 23}, {"cat25k": 19, "ncat25k": 26, "os": 0.4931108470024541, "cat": 6, "y": 0.7559115179252479, "term": "corpora", "s": 0.3837920489296636, "bg": 0.00010584574276661955, "x": 0.8466819221967964, "ncat": 23}, {"cat25k": 25, "ncat25k": 26, "os": 0.5442543723043243, "cat": 8, "y": 0.8337147215865751, "term": "standard", "s": 0.5229357798165137, "bg": 4.890218865412986e-07, "x": 0.84744469870328, "ncat": 23}, {"cat25k": 22, "ncat25k": 26, "os": 0.5197742130715316, "cat": 7, "y": 0.8047292143401983, "term": "source", "s": 0.4426605504587156, "bg": 4.77726408918641e-07, "x": 0.8482074752097636, "ncat": 23}, {"cat25k": 31, "ncat25k": 26, "os": 0.5877043502180904, "cat": 10, "y": 0.8779557589626239, "term": "feature", "s": 0.6681957186544343, "bg": 1.5230543256848705e-06, "x": 0.8489702517162472, "ncat": 23}, {"cat25k": 9, "ncat25k": 26, "os": 0.39716438826341927, "cat": 3, "y": 0.49122807017543857, "term": "parallel", "s": 0.13608562691131498, "bg": 5.128813702662481e-06, "x": 0.8497330282227308, "ncat": 23}, {"cat25k": 31, "ncat25k": 26, "os": 0.5877043502180904, "cat": 10, "y": 0.8802440884820748, "term": "quality", "s": 0.6681957186544343, "bg": 4.325693034051644e-07, "x": 0.8504958047292144, "ncat": 23}, {"cat25k": 47, "ncat25k": 27, "os": 0.6627851882275657, "cat": 15, "y": 0.9252479023646072, "term": "they", "s": 0.8470948012232415, "bg": 9.962873735952186e-08, "x": 0.851258581235698, "ncat": 24}, {"cat25k": 12, "ncat25k": 27, "os": 0.4269987641066949, "cat": 4, "y": 0.5881006864988558, "term": "evaluated", "s": 0.2110091743119266, "bg": 5.800535254058128e-06, "x": 0.8520213577421816, "ncat": 24}, {"cat25k": 34, "ncat25k": 27, "os": 0.5983751985024345, "cat": 11, "y": 0.8863463005339436, "term": "better", "s": 0.7048929663608562, "bg": 4.963889517489128e-07, "x": 0.8527841342486652, "ncat": 24}, {"cat25k": 22, "ncat25k": 27, "os": 0.5124193866043707, "cat": 7, "y": 0.7932875667429443, "term": "prediction", "s": 0.4319571865443425, "bg": 1.2505347773026829e-05, "x": 0.8535469107551488, "ncat": 24}, {"cat25k": 47, "ncat25k": 27, "os": 0.6627851882275657, "cat": 15, "y": 0.9267734553775744, "term": "pairs", "s": 0.8470948012232415, "bg": 1.1172484825973792e-05, "x": 0.8543096872616324, "ncat": 24}, {"cat25k": 19, "ncat25k": 27, "os": 0.4863720226471276, "cat": 6, "y": 0.7574370709382151, "term": "entity", "s": 0.3486238532110092, "bg": 5.5765796401581105e-06, "x": 0.855072463768116, "ncat": 24}, {"cat25k": 25, "ncat25k": 27, "os": 0.5364150567813494, "cat": 8, "y": 0.8344774980930587, "term": "support", "s": 0.474006116207951, "bg": 1.9273597852381538e-07, "x": 0.8558352402745996, "ncat": 24}, {"cat25k": 22, "ncat25k": 27, "os": 0.5124193866043707, "cat": 7, "y": 0.8054919908466819, "term": "space", "s": 0.4319571865443425, "bg": 7.074652672806247e-07, "x": 0.8565980167810832, "ncat": 24}, {"cat25k": 16, "ncat25k": 27, "os": 0.45798741238718543, "cat": 5, "y": 0.7177726926010679, "term": "sequence", "s": 0.30581039755351686, "bg": 3.1933698918161916e-06, "x": 0.8573607932875668, "ncat": 24}, {"cat25k": 50, "ncat25k": 27, "os": 0.6762818908915833, "cat": 16, "y": 0.938977879481312, "term": "most", "s": 0.870795107033639, "bg": 2.0659872483423337e-07, "x": 0.8581235697940504, "ncat": 24}, {"cat25k": 44, "ncat25k": 28, "os": 0.639785325411562, "cat": 14, "y": 0.9168573607932876, "term": "twitter", "s": 0.8264525993883791, "bg": 0.001602322206095791, "x": 0.858886346300534, "ncat": 25}, {"cat25k": 28, "ncat25k": 28, "os": 0.5508556859562381, "cat": 9, "y": 0.8451563691838292, "term": "techniques", "s": 0.5481651376146789, "bg": 2.0330384617654145e-06, "x": 0.8596491228070176, "ncat": 25}, {"cat25k": 31, "ncat25k": 28, "os": 0.5711714796452533, "cat": 10, "y": 0.8710907704042715, "term": "test", "s": 0.6039755351681957, "bg": 5.159457783036584e-07, "x": 0.8604118993135011, "ncat": 25}, {"cat25k": 22, "ncat25k": 28, "os": 0.505515233626712, "cat": 7, "y": 0.7963386727688787, "term": "multiple", "s": 0.40825688073394495, "bg": 1.1173720689386554e-06, "x": 0.8611746758199847, "ncat": 25}, {"cat25k": 22, "ncat25k": 28, "os": 0.505515233626712, "cat": 7, "y": 0.8001525553012967, "term": "recent", "s": 0.40825688073394495, "bg": 4.794770124230167e-07, "x": 0.8619374523264683, "ncat": 25}, {"cat25k": 47, "ncat25k": 29, "os": 0.6460150774913231, "cat": 15, "y": 0.9260106788710908, "term": "describe", "s": 0.8302752293577981, "bg": 3.404666086765564e-06, "x": 0.8627002288329519, "ncat": 26}, {"cat25k": 25, "ncat25k": 29, "os": 0.5220697025993389, "cat": 8, "y": 0.8222730739893211, "term": "cross", "s": 0.44648318042813456, "bg": 1.5884455287634303e-06, "x": 0.8634630053394355, "ncat": 26}, {"cat25k": 25, "ncat25k": 29, "os": 0.5220697025993389, "cat": 8, "y": 0.8253241800152555, "term": "baseline", "s": 0.44648318042813456, "bg": 8.149621037260174e-06, "x": 0.8642257818459191, "ncat": 26}, {"cat25k": 25, "ncat25k": 29, "os": 0.5220697025993389, "cat": 8, "y": 0.8260869565217391, "term": "existing", "s": 0.44648318042813456, "bg": 1.4611302154830668e-06, "x": 0.8649885583524027, "ncat": 26}, {"cat25k": 22, "ncat25k": 29, "os": 0.49902346840913836, "cat": 7, "y": 0.8016781083142639, "term": "about", "s": 0.3876146788990826, "bg": 6.684113436307585e-08, "x": 0.8657513348588863, "ncat": 26}, {"cat25k": 34, "ncat25k": 29, "os": 0.5822676338179731, "cat": 11, "y": 0.8901601830663616, "term": "types", "s": 0.620795107033639, "bg": 1.2447129843557473e-06, "x": 0.8665141113653699, "ncat": 26}, {"cat25k": 22, "ncat25k": 29, "os": 0.49902346840913836, "cat": 7, "y": 0.8077803203661327, "term": "achieves", "s": 0.3876146788990826, "bg": 3.783240356492513e-05, "x": 0.8672768878718535, "ncat": 26}, {"cat25k": 12, "ncat25k": 29, "os": 0.41794004689965325, "cat": 4, "y": 0.6209000762776506, "term": "end", "s": 0.1712538226299694, "bg": 5.885873305970392e-07, "x": 0.8680396643783371, "ncat": 26}, {"cat25k": 53, "ncat25k": 31, "os": 0.6643307966723737, "cat": 17, "y": 0.9397406559877955, "term": "corpus", "s": 0.8486238532110091, "bg": 2.5034359658631474e-05, "x": 0.8688024408848207, "ncat": 27}, {"cat25k": 50, "ncat25k": 31, "os": 0.6516285641336786, "cat": 16, "y": 0.931350114416476, "term": "study", "s": 0.8333333333333333, "bg": 6.665192874900976e-07, "x": 0.8695652173913043, "ncat": 27}, {"cat25k": 34, "ncat25k": 31, "os": 0.5747927067754147, "cat": 11, "y": 0.8832951945080092, "term": "even", "s": 0.6070336391437309, "bg": 3.173916384051793e-07, "x": 0.8703279938977879, "ncat": 27}, {"cat25k": 31, "ncat25k": 31, "os": 0.5562962203925745, "cat": 10, "y": 0.8733790999237223, "term": "non", "s": 0.558868501529052, "bg": 5.199703694375201e-07, "x": 0.8710907704042715, "ncat": 27}, {"cat25k": 41, "ncat25k": 31, "os": 0.6084443121676681, "cat": 13, "y": 0.9107551487414187, "term": "level", "s": 0.7194189602446482, "bg": 6.317271164699295e-07, "x": 0.8718535469107551, "ncat": 27}, {"cat25k": 22, "ncat25k": 31, "os": 0.4929098025614002, "cat": 7, "y": 0.7986270022883295, "term": "achieve", "s": 0.3814984709480122, "bg": 2.6288663915533646e-06, "x": 0.8726163234172387, "ncat": 27}, {"cat25k": 16, "ncat25k": 31, "os": 0.44233484824009733, "cat": 5, "y": 0.7025171624713958, "term": "through", "s": 0.22171253822629966, "bg": 2.0442207944890986e-07, "x": 0.8733790999237223, "ncat": 27}, {"cat25k": 28, "ncat25k": 31, "os": 0.5365694840492724, "cat": 9, "y": 0.8657513348588863, "term": "without", "s": 0.47477064220183485, "bg": 3.557654551469386e-07, "x": 0.8741418764302059, "ncat": 27}, {"cat25k": 22, "ncat25k": 31, "os": 0.4929098025614002, "cat": 7, "y": 0.8115942028985508, "term": "provide", "s": 0.3814984709480122, "bg": 3.975781834184541e-07, "x": 0.8749046529366895, "ncat": 27}, {"cat25k": 22, "ncat25k": 31, "os": 0.4929098025614002, "cat": 7, "y": 0.8123569794050344, "term": "find", "s": 0.3814984709480122, "bg": 1.4738143980238652e-07, "x": 0.8756674294431731, "ncat": 27}, {"cat25k": 41, "ncat25k": 31, "os": 0.6084443121676681, "cat": 13, "y": 0.9145690312738368, "term": "lexical", "s": 0.7194189602446482, "bg": 7.574421960599947e-05, "x": 0.8764302059496567, "ncat": 27}, {"cat25k": 19, "ncat25k": 32, "os": 0.46338298309355, "cat": 6, "y": 0.7459954233409611, "term": "three", "s": 0.30810397553516816, "bg": 3.221867804830847e-07, "x": 0.8771929824561403, "ncat": 28}, {"cat25k": 31, "ncat25k": 32, "os": 0.5494104304684393, "cat": 10, "y": 0.8741418764302059, "term": "specific", "s": 0.5451070336391437, "bg": 8.901973718721536e-07, "x": 0.8779557589626239, "ncat": 28}, {"cat25k": 53, "ncat25k": 32, "os": 0.6567117681119481, "cat": 17, "y": 0.9427917620137299, "term": "automatic", "s": 0.8379204892966361, "bg": 4.334678575193949e-06, "x": 0.8787185354691075, "ncat": 28}, {"cat25k": 31, "ncat25k": 32, "os": 0.5494104304684393, "cat": 10, "y": 0.8787185354691075, "term": "subtask", "s": 0.5451070336391437, "bg": 0.0007077343891965303, "x": 0.8794813119755912, "ncat": 28}, {"cat25k": 31, "ncat25k": 32, "os": 0.5494104304684393, "cat": 10, "y": 0.8810068649885584, "term": "translation", "s": 0.5451070336391437, "bg": 6.512725141289955e-06, "x": 0.8802440884820748, "ncat": 28}, {"cat25k": 22, "ncat25k": 33, "os": 0.4816968069832348, "cat": 7, "y": 0.7887109077040427, "term": "time", "s": 0.34174311926605505, "bg": 1.2544551686459653e-07, "x": 0.8810068649885584, "ncat": 29}, {"cat25k": 44, "ncat25k": 33, "os": 0.608988323083506, "cat": 14, "y": 0.9221967963386728, "term": "where", "s": 0.7209480122324158, "bg": 2.551842546677173e-07, "x": 0.881769641495042, "ncat": 29}, {"cat25k": 22, "ncat25k": 33, "os": 0.4816968069832348, "cat": 7, "y": 0.7917620137299771, "term": "input", "s": 0.34174311926605505, "bg": 1.7468118195087125e-06, "x": 0.8825324180015256, "ncat": 29}, {"cat25k": 25, "ncat25k": 33, "os": 0.5033890726387817, "cat": 8, "y": 0.8268497330282227, "term": "introduce", "s": 0.39602446483180426, "bg": 5.623060566517274e-06, "x": 0.8832951945080092, "ncat": 29}, {"cat25k": 41, "ncat25k": 33, "os": 0.593884467771275, "cat": 13, "y": 0.9115179252479023, "term": "many", "s": 0.6811926605504587, "bg": 2.7584312226127945e-07, "x": 0.8840579710144928, "ncat": 29}, {"cat25k": 16, "ncat25k": 33, "os": 0.4334585633910854, "cat": 5, "y": 0.700228832951945, "term": "embedding", "s": 0.21406727828746175, "bg": 6.263431145161906e-05, "x": 0.8848207475209764, "ncat": 29}, {"cat25k": 37, "ncat25k": 33, "os": 0.5778677363988043, "cat": 12, "y": 0.9038901601830663, "term": "question", "s": 0.6169724770642201, "bg": 1.5455236634707301e-06, "x": 0.88558352402746, "ncat": 29}, {"cat25k": 25, "ncat25k": 34, "os": 0.4978076995427668, "cat": 8, "y": 0.8230358504958047, "term": "human", "s": 0.386085626911315, "bg": 7.09708932118339e-07, "x": 0.8863463005339436, "ncat": 30}, {"cat25k": 31, "ncat25k": 34, "os": 0.536621807597374, "cat": 10, "y": 0.8718535469107551, "term": "learn", "s": 0.4755351681957186, "bg": 5.125811996871606e-07, "x": 0.8871090770404272, "ncat": 30}, {"cat25k": 44, "ncat25k": 34, "os": 0.6020499918415865, "cat": 14, "y": 0.9229595728451564, "term": "supervised", "s": 0.7087155963302753, "bg": 3.628283596654972e-05, "x": 0.8878718535469108, "ncat": 30}, {"cat25k": 59, "ncat25k": 34, "os": 0.6655588240793407, "cat": 19, "y": 0.9488939740655988, "term": "'s", "s": 0.8600917431192661, "bg": 0.0, "x": 0.8886346300533944, "ncat": 30}, {"cat25k": 50, "ncat25k": 34, "os": 0.6296031744104607, "cat": 16, "y": 0.9374523264683448, "term": "accuracy", "s": 0.746177370030581, "bg": 3.717283553814996e-06, "x": 0.889397406559878, "ncat": 30}, {"cat25k": 28, "ncat25k": 34, "os": 0.5177888117307387, "cat": 9, "y": 0.8611746758199847, "term": "vector", "s": 0.441131498470948, "bg": 8.886154901324568e-06, "x": 0.8901601830663616, "ncat": 30}, {"cat25k": 37, "ncat25k": 34, "os": 0.571193809192528, "cat": 12, "y": 0.9054157131960335, "term": "automatically", "s": 0.6047400611620795, "bg": 2.834353601427471e-06, "x": 0.8909229595728452, "ncat": 30}, {"cat25k": 34, "ncat25k": 34, "os": 0.5544003724542579, "cat": 11, "y": 0.8924485125858124, "term": "processing", "s": 0.5527522935779816, "bg": 1.8364366862796303e-06, "x": 0.8916857360793288, "ncat": 30}, {"cat25k": 19, "ncat25k": 34, "os": 0.45381838575521466, "cat": 6, "y": 0.7772692601067888, "term": "syntactic", "s": 0.29892966360856266, "bg": 8.277020959603452e-05, "x": 0.8924485125858124, "ncat": 30}, {"cat25k": 34, "ncat25k": 34, "os": 0.5544003724542579, "cat": 11, "y": 0.897025171624714, "term": "high", "s": 0.5527522935779816, "bg": 2.778834064387166e-07, "x": 0.893211289092296, "ncat": 30}, {"cat25k": 9, "ncat25k": 34, "os": 0.37465184815244795, "cat": 3, "y": 0.5507246376811594, "term": "parsing", "s": 0.10321100917431192, "bg": 4.847238909356988e-05, "x": 0.8939740655987796, "ncat": 30}, {"cat25k": 44, "ncat25k": 35, "os": 0.5953853285365582, "cat": 14, "y": 0.9153318077803204, "term": "then", "s": 0.6819571865443425, "bg": 2.432534914470937e-07, "x": 0.8947368421052632, "ncat": 31}, {"cat25k": 34, "ncat25k": 35, "os": 0.548211434616135, "cat": 11, "y": 0.8848207475209764, "term": "available", "s": 0.5420489296636085, "bg": 2.317619740686426e-07, "x": 0.8954996186117468, "ncat": 31}, {"cat25k": 41, "ncat25k": 35, "os": 0.5805159644463591, "cat": 13, "y": 0.9084668192219679, "term": "detection", "s": 0.6192660550458715, "bg": 8.855997059808977e-06, "x": 0.8962623951182304, "ncat": 31}, {"cat25k": 22, "ncat25k": 35, "os": 0.47166525416304556, "cat": 7, "y": 0.7879481311975591, "term": "context", "s": 0.32492354740061163, "bg": 3.0523905670595807e-06, "x": 0.897025171624714, "ncat": 31}, {"cat25k": 25, "ncat25k": 35, "os": 0.49251010732719597, "cat": 8, "y": 0.8276125095347063, "term": "them", "s": 0.3792048929663609, "bg": 2.2329409895573737e-07, "x": 0.8977879481311976, "ncat": 31}, {"cat25k": 28, "ncat25k": 35, "os": 0.5121383101276821, "cat": 9, "y": 0.8604118993135011, "term": "across", "s": 0.43119266055045874, "bg": 1.1480364122187029e-06, "x": 0.8985507246376812, "ncat": 31}, {"cat25k": 31, "ncat25k": 35, "os": 0.5306763252340955, "cat": 10, "y": 0.8794813119755912, "term": "semeval", "s": 0.4625382262996942, "bg": 0.001730540433356167, "x": 0.8993135011441648, "ncat": 31}, {"cat25k": 22, "ncat25k": 35, "os": 0.47166525416304556, "cat": 7, "y": 0.8138825324180016, "term": "sentences", "s": 0.32492354740061163, "bg": 2.0765161596217973e-05, "x": 0.9000762776506483, "ncat": 31}, {"cat25k": 31, "ncat25k": 36, "os": 0.5250044018992895, "cat": 10, "y": 0.8688024408848207, "term": "demonstrate", "s": 0.4571865443425076, "bg": 5.920905715564669e-06, "x": 0.900839054157132, "ncat": 32}, {"cat25k": 37, "ncat25k": 36, "os": 0.5586914117056688, "cat": 12, "y": 0.9000762776506483, "term": "problem", "s": 0.5642201834862385, "bg": 7.372357100361783e-07, "x": 0.9016018306636155, "ncat": 32}, {"cat25k": 47, "ncat25k": 36, "os": 0.6029590198286711, "cat": 15, "y": 0.9282990083905416, "term": "sentence", "s": 0.709480122324159, "bg": 1.0544298052898246e-05, "x": 0.9023646071700991, "ncat": 32}, {"cat25k": 25, "ncat25k": 36, "os": 0.48747606244302166, "cat": 8, "y": 0.8291380625476735, "term": "simple", "s": 0.3669724770642202, "bg": 1.1438790036538414e-06, "x": 0.9031273836765827, "ncat": 32}, {"cat25k": 34, "ncat25k": 36, "os": 0.5422959480625898, "cat": 11, "y": 0.8947368421052632, "term": "how", "s": 0.4801223241590214, "bg": 1.853459352226203e-07, "x": 0.9038901601830663, "ncat": 32}, {"cat25k": 66, "ncat25k": 37, "os": 0.666558026186178, "cat": 21, "y": 0.9534706331045004, "term": "linguistic", "s": 0.8608562691131498, "bg": 3.638552605176912e-05, "x": 0.9046529366895499, "ncat": 33}, {"cat25k": 44, "ncat25k": 37, "os": 0.5828218725433858, "cat": 14, "y": 0.9206712433257056, "term": "knowledge", "s": 0.6215596330275229, "bg": 2.137968901260256e-06, "x": 0.9054157131960335, "ncat": 33}, {"cat25k": 34, "ncat25k": 37, "os": 0.5366374204435478, "cat": 11, "y": 0.8878718535469108, "term": "several", "s": 0.47629969418960244, "bg": 8.918198548418267e-07, "x": 0.9061784897025171, "ncat": 33}, {"cat25k": 41, "ncat25k": 37, "os": 0.5682125385157284, "cat": 13, "y": 0.9099923722349351, "term": "domain", "s": 0.5894495412844036, "bg": 1.6789012625802596e-06, "x": 0.9069412662090007, "ncat": 33}, {"cat25k": 28, "ncat25k": 37, "os": 0.5016307282307393, "cat": 9, "y": 0.8573607932875668, "term": "score", "s": 0.3906727828746177, "bg": 1.6145194658143237e-06, "x": 0.9077040427154843, "ncat": 33}, {"cat25k": 37, "ncat25k": 38, "os": 0.5472112512190996, "cat": 12, "y": 0.9031273836765827, "term": "all", "s": 0.540519877675841, "bg": 4.8454515466729044e-08, "x": 0.9084668192219679, "ncat": 34}, {"cat25k": 34, "ncat25k": 38, "os": 0.5312205465486979, "cat": 11, "y": 0.8939740655987796, "term": "sentiment", "s": 0.463302752293578, "bg": 9.143122463777335e-05, "x": 0.9092295957284515, "ncat": 34}, {"cat25k": 22, "ncat25k": 38, "os": 0.45846585403981815, "cat": 7, "y": 0.813119755911518, "term": "framework", "s": 0.3065749235474006, "bg": 3.3253974365681206e-06, "x": 0.9099923722349351, "ncat": 34}, {"cat25k": 34, "ncat25k": 38, "os": 0.5312205465486979, "cat": 11, "y": 0.8962623951182304, "term": "languages", "s": 0.463302752293578, "bg": 3.686733056001956e-06, "x": 0.9107551487414187, "ncat": 34}, {"cat25k": 50, "ncat25k": 40, "os": 0.5978534595056875, "cat": 16, "y": 0.9321128909229596, "term": "its", "s": 0.6865443425076452, "bg": 2.2446977680144498e-07, "x": 0.9115179252479023, "ncat": 35}, {"cat25k": 34, "ncat25k": 40, "os": 0.5260311169956631, "cat": 11, "y": 0.8840579710144928, "term": "only", "s": 0.4587155963302752, "bg": 1.5410192329307544e-07, "x": 0.9122807017543859, "ncat": 35}, {"cat25k": 53, "ncat25k": 40, "os": 0.6102422936424358, "cat": 17, "y": 0.9412662090007627, "term": "similarity", "s": 0.7217125382262997, "bg": 4.666502936779144e-05, "x": 0.9130434782608695, "ncat": 35}, {"cat25k": 41, "ncat25k": 40, "os": 0.5568626930870272, "cat": 13, "y": 0.9092295957284515, "term": "previous", "s": 0.5596330275229358, "bg": 5.25407525779777e-07, "x": 0.9138062547673532, "ncat": 35}, {"cat25k": 19, "ncat25k": 40, "os": 0.43404881380532234, "cat": 6, "y": 0.7551487414187643, "term": "uses", "s": 0.21483180428134555, "bg": 1.5027424513042572e-06, "x": 0.9145690312738368, "ncat": 35}, {"cat25k": 16, "ncat25k": 40, "os": 0.4122594995800138, "cat": 5, "y": 0.7017543859649122, "term": "when", "s": 0.16437308868501527, "bg": 1.4139127322303636e-07, "x": 0.9153318077803204, "ncat": 35}, {"cat25k": 28, "ncat25k": 41, "os": 0.48760359387939906, "cat": 9, "y": 0.8482074752097636, "term": "deep", "s": 0.367737003058104, "bg": 2.7288235860222103e-06, "x": 0.916094584286804, "ncat": 36}, {"cat25k": 25, "ncat25k": 41, "os": 0.4696297923015471, "cat": 8, "y": 0.8299008390541571, "term": "representation", "s": 0.32339449541284404, "bg": 6.9497670304442035e-06, "x": 0.9168573607932876, "ncat": 36}, {"cat25k": 50, "ncat25k": 42, "os": 0.5866427764509813, "cat": 16, "y": 0.9344012204424104, "term": "proposed", "s": 0.6674311926605504, "bg": 2.538816402673008e-06, "x": 0.9176201372997712, "ncat": 37}, {"cat25k": 37, "ncat25k": 42, "os": 0.5316670978849662, "cat": 12, "y": 0.8993135011441648, "term": "networks", "s": 0.4648318042813455, "bg": 2.3556815423484633e-06, "x": 0.9183829138062548, "ncat": 37}, {"cat25k": 28, "ncat25k": 42, "os": 0.4833329704433897, "cat": 9, "y": 0.858886346300534, "term": "extraction", "s": 0.3440366972477064, "bg": 2.747978518302474e-05, "x": 0.9191456903127384, "ncat": 37}, {"cat25k": 47, "ncat25k": 42, "os": 0.5738292707556865, "cat": 15, "y": 0.9298245614035088, "term": "research", "s": 0.6062691131498471, "bg": 4.2362835413124977e-07, "x": 0.919908466819222, "ncat": 37}, {"cat25k": 9, "ncat25k": 42, "os": 0.360181814681929, "cat": 3, "y": 0.5003813882532419, "term": "evaluate", "s": 0.09174311926605504, "bg": 5.245795822510497e-06, "x": 0.9206712433257056, "ncat": 37}, {"cat25k": 34, "ncat25k": 42, "os": 0.516282727886169, "cat": 11, "y": 0.8954996186117468, "term": "natural", "s": 0.43654434250764523, "bg": 1.2933010382116728e-06, "x": 0.9214340198321892, "ncat": 37}, {"cat25k": 47, "ncat25k": 44, "os": 0.5635642017091728, "cat": 15, "y": 0.927536231884058, "term": "while", "s": 0.5802752293577982, "bg": 5.392253801116831e-07, "x": 0.9221967963386728, "ncat": 39}, {"cat25k": 50, "ncat25k": 44, "os": 0.5761727220894393, "cat": 16, "y": 0.9366895499618612, "term": "experiments", "s": 0.6146788990825688, "bg": 8.002318635450448e-06, "x": 0.9229595728451564, "ncat": 39}, {"cat25k": 22, "ncat25k": 44, "os": 0.4403419888722732, "cat": 7, "y": 0.8039664378337147, "term": "2017", "s": 0.2209480122324159, "bg": 0.0, "x": 0.92372234935164, "ncat": 39}, {"cat25k": 47, "ncat25k": 45, "os": 0.5586926804484746, "cat": 15, "y": 0.92372234935164, "term": "than", "s": 0.5649847094801224, "bg": 2.3872769549485086e-07, "x": 0.9244851258581236, "ncat": 40}, {"cat25k": 53, "ncat25k": 45, "os": 0.583177588017859, "cat": 17, "y": 0.9405034324942791, "term": "well", "s": 0.6230886850152905, "bg": 3.4241067436779935e-07, "x": 0.9252479023646072, "ncat": 40}, {"cat25k": 44, "ncat25k": 45, "os": 0.5456491427949544, "cat": 14, "y": 0.919908466819222, "term": "other", "s": 0.5305810397553518, "bg": 1.2876367957739616e-07, "x": 0.9260106788710908, "ncat": 40}, {"cat25k": 25, "ncat25k": 45, "os": 0.4547794352463083, "cat": 8, "y": 0.8306636155606407, "term": "trained", "s": 0.30351681957186544, "bg": 9.22158750214347e-06, "x": 0.9267734553775744, "ncat": 40}, {"cat25k": 37, "ncat25k": 46, "os": 0.5135908153900494, "cat": 12, "y": 0.8977879481311976, "term": "each", "s": 0.43348623853211005, "bg": 3.695574471845582e-07, "x": 0.927536231884058, "ncat": 41}, {"cat25k": 56, "ncat25k": 46, "os": 0.5896796650637876, "cat": 18, "y": 0.9450800915331807, "term": "classification", "s": 0.6735474006116208, "bg": 9.506581406307586e-06, "x": 0.9282990083905416, "ncat": 41}, {"cat25k": 37, "ncat25k": 48, "os": 0.5094805852272289, "cat": 12, "y": 0.900839054157132, "term": "describes", "s": 0.41131498470948014, "bg": 6.7644490322441e-06, "x": 0.9290617848970252, "ncat": 42}, {"cat25k": 50, "ncat25k": 49, "os": 0.557204198246452, "cat": 16, "y": 0.9328756674294432, "term": "approaches", "s": 0.5626911314984709, "bg": 8.876094854621246e-06, "x": 0.9298245614035088, "ncat": 43}, {"cat25k": 50, "ncat25k": 49, "os": 0.557204198246452, "cat": 16, "y": 0.9382151029748284, "term": "large", "s": 0.5626911314984709, "bg": 8.678920044129174e-07, "x": 0.9305873379099924, "ncat": 43}, {"cat25k": 53, "ncat25k": 50, "os": 0.5644414334392637, "cat": 17, "y": 0.9435545385202135, "term": "evaluation", "s": 0.5833333333333334, "bg": 3.4479024493899002e-06, "x": 0.931350114416476, "ncat": 44}, {"cat25k": 37, "ncat25k": 50, "os": 0.5016936855470018, "cat": 12, "y": 0.9046529366895499, "term": "representations", "s": 0.3937308868501529, "bg": 2.818180019343508e-05, "x": 0.9321128909229596, "ncat": 44}, {"cat25k": 41, "ncat25k": 50, "os": 0.5152133283994696, "cat": 13, "y": 0.9122807017543859, "term": "best", "s": 0.43425076452599387, "bg": 3.603039277637303e-07, "x": 0.9328756674294432, "ncat": 44}, {"cat25k": 50, "ncat25k": 51, "os": 0.5485955645559286, "cat": 16, "y": 0.9336384439359268, "term": "set", "s": 0.5435779816513762, "bg": 4.4653524009707074e-07, "x": 0.9336384439359268, "ncat": 45}, {"cat25k": 50, "ncat25k": 51, "os": 0.5485955645559286, "cat": 16, "y": 0.9359267734553776, "term": "however", "s": 0.5435779816513762, "bg": 7.560391799989297e-07, "x": 0.9344012204424104, "ncat": 45}, {"cat25k": 41, "ncat25k": 51, "os": 0.5113597446970347, "cat": 13, "y": 0.9138062547673532, "term": "one", "s": 0.4136085626911315, "bg": 1.3285129475608774e-07, "x": 0.935163996948894, "ncat": 45}, {"cat25k": 62, "ncat25k": 52, "os": 0.5877294026340918, "cat": 20, "y": 0.9511823035850496, "term": "been", "s": 0.6697247706422018, "bg": 2.573577887548912e-07, "x": 0.9359267734553776, "ncat": 46}, {"cat25k": 87, "ncat25k": 53, "os": 0.6527402016757692, "cat": 28, "y": 0.9679633867276888, "term": "features", "s": 0.8363914373088684, "bg": 1.7762137491154098e-06, "x": 0.9366895499618612, "ncat": 47}, {"cat25k": 37, "ncat25k": 53, "os": 0.49099333424421565, "cat": 12, "y": 0.9023646071700991, "term": "tasks", "s": 0.3746177370030581, "bg": 7.575431125655939e-06, "x": 0.9374523264683448, "ncat": 47}, {"cat25k": 44, "ncat25k": 55, "os": 0.5094816095607309, "cat": 14, "y": 0.9214340198321892, "term": "machine", "s": 0.4120795107033639, "bg": 2.8972417899590063e-06, "x": 0.9382151029748284, "ncat": 49}, {"cat25k": 34, "ncat25k": 55, "os": 0.4712878405299666, "cat": 11, "y": 0.889397406559878, "term": "english", "s": 0.32415902140672787, "bg": 1.148311566459306e-06, "x": 0.938977879481312, "ncat": 49}, {"cat25k": 78, "ncat25k": 55, "os": 0.6203938546108891, "cat": 25, "y": 0.9626239511823036, "term": "their", "s": 0.7392966360856269, "bg": 2.42685915280452e-07, "x": 0.9397406559877955, "ncat": 49}, {"cat25k": 62, "ncat25k": 57, "os": 0.5711951423459435, "cat": 20, "y": 0.950419527078566, "term": "first", "s": 0.6055045871559633, "bg": 2.697948820592279e-07, "x": 0.9405034324942791, "ncat": 50}, {"cat25k": 41, "ncat25k": 57, "os": 0.49390116121498984, "cat": 13, "y": 0.9061784897025171, "term": "but", "s": 0.3853211009174312, "bg": 1.3400601057159218e-07, "x": 0.9412662090007627, "ncat": 50}, {"cat25k": 47, "ncat25k": 57, "os": 0.5178569805426043, "cat": 15, "y": 0.9290617848970252, "term": "into", "s": 0.44189602446483184, "bg": 3.2332609723540205e-07, "x": 0.9420289855072463, "ncat": 50}, {"cat25k": 59, "ncat25k": 57, "os": 0.5612357918891397, "cat": 19, "y": 0.9496567505720824, "term": "novel", "s": 0.5695718654434251, "bg": 7.130876682321226e-06, "x": 0.9427917620137299, "ncat": 50}, {"cat25k": 25, "ncat25k": 57, "os": 0.42674741955480633, "cat": 8, "y": 0.8360030511060259, "term": "over", "s": 0.21024464831804282, "bg": 3.5272726390711176e-07, "x": 0.9435545385202135, "ncat": 50}, {"cat25k": 56, "ncat25k": 59, "os": 0.5435931440636282, "cat": 18, "y": 0.9443173150266971, "term": "methods", "s": 0.5114678899082569, "bg": 2.205718219883979e-06, "x": 0.9443173150266971, "ncat": 52}, {"cat25k": 72, "ncat25k": 59, "os": 0.5911796104222532, "cat": 23, "y": 0.9565217391304348, "term": "work", "s": 0.6743119266055047, "bg": 4.290418791210545e-07, "x": 0.9450800915331807, "ncat": 52}, {"cat25k": 37, "ncat25k": 60, "os": 0.4725499206691062, "cat": 12, "y": 0.8985507246376812, "term": "datasets", "s": 0.3264525993883792, "bg": 8.487007544006705e-05, "x": 0.9458428680396643, "ncat": 53}, {"cat25k": 84, "ncat25k": 61, "os": 0.6162151281553889, "cat": 27, "y": 0.9649122807017544, "term": "between", "s": 0.7377675840978594, "bg": 7.749746652758193e-07, "x": 0.9466056445461479, "ncat": 54}, {"cat25k": 59, "ncat25k": 61, "os": 0.5466343828689305, "cat": 19, "y": 0.9481311975591151, "term": "method", "s": 0.5397553516819572, "bg": 2.4154861649004098e-06, "x": 0.9473684210526315, "ncat": 54}, {"cat25k": 44, "ncat25k": 62, "os": 0.49051165884288944, "cat": 14, "y": 0.9176201372997712, "term": "different", "s": 0.3738532110091743, "bg": 1.0119558637562898e-06, "x": 0.9481311975591151, "ncat": 55}, {"cat25k": 59, "ncat25k": 63, "os": 0.5398883383704067, "cat": 19, "y": 0.9473684210526315, "term": "words", "s": 0.4785932721712538, "bg": 2.4844534227754154e-06, "x": 0.9488939740655988, "ncat": 56}, {"cat25k": 84, "ncat25k": 65, "os": 0.6050991009732849, "cat": 27, "y": 0.9641495041952708, "term": "more", "s": 0.713302752293578, "bg": 1.2299110265403577e-07, "x": 0.9496567505720824, "ncat": 57}, {"cat25k": 97, "ncat25k": 65, "os": 0.633677037152898, "cat": 31, "y": 0.9740655987795576, "term": "has", "s": 0.7645259938837919, "bg": 1.8922461228973585e-07, "x": 0.950419527078566, "ncat": 57}, {"cat25k": 62, "ncat25k": 65, "os": 0.5461162411203945, "cat": 20, "y": 0.9519450800915332, "term": "network", "s": 0.5389908256880733, "bg": 1.0120984337994252e-06, "x": 0.9511823035850496, "ncat": 57}, {"cat25k": 94, "ncat25k": 68, "os": 0.6162151281553889, "cat": 30, "y": 0.9710144927536232, "term": "used", "s": 0.7377675840978594, "bg": 4.6975795109461006e-07, "x": 0.9519450800915332, "ncat": 60}, {"cat25k": 50, "ncat25k": 68, "os": 0.4980037419419876, "cat": 16, "y": 0.935163996948894, "term": "training", "s": 0.3868501529051988, "bg": 1.3281516725598478e-06, "x": 0.9527078565980168, "ncat": 60}, {"cat25k": 81, "ncat25k": 69, "os": 0.5837538451230795, "cat": 26, "y": 0.9633867276887872, "term": "or", "s": 0.6636085626911314, "bg": 8.414404181277697e-08, "x": 0.9534706331045004, "ncat": 61}, {"cat25k": 72, "ncat25k": 69, "os": 0.5597375510611594, "cat": 23, "y": 0.958047292143402, "term": "information", "s": 0.5688073394495413, "bg": 2.508979977085293e-07, "x": 0.954233409610984, "ncat": 61}, {"cat25k": 87, "ncat25k": 70, "os": 0.5953853781196474, "cat": 28, "y": 0.9672006102212052, "term": "analysis", "s": 0.6827217125382262, "bg": 1.90392254843073e-06, "x": 0.9549961861174676, "ncat": 62}, {"cat25k": 47, "ncat25k": 70, "os": 0.4825602286416983, "cat": 15, "y": 0.9244851258581236, "term": "also", "s": 0.34327217125382264, "bg": 2.788200866931405e-07, "x": 0.9557589626239512, "ncat": 62}, {"cat25k": 28, "ncat25k": 71, "os": 0.41431231832663, "cat": 9, "y": 0.851258581235698, "term": "embeddings", "s": 0.16513761467889906, "bg": 0.0016964627573410303, "x": 0.9565217391304348, "ncat": 63}, {"cat25k": 69, "ncat25k": 72, "os": 0.5423013335755663, "cat": 22, "y": 0.9557589626239512, "term": "systems", "s": 0.4808868501529052, "bg": 1.171675127651769e-06, "x": 0.9572845156369184, "ncat": 64}, {"cat25k": 75, "ncat25k": 74, "os": 0.5557314311720007, "cat": 24, "y": 0.9588100686498856, "term": "propose", "s": 0.5581039755351681, "bg": 2.8986009524424652e-05, "x": 0.958047292143402, "ncat": 65}, {"cat25k": 44, "ncat25k": 74, "os": 0.4652862131578007, "cat": 14, "y": 0.9191456903127384, "term": "not", "s": 0.31574923547400613, "bg": 7.670276333643211e-08, "x": 0.9588100686498856, "ncat": 65}, {"cat25k": 84, "ncat25k": 74, "os": 0.5786291481776861, "cat": 27, "y": 0.9664378337147216, "term": "both", "s": 0.617737003058104, "bg": 8.65747616397865e-07, "x": 0.9595728451563692, "ncat": 65}, {"cat25k": 75, "ncat25k": 75, "os": 0.5528321493694616, "cat": 24, "y": 0.9595728451563692, "term": "have", "s": 0.5512232415902141, "bg": 1.3808461314180261e-07, "x": 0.9603356216628528, "ncat": 66}, {"cat25k": 53, "ncat25k": 75, "os": 0.49239853553262813, "cat": 17, "y": 0.9420289855072463, "term": "dataset", "s": 0.37844036697247707, "bg": 7.691765324239957e-05, "x": 0.9610983981693364, "ncat": 66}, {"cat25k": 69, "ncat25k": 76, "os": 0.5339049095601778, "cat": 22, "y": 0.954233409610984, "term": "use", "s": 0.4701834862385321, "bg": 3.027627271062103e-07, "x": 0.96186117467582, "ncat": 67}, {"cat25k": 50, "ncat25k": 77, "os": 0.4783073178053671, "cat": 16, "y": 0.9305873379099924, "term": "new", "s": 0.3379204892966361, "bg": 1.2892295061607216e-07, "x": 0.9626239511823036, "ncat": 68}, {"cat25k": 72, "ncat25k": 78, "os": 0.5366426941532444, "cat": 23, "y": 0.9572845156369184, "term": "these", "s": 0.4770642201834862, "bg": 4.066096107378708e-07, "x": 0.9633867276887872, "ncat": 69}, {"cat25k": 84, "ncat25k": 79, "os": 0.5641159109187717, "cat": 27, "y": 0.965675057208238, "term": "such", "s": 0.5825688073394495, "bg": 6.302828238176882e-07, "x": 0.9641495041952708, "ncat": 70}, {"cat25k": 94, "ncat25k": 79, "os": 0.584848148386538, "cat": 30, "y": 0.9725400457665904, "term": "text", "s": 0.6659021406727829, "bg": 1.6568050136681866e-06, "x": 0.9649122807017544, "ncat": 70}, {"cat25k": 69, "ncat25k": 84, "os": 0.5162876091169691, "cat": 22, "y": 0.9549961861174676, "term": "semeval-2017", "s": 0.43730886850152906, "bg": 0.0, "x": 0.965675057208238, "ncat": 74}, {"cat25k": 75, "ncat25k": 85, "os": 0.529253716437273, "cat": 24, "y": 0.9610983981693364, "term": "two", "s": 0.4602446483180428, "bg": 5.617799502996449e-07, "x": 0.9664378337147216, "ncat": 75}, {"cat25k": 94, "ncat25k": 88, "os": 0.5635642085150332, "cat": 30, "y": 0.9702517162471396, "term": "be", "s": 0.581039755351682, "bg": 1.1422474399978515e-07, "x": 0.9672006102212052, "ncat": 78}, {"cat25k": 94, "ncat25k": 88, "os": 0.5635642085150332, "cat": 30, "y": 0.9717772692601068, "term": "it", "s": 0.581039755351682, "bg": 9.384266189726788e-08, "x": 0.9679633867276888, "ncat": 78}, {"cat25k": 56, "ncat25k": 88, "os": 0.47538385226944513, "cat": 18, "y": 0.9458428680396643, "term": "art", "s": 0.3279816513761468, "bg": 1.0057821765433622e-06, "x": 0.9687261632341724, "ncat": 78}, {"cat25k": 128, "ncat25k": 94, "os": 0.6137140785443125, "cat": 41, "y": 0.9809305873379099, "term": "present", "s": 0.7285932721712538, "bg": 2.714214204076036e-06, "x": 0.969488939740656, "ncat": 83}, {"cat25k": 112, "ncat25k": 95, "os": 0.584848148386538, "cat": 36, "y": 0.9748283752860412, "term": "semantic", "s": 0.6659021406727829, "bg": 0.00011231354499201004, "x": 0.9702517162471396, "ncat": 84}, {"cat25k": 56, "ncat25k": 96, "os": 0.4628747173671864, "cat": 18, "y": 0.9466056445461479, "term": "performance", "s": 0.3073394495412844, "bg": 1.8316308539190394e-06, "x": 0.9710144927536232, "ncat": 85}, {"cat25k": 125, "ncat25k": 97, "os": 0.6013714976383022, "cat": 40, "y": 0.9801678108314263, "term": "show", "s": 0.7079510703363914, "bg": 1.122789780743833e-06, "x": 0.9717772692601068, "ncat": 86}, {"cat25k": 62, "ncat25k": 97, "os": 0.47654215351491847, "cat": 20, "y": 0.9527078565980168, "term": "state", "s": 0.33562691131498473, "bg": 5.472684559186612e-07, "x": 0.9725400457665904, "ncat": 86}, {"cat25k": 116, "ncat25k": 102, "os": 0.5765836164743442, "cat": 37, "y": 0.9763539282990084, "term": "models", "s": 0.6154434250764526, "bg": 4.6404883788491944e-06, "x": 0.973302822273074, "ncat": 90}, {"cat25k": 119, "ncat25k": 104, "os": 0.5775103942194532, "cat": 38, "y": 0.977116704805492, "term": "can", "s": 0.6162079510703363, "bg": 2.736684811973595e-07, "x": 0.9740655987795576, "ncat": 92}, {"cat25k": 119, "ncat25k": 105, "os": 0.5753757468612561, "cat": 38, "y": 0.9778794813119756, "term": "data", "s": 0.6108562691131498, "bg": 1.0222035335895419e-06, "x": 0.9748283752860412, "ncat": 93}, {"cat25k": 116, "ncat25k": 106, "os": 0.5680533012823447, "cat": 37, "y": 0.9755911517925248, "term": "learning", "s": 0.5886850152905199, "bg": 3.567530952854136e-06, "x": 0.9755911517925248, "ncat": 94}, {"cat25k": 137, "ncat25k": 110, "os": 0.5962786003493427, "cat": 44, "y": 0.9824561403508771, "term": "language", "s": 0.6834862385321101, "bg": 3.795814589063272e-06, "x": 0.9763539282990084, "ncat": 97}, {"cat25k": 78, "ncat25k": 114, "os": 0.4861045598678073, "cat": 25, "y": 0.96186117467582, "term": "system", "s": 0.3478593272171254, "bg": 1.1938623957376232e-06, "x": 0.977116704805492, "ncat": 101}, {"cat25k": 91, "ncat25k": 115, "os": 0.5086498507674857, "cat": 29, "y": 0.969488939740656, "term": "neural", "s": 0.41055045871559637, "bg": 9.04953517361739e-05, "x": 0.9778794813119756, "ncat": 102}, {"cat25k": 97, "ncat25k": 118, "os": 0.516741035942624, "cat": 31, "y": 0.973302822273074, "term": "approach", "s": 0.44036697247706424, "bg": 5.948861839459093e-06, "x": 0.9786422578184591, "ncat": 104}, {"cat25k": 122, "ncat25k": 118, "os": 0.5586926871371821, "cat": 39, "y": 0.9794050343249427, "term": "at", "s": 0.5657492354740061, "bg": 1.6106826947209616e-07, "x": 0.9794050343249427, "ncat": 104}, {"cat25k": 75, "ncat25k": 119, "os": 0.47395629193069433, "cat": 24, "y": 0.9603356216628528, "term": "results", "s": 0.327217125382263, "bg": 1.1184163623955926e-06, "x": 0.9801678108314263, "ncat": 105}, {"cat25k": 91, "ncat25k": 121, "os": 0.5006635447600053, "cat": 29, "y": 0.9687261632341724, "term": "word", "s": 0.389908256880734, "bg": 6.442001199569499e-06, "x": 0.9809305873379099, "ncat": 107}, {"cat25k": 119, "ncat25k": 121, "os": 0.5483762298406019, "cat": 38, "y": 0.9786422578184591, "term": "using", "s": 0.5428134556574924, "bg": 1.4916262606324427e-06, "x": 0.9816933638443935, "ncat": 107}, {"cat25k": 128, "ncat25k": 131, "os": 0.54748122414169, "cat": 41, "y": 0.9816933638443935, "term": "model", "s": 0.5412844036697247, "bg": 3.832285423409403e-06, "x": 0.9824561403508771, "ncat": 116}, {"cat25k": 147, "ncat25k": 147, "os": 0.5517378234626132, "cat": 47, "y": 0.9832189168573608, "term": "which", "s": 0.5489296636085628, "bg": 5.798390605118884e-07, "x": 0.9832189168573608, "ncat": 130}, {"cat25k": 159, "ncat25k": 149, "os": 0.5644414335488402, "cat": 51, "y": 0.9855072463768116, "term": "are", "s": 0.5840978593272171, "bg": 2.230883431723098e-07, "x": 0.9839816933638444, "ncat": 132}, {"cat25k": 194, "ncat25k": 158, "os": 0.591429804437989, "cat": 62, "y": 0.9900839054157132, "term": "an", "s": 0.6750764525993884, "bg": 3.8463504143173406e-07, "x": 0.984744469870328, "ncat": 140}, {"cat25k": 156, "ncat25k": 162, "os": 0.54546282225191, "cat": 50, "y": 0.9839816933638444, "term": "based", "s": 0.5275229357798166, "bg": 2.3449173279194895e-06, "x": 0.9855072463768116, "ncat": 143}, {"cat25k": 190, "ncat25k": 165, "os": 0.5797826266690849, "cat": 61, "y": 0.9893211289092296, "term": "from", "s": 0.6185015290519877, "bg": 2.7069176057213584e-07, "x": 0.9862700228832952, "ncat": 146}, {"cat25k": 159, "ncat25k": 169, "os": 0.5415097986990348, "cat": 51, "y": 0.984744469870328, "term": "by", "s": 0.4793577981651376, "bg": 1.7850188937802349e-07, "x": 0.9870327993897788, "ncat": 149}, {"cat25k": 190, "ncat25k": 173, "os": 0.5705544869493482, "cat": 61, "y": 0.988558352402746, "term": "as", "s": 0.6032110091743119, "bg": 3.0611960998172575e-07, "x": 0.9877955758962624, "ncat": 153}, {"cat25k": 181, "ncat25k": 179, "os": 0.5546245055002107, "cat": 58, "y": 0.9870327993897788, "term": "paper", "s": 0.5550458715596329, "bg": 3.3038242321062453e-06, "x": 0.988558352402746, "ncat": 158}, {"cat25k": 165, "ncat25k": 180, "os": 0.5366426941532445, "cat": 53, "y": 0.9862700228832952, "term": "task", "s": 0.47782874617737003, "bg": 2.1710474526794385e-05, "x": 0.9893211289092296, "ncat": 159}, {"cat25k": 184, "ncat25k": 213, "os": 0.5257781413155037, "cat": 59, "y": 0.9877955758962624, "term": "our", "s": 0.45795107033639143, "bg": 8.349904447908498e-07, "x": 0.9900839054157132, "ncat": 188}, {"cat25k": 244, "ncat25k": 232, "os": 0.5614827471903708, "cat": 78, "y": 0.9908466819221968, "term": "with", "s": 0.5726299694189603, "bg": 2.8525054668400786e-07, "x": 0.9908466819221968, "ncat": 205}, {"cat25k": 244, "ncat25k": 232, "os": 0.5614827471903708, "cat": 78, "y": 0.9916094584286804, "term": "is", "s": 0.5726299694189603, "bg": 1.9762847080308172e-07, "x": 0.9916094584286804, "ncat": 205}, {"cat25k": 259, "ncat25k": 259, "os": 0.5522113928456085, "cat": 83, "y": 0.992372234935164, "term": "that", "s": 0.5504587155963303, "bg": 3.5410857240175826e-07, "x": 0.992372234935164, "ncat": 229}, {"cat25k": 275, "ncat25k": 272, "os": 0.5544060010684418, "cat": 88, "y": 0.9931350114416476, "term": "on", "s": 0.5542813455657492, "bg": 3.444893056709285e-07, "x": 0.9931350114416476, "ncat": 240}, {"cat25k": 281, "ncat25k": 276, "os": 0.5555362375777458, "cat": 90, "y": 0.9938977879481312, "term": "this", "s": 0.5573394495412843, "bg": 3.122168114343284e-07, "x": 0.9938977879481312, "ncat": 244}, {"cat25k": 347, "ncat25k": 324, "os": 0.5653160592979745, "cat": 111, "y": 0.996186117467582, "term": "we", "s": 0.5863914373088686, "bg": 1.3805815331265596e-06, "x": 0.9946605644546148, "ncat": 286}, {"cat25k": 331, "ncat25k": 326, "os": 0.5551246565616121, "cat": 106, "y": 0.9954233409610984, "term": "for", "s": 0.5565749235474006, "bg": 3.1011002213982475e-07, "x": 0.9954233409610984, "ncat": 288}, {"cat25k": 362, "ncat25k": 337, "os": 0.565889902967148, "cat": 116, "y": 0.9969488939740656, "term": "in", "s": 0.5871559633027523, "bg": 2.828987383819644e-07, "x": 0.996186117467582, "ncat": 298}, {"cat25k": 331, "ncat25k": 343, "os": 0.5455612450247477, "cat": 106, "y": 0.9946605644546148, "term": "to", "s": 0.5282874617737003, "bg": 2.1669208639649367e-07, "x": 0.9969488939740656, "ncat": 303}, {"cat25k": 362, "ncat25k": 349, "os": 0.5595207351229244, "cat": 116, "y": 0.9984744469870328, "term": "a", "s": 0.5665137614678899, "bg": 3.250660406018056e-07, "x": 0.9977116704805492, "ncat": 308}, {"cat25k": 362, "ncat25k": 366, "os": 0.5504783453493313, "cat": 116, "y": 0.9977116704805492, "term": "and", "s": 0.5474006116207951, "bg": 2.38196081250696e-07, "x": 0.9984744469870328, "ncat": 323}, {"cat25k": 372, "ncat25k": 370, "os": 0.5529768758838078, "cat": 119, "y": 0.9992372234935164, "term": "of", "s": 0.551987767584098, "bg": 2.8604014418025155e-07, "x": 0.9992372234935164, "ncat": 327}, {"cat25k": 372, "ncat25k": 372, "os": 0.5518233361185884, "cat": 119, "y": 1.0, "term": "the", "s": 0.5496941896024465, "bg": 2.1879408213282236e-07, "x": 1.0, "ncat": 329}], "info": {"category_terms": ["extending", "exists", "nmt", "treebank", "means", "weights", "publicly", "inherent", "modifying", "syntax"], "category_internal_name": "f", "category_name": "Women", "not_category_name": "Men", "not_category_terms": ["extending", "exists", "nmt", "treebank", "means", "weights", "publicly", "inherent", "modifying", "syntax"]}, "docs": {"meta": ["ALW1: Isobelle Clarke, Dr. Jack Grieve: \"Dimensions of Abusive Language on Twitter\"", "ALW1: Lucas Wright, Derek Ruths, Kelly P Dillon, Haji Mohammad Saleem, Susan Benesch: \"Vectors for Counterspeech on Twitter\"", "ALW1: Niloofar Safi Samghabadi, Suraj Maharjan, Alan Sprague, Raquel Diaz-Sprague, Thamar Solorio: \"Detecting Nastiness in Social Media\"", "SemEval: Niloofar Ranjbar, Fatemeh Mashhadirajab, Mehrnoush Shamsfard, Rayeheh Hosseini pour, Aryan Vahid pour: \"Mahtab at SemEval-2017 Task 2: Combination of Corpus-based and Knowledge-based Methods to Measure Semantic Word Similarity\"", "ALW1: George Kennedy, Andrew McCollough, Edward Dixon, Alexei Bastidas, John Ryan, Chris Loo, Saurav Sahay: \"Technology Solutions to Combat Online Harassment\"", "ALW1: Joan Serr\u00e0, Ilias Leontiadis, Dimitris Spathis, Gianluca Stringhini, Jeremy Blackburn, Athena Vakali: \"Class-based Prediction Errors to Detect Hate Speech with Out-of-vocabulary Words\"", "ALW1: John Pavlopoulos, Prodromos Malakasiotis, Ion Androutsopoulos: \"Deep Learning for User Comment Moderation\"", "papers: John Wieting, Kevin Gimpel: \"Revisiting Recurrent Networks for Paraphrastic Sentence Embeddings\"", "SemEval: John Henderson, Elizabeth Merkhofer, Laura Strickhart, Guido Zarrella: \"MITRE at SemEval-2017 Task 1: Simple Semantic Similarity\"", "BioNLP: Pieter Fivez, Simon Suster, Walter Daelemans: \"Unsupervised Context-Sensitive Spelling Correction of Clinical Free-Text with Word and Character N-Gram Embeddings\"", "BioNLP: Kevin Patel, Divya Patel, Mansi Golakiya, Pushpak Bhattacharyya, Nilesh Birari: \"Adapting Pre-trained Word Embeddings For Use In Medical Coding\"", "BioNLP: Timothy Miller, Steven Bethard, Hadi Amiri, Guergana Savova: \"Unsupervised Domain Adaptation for Clinical Negation Detection\"", "BioNLP: Rahul V S S Patchigolla, Sunil Sahu, Ashish Anand: \"Biomedical Event Trigger Identification Using Bidirectional Recurrent Neural Network Based Models\"", "BioNLP: Denis Newman-Griffis, Albert Lai, Eric Fosler-Lussier: \"Insights into Analogy Completion from the Biomedical Domain\"", "shortpapers: Denis Savenkov, Eugene Agichtein: \"EviNets: Neural Networks for Combining Evidence Signals for Factoid Question Answering\"", "BioNLP: Georg Wiese, Dirk Weissenborn, Mariana Neves: \"Neural Question Answering at BioASQ 5B\"", "CoNLL: Georg Wiese, Dirk Weissenborn, Mariana Neves: \"Neural Domain Adaptation for Biomedical Question Answering\"", "EventStory: Georg Rehm, Julian Moreno Schneider, peter bourgonje, Ankit Srivastava, Jan Nehring, Armin Berger, Luca K\u00f6nig, S\u00f6ren R\u00e4uchle, Jens Gerth: \"Event Detection and Semantic Storytelling: Generating a Travelogue from a large Collection of Personal Letters\"", "BioNLP: Sunil Mohan, Nicolas Fiorini, Sun Kim, Zhiyong Lu: \"Deep Learning for Biomedical Information Retrieval: Learning Textual Relevance from Click Logs\"", "BioNLP: Aakanksha Naik, Chris Bogart, Carolyn Rose: \"Extracting Personal Medical Events for User Timeline Construction using Minimal Supervision\"", "BioNLP: Vaden Masrani, Gabriel Murray, Thalia Field, Giuseppe Carenini: \"Detecting Dementia through Retrospective Analysis of Routine Blog Posts by Bloggers with Dementia\"", "BioNLP: Seth Polsley, Atif Tahir, Muppala Raju, Akintayo Akinleye, Duane Steward: \"Role-Preserving Redaction of Medical Records to Enable Ontology-Driven Processing\"", "BioNLP: Wael Salloum, Greg Finley, Erik Edwards, Mark Miller, David Suendermann-Oeft: \"Automated Preamble Detection in Dictated Medical Reports\"", "BioNLP: Wael Salloum, Greg Finley, Erik Edwards, Mark Miller, David Suendermann-Oeft: \"Deep Learning for Punctuation Restoration in Medical Reports\"", "BioNLP: Simon Baker, Anna Korhonen: \"Initializing neural networks for hierarchical multi-label text classification\"", "SemEval: Simon M\u00fcller, Tobias Huonder, Jan Deriu, Mark Cieliebak: \"TopicThunder at SemEval-2017 Task 4: Sentiment Classification Using a Convolutional Neural Network with Distant Supervision\"", "SemEval: Simon Mille, Roberto Carlini, Alicia Burga, Leo Wanner: \"FORGe at SemEval-2017 Task 9: Deep sentence generation based on a sequence of graph transducers\"", "starSEM: Simon Ostermann, Michael Roth, Stefan Thater, Manfred Pinkal: \"Aligning Script Events with Narrative Texts\"", "BioNLP: Helen Cook, Rudolfs Berzins, Cristina Leal Rodr\u0131guez, Juan Miguel Cejuela, Lars Juhl Jensen: \"Creation and evaluation of a dictionary-based tagger for virus species and proteins\"", "BioNLP: Sudha Rao, Daniel Marcu, Kevin Knight, Hal Daum\u00e9 III: \"Biomedical Event Extraction using Abstract Meaning Representation\"", "SRW: Sudha Rao: \"Are You Asking the Right Questions? Teaching Machines to Ask Clarification Questions\"", "BioNLP: Devi Ganesan, Ashish V. Tendulkar, Sutanu Chakraborti: \"Protein Word Detection using Text Segmentation Techniques\"", "BioNLP: Danielle Mowery, Brett South, Olga Patterson, Shu-Hong Zhu, Mike Conway: \"Investigating the Documentation of Electronic Cigarette Use in the Veteran Affairs Electronic Health Record: A Pilot Study\"", "BioNLP: Mariana Neves, Fabian Eckert, Hendrik Folkerts, Matthias Uflacker: \"Assessing the performance of Olelo, a real-time biomedical question answering application\"", "BUCC: Mariana Neves: \"A parallel collection of clinical trials in Portuguese and English\"", "demos: Mariana Neves, Hendrik Folkerts, Marcel Jankrift, Julian Niedermeier, Toni Stachewicz, S\u00f6ren Tietb\u00f6hl, Milena Kraus, Matthias Uflacker: \"Olelo: A Question Answering Application for Biomedicine\"", "BioNLP: Wojciech Kusa, Michael Spranger: \"External Evaluation of Event Extraction Classifiers for Automatic Pathway Curation: An extended study of the mTOR pathway\"", "BioNLP: Diego Molla: \"Macquarie University at BioASQ 5b -- Query-based Summarisation Techniques for Selecting the Ideal Answers\"", "CoNLL: Diego Marcheggiani, Anton Frolov, Ivan Titov: \"A Simple and Accurate Syntax-Agnostic Neural Model for Dependency-based Semantic Role Labeling\"", "BioNLP: Masaki Asada, Makoto Miwa, Yutaka Sasaki: \"Extracting Drug-Drug Interactions with Attention CNNs\"", "BioNLP: Leonardo Campillos Llanos, Sophie Rosset, Pierre Zweigenbaum: \"Automatic classification of doctor-patient questions for a virtual patient record query task\"", "BioNLP: Mourad Sarrouti, Said Ouatik El Alaoui: \"A Biomedical Question Answering System in BioASQ 2017\"", "BioNLP: Sam Henry, Clint Cuffy, Bridget McInnes: \"Evaluating Feature Extraction Methods for Knowledge-based Biomedical Word Sense Disambiguation\"", "shortpapers: Sam Wei, Igor Korostil, Joel Nothman, Ben Hachey: \"English Event Detection With Translated Language Features\"", "BioNLP: Samir Gupta, A.S.M. Ashique Mahmood, Karen Ross, Cathy Wu, K. Vijay-Shanker: \"Identifying Comparative Structures in Biomedical Text\"", "BioNLP: Bridget McInnes, Ted Pedersen: \"Improving Correlation with Human Judgments by Integrating Semantic Similarity with Second--Order Vectors\"", "BioNLP: Hans Moen, Kai Hakala, Farrokh Mehryary, Laura-Maria Peltonen, Tapio Salakoski, Filip Ginter, Sanna Salanter\u00e4: \"Detecting mentions of pain and acute confusion in Finnish clinical text\"", "BioNLP: Arnaud Ferr\u00e9, Pierre Zweigenbaum, Claire N\u00e9dellec: \"Representation of complex terms in a vector space structured by an ontology for a normalization task\"", "BioNLP: Jake Lever, Steven Jones: \"Painless Relation Extraction with Kindred\"", "BioNLP: Joel Adams, Steven Bedrick, Gerasimos Fergadiotis, Kyle Gorman, Jan van Santen: \"Target word prediction and paraphasia classification in spoken discourse\"", "BioNLP: Anastasios Nentidis, Konstantinos Bougiatiotis, Anastasia Krithara, Georgios Paliouras, Ioannis Kakadiaris: \"Results of the fifth edition of the BioASQ Challenge\"", "BioNLP: Emilia Apostolova, Tom Velez: \"Toward Automated Early Sepsis Alerting: Identifying Infection Patients from Nursing Notes\"", "BUCC: Alp \u00d6ktem, Mireia Farr\u00fas, Leo Wanner: \"Automatic Extraction of Parallel Speech Corpora from Dubbed Movies\"", "BUCC: Michael Bloodgood, Benjamin Strauss: \"Acquisition of Translation Lexicons for Historically Unwritten Languages via Bridging Loanwords\"", "NLPandCSS: Michael Yoder, Shruti Rijhwani, Carolyn Ros\u00e9, Lori Levin: \"Code-Switching as a Social Act: The Case of Arabic Wikipedia Talk Pages\"", "NMT: Michael Denkowski, Graham Neubig: \"Stronger Baselines for Trustable Results in Neural Machine Translation\"", "papers: Michael Bloodgood, Benjamin Strauss: \"Using Global Constraints and Reranking to Improve Cognates Detection\"", "BUCC: Andoni Azpeitia, Thierry Etchegoyhen, Eva Mart\u00ednez Garcia: \"Weighted Set-Theoretic Alignment of Comparable Sentences\"", "BUCC: Francis Gr\u00e9goire, Philippe Langlais: \"BUCC 2017 Shared Task: a First Attempt Toward a Deep Learning Framework for Identifying Parallel Sentences in Comparable Corpora\"", "starSEM: Francis Ferraro, Adam Poliak, Ryan Cotterell, Benjamin Van Durme: \"Frame-Based Continuous Lexical Semantics through Exponential Family Tensor Factorization and Semantic Proto-Roles\"", "BUCC: Zheng Zhang, Pierre Zweigenbaum: \"zNLP: Identifying Parallel Sentences in Chinese-English Comparable Corpora\"", "shortpapers: Zheng Cai, Lifu Tu, Kevin Gimpel: \"Pay Attention to the Ending:Strong Neural Baselines for the ROC Story Cloze Task\"", "BUCC: Phillippe Langlais: \"Users and Data: The Two Neglected Children of Bilingual Natural Language Processing Research\"", "BUCC: Pierre Zweigenbaum, Serge Sharoff, Reinhard Rapp: \"Overview of the Second BUCC Shared Task: Spotting Parallel Sentences in Comparable Corpora\"", "CLPsych: Jude Mikal, Samantha Hurst, Mike Conway: \"Investigating Patient Attitudes Towards the use of Social Media Data to Augment Depression Diagnosis and Treatment: a Qualitative Study\"", "CLPsych: Michelle Morales, Stefan Scherer, Rivka Levitan: \"A Cross-modal Review of Indicators for Depression Detection Systems\"", "CLPsych: Melissa Roemmele, Paola Mardo, Andrew Gordon: \"Natural-language Interactive Narratives in Imaginal Exposure Therapy for Obsessive-Compulsive Disorder\"", "CLPsych: Zunaira Jamil, Diana Inkpen, Prasadith Buddhitha, Kenton White: \"Monitoring Tweets for Depression to Detect At-risk Users\"", "CLPsych: Kate Loveys, Patrick Crutchley, Emily Wyatt, Glen Coppersmith: \"Small but Mighty: Affective Micropatterns for Quantifying Mental Health from Social Media Language\"", "CLPsych: Kate Niederhoffer, Jonathan Schler, Patrick Crutchley, Kate Loveys, Glen Coppersmith: \"In your wildest dreams: the language and psychological features of dreams\"", "CLPsych: Rohan Kshirsagar, Robert Morris, Samuel Bowman: \"Detecting and Explaining Crisis\"", "CoNLL: Fatemeh Torabi Asr, Michael Jones: \"An Artificial Language Evaluation of Distributional Semantic Models\"", "shortpapers: Fatemeh Almodaresi, Lyle Ungar, Vivek Kulkarni, Mohsen Zakeri, Salvatore Giorgi, H. Andrew Schwartz: \"On the Distribution of Lexical Features at Multiple Levels of Analysis\"", "CoNLL: Shafiq Joty, Preslav Nakov, Llu\u00eds M\u00e0rquez, Israa Jaradat: \"Cross-language Learning with Adversarial Neural Networks\"", "CoNLL: SHOAIB JAMEEL, STEVEN SCHOCKAERT: \"Modeling Context Words as Regions: An Ordinal Regression Approach to Word Embedding\"", "CoNLL: Dominik Schlechtweg, Stefanie Eckmann, Enrico Santus, Sabine Schulte im Walde, Daniel Hole: \"German in Flux: Detecting Metaphoric Change via Word Entropy\"", "CoNLL: Ed Collins, Isabelle Augenstein, Sebastian Riedel: \"A Supervised Approach to Extractive Summarisation of Scientific Papers\"", "CoNLL: Olga Uryupina, Alessandro Moschitti: \"Collaborative Partitioning for Coreference Resolution\"", "SemEval: Olga Vechtomova: \"UWaterloo at SemEval-2017 Task 7: Locating the Pun Using Syntactic Characteristics and Corpus-based Metrics\"", "CoNLL: Younes Samih, Mohamed Eldesouki, Mohammed Attia, Kareem Darwish, Ahmed Abdelali, Hamdy Mubarak, Laura Kallmeyer: \"Learning from Relatives: Unified Dialectal Arabic Segmentation\"", "CoNLL: Phong Le, Ivan Titov: \"Optimizing Differentiable Relaxations of Coreference Evaluation Metrics\"", "CoNLL: Adithya Renduchintala, Philipp Koehn, Jason Eisner: \"Knowledge Tracing in Sequential Learning of Inflected Vocabulary\"", "CoNLL: Massimo Nicosia, Alessandro Moschitti: \"Learning Contextual Embeddings for Structural Semantic Similarity using Categorical Information\"", "CoNLL: Long Duong, Hadi Afshar, Dominique Estival, Glen Pink, Philip Cohen, Mark Johnson: \"Multilingual Semantic Parsing And Code-Switching\"", "shortpapers: Long Zhou, Wenpeng Hu, Jiajun Zhang, Chengqing Zong: \"Neural System Combination for Machine Translation\"", "CoNLL: Tatyana Ruzsics, Tanja Samardzic: \"Neural Sequence-to-sequence Learning of Internal Word Structure\"", "CoNLL: Naomi Feldman: \"Rational Distortions of Learners' Linguistic Input\"", "CoNLL: Massimiliano Mancini, Jose Camacho-Collados, Ignacio Iacobacci, Roberto Navigli: \"Embedding Words and Senses Together via Joint Knowledge-Enhanced Training\"", "CoNLL: Omer Levy, Minjoon Seo, Eunsol Choi, Luke Zettlemoyer: \"Zero-Shot Relation Extraction via Reading Comprehension\"", "CoNLL: Yotam Eshel, Noam Cohen, Kira Radinsky, Shaul Markovitch, Ikuya Yamada, Omer Levy: \"Named Entity Disambiguation for Noisy Text\"", "CoNLL: Afra Alishahi, Marie Barking, Grzegorz Chrupa\u0142a: \"Encoding of phonology in a recurrent neural model of grounded speech\"", "CoNLL: Rebecca Sharp, Mihai Surdeanu, Peter Jansen, Marco A. Valenzuela-Esc\u00e1rcega, Peter Clark, Michael Hammond: \"Tell Me Why: Using Question Answering as Distant Supervision for Answer Justification\"", "CoNLL: Ivan Vuli\u0107, Roy Schwartz, Ari Rappoport, Roi Reichart, Anna Korhonen: \"Automatic Selection of Context Configurations for Improved Class-Specific Word Representations\"", "papers: Ivan Vuli\u0107, Nikola Mrk\u0161i\u0107, Roi Reichart, Diarmuid \u00d3 S\u00e9aghdha, Steve Young, Anna Korhonen: \"Morph-fitting: Fine-Tuning Word Vector Spaces with Simple Language-Specific Rules\"", "CoNLL: Roy Schwartz, Maarten Sap, Ioannis Konstas, Leila Zilles, Yejin Choi, Noah A. Smith: \"The Effect of Different Writing Tasks on Linguistic Style: A Case Study of the ROC Story Cloze Task\"", "CoNLL: Daniel Khashabi, Tushar Khot, Ashish Sabharwal, Dan Roth: \"Learning What is Essential in Questions\"", "NLPandCSS: Daniel Preo\u0163iuc-Pietro, Jordan Carpenter, Lyle Ungar: \"Personality Driven Differences in Paraphrase Preference\"", "papers: Daniel Hershcovich, Omri Abend, Ari Rappoport: \"A Transition-Based Directed Acyclic Graph Parser for UCCA\"", "papers: Daniel Preo\u0163iuc-Pietro, Ye Liu, Daniel Hopkins, Lyle Ungar: \"Beyond Binary Labels: Political Ideology Prediction of Twitter Users\"", "papers: Daniel Fern\u00e1ndez-Gonz\u00e1lez, Carlos G\u00f3mez-Rodr\u00edguez: \"A Full Non-Monotonic Transition System for Unrestricted Non-Projective Parsing\"", "SemEval: Daniel Cer, Mona Diab, Eneko Agirre, Inigo Lopez-Gazpio, Lucia Specia: \"SemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation\"", "shortpapers: Daniel Dahlmeier: \"On the Challenges of Translating NLP Research into Commercial Products\"", "shortpapers: Daniel Fried, Mitchell Stern, Dan Klein: \"Improving Neural Parsing by Disentangling Model Combination and Reranking Effects\"", "CoNLL: Dirk Weissenborn, Georg Wiese, Laura Seiffe: \"Making Neural QA as Simple as Possible but not Simpler\"", "demos: Gus Hahn-Powell, Marco A. Valenzuela-Esc\u00e1rcega, Mihai Surdeanu: \"Swanson linking revisited: Accelerating literature-based discovery across domains using a conceptual influence graph\"", "demos: Jason Kessler: \"Scattertext: a Browser-Based Tool for Visualizing how Corpora Differ\"", "demos: Marjan Ghazvininejad, Xing Shi, Jay Priyadarshi, Kevin Knight: \"Hafez: an Interactive Poetry Generation System\"", "demos: Lei Cui, Shaohan Huang, Furu Wei, Chuanqi Tan, Chaoqun Duan, Ming Zhou: \"SuperAgent: A Customer Service Chatbot for E-commerce Websites\"", "shortpapers: Lei Shu, Hu Xu, Bing Liu: \"Lifelong Learning CRF for Supervised Aspect Extraction\"", "demos: Andreas R\u00fcckl\u00e9, Iryna Gurevych: \"End-to-End Non-Factoid Question Answering with an Interactive Visualization of Neural Attention Weights\"", "demos: Stefan Ultes, Lina M. Rojas Barahona, Pei-Hao Su, David Vandyke, Dongho Kim, I\u00f1igo Casanueva, Pawe\u0142 Budzianowski, Nikola Mrk\u0161i\u0107, Tsung-Hsien Wen, Milica Gasic, Steve Young: \"PyDial: A Multi-domain Statistical Dialogue System Toolkit\"", "demos: Omri Abend, Shai Yerushalmi, Ari Rappoport: \"UCCAApp: Web-application for Syntactic and Semantic Phrase-based Annotation\"", "papers: Omri Abend, Ari Rappoport: \"The State of the Art in Semantic Representation\"", "demos: Erik Faessler, Udo Hahn: \"Semedico: A Comprehensive Semantic Search Engine for the Life Sciences\"", "demos: Johannes Hellrich, Udo Hahn: \"Exploring Diachronic Lexical Semantics with JeSemE\"", "SemEval: Johannes Bjerva, Robert \u00d6stling: \"ResSim at SemEval-2017 Task 1: Multilingual Word Representations for Semantic Textual Similarity\"", "demos: Xiang Ren, Jiaming Shen, Meng Qu, Xuan Wang, Zeqiu Wu, Qi Zhu, Meng Jiang, Fangbo Tao, Saurabh Sinha, David Liem, Peipei Ping, Richard Weinshilboum, Jiawei Han: \"Life-iNet: A Structured Network-Based Knowledge Exploration and Analytics System for Life Sciences\"", "shortpapers: Xiang Yu, Ngoc Thang Vu: \"Character Composition Model with Convolutional Neural Networks for Dependency Parsing on Morphologically Rich Languages\"", "demos: Anita Ramm, Sharid Lo\u00e1iciga, Annemarie Friedrich, Alexander Fraser: \"Annotating tense, mood and voice for English, French and German\"", "demos: Iain Marshall, Jo\u00ebl Kuiper, Edward Banner, Byron C. Wallace: \"Automating Biomedical Evidence Synthesis: RobotReviewer\"", "demos: Dustin Arendt, Svitlana Volkova: \"ESTEEM: A Novel Framework for Qualitatively Evaluating and Visualizing Spatiotemporal Embeddings in Social Media\"", "demos: Guillaume Klein, Yoon Kim, Yuntian Deng, Jean Senellart, Alexander Rush: \"OpenNMT: Open-Source Toolkit for Neural Machine Translation\"", "demos: Niket Tandon, Gerard de Melo, Gerhard Weikum: \"WebChild 2.0 : Fine-Grained Commonsense Knowledge Distillation\"", "demos: Kateryna Tymoshenko, Alessandro Moschitti, Massimo Nicosia, Aliaksei Severyn: \"RelTextRank: An Open Source Framework for Building Relational Syntactic-Semantic Text Pair Representations\"", "EventStory: Andrey Kutuzov, Erik Velldal, Lilja \u00d8vrelid: \"Tracing armed conflicts with diachronic word embedding models\"", "shortpapers: Andrey Malinin, Anton Ragni, Kate Knill, Mark Gales: \"Incorporating Uncertainty into Deep Learning for Spoken Language Assessment\"", "EventStory: Susan Brown, Claire Bonial, Leo Obrst, Martha Palmer: \"The Rich Event Ontology\"", "EventStory: William Croft, Pavlina Peskova, Michael Regan: \"Integrating Decompositional Event Structures into Storylines\"", "papers: William Foland, James H. Martin: \"Abstract Meaning Representation Parsing using LSTM Recurrent Neural Networks\"", "EventStory: Martin Atkinson, Jakub Piskorski, Hristo Tanev, Vanni Zavarella: \"On the Creation of a Security-Related Event Corpus\"", "papers: Martin Villalba, Christoph Teichmann, Alexander Koller: \"Generating Contrastive Referring Expressions\"", "EventStory: Evangelia Spiliopoulou, Eduard Hovy, Teruko Mitamura: \"Event Detection Using Frame-Semantic Parser\"", "EventStory: Philippe Laban, Marti Hearst: \"newsLens: building and visualizing long-ranging news stories\"", "EventStory: Tommaso Caselli, Piek Vossen: \"The Event StoryLine Corpus: A New Benchmark for Causal and Temporal Relation Extraction\"", "EventStory: Roxane Segers, Tommaso Caselli, Piek Vossen: \"The Circumstantial Event Ontology (CEO)\"", "EventStory: Natalie Ahn: \"Inducing Event Types and Roles in Reverse: Using Function to Discover Theme\"", "LaTeCH-CLfL: Conor Kelleher, Mark Keane: \"Plotting Markson's ``Mistress''\"", "LaTeCH-CLfL: Amrith Krishna, Pavan Kumar Satuluri, Pawan Goyal: \"A Dataset for Sanskrit Word Segmentation\"", "TextGraphs-11: Amrith Krishna, Pavankumar Satuluri, Harshavardhan Ponnada, Muneeb Ahmed, Gulab Arora, Kaustubh Hiware, Pawan Goyal: \"A Graph Based Semi-Supervised Approach for Analysis of Derivational Nouns in Sanskrit\"", "LaTeCH-CLfL: Andre Blessing, Nora Echelmeyer, Markus John, Nils Reiter: \"An End-to-end Environment for Research Question-Driven Entity Extraction and Network Analysis\"", "SemEval: Andre Lamurias, Diana Sousa, Sofia Pereira, Luka Clarke, Francisco M Couto: \"ULISBOA at SemEval-2017 Task 12: Extraction and classification of temporal expressions and events\"", "LaTeCH-CLfL: Stefania Degaetano-Ortlieb, Elke Teich: \"Modeling intra-textual variation with entropy and surprisal: topical vs. stylistic patterns\"", "LaTeCH-CLfL: Pablo Ruiz, Clara Mart\u00ednez Cant\u00f3n, Thierry Poibeau, Elena Gonz\u00e1lez-Blanco: \"Enjambment Detection in a Large Diachronic Corpus of Spanish Sonnets\"", "Repl4NLP: Pablo Gamallo: \"Sense Contextualization in a Dependency-Based Compositional Distributional Model\"", "SemEval: Pablo Gamallo: \"Citius at SemEval-2017 Task 2: Cross-Lingual Similarity from Comparable Corpora and Dependency-Based Contexts\"", "shortpapers: Pablo Loyola, Edison Marrese-Taylor, Yutaka Matsuo: \"A Neural Architecture for Generating Natural Language Descriptions from Source Code Changes\"", "LaTeCH-CLfL: Maciej Ogrodniczuk, Mateusz Kope\u0107: \"Lexical Correction of Polish Twitter Political Data\"", "LaTeCH-CLfL: Vaibhav Kesarwani, Diana Inkpen, Stan Szpakowicz, Chris Tanasescu: \"Metaphor Detection in a Poetry Corpus\"", "LaTeCH-CLfL: Nina Seemann, Marie-Luis Merten, Michaela Geierhos, Doris Tophinke, Eyke H\u00fcllermeier: \"Annotation Challenges for Reconstructing the Structural Elaboration of Middle Low German\"", "LaTeCH-CLfL: Maria Sukhareva, Francesco Fuscagni, Johannes Daxenberger, Susanne G\u00f6rke, Doris Prechel, Iryna Gurevych: \"Distantly Supervised POS Tagging of Low-Resource Languages under Extreme Data Sparsity: The Case of Hittite\"", "shortpapers: Maria Ryskina, Hannah Alpert-Abrams, Dan Garrette, Taylor Berg-Kirkpatrick: \"Automatic Compositor Attribution in the First Folio of Shakespeare\"", "starSEM: Maria Becker, Michael Staniek, Vivi Nastase, Alexis Palmer, Anette Frank: \"Classifying Semantic Clause Types: Modeling Context and Genre Characteristics with Recurrent Neural Networks and Attention\"", "LaTeCH-CLfL: Christopher Hench: \"Phonological Soundscapes in Medieval Poetry\"", "papers: Christopher Bryant, Mariano Felice, Ted Briscoe: \"Automatic Annotation and Evaluation of Error Types for Grammatical Error Correction\"", "NLPandCSS: Akshita Jha, Radhika Mamidi: \"When does a compliment become sexist? Analysis and classification of ambivalent sexism using twitter data\"", "NLPandCSS: Goran Glava\u0161, Federico Nanni, Simone Paolo Ponzetto: \"Cross-Lingual Classification of Topics in Political Texts\"", "NLPandCSS: Andrea Zielinski, Peter Mutschke: \"Mining Social Science Publications for Survey Variables\"", "RoboNLP: Andrea Vanzo, Danilo Croce, Roberto Basili, Daniele Nardi: \"Structured Learning for Context-aware Spoken Language Understanding of Robotic Commands\"", "NLPandCSS: Rachael Tatman, Leo Stewart, Amandalynne Paullada, Emma Spiro: \"Non-lexical Features Encode Political Affiliation on Twitter\"", "NLPandCSS: Gabriel Murray: \"Modelling Participation in Small Group Social Sequences with Markov Rewards Analysis\"", "papers: Gabriel Doyle, Amir Goldberg, Sameer Srivastava, Michael Frank: \"Alignment at Work: Using Language to Distinguish the Internalization and Self-Regulation Components of Cultural Fit in Organizations\"", "shortpapers: Gabriel Stanovsky, Judith Eckle-Kohler, Yevgeniy Puzikov, Ido Dagan, Iryna Gurevych: \"Integrating Deep Linguistic Features in Factuality Prediction over Unified Datasets\"", "NLPandCSS: Zach Wood-Doughty, Michael Smith, David Broniatowski, Mark Dredze: \"How Does Twitter User Behavior Vary Across Demographic Groups?\"", "NLPandCSS: Kristen Johnson, I-Ta Lee, Dan Goldwasser: \"Ideological Phrase Indicators for Classification of Political Discourse Framing on Twitter\"", "papers: Kristen Johnson, Di Jin, Dan Goldwasser: \"Leveraging Behavioral and Social Information for Weakly Supervised Collective Classification of Political Discourse on Twitter\"", "NLPandCSS: Trevor Martin: \"community2vec: Vector representations of online communities encode semantic relationships\"", "NMT: Makoto Morishita, Yusuke Oda, Graham Neubig, Koichiro Yoshino, Katsuhito Sudoh, Satoshi Nakamura: \"An Empirical Study of Mini-Batch Creation Strategies for Neural Machine Translation\"", "NMT: Isao Goto, Hideki Tanaka: \"Detecting Untranslated Content for Neural Machine Translation\"", "NMT: Markus Freitag, Yaser Al-Onaizan: \"Beam Search Strategies for Neural Machine Translation\"", "NMT: Philipp Koehn, Rebecca Knowles: \"Six Challenges for Neural Machine Translation\"", "NMT: Marine Carpuat, Yogarshi Vyas, Xing Niu: \"Detecting Cross-Lingual Semantic Divergence for Neural Machine Translation\"", "NMT: Raphael Shu, Hideki Nakayama: \"An Empirical Study of Adequate Vision Span for Attention-Based Neural Machine Translation\"", "SemEval: Raphael Troncy, Enrico Palumbo, Efstratios Sygkounas, Giuseppe Rizzo: \"SentiME++ at SemEval-2017 Task 4: Stacking State-of-the-Art Classifiers to Enhance Sentiment Classification\"", "papers: Yixin Cao, Lifu Huang, Heng Ji, Xu Chen, Juanzi Li: \"Bridge Text and Knowledge by Learning Multi-Prototype Entity Mention Embedding\"", "papers: Roee Aharoni, Yoav Goldberg: \"Morphological Inflection Generation with Hard Monotonic Attention\"", "shortpapers: Roee Aharoni, Yoav Goldberg: \"Towards String-To-Tree Neural Machine Translation\"", "papers: Jian Ni, Georgiana Dinu, Radu Florian: \"Weakly Supervised Cross-Lingual Named Entity Recognition via Effective Annotation and Representation Projection\"", "papers: Mo Yu, Wenpeng Yin, Kazi Saidul Hasan, Cicero dos Santos, Bing Xiang, Bowen Zhou: \"Improved Neural Relation Detection for Knowledge Base Question Answering\"", "papers: Anil Ramakrishna, Victor R. Mart\u00ednez, Nikolaos Malandrakis, Karan Singla, Shrikanth Narayanan: \"Linguistic analysis of differences in portrayal of movie characters\"", "papers: Leandro Santos, Edilson Anselmo Corr\u00eaa J\u00fanior, Osvaldo Oliveira Jr, Diego Amancio, Let\u00edcia Mansur, Sandra Alu\u00edsio: \"Enriching Complex Networks with Word Embeddings for Detecting Mild Cognitive Impairment from Speech Transcripts\"", "papers: Steffen Eger, Johannes Daxenberger, Iryna Gurevych: \"Neural End-to-End Learning for Computational Argumentation Mining\"", "SemEval: Steffen Eger, Erik-L\u00e2n Do Dinh, Ilia Kuznetsov, Masoud Kiaeeha, Iryna Gurevych: \"EELECTION at SemEval-2017 Task 10: Ensemble of nEural Learners for kEyphrase ClassificaTION\"", "papers: Jonas Gehring, Michael Auli, David Grangier, Yann Dauphin: \"A Convolutional Encoder Model for Neural Machine Translation\"", "papers: Meng Zhang, Yang Liu, Huanbo Luan, Maosong Sun: \"Adversarial Training for Unsupervised Bilingual Lexicon Induction\"", "shortpapers: Meng Fang, Trevor Cohn: \"Model Transfer for Tagging Low-resource Languages using a Bilingual Dictionary\"", "papers: Ben Athiwaratkun, Andrew Wilson: \"Multimodal Word Distributions\"", "papers: Saku Sugawara, Yusuke Kido, Hikaru Yokono, Akiko Aizawa: \"Evaluation Metrics for Machine Reading Comprehension: Prerequisite Skills and Readability\"", "papers: Yiming Cui, Zhipeng Chen, si wei, Shijin Wang, Ting Liu, Guoping Hu: \"Attention-over-Attention Neural Networks for Reading Comprehension\"", "papers: Satoshi Akasaki, Nobuhiro Kaji: \"Chat Detection in an Intelligent Assistant: Combining Task-oriented and Non-task-oriented Spoken Dialogue Systems\"", "papers: Rie Johnson, Tong Zhang: \"Deep Pyramid Convolutional Neural Networks for Text Categorization\"", "papers: Chengyu Wang, Junchi Yan, Aoying Zhou, Xiaofeng He: \"Transductive Non-linear Learning for Chinese Hypernym Prediction\"", "papers: Tomer Cagan, Stefan L. Frank, Reut Tsarfaty: \"Data-Driven Broad-Coverage Grammars for Opinionated Natural Language Generation (ONLG)\"", "papers: Alina Wr\u00f3blewska, Katarzyna Krasnowska-Kiera\u015b: \"Polish evaluation dataset for compositional distributional semantics models\"", "papers: Shervin Malmasi, Mark Dras, Mark Johnson, Lan Du, Magdalena Wolska: \"Unsupervised Text Segmentation Based on Native Language Characteristics\"", "shortpapers: Shervin Malmasi, Mark Dras: \"Feature Hashing for Language and Dialect Identification\"", "papers: Alex Gittens, Dimitris Achlioptas, Michael W. Mahoney: \"Skip-Gram - Zipf + Uniform = Vector Additivity\"", "papers: Qian Chen, Xiaodan Zhu, Zhen-Hua Ling, Si Wei, Hui Jiang, Diana Inkpen: \"Enhanced LSTM for Natural Language Inference\"", "papers: Marek Rei: \"Semi-supervised Multitask Learning for Sequence Labeling\"", "SemEval: Marek Kubis, Pawe\u0142 Sk\u00f3rzewski, Tomasz Zi\u0119tkiewicz: \"EUDAMU at SemEval-2017 Task 11: Action Ranking and Type Matching for End-User Development\"", "papers: Ella Rabinovich, Noam Ordan, Shuly Wintner: \"Found in Translation: Reconstructing Phylogenetic Language Trees from Translations\"", "papers: Junjie Cao, Sheng Huang, Weiwei Sun, Xiaojun Wan: \"Parsing to 1-Endpoint-Crossing, Pagenumber-2 Graphs\"", "papers: Dat Tien Nguyen, Shafiq Joty: \"A Neural Local Coherence Model\"", "papers: Shuhei Kurita, Daisuke Kawahara, Sadao Kurohashi: \"Neural Joint Model for Transition-based Chinese Syntactic Analysis\"", "papers: Hai Ye, Wenhan Chao, Zhunchen Luo, Zhoujun Li: \"Jointly Extracting Relations with Class Ties via Effective Deep Ranking\"", "Repl4NLP: Hai Wang, Takeshi Onishi, Kevin Gimpel, David McAllester: \"Emergent Predication Structure in Hidden State Vectors of Neural Readers\"", "papers: Hiroki Ouchi, Hiroyuki Shindo, Yuji Matsumoto: \"Neural Modeling of Multi-Predicate Interactions for Japanese Predicate Argument Structure Analysis\"", "papers: Marcel Bollmann, Joachim Bingel, Anders S\u00f8gaard: \"Learning attention for historical text normalization by learning to pronounce\"", "papers: Vlad Niculae, Joonsuk Park, Claire Cardie: \"Argument Mining with Structured SVMs and RNNs\"", "papers: Claire Gardent, Anastasia Shimorina, Shashi Narayan, Laura Perez-Beltrachini: \"Creating Training Corpora for NLG Micro-Planners\"", "papers: Ellie Pavlick, Marius Pasca: \"Identifying 1950s American Jazz Musicians: Fine-Grained IsA Extraction via Modifier Composition\"", "papers: Abhijit Mishra, Kuntal Dey, Pushpak Bhattacharyya: \"Learning Cognitive Features from Gaze Data for Sentiment and Sarcasm Classification using Convolutional Neural Network\"", "papers: Katharina Kann, Ryan Cotterell, Hinrich Sch\u00fctze: \"One-Shot Neural Cross-Lingual Transfer for Paradigm Completion\"", "papers: Maxime Peyrard, Judith Eckle-Kohler: \"Supervised Learning of Automatic Pyramid for Optimization-Based Multi-Document Summarization\"", "shortpapers: Maxime Peyrard, Judith Eckle-Kohler: \"A Principled Framework for Evaluating Summarizers: Comparing Models of Summary Quality against Human Judgments\"", "papers: Sayan Ghosh, Mathieu Chollet, Eugene Laksana, Louis-Philippe Morency, Stefan Scherer: \"Affect-LM: A Neural Language Model for Customizable Affective Text Generation\"", "papers: Kyle Richardson, Jonas Kuhn: \"Learning Semantic Correspondences in Technical Documentation\"", "papers: Masashi Yoshikawa, Hiroshi Noji, Yuji Matsumoto: \"A* CCG Parsing with a Supertag and Dependency Factored Model\"", "papers: Navid Rekabsaz, Mihai Lupu, Artem Baklanov, Alexander D\u00fcr, Linda Andersson, Allan Hanbury: \"Volatility Prediction using Financial Disclosures Sentiments with Word Embedding-based IR Models\"", "papers: Mikel Artetxe, Gorka Labaka, Eneko Agirre: \"Learning bilingual word embeddings with (almost) no bilingual data\"", "papers: Clara Vania, Adam Lopez: \"From Characters to Words to in Between: Do We Capture Morphology?\"", "papers: Ravi Shekhar, Sandro Pezzelle, Yauhen Klimovich, Aur\u00e9lie Herbelot, Moin Nabi, Enver Sangineto, Raffaella Bernardi: \"FOIL it! Find One mismatch between Image and Language caption\"", "papers: Grzegorz Chrupa\u0142a, Lieke Gelderloos, Afra Alishahi: \"Representations of language in a model of visually grounded speech signal\"", "papers: Yonatan Belinkov, Nadir Durrani, Fahim Dalvi, Hassan Sajjad, James Glass: \"What do Neural Machine Translation Models Learn about Morphology?\"", "Repl4NLP: Yonatan Belinkov, Llu\u00eds M\u00e0rquez, Hassan Sajjad, Nadir Durrani, Fahim Dalvi, James Glass: \"Evaluating Layers of Representation in Neural Machine Translation on Syntactic and Semantic Tagging\"", "papers: Alexander Fonarev, Oleksii Grinchuk, Gleb Gusev, Pavel Serdyukov, Ivan Oseledets: \"Riemannian Optimization for Skip-Gram Negative Sampling\"", "Repl4NLP: Alexander Johansen, Richard Socher: \"Learning when to skim and when to read\"", "papers: Jeffrey Lund, Connor Cook, Kevin Seppi, Jordan Boyd-Graber: \"Tandem Anchoring: a Multiword Anchor Approach for Interactive Topic Modeling\"", "papers: Muhammad Abdul-Mageed, Lyle Ungar: \"EmoNet: Fine-Grained Emotion Detection with Gated Recurrent Neural Networks\"", "papers: Frederick Liu, Han Lu, Chieh Lo, Graham Neubig: \"Learning Character-level Compositionality with Visual Features\"", "papers: Kazuya Kawakami, Chris Dyer, Phil Blunsom: \"Learning to Create and Reuse Words in Open-Vocabulary Neural Language Modeling\"", "papers: Wang Ling, Dani Yogatama, Chris Dyer, Phil Blunsom: \"Program Induction by Rationale Generation: Learning to Solve and Explain Algebraic Word Problems\"", "SemEval: wang maoquan, Chen Shiyun, Xie yufei, Zhao lu: \"EICA at SemEval-2017 Task 4: A Simple Convolutional Neural Network for Topic-based Sentiment Classification\"", "papers: Matthew Peters, Waleed Ammar, Chandra Bhagavatula, Russell Power: \"Semi-supervised sequence tagging with bidirectional language models\"", "RoboNLP: Matthew Marge, Claire Bonial, Ashley Foots, Cory Hayes, Cassidy Henry, Kimberly Pollard, Ron Artstein, Clare Voss, David Traum: \"Exploring Variation of Natural Human Commands to a Robot in a Collaborative Navigation Task\"", "SRW: Matthew Garber, Meital Singer, Christopher Ward: \"Accent Adaptation for the Air Traffic Control Domain\"", "papers: Joao Sedoc, Jean Gallier, Dean Foster, Lyle Ungar: \"Semantic Word Clusters Using Signed Spectral Clustering\"", "papers: Ines Rehbein, Josef Ruppenhofer: \"Detecting annotation noise in automatically labelled data\"", "papers: David Harwath, James Glass: \"Learning Word-Like Units from Joint Audio-Visual Analysis\"", "SemEval: David Lozi\u0107, Doria \u0160ari\u0107, Ivan Toki\u0107, Zoran Medi\u0107, Jan \u0160najder: \"TakeLab at SemEval-2017 Task 4: Recent Deaths and the Power of Nostalgia in Sentiment Analysis in Twitter\"", "SemEval: David Donahue, Alexey Romanov, Anna Rumshisky: \"HumorHawk at SemEval-2017 Task 6: Mixing Meaning and Sound for Humor Recognition\"", "shortpapers: David Jurgens, Yulia Tsvetkov, Dan Jurafsky: \"Incorporating Dialectal Variability for Socially Equitable Language Identification\"", "papers: Hao Peng, Sam Thomson, Noah A. Smith: \"Deep Multitask Learning for Semantic Dependency Parsing\"", "SemEval: Hao Wu, Heyan Huang, Ping Jian, Yuhang Guo, Chao Su: \"BIT at SemEval-2017 Task 1: Using Semantic Information Space to Evaluate Semantic Textual Similarity\"", "shortpapers: Hao Zhou, Zhaopeng Tu, Shujian Huang, Xiaohua Liu, Hang Li, Jiajun Chen: \"Chunk-Based Bi-Scale Decoder for Neural Machine Translation\"", "papers: Julia Kreutzer, Artem Sokolov, Stefan Riezler: \"Bandit Structured Prediction for Neural Sequence-to-Sequence Learning\"", "papers: Fan Zhang, Homa B. Hashemi, Rebecca Hwa, Diane Litman: \"A Corpus of Annotated Revisions for Studying Argumentative Writing\"", "papers: Arzoo Katiyar, Claire Cardie: \"Going out on a limb: Joint Extraction of Entity Mentions and Relations without Dependency Trees\"", "papers: Ryan Lowe, Michael Noseworthy, Iulian Vlad Serban, Nicolas Angelard-Gontier, Yoshua Bengio, Joelle Pineau: \"Towards an Automatic Turing Test: Learning to Evaluate Dialogue Responses\"", "papers: Ryan Cotterell, Jason Eisner: \"Probabilistic Typology: Deep Generative Models of Vowel Inventories\"", "papers: Jack Hopkins, Douwe Kiela: \"Automatically Generating Rhythmic Verse with Neural Networks\"", "papers: Yusuke Oda, Philip Arthur, Graham Neubig, Koichiro Yoshino, Satoshi Nakamura: \"Neural Machine Translation via Binary Code Prediction\"", "papers: Shruti Rijhwani, Royal Sequiera, Monojit Choudhury, Kalika Bali, Chandra Shekhar Maddila: \"Estimating Code-Switching on Twitter with a Novel Generalized Word-Level Language Detection Technique\"", "papers: Pradeep Dasigi, Waleed Ammar, Chris Dyer, Eduard Hovy: \"Ontology-Aware Token Embeddings for Prepositional Phrase Attachment\"", "papers: Omid Bakhshandeh, James Allen: \"Apples to Apples: Learning Semantics of Common Entities Through a Novel Comprehension Task\"", "papers: Rui Meng, Sanqiang Zhao, Shuguang Han, Daqing He, Peter Brusilovsky, Yu Chi: \"Deep Keyphrase Generation\"", "shortpapers: Rui Wang, Andrew Finch, Masao Utiyama, Eiichiro Sumita: \"Sentence Embedding for Neural Machine Translation Domain Adaptation\"", "papers: Preksha Nema, Mitesh M. Khapra, Anirban Laha, Balaraman Ravindran: \"Diversity driven attention model for query-based abstractive summarization\"", "papers: Maxim Rabinovich, Mitchell Stern, Dan Klein: \"Abstract Syntax Networks for Code Generation and Semantic Parsing\"", "shortpapers: Maxim Rabinovich, Dan Klein: \"Fine-Grained Entity Typing with High-Multiplicity Assignments\"", "papers: Edmund Tong, Amir Zadeh, Cara Jones, Louis-Philippe Morency: \"Combating Human Trafficking with Multimodal Deep Models\"", "papers: Tarek Sakakini, Suma Bhat, Pramod Viswanath: \"MORSE: Semantic-ally Drive-n MORpheme SEgment-er\"", "papers: Jing Ma, Wei Gao, Kam-Fai Wong: \"Detect Rumors in Microblog Posts Using Propagation Structure via Kernel Learning\"", "papers: Jing Lu, Vincent Ng: \"Joint Learning for Event Coreference Resolution\"", "papers: Danilo Croce, Simone Filice, Giuseppe Castellucci, Roberto Basili: \"Deep Learning in Semantic Kernel Spaces\"", "papers: Dmitry Ustalov, Alexander Panchenko, Chris Biemann: \"Automatic Induction of Synsets from a Graph of Synonyms\"", "papers: Jiacheng Zhang, Yang Liu, Huanbo Luan, Jingfang Xu, Maosong Sun: \"Prior Knowledge Integration for Neural Machine Translation using Posterior Regularization\"", "papers: Jacob Andreas, Anca Dragan, Dan Klein: \"Translating Neuralese\"", "papers: Ioannis Konstas, Srinivasan Iyer, Mark Yatskar, Yejin Choi, Luke Zettlemoyer: \"Neural AMR: Sequence-to-Sequence Models for Parsing and Generation\"", "papers: Abigail See, Peter J. Liu, Christopher D. Manning: \"Get To The Point: Summarization with Pointer-Generator Networks\"", "papers: Nicholas Andrews, Mark Dredze, Benjamin Van Durme, Jason Eisner: \"Bayesian Modeling of Lexical Resources for Low-Resource Settings\"", "papers: Mohit Iyyer, Wen-tau Yih, Ming-Wei Chang: \"Search-based Neural Structured Learning for Sequential Question Answering\"", "papers: Iryna Haponchyk, Alessandro Moschitti: \"Don't understand a measure? Learn it: Structured Prediction for Coreference Resolution optimizing its measures\"", "papers: Kelvin Guu, Panupong Pasupat, Evan Liu, Percy Liang: \"From Language to Programs: Bridging Reinforcement Learning and Maximum Marginal Likelihood\"", "papers: Mitchell Stern, Jacob Andreas, Dan Klein: \"A Minimal Span-Based Neural Constituency Parser\"", "papers: Yassine Mrabet, Halil Kilicoglu, Dina Demner-Fushman: \"TextFlow: A Text Similarity Measure based on Continuous Sequences\"", "SemEval: Yassine El Adlouni, Imane Lahbari, Horacio Rodriguez, Mohammed Meknassi, Said Ouatik El Alaoui, Noureddine Ennahnahi: \"UPC-USMBA at SemEval-2017 Task 3: Combining multiple approaches for CQA for Arabic\"", "papers: Maxwell Forbes, Yejin Choi: \"Verb Physics: Relative Physical Knowledge of Actions and Objects\"", "papers: Takuya Matsuzaki, Takumi Ito, Hidenao Iwane, Hirokazu Anai, Noriko H. Arai: \"Semantic Parsing of Pre-university Math Problems\"", "papers: Vivek Srikumar: \"An Algebra for Feature Extraction\"", "papers: Corina Florescu, Cornelia Caragea: \"PositionRank: An Unsupervised Approach to Keyphrase Extraction from Scholarly Documents\"", "Repl4NLP: Joe Cheri, Pushpak Bhattacharyya: \"Towards Harnessing Memory Networks for Coreference Resolution\"", "SemEval: Joe Barrow, Denis Peskov: \"UMDeep at SemEval-2017 Task 1: End-to-End Shared Weight LSTM Model for Semantic Textual Similarity\"", "Repl4NLP: Anna Potapenko, Artem Popov: \"Regularized Topic Models for Sparse Interpretable Word Embeddings\"", "starSEM: Anna Rogers, Aleksandr Drozd, Bofang Li: \"The (too Many) Problems of Analogical Reasoning with Word Vectors\"", "Repl4NLP: Tolga Bolukbasi, Kai-Wei Chang, James Zou, Venkatesh Saligrama, Adam T. Kalai: \"Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings\"", "Repl4NLP: Rudolf Kadlec, Ondrej Bajgar, Jan Kleindienst: \"Knowledge Base Completion: Baselines Strike Back\"", "Repl4NLP: Sebastian Brarda, Philip Yeres, Samuel Bowman: \"Sequential Attention: A Context-Aware Alignment Function for Machine Reading\"", "Repl4NLP: Shyam Upadhyay, Kai-Wei Chang, Matt Taddy, Adam Kalai, James Zou: \"Beyond Bilingual: Multi-sense Word Embeddings using Multilingual Context\"", "Repl4NLP: Sheng Chen, Akshay Soni, Aasish Pappu, Yashar Mehdad: \"DocTag2Vec: An Embedding Based Multi-label Learning Approach for Document Tagging\"", "SemEval: Sheng Zhang, Jiajun Cheng, Hui Wang, Xin Zhang, Pei Li, Zhaoyun Ding: \"FuRongWang at SemEval-2017 Task 3: Deep Neural Networks for Selecting Relevant Answers in Community Question Answering\"", "Repl4NLP: Teresa Botschen, Hatem Mousselly Sergieh, Iryna Gurevych: \"Prediction of Frame-to-Frame Relations in the FrameNet Hierarchy with Frame Embeddings\"", "Repl4NLP: Holger Schwenk, Matthijs Douze: \"Learning Joint Multilingual Sentence Representations with Neural Machine Translation\"", "Repl4NLP: Julius Kunze, Louis Kirsch, Ilia Kurenkov, Andreas Krug, Jens Johannsmeier, Sebastian Stober: \"Transfer Learning for Speech Recognition on a Budget\"", "Repl4NLP: Shima Asaadi, Sebastian Rudolph: \"Gradual Learning of Matrix-Space Models of Language for Sentiment Analysis\"", "Repl4NLP: Adam Trischler, Tong Wang, Xingdi Yuan, Justin Harris, Alessandro Sordoni, Philip Bachman, Kaheer Suleman: \"NewsQA: A Machine Comprehension Dataset\"", "Repl4NLP: Lawrence Phillips, Kyle Shaffer, Dustin Arendt, Nathan Hodas, Svitlana Volkova: \"Intrinsic and Extrinsic Evaluation of Spatiotemporal Text Representations in Twitter Streams\"", "Repl4NLP: Hannes Schulz, Jeremie Zumer, Layla El Asri, Shikhar Sharma: \"A Frame Tracking Model for Memory-Enhanced Dialogue Systems\"", "Repl4NLP: Paul Michel, Abhilasha Ravichander, Shruti Rijhwani: \"Does the Geometry of Word Embeddings Help Document Classification? A Case Study on Persistent Homology-Based Representations\"", "SRW: Paul Michel, Okko R\u00e4s\u00e4nen, Roland Thiolliere, Emmanuel Dupoux: \"Blind Phoneme Segmentation With Temporal Prediction Errors\"", "Repl4NLP: Andrew Drozdov, Samuel Bowman: \"The Coadaptation Problem when Learning How and What to Compose\"", "SemEval: Andrew Moore, Paul Rayson: \"Lancaster A at SemEval-2017 Task 5: Evaluation metrics matter: predicting sentiment from financial news headlines\"", "SemEval: Andrew Cattle, Xiaojuan Ma: \"SRHR at SemEval-2017 Task 6: Word Associations for Humour Recognition\"", "Repl4NLP: Franziska Horn: \"Context encoders as a simple but powerful extension of word2vec\"", "RoboNLP: Yordan Hristov, Svetlin Penkov, Alex Lascarides, Subramanian Ramamoorthy: \"Grounding Symbols in Multi-Modal Instructions\"", "RoboNLP: Siddharth Karamcheti, Edward Clem Williams, Dilip Arumugam, Mina Rhee, Nakul Gopalan, Lawson L.S. Wong, Stefanie Tellex: \"A Tale of Two DRAGGNs: A Hybrid Approach for Interpreting Action-Oriented and Goal-Oriented Instructions\"", "RoboNLP: Peter Lindes, Aaron Mininger, James R. Kirk, John E. Laird: \"Grounding Language for Interactive Task Learning\"", "SemEval: Peter Potash, Alexey Romanov, Anna Rumshisky: \"SemEval-2017 Task 6: \\#HashtagWars: Learning a Sense of Humor\"", "RoboNLP: Anjali Narayan-Chen, Colin Graber, Mayukh Das, Md Rakibul Islam, Soham Dan, Sriraam Natarajan, Janardhan Rao Doppa, Julia Hockenmaier, Martha Palmer, Dan Roth: \"Towards Problem Solving Agents that Communicate and Learn\"", "RoboNLP: Jesse Thomason, Jivko Sinapov, Raymond Mooney: \"Guiding Interaction Behaviors for Multi-modal Grounded Language Learning\"", "RoboNLP: Muhannad Alomari, Paul Duckworth, Majd Hawasly, David C. Hogg, Anthony G. Cohn: \"Natural Language Grounding and Grammar Induction for Robotic Manipulation Commands\"", "SemEval: Ted Pedersen: \"Duluth at SemEval-2017 Task 7 : Puns Upon a Midnight Dreary, Lexical Semantics for the Weak and Weary\"", "SemEval: Georgios Balikas: \"TwiSe at SemEval-2017 Task 4: Five-point Twitter Sentiment Classification and Quantification\"", "SemEval: Rik van Noord, Johan Bos: \"The Meaning Factory at SemEval-2017 Task 9: Producing AMRs with Neural Semantic Parsing\"", "SemEval: Sergio Jimenez, George Due\u00f1as, Lorena Gaitan, Jorge Segura: \"RUFINO at SemEval-2017 Task 2: Cross-lingual lexical similarity by extending PMI and word embeddings systems with a Swadesh's-like list\"", "SemEval: Mickael Rouvier: \"LIA at SemEval-2017 Task 4: An Ensemble of Neural Networks for Sentiment Classification\"", "SemEval: Roman Kern, Stefan Falk, Andi Rexha: \"Know-Center at SemEval-2017 Task 10: Sequence Classification with the CODE Annotator\"", "SemEval: Sabino Miranda-Jim\u00e9nez, Mario Graff, Eric Sadit Tellez, Daniela Moctezuma: \"INGEOTEC at SemEval 2017 Task 4: A B4MSA Ensemble based on Genetic Programming for Twitter Sentiment Analysis\"", "SemEval: Ankit Vadehra: \"UWAV at SemEval-2017 Task 7: Automated feature-based system for locating puns\"", "SemEval: Ankit Srivastava, Georg Rehm, Julian Moreno Schneider: \"DFKI-DKT at SemEval-2017 Task 8: Rumour Detection and Classification using Cascading Heuristics\"", "SemEval: Samuel Doogan, Aniruddha Ghosh, Hanyang Chen, Tony Veale: \"Idiom Savant at Semeval-2017 Task 7: Detection and Interpretation of English Puns\"", "shortpapers: Samuel R\u00f6nnqvist, Niko Schenk, Christian Chiarcos: \"A Recurrent Neural Model with Attention for the Recognition of Chinese Implicit Discourse Relations\"", "SemEval: Enrico Mensa, Daniele P. Radicioni, Antonio Lieto: \"MERALI at SemEval-2017 Task 2 Subtask 1: a Cognitively Inspired approach\"", "SemEval: Narges Tabari, Armin Seyeditabari, Wlodek Zadrozny: \"SentiHeros at SemEval-2017 Task 5: An application of Sentiment Analysis on Financial Tweets\"", "SemEval: Julien Tourille, Olivier Ferret, Xavier Tannier, Aur\u00e9lie N\u00e9v\u00e9ol: \"LIMSI-COT at SemEval-2017 Task 12: Neural Architecture for Temporal Information Extraction from Clinical Narratives\"", "shortpapers: Julien Tourille, Olivier Ferret, Aurelie Neveol, Xavier Tannier: \"Neural Architecture for Temporal Relation Extraction: A Bi-LSTM Approach for Detecting Narrative Containers\"", "SemEval: Christos Baziotis, Nikos Pelekis, Christos Doulkeridis: \"DataStories at SemEval-2017 Task 6: Siamese LSTM with Attention for Humorous Text Comparison\"", "SemEval: Christos Baziotis, Nikos Pelekis, Christos Doulkeridis: \"DataStories at SemEval-2017 Task 4: Deep LSTM with Attention for Message-level and Topic-based Sentiment Analysis\"", "SemEval: Gerasimos Lampouras, Andreas Vlachos: \"Sheffield at SemEval-2017 Task 9: Transition-based language generation from AMR.\"", "SemEval: Robert Speer, Joanna Lowry-Duda: \"ConceptNet at SemEval-2017 Task 2: Extending Word Embeddings with Multilingual Relational Knowledge\"", "SemEval: Behrang QasemiZadeh, Laura Kallmeyer: \"HHU at SemEval-2017 Task 2: Fast Hash-Based Embeddings for Semantic Word Similarity Assessment\"", "SemEval: Filip \u0160aina, Toni Kukurin, Lukrecija Pulji\u0107, Mladen Karan, Jan \u0160najder: \"TakeLab-QA at SemEval-2017 Task 3: Classification Experiments for Answer Retrieval in Community QA\"", "SemEval: Sarah Kohail, Amr Rekaby Salama, Chris Biemann: \"STS-UHH at SemEval-2017 Task 1: Scoring Semantic Textual Similarity Using Supervised and Unsupervised Ensemble\"", "SemEval: Sean MacAvaney, Arman Cohan, Nazli Goharian: \"GUIR at SemEval-2017 Task 12: A Framework for Cross-Domain Clinical Temporal Information Extraction\"", "SemEval: Symeon Symeonidis, John Kordonis, Dimitrios Effrosynidis, Avi Arampatzis: \"DUTH at SemEval-2017 Task 5: Sentiment Predictability in Financial Microblogging and News Articles\"", "SemEval: Symeon Symeonidis, Dimitrios Effrosynidis, John Kordonis, Avi Arampatzis: \"DUTH at SemEval-2017 Task 4: A Voting Classification Approach for Twitter Sentiment Analysis\"", "SemEval: Leon Rotim, Martin Tutek, Jan \u0160najder: \"TakeLab at SemEval-2017 Task 5: Linear aggregation of word embeddings for fine-grained sentiment analysis of financial news\"", "SemEval: Leon Derczynski, Kalina Bontcheva, Maria Liakata, Rob Procter, Geraldine Wong Sak Hoi, Arkaitz Zubiaga: \"SemEval-2017 Task 8: RumourEval: Determining rumour veracity and support for rumours\"", "SemEval: Omar Enayet, Samhaa R. El-Beltagy: \"NileTMRG at SemEval-2017 Task 8: Determining Rumour and Veracity Support for Rumours on Twitter.\"", "SemEval: Animesh Prasad, Min-Yen Kan: \"WING-NUS at SemEval-2017 Task 10: Keyphrase Extraction and Classification as Joint Sequence Labeling\"", "SemEval: Vineet John, Olga Vechtomova: \"UW-FinSent at SemEval-2017 Task 5: Sentiment Analysis on Financial News Headlines using Training Dataset Augmentation\"", "SemEval: Elena Kochkina, Maria Liakata, Isabelle Augenstein: \"Turing at SemEval-2017 Task 8: Sequential Approach to Rumour Stance Classification with Branch-LSTM\"", "SemEval: Elena Mikhalkova, Yuri Karyakin: \"PunFields at SemEval-2017 Task 7: Employing Roget's Thesaurus in Automatic Pun Recognition and Interpretation\"", "SemEval: Liang Wang, Sujian Li: \"PKU\\_ICL at SemEval-2017 Task 10: Keyphrase Extraction with Model Ensemble and External Knowledge\"", "SemEval: Marianela Garc\u00eda Lozano, Hanna Lilja, Edward Tj\u00f6rnhammar, Maja Karasalo: \"Mama Edha at SemEval-2017 Task 8: Stance Classification with CNN and Rules\"", "SemEval: Nada Almarwani, Mona Diab: \"GW\\_QA at SemEval-2017 Task 3: Question Answer Re-ranking on Arabic Fora\"", "SemEval: Asma Ben Abacha, Dina Demner-Fushman: \"NLM\\_NIH at SemEval-2017 Task 3: from Question Entailment to Question Similarity for Community Question Answering\"", "SemEval: Tomoki Tsujimura, Makoto Miwa, Yutaka Sasaki: \"TTI-COIN at SemEval-2017 Task 10: Investigating Embeddings for End-to-End Relation Extraction from Scientific Papers\"", "SemEval: Yuta Koreeda, Takuya Hashito, Yoshiki Niwa, Misa Sato, Toshihiko Yanase, Kenzo Kurotsuchi, Kohsuke Yanai: \"bunji at SemEval-2017 Task 3: Combination of Neural Similarity Features and Comment Plausibility Features\"", "SemEval: Claudio Delli Bovi, Alessandro Raganato: \"Sew-Embed at SemEval-2017 Task 2: Language-Independent Concept Representations from a Semantically Enriched Wikipedia\"", "shortpapers: Claudio Delli Bovi, Jose Camacho-Collados, Alessandro Raganato, Roberto Navigli: \"EuroSense: Automatic Harvesting of Multilingual Sense Annotations from Parallel Text\"", "SemEval: Marwan Torki, Maram Hasanain, Tamer Elsayed: \"QU-BIGIR at SemEval 2017 Task 3: Using Similarity Features for Arabic Community Question Answering Forums\"", "SemEval: Vikram Singh, Sunny Narayan, Md Shad Akhtar, Asif Ekbal, Pushpak Bhattacharyya: \"IITP at SemEval-2017 Task 8 : A Supervised Approach for Rumour Evaluation\"", "SemEval: Ignacio Arroyo-Fern\u00e1ndez, Ivan Vladimir Meza Ruiz: \"LIPN-IIMAS at SemEval-2017 Task 1: Subword Embeddings, Attention Recurrent Neural Networks and Cross Word Alignment for Semantic Textual Similarity\"", "SemEval: Abhishek Kumar, Abhishek Sethi, Md Shad Akhtar, Asif Ekbal, Chris Biemann, Pushpak Bhattacharyya: \"IITPB at SemEval-2017 Task 5: Sentiment Prediction in Financial Text\"", "SemEval: Pedro Saleiro, Eduarda Mendes Rodrigues, Carlos Soares, Eug\u00e9nio Oliveira: \"FEUP at SemEval-2017 Task 5: Predicting Sentiment Polarity and Intensity with Financial Word Embeddings\"", "SemEval: Pedro Fialho, Hugo Patinho Rodrigues, Lu\u00edsa Coheur, Paulo Quaresma: \"L2F/INESC-ID at SemEval-2017 Tasks 1 and 2: Lexical and semantic features in word and textual similarity\"", "SemEval: Byron Galbraith, Bhanu Pratap, Daniel Shank: \"Talla at SemEval-2017 Task 3: Identifying Similar Questions Through Paraphrase Detection\"", "SemEval: Jose Camacho-Collados, Mohammad Taher Pilehvar, Nigel Collier, Roberto Navigli: \"SemEval-2017 Task 2: Multilingual and Cross-lingual Semantic Word Similarity\"", "SRW: Jose Ramirez, Matthew Garber, Xinhao Wang: \"SoccEval: An Annotation Schema for Rating Soccer Players\"", "SemEval: Isabelle Augenstein, Mrinal Das, Sebastian Riedel, Lakshmi Vikraman, Andrew McCallum: \"SemEval 2017 Task 10: ScienceIE - Extracting Keyphrases and Relations from Scientific Publications\"", "shortpapers: Isabelle Augenstein, Anders S\u00f8gaard: \"Multi-Task Learning of Keyphrase Boundary Classification\"", "SemEval: Tristan Miller, Christian Hempelmann, Iryna Gurevych: \"SemEval-2017 Task 7: Detection and Interpretation of English Puns\"", "SemEval: Keith Cortis, Andr\u00e9 Freitas, Tobias Daudert, Manuela Huerlimann, Manel Zarrouk, Siegfried Handschuh, Brian Davis: \"SemEval-2017 Task 5: Fine-Grained Sentiment Analysis on Financial Microblogs and News\"", "SemEval: Jonathan May, Jay Priyadarshi: \"SemEval-2017 Task 9: Abstract Meaning Representation Parsing and Generation\"", "shortpapers: Jonathan Herzig, Jonathan Berant: \"Neural Semantic Parsing over Multiple Knowledge-bases\"", "SemEval: Sara Rosenthal, Noura Farra, Preslav Nakov: \"SemEval-2017 Task 4: Sentiment Analysis in Twitter\"", "SemEval: Steven Bethard, Guergana Savova, Martha Palmer, James Pustejovsky: \"SemEval-2017 Task 12: Clinical TempEval\"", "SemEval: Youness Mansar, Lorenzo Gatti, Sira Ferradans, Marco Guerini, Jacopo Staiano: \"Fortia-FBK at SemEval-2017 Task 5: Bullish or Bearish? Inferring Sentiment towards Brands from Financial News Headlines\"", "SemEval: Juliano Sales, Siegfried Handschuh, Andr\u00e9 Freitas: \"SemEval-2017 Task 11: End-User Development using Natural Language\"", "SemEval: Zarmeen Nasim: \"IBA-Sys at SemEval-2017 Task 5: Fine-Grained Sentiment Analysis on Financial Microblogs and News\"", "SemEval: Mathieu Cliche: \"BB\\_twtr at SemEval-2017 Task 4: Twitter Sentiment Analysis with CNNs and LSTMs\"", "SemEval: Yufei Xie, Maoquan Wang, Jing Ma, Jian Jiang, Zhao Lu: \"EICA Team at SemEval-2017 Task 3: Semantic and Metadata-based Features for Community Question Answering\"", "SemEval: Aniket Pramanick, Dipankar Das: \"JU CSE NLP @ SemEval 2017 Task 7: Employing Rules to Detect and Interpret English Puns\"", "SemEval: Khoa Nguyen, Dang Nguyen: \"UIT-DANGNT-CLNLP at SemEval-2017 Task 9: Building Scientific Concept Fixing Patterns for Improving CAMR\"", "SemEval: Alon Rozental, Daniel Fleischer: \"Amobee at SemEval-2017 Task 4: Deep Learning System for Sentiment Detection on Twitter\"", "starSEM: Alon Talmor, Mor Geva, Jonathan Berant: \"Evaluating Semantic Parsing against a Simple Web-based Question Answering Model\"", "SemEval: Giuseppe Attardi, Antonio Carta, Federico Errica, Andrea Madotto, Ludovica Pannitto: \"FA3L at SemEval-2017 Task 3: A ThRee Embeddings Recurrent Neural Network for Question Answering\"", "SemEval: Hala Mulki, Hatem Haddad, Mourad Gridach, Ismail Babao\u011flu: \"Tw-StAR at SemEval-2017 Task 4: Sentiment Classification of Arabic Tweets\"", "SemEval: Athanasia Kolovou, Filippos Kokkinos, Aris Fergadis, Pinelopi Papalampidi, Elias Iosif, Nikolaos Malandrakis, Elisavet Palogiannidi, Haris Papageorgiou, Shrikanth Narayanan, Alexandros Potamianos: \"Tweester at SemEval-2017 Task 4: Fusion of Semantic-Affective and pairwise classification models for sentiment analysis in Twitter\"", "SemEval: Nikolay Karpov: \"NRU-HSE at SemEval-2017 Task 4: Tweet Quantification Using Deep Learning Architecture\"", "SemEval: Waleed Ammar, Matthew Peters, Chandra Bhagavatula, Russell Power: \"The AI2 system at SemEval-2017 Task 10 (ScienceIE): semi-supervised end-to-end entity and relation extraction\"", "SemEval: Ramy Baly, Gilbert Badaro, Ali Hamdi, Rawan Moukalled, Rita Aoun, Georges El-Khoury, Ahmad Al Sallab, Hazem Hajj, Nizar Habash, Khaled Shaban, Wassim El-Hajj: \"OMAM at SemEval-2017 Task 4: Evaluation of English State-of-the-Art Sentiment Analysis Models for Arabic and a New Topic-based Model\"", "SemEval: Naman Goyal: \"LearningToQuestion at SemEval 2017 Task 3: Ranking Similar Questions by Learning to Rank Using Rich Features\"", "SemEval: Delphine Charlet, Geraldine Damnati: \"SimBow at SemEval-2017 Task 3: Soft-Cosine Semantic Similarity between Questions for Community Question Answering\"", "SemEval: Basma Hassan, Samir AbdelRahman, Reem Bahgat, Ibrahim Farag: \"FCICU at SemEval-2017 Task 1: Sense-Based Language Independent Semantic Textual Similarity Approach\"", "SemEval: Erwin Marsi, Utpal Kumar Sikdar, Cristina Marco, Biswanath Barik, Rune S\u00e6tre: \"NTNU-1@ScienceIE at SemEval-2017 Task 10: Identifying and Labelling Keyphrases with Conditional Random Fields\"", "SemEval: Mohammed Jabreel, Antonio Moreno: \"SiTAKA at SemEval-2017 Task 4: Sentiment Analysis in Twitter Based on a Rich Set of Features\"", "shortpapers: Mohammed Elrazzaz, Shady Elbassuoni, Khaled Shaban, Chadi Helwe: \"Methodical Evaluation of Arabic Word Embeddings\"", "shortpapers: Mohammed Hasanuzzaman, Sabyasachi Kamila, Mandeep Kaur, Sriparna Saha, Asif Ekbal: \"Temporal Orientation of Tweets for Predicting Income of Users\"", "SemEval: Hussam Hamdan: \"Senti17 at SemEval-2017 Task 4: Ten Convolutional Neural Network Voters for Tweet Polarity Classification\"", "SemEval: Tobias Cabanski, Julia Romberg, Stefan Conrad: \"HHU at SemEval-2017 Task 5: Fine-Grained Sentiment Analysis on Financial Data using Machine Learning Methods\"", "SemEval: Martyna \u015apiewak, Piotr Sobecki, Daniel Kara\u015b: \"OPI-JSA at SemEval-2017 Task 1: Application of Ensemble learning for computing semantic textual similarity\"", "SemEval: Tiago Zini, Karin Becker, Marcelo Dias: \"INF-UFRGS at SemEval-2017 Task 5: A Supervised Identification of Sentiment Score in Tweets and Headlines\"", "SemEval: Cristina Espa\u00f1a-Bonet, Alberto Barr\u00f3n-Cede\u00f1o: \"Lump at SemEval-2017 Task 1: Towards an Interlingua Semantic Similarity\"", "SemEval: Isabel Segura-Bedmar, Crist\u00f3bal Col\u00f3n-Ruiz, Paloma Mart\u00ednez: \"LABDA at SemEval-2017 Task 10: Extracting Keyphrases from Scientific Publications by combining the BANNER tool and the UMLS Semantic Network\"", "SemEval: Simone Filice, Giovanni Da San Martino, Alessandro Moschitti: \"KeLP at SemEval-2017 Task 3: Learning Pairwise Patterns in Community Question Answering\"", "SemEval: Lidia Pivovarova, Lloren\u00e7 Escoter, Arto Klami, Roman Yangarber: \"HCS at SemEval-2017 Task 5: Polarity detection in business news using convolutional neural networks\"", "shortpapers: Michaeel Kazi, Brian Thompson: \"Implicitly-Defined Neural Networks for Sequence Labeling\"", "shortpapers: Deng Cai, Hai Zhao, Zhisong Zhang, Yuan Xin, Yongjian Wu, Feiyue Huang: \"Fast and Accurate Neural Word Segmentation for Chinese\"", "shortpapers: Spandana Gella, Frank Keller: \"An Analysis of Action Recognition Datasets for Language and Vision Tasks\"", "shortpapers: Glorianna Jagfeld, Patrick Ziering, Lonneke van der Plas: \"Evaluating Compound Splitters Extrinsically with Textual Entailment\"", "shortpapers: Lena Reed, Jiaqi Wu, Shereen Oraby, Pranav Anand, Marilyn Walker: \"Learning Lexico-Functional Patterns for First-Person Affect\"", "shortpapers: Yuya Yoshikawa, Yutaro Shigeto, Akikazu Takeuchi: \"STAIR Captions: Constructing a Large-Scale Japanese Image Caption Dataset\"", "shortpapers: Terrence Szymanski: \"Temporal Word Analogies: Identifying Lexical Replacement with Diachronic Word Embeddings\"", "shortpapers: Benjamin Marie, Atsushi Fujita: \"Efficient Extraction of Pseudo-Parallel Sentences from Raw Monolingual Data Using Word Embeddings\"", "shortpapers: Paria Jamshid Lou, Mark Johnson: \"Disfluency Detection using a Noisy Channel Model and a Deep Neural Language Model\"", "shortpapers: Sanja \u0160tajner, Marc Franco-Salvador, Simone Paolo Ponzetto, Paolo Rosso, Heiner Stuckenschmidt: \"Sentence Alignment Methods for Improving Text Simplification Systems\"", "shortpapers: Thomas Kober, Julie Weeds, Jeremy Reffin, David Weir: \"Improving Semantic Composition with Offset Inference\"", "shortpapers: Henning Wachsmuth, Nona Naderi, Ivan Habernal, Yufang Hou, Graeme Hirst, Iryna Gurevych, Benno Stein: \"Argumentation Quality Assessment: Theory vs. Practice\"", "shortpapers: Bogdan Ludusan, Reiko Mazuka, Mathieu Bernard, Alejandrina Cristia, Emmanuel Dupoux: \"The Role of Prosody and Speech Register in Word Segmentation: A Computational Modelling Perspective\"", "shortpapers: Hongyu GUO: \"A Deep Network with Visual Text Composition Behavior\"", "shortpapers: Akiko Eriguchi, Yoshimasa Tsuruoka, Kyunghyun Cho: \"Learning to Parse and Translate Improves Neural Machine Translation\"", "shortpapers: Svetlana Kiritchenko, Saif Mohammad: \"Best-Worst Scaling More Reliable than Rating Scales: A Case Study on Sentiment Intensity Annotation\"", "shortpapers: Hassan Sajjad, Fahim Dalvi, Nadir Durrani, Ahmed Abdelali, Yonatan Belinkov, Stephan Vogel: \"Challenging Language-Dependent Segmentation for Arabic: An Application to Machine Translation and Part-of-Speech Tagging\"", "shortpapers: Oren Melamud, Jacob Goldberger: \"Information-Theory Interpretation of the Skip-Gram Negative-Sampling Objective Function\"", "shortpapers: Keisuke Sakaguchi, Matt Post, Benjamin Van Durme: \"Error-repair Dependency Parsing for Ungrammatical Texts\"", "shortpapers: Beata Beigman Klebanov, Binod Gyawali, Yi Song: \"Detecting Good Arguments in a Non-Topic-Specific Way: An Oxymoron?\"", "shortpapers: Jiaqi Mu, Suma Bhat, Pramod Viswanath: \"Representing Sentences as Low-Rank Subspaces\"", "shortpapers: Azad Abad, Moin Nabi, Alessandro Moschitti: \"Self-Crowdsourcing Training for Relation Extraction\"", "shortpapers: Peng Qi, Christopher D. Manning: \"Arc-swift: A Novel Transition System for Dependency Parsing\"", "shortpapers: Xinyu Hua, Lu Wang: \"Understanding and Detecting Diverse Supporting Arguments on Controversial Issues\"", "shortpapers: Travis Wolfe, Mark Dredze, Benjamin Van Durme: \"Pocket Knowledge Base Population\"", "shortpapers: Afshin Rahimi, Trevor Cohn, Timothy Baldwin: \"A Neural Model for User Geolocation and Lexical Dialectology\"", "shortpapers: Tushar Khot, Ashish Sabharwal, Peter Clark: \"Answering Complex Questions Using Open Information Extraction\"", "shortpapers: Hannah Rashkin, Eric Bell, Yejin Choi, Svitlana Volkova: \"Multilingual Connotation Frames: A Case Study on Social Media for Targeted Sentiment Analysis and Forecast\"", "shortpapers: Alane Suhr, Mike Lewis, James Yeh, Yoav Artzi: \"A Corpus of Natural Language for Visual Reasoning\"", "shortpapers: Emily Prud'hommeaux, Jan van Santen, Douglas Gliner: \"Vector space models for evaluating semantic fluency in autism\"", "shortpapers: Kartik Goyal, Chris Dyer, Taylor Berg-Kirkpatrick: \"Differentiable Scheduled Sampling for Credit Assignment\"", "shortpapers: Tsutomu Hirao, Masaaki Nishino, Masaaki Nagata: \"Oracle Summaries of Compressive Summarization\"", "shortpapers: Prashanth Vijayaraghavan, Soroush Vosoughi, Deb Roy: \"Twitter Demographic Classification Using Deep Multi-modal Multi-task Learning\"", "shortpapers: Shun Hasegawa, Yuta Kikuchi, Hiroya Takamura, Manabu Okumura: \"Japanese Sentence Compression with a Large Training Dataset\"", "shortpapers: Rob van der Goot, Gertjan van Noord: \"Parser Adaptation for Social Media by Integrating Normalization\"", "shortpapers: Alexandros Komninos, Suresh Manandhar: \"Feature-Rich Networks for Knowledge Base Completion\"", "SRW: Facundo Carrillo: \"Computational Characterization of Mental States: A Natural Language Processing Approach\"", "SRW: Nandan Sukthankar, Sanket Maharnawar, Pranay Deshmukh, Yashodhara Haribhakta, Vibhavari Kamble: \"nQuery - A Natural Language Statement to SQL Query Generator\"", "SRW: Yui Suzuki, Tomoyuki Kajiwara, Mamoru Komachi: \"Building a Non-Trivial Paraphrase Corpus Using Multiple Machine Translation Systems\"", "SRW: Vasu Sharma, Ankita Bishnu, Labhesh Patel: \"Segmentation Guided Attention Networks for Visual Question Answering\"", "SRW: Hang Li, Haozheng Wang, Zhenglu Yang, Masato Odagaki: \"Variation Autoencoder Based Network Representation Learning for Classification\"", "SRW: Srishti Aggarwal, Radhika Mamidi: \"Automatic Generation of Jokes in Hindi\"", "SRW: Haoran Zhang, Diane Litman: \"Word Embedding for Response-To-Text Assessment of Evidence\"", "SRW: Katira Soleymanzadeh: \"Domain Specific Automatic Question Generation from Text\"", "SRW: Tina Fang, Martin Jaggi, Katerina Argyraki: \"Generating Steganographic Text with LSTMs\"", "SRW: Misato Hiraga: \"Predicting Depression for Japanese Blog Text\"", "SRW: Petr Babkin, Sergei Nirenburg: \"Fast Forward Through Opportunistic Incremental Meaning Representation Construction\"", "SRW: Ganesh Jawahar: \"Improving Distributed Representations of Tweets - Present and Future\"", "starSEM: Sorcha Gilroy, Adam Lopez, Sebastian Maneth: \"Parsing Graphs with Regular Graph Grammars\"", "starSEM: Abhijeet Gupta, Gemma Boleda, Sebastian Pad\u00f3: \"Distributed Prediction of Relations for Entities: The Easy, The Difficult, and The Impossible\"", "starSEM: Tibor Kiss, Francis Jeffry Pelletier, Halima Husic, Johanna Poppek: \"Issues of Mass and Count: Dealing with `Dual-Life' Nouns\"", "starSEM: Ekaterina Shutova, Andreas Wundsam, Helen Yannakoudakis: \"Semantic Frames and Visual Scenes: Learning Semantic Role Inventories from Image and Video Descriptions\"", "starSEM: Saif Mohammad, Felipe Bravo-Marquez: \"Emotion Intensities in Tweets\"", "starSEM: Zoran Medi\u0107, Jan \u0160najder, Sebastian Pad\u00f3: \"Does Free Word Order Hurt? Assessing the Practical Lexical Function Model for Croatian\"", "starSEM: Waseem Gharbieh, Virendrakumar Bhavsar, Paul Cook: \"Deep Learning Models For Multiword Expression Identification\"", "starSEM: Anne Cocos, Marianna Apidianaki, Chris Callison-Burch: \"Mapping the Paraphrase Database to WordNet\"", "starSEM: Kathrin Eichler, Feiyu Xu, Hans Uszkoreit, Sebastian Krause: \"Generating Pattern-Based Entailment Graphs for Relation Extraction\"", "starSEM: Nabiha Asghar, Pascal Poupart, Xin Jiang, Hang Li: \"Deep Active Learning for Dialogue Generation\"", "starSEM: Sneha Rajana, Chris Callison-Burch, Marianna Apidianaki, Vered Shwartz: \"Learning Antonyms with Paraphrases and a Morphology-Aware Neural Network\"", "starSEM: Gregory Finley, Stephanie Farmer, Serguei Pakhomov: \"What Analogies Reveal about Word Vectors and their Compositionality\"", "TextGraphs-11: Collin Baker, Michael Ellsworth: \"Graph Methods for Multilingual FrameNets\"", "TextGraphs-11: Kazuki Fukui, Takamasa Oshikiri, Hidetoshi Shimodaira: \"Spectral Graph-Based Method of Multimodal Word Embedding\""], "labels": [0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1], "texts": ["Dimensions of Abusive Language on Twitter.\n\nIn this paper, we use a new categorical form of multidimensional register analysis to identify the main dimensions of functional linguistic variation in a corpus of abusive language, consisting of racist and sexist Tweets. By analysing the use of a wide variety of parts-of-speech and grammatical constructions, as well as various features related to Twitter and computer-mediated communication, we discover three dimensions of linguistic variation in this corpus, which we interpret as being related to the degree of interactive, antagonistic and attitudinal language exhibited by individual Tweets. We then demonstrate that there is a significant functional difference between racist and sexist Tweets, with sexists Tweets tending to be more interactive and attitudinal than racist Tweets.", "Vectors for Counterspeech on Twitter.\n\nA study of conversations on Twitter found that some arguments between strangers led to favorable change in discourse and even in attitudes. The authors propose that such exchanges can be usefully distinguished according to whether individuals or groups take part on each side, since the opportunity for a constructive exchange of views seems to vary accordingly.", "Detecting Nastiness in Social Media.\n\nAlthough social media has made it easy for people to connect on a virtually unlimited basis, it has also opened doors to people who misuse it to undermine, harass, humiliate, threaten and bully others. There is a lack of adequate resources to detect and hinder its occurrence. In this paper, we  present our initial NLP approach to detect invective posts as a first step to eventually detect and deter cyberbullying. We crawl data containing profanities and then determine whether or not it contains invective. Annotations on this data are improved iteratively by in-lab annotations and crowdsourcing. We pursue different NLP approaches containing various typical and some newer techniques to distinguish the use of swear words in a neutral way from those instances in which they are used in an insulting way. We also show that this model not only works for our data set, but also can be successfully applied to different data sets.", "Mahtab at SemEval-2017 Task 2: Combination of Corpus-based and Knowledge-based Methods to Measure Semantic Word Similarity.\n\nIn this paper, we describe our proposed method for measuring semantic similarity for a given pair of words at SemEval-2017 monolingual semantic word similarity task. We use a combination of knowledge-based and corpus-based techniques. We use FarsNet, the Persian Word Net, besides deep learning techniques to extract the similarity of words. We evaluated our proposed approach on Persian (Farsi) test data at SemEval-2017. It outperformed the other participants and ranked the first in the challenge.", "Technology Solutions to Combat Online Harassment.\n\nThis work is part of a new initiative to use machine learning to identify online harassment in social media and comment streams. Online harassment goes under-reported due to the reliance on humans to identify and report harassment, reporting that is further slowed by requirements to fill out forms providing context. In addition, the time for moderators to respond and apply human judgment can take days, but response times in terms of minutes are needed in the online context. Though some of the major social media companies have been doing proprietary work in automating the detection of harassment, there are few tools available for use by the public. In addition, the amount of labeled online harassment data and availability of cross-platform online harassment datasets is limited. We present the methodology used to create a harassment dataset and classifier and the dataset used to help the system learn what harassment looks like.", "Class-based Prediction Errors to Detect Hate Speech with Out-of-vocabulary Words.\n\nCommon approaches  to text categorization essentially rely either on n-gram counts or on word embeddings. This presents important difficulties in highly dynamic or quickly-interacting environments, where the appearance of new words and/or varied misspellings is the norm. A paradigmatic example of this situation is abusive online behavior, with social networks and media platforms struggling to effectively combat uncommon or non-blacklisted hate words. To better deal with these issues in those fast-paced environments, we propose using the error signal of class-based language models as input to text classification algorithms. In particular, we train a next-character prediction model for any given class and then exploit the error of such class-based models to inform a neural network classifier. This way, we shift from the \u2018ability to describe' seen documents to the \u2018ability to predict' unseen content. Preliminary studies using out-of-vocabulary splits from abusive tweet data show promising results, outperforming competitive text categorization strategies by 4-11%.", "Deep Learning for User Comment Moderation.\n\nExperimenting with a new dataset of 1.6M user comments from a Greek news portal and existing datasets of EnglishWikipedia comments, we show that an RNN outperforms the previous state of the art in moderation. A deep, classification-specific attention mechanism improves further the overall performance of the RNN. We also compare against a CNN and a word-list baseline, considering both fully automatic and semi-automatic moderation.", "Revisiting Recurrent Networks for Paraphrastic Sentence Embeddings.\n\nWe consider the problem of learning general-purpose, paraphrastic sentence embeddings, revisiting the setting of Wieting et al. (2016b). While they found LSTM recurrent networks to underperform word averaging, we present several developments that together produce the opposite conclusion. These include training on sentence pairs rather than phrase pairs, averaging states to represent sequences, and regularizing aggressively. These improve LSTMs in both transfer learning and supervised settings. We also introduce a new recurrent architecture, the Gated Recurrent Averaging Network, that is inspired by averaging and LSTMs while outperforming them both. We analyze our learned models, finding evidence of preferences for particular parts of speech and dependency relations.", "MITRE at SemEval-2017 Task 1: Simple Semantic Similarity.\n\nThis paper describes MITRE's participation in the Semantic Textual Similarity task (SemEval-2017 Task 1), which evaluated machine learning approaches to the identification of similar meaning among text snippets in English, Arabic, Spanish, and Turkish. We detail the techniques we explored ranging from simple bag-of-ngrams classifiers to neural architectures with varied attention and alignment mechanisms. Linear regression is used to tie the systems together into an ensemble submitted for evaluation. The resulting system is capable of matching human similarity ratings of image captions with correlations of 0.73 to 0.83 in monolingual settings and 0.68 to 0.78 in cross-lingual conditions, demonstrating the power of relatively simple approaches.", "Unsupervised Context-Sensitive Spelling Correction of Clinical Free-Text with Word and Character N-Gram Embeddings.\n\nWe present an unsupervised context-sensitive spelling correction method for clinical free-text that uses word and character n-gram embeddings. Our method generates misspelling replacement candidates and ranks them according to their semantic fit, by calculating a weighted cosine similarity between the vectorized representation of a candidate and the misspelling context. We greatly outperform two baseline off-the-shelf spelling correction tools on a manually annotated MIMIC-III test set, and counter the frequency bias of an optimized noisy channel model, showing that neural embeddings can be successfully exploited to include context-awareness in a spelling correction model.", "Adapting Pre-trained Word Embeddings For Use In Medical Coding.\n\nWord embeddings are a crucial component in modern NLP. Pre-trained embeddings released by different groups have been a major reason for their popularity. However, they are trained on generic corpora, which limits their direct use for domain specific tasks. In this paper, we propose a method to add task specific information to pre-trained word embeddings. Such information can improve their utility. We add information from medical coding data, as well as the first level from the hierarchy of ICD-10 medical code set to different pre-trained word embeddings. We adapt CBOW algorithm from the word2vec package for our purpose. We evaluated our approach on five different pre-trained word embeddings. Both the original word embeddings, and their modified versions (the ones with added information) were used for automated review of medical coding. The modified word embeddings give an improvement in f-score by 1% on the 5-fold evaluation on a private medical claims dataset. Our results show that adding extra information is possible and beneficial for the task at hand.", "Unsupervised Domain Adaptation for Clinical Negation Detection.\n\nDetecting negated concepts in clinical texts is an important part of NLP information extraction systems. However, generalizability of negation systems is lacking, as cross-domain experiments suffer dramatic performance losses. We examine the performance of multiple unsupervised domain adaptation algorithms on clinical negation detection, finding only modest gains that fall well short of in-domain performance.", "Biomedical Event Trigger Identification Using Bidirectional Recurrent Neural Network Based Models.\n\nBiomedical events describe complex interactions between various biomedical entities. Event trigger is a word or a phrase which typically signifies the occurrence of an event. Event trigger identification is an important first step in all event extraction methods. However many of the current approaches either rely on complex hand-crafted features or consider features only within a window. In this paper we propose a method that takes the advantage of recurrent neural network (RNN) to extract higher level features present across the sentence. Thus hidden state representation of RNN along with word and entity type embedding as features avoid relying on the complex hand-crafted features generated using various NLP toolkits. Our experiments have shown to achieve state-of-art F1-score on Multi Level Event Extraction (MLEE) corpus. We have also performed category-wise analysis of the result and discussed the importance of various features in trigger identification task.", "Insights into Analogy Completion from the Biomedical Domain.\n\nAnalogy completion has been a popular task in recent years for evaluating the semantic properties of word embeddings, but the standard methodology makes a number of assumptions about analogies that do not always hold, either in recent benchmark datasets or when expanding into other domains.  Through an analysis of analogies in the biomedical domain, we identify three assumptions: that of a Single Answer for any given analogy, that the pairs involved describe the Same Relationship, and that each pair is Informative with respect to the other. We propose modifying the standard methodology to relax these assumptions by allowing for multiple correct answers, reporting MAP and MRR in addition to accuracy, and using multiple example pairs.  We further present BMASS, a novel dataset for evaluating linguistic regularities in biomedical embeddings, and demonstrate that the relationships described in the dataset pose significant semantic challenges to current word embedding methods.", "EviNets: Neural Networks for Combining Evidence Signals for Factoid Question Answering.\n\nA critical task for question answering is the final answer selection stage, which has to combine multiple signals available about each answer candidate. This paper proposes EviNets: a novel neural network architecture for factoid question answering. EviNets scores candidate answer entities by combining the available supporting evidence, e.g., structured knowledge bases and unstructured text documents. EviNets represents each piece of evidence with a dense embeddings vector, scores their relevance to the question, and aggregates the support for each candidate to predict their final scores. Each of the components is generic and allows plugging in a variety of models for semantic similarity scoring and information aggregation. We demonstrate the effectiveness of EviNets in experiments on the existing TREC QA and WikiMovies benchmarks, and on the new Yahoo! Answers dataset introduced in this paper. EviNets can be extended to other information types and could facilitate future work on combining evidence signals for joint reasoning in question answering.", "Neural Question Answering at BioASQ 5B.\n\nThis paper describes our submission to the 2017 BioASQ challenge. We participated in Task B, Phase B which is concerned with biomedical question answering (QA). We focus on factoid and list question, using an extractive QA model, that is, we restrict our system to output  substrings of the provided text snippets. At the core of our system, we use FastQA, a state-of-the-art neural QA system. We extended it with biomedical word embeddings and changed its answer layer to be able to answer list questions in addition to factoid questions. We pre-trained the model on a large-scale open-domain QA dataset, SQuAD, and then fine-tuned the parameters on the BioASQ training set. With our approach, we achieve state-of-the-art results on factoid questions and competitive results on list questions.", "Neural Domain Adaptation for Biomedical Question Answering.\n\nFactoid question answering (QA) has recently benefited from the development of deep learning (DL) systems. Neural network models outperform traditional approaches in domains where large datasets exist, such as SQuAD (ca. 100,000 questions) for Wikipedia articles. However, these systems have not yet been applied to QA in more specific domains, such as biomedicine, because datasets are generally too small to train a DL system from scratch. For example, the BioASQ dataset for biomedical QA comprises less then 900 factoid (single answer) and list (multiple answers) QA instances. In this work, we adapt a neural QA system trained on a large open-domain dataset (SQuAD, source) to a biomedical dataset (BioASQ, target) by employing various transfer learning techniques. Our network architecture is based on a state-of-the-art QA system, extended with biomedical word embeddings and a novel mechanism to answer list questions. In contrast to existing biomedical QA systems, our system does not rely on domain-specific ontologies, parsers or entity taggers, which are expensive to create. Despite this fact, our systems achieve state-of-the-art results on factoid questions and competitive results on list questions.", "Event Detection and Semantic Storytelling: Generating a Travelogue from a large Collection of Personal Letters.\n\nWe present an approach at identifying a specific class of events, movement action events (MAEs), in a data set that consists of ca. 2,800 personal letters exchanged by the German architect Erich Mendelsohn and his wife, Luise. A backend system uses these and other semantic analysis results as input for an authoring environment that digital curators can use to produce new pieces of digital content. In our example case, the human expert will receive recommendations from the system with the goal of putting together a travelogue, i.e., a description of the trips and journeys undertaken by the couple. We describe the components and architecture and also apply the system to news data.", "Deep Learning for Biomedical Information Retrieval: Learning Textual Relevance from Click Logs.\n\nWe describe a Deep Learning approach to modeling the relevance of a document's text to a query, applied to biomedical literature. Instead of mapping each document and query to a common semantic space, we compute a variable-length difference vector between the query and document which is then passed through a deep convolution stage followed by a deep regression network to produce the estimated probability of the document's relevance to the query. Despite the small amount of training data, this approach produces a more robust predictor than computing similarities between semantic vector representations of the query and document, and also results in significant improvements over traditional IR text factors. In the future, we plan to explore its application in improving PubMed search.", "Extracting Personal Medical Events for User Timeline Construction using Minimal Supervision.\n\nIn this paper, we describe a system for automatic construction of user disease progression timelines from their posts in online support groups using minimal supervision. In recent years, several online support groups have been established which has led to a huge increase in the amount of patient-authored text available. Creating systems which can automatically extract important medical events and create disease progression timelines for users from such text can help in patient health monitoring as well as studying links between medical events and users' participation in support groups. Prior work in this domain has used manually constructed keyword sets to detect medical events. In this work, our aim is to perform medical event detection using minimal supervision in order to develop a more general timeline construction system. Our system achieves an accuracy of 55.17%, which is 92\\% of the performance achieved by a supervised baseline system.", "Detecting Dementia through Retrospective Analysis of Routine Blog Posts by Bloggers with Dementia.\n\nWe investigate if writers with dementia can be automatically distinguished from those without by analyzing linguistic markers in written text, in the form of blog posts. We have built a corpus of several thousand blog posts, some by people with dementia and others by people with loved ones with dementia. We use this dataset to train and test several machine learning methods, and achieve prediction performance at a level far above the baseline.", "Role-Preserving Redaction of Medical Records to Enable Ontology-Driven Processing.\n\nElectronic medical records (EMR) have largely replaced hand-written patient files in healthcare. The growing pool of EMR data presents a significant resource in medical research, but the U.S. Health Insurance Portability and Accountability Act (HIPAA) mandates redacting medical records before performing any analysis on the same. This process complicates obtaining medical data and can remove much useful information from the record. As part of a larger project involving ontology-driven medical processing, we employ a method of recognizing protected health information (PHI) that maps to ontological terms. We then use the relationships defined in the ontology to redact medical texts so that roles and semantics of terms are retained without compromising anonymity. The method is evaluated by clinical experts on several hundred medical documents, achieving up to a 98.8% f-score, and has already shown promise for retaining semantic information in later processing.", "Automated Preamble Detection in Dictated Medical Reports.\n\nDictated medical reports very often feature a preamble containing metainformation about the report such as patient and physician names, location and name of the clinic, date of procedure, and so on. In the medical transcription process, the preamble is usually omitted from the final report, as it contains information already available in the electronic medical record. We present a method which is able to automatically identify preambles in medical dictations. The method makes use of stateof- the-art NLP techniques including word embeddings and Bi-LSTMs and achieves preamble detection performance superior to humans.", "Deep Learning for Punctuation Restoration in Medical Reports.\n\nIn clinical dictation, speakers try to be as concise as possible to save time, often resulting in utterances without explicit punctuation commands.  Since the end product of a dictated report, e.g. an out-patient letter, does require correct orthography, including exact punctuation, the latter need to be restored, preferably by automated means.  This paper describes a method for punctuation restoration based on a state-of-the-art stack of NLP and machine learning techniques including B-RNNs with an attention mechanism and late fusion, as well as a feature extraction technique tailored to the processing of medical terminology using a novel vocabulary reduction model.  To the best of our knowledge, the resulting performance is superior to that reported in prior art on similar tasks.", "Initializing neural networks for hierarchical multi-label text classification.\n\nMany tasks in the biomedical domain require the assignment of one or more predefined labels to input text, where the labels are a part of a hierarchical structure (such as a taxonomy). The conventional approach is to use a one-vs.-rest (OVR) classification setup, where a binary classifier is trained for each label in the taxonomy or ontology where all instances not belonging to the class are considered negative examples. The main drawbacks to this approach are that dependencies between classes are not leveraged in the training and classification process, and the additional computational cost of training parallel classifiers. In this paper, we apply a new method for hierarchical multi-label text classification that initializes a neural network model final hidden layer such that it leverages label co-occurrence relations such as hypernymy. This approach elegantly lends itself to hierarchical classification. We evaluated this approach using two hierarchical multi-label text classification tasks in the biomedical domain using both sentence- and document-level classification. Our evaluation shows promising results for this approach.", "TopicThunder at SemEval-2017 Task 4: Sentiment Classification Using a Convolutional Neural Network with Distant Supervision.\n\nIn this paper, we propose a classifier for predicting topic-specific sentiments of English Twitter messages. Our method is based on a 2-layer CNN.With a distant supervised phase we leverage a large amount of weakly-labelled training data. Our system was evaluated on the data provided by the SemEval-2017 competition in the Topic-Based Message Polarity Classification subtask, where it ranked 4th place.", "FORGe at SemEval-2017 Task 9: Deep sentence generation based on a sequence of graph transducers.\n\nWe present the contribution of Universitat Pompeu Fabra's NLP group to the SemEval Task 9.2 (AMR-to-English Generation). The proposed generation pipeline comprises: (i) a series of rule-based graph-transducers for the syntacticization of the input graphs and the resolution of morphological agreements, and (ii) an off-the-shelf statistical linearization component.", "Aligning Script Events with Narrative Texts.\n\nScript knowledge plays a central role in text understanding and is relevant for a variety of downstream tasks. In this paper, we consider two recent datasets which provide a rich and general representation of script events in terms of paraphrase sets. We introduce the task of mapping event mentions in narrative texts to such script event types, and present a model for this task that exploits rich linguistic representations as well as information on temporal ordering. The results of our experiments demonstrate that this complex task is indeed feasible.", "Creation and evaluation of a dictionary-based tagger for virus species and proteins.\n\next mining automatically extracts information from the literature with the goal of making it available for further analysis, for example by incorporating it into biomedical databases.  A key first step towards this goal is to identify and normalize the named entities, such as proteins and species, which are mentioned in text.  Despite the large detrimental impact that viruses have on human and agricultural health, very little previous text-mining work has focused on identifying virus species and proteins in the literature.  Here, we present an improved dictionary-based system for viral species and the first dictionary for viral proteins, which we benchmark on a new corpus of 300 manually annotated abstracts.  We achieve 81.0\\% precision and 72.7\\% recall at the task of recognizing and normalizing viral species and 76.2\\% precision and 34.9\\% recall on viral proteins.  These results are achieved despite the many challenges involved with the names of viral species and, especially, proteins. This work provides a foundation that can be used to extract more complicated relations about viruses from the literature.", "Biomedical Event Extraction using Abstract Meaning Representation.\n\nWe propose a novel, Abstract Meaning Representation (AMR) based approach to identifying molecular events/interactions in biomedical text. Our key contributions are: (1) an empirical validation of our hypothesis that an event is a subgraph of the AMR graph, (2) a neural network-based model that identifies such an event subgraph given an AMR, and (3) a distant supervision based approach to gather additional training data. We evaluate our approach on the 2013 Genia Event Extraction dataset and show promising results.", "Are You Asking the Right Questions? Teaching Machines to Ask Clarification Questions.\n\nInquiry is fundamental to communication, and machines cannot effectively collaborate with humans unless they can ask questions. In this thesis work, we explore how can we teach machines to ask clarification questions when faced with uncertainty, a goal of increasing importance in today's automated society. We do a preliminary study using data from StackExchange, a plentiful online resource where people routinely ask clarifying questions to posts so that they can better offer assistance to the original poster. We build neural network models inspired by the idea of the expected value of perfect information: a good question is one whose expected answer is going to be most useful. To build generalizable systems, we propose two future research directions: a template-based model and a sequence-to-sequence based neural generative model.", "Protein Word Detection using Text Segmentation Techniques.\n\nLiterature in Molecular Biology is abundant with linguistic metaphors. There have been works in the past that attempt to draw parallels between linguistics and biology, driven by the fundamental premise that proteins have a language of their own. Since word detection is crucial to the decipherment of any  unknown language, we attempt to establish a problem mapping from natural language text to protein sequences at the level of words. Towards this end, we explore the use of an unsupervised text segmentation algorithm to the task of extracting ``biological words'' from protein sequences. In particular, we demonstrate the effectiveness of using domain knowledge to complement data driven approaches in the text segmentation task, as well as in its biological counterpart. We also propose a novel extrinsic evaluation measure for protein words through protein family classification.", "Investigating the Documentation of Electronic Cigarette Use in the Veteran Affairs Electronic Health Record: A Pilot Study.\n\nIn this paper, we present pilot work on characterising the documentation of electronic cigarettes (e-cigarettes) in the United States Veterans Administration Electronic Health Record.  The Veterans Health Administration is the largest health care system in the United States with 1,233 health care facilities nationwide, serving 8.9 million veterans per year.   We identified a random sample of 2000 Veterans Administration patients, coded as current tobacco users, from 2008 to 2014.                       Using simple keyword matching techniques combined with qualitative analysis, we investigated the prevalence and distribution of e-cigarette terms in these clinical notes, discovering that for current smokers, 11.9\\% of  patient records contain an e-cigarette related term.", "Assessing the performance of Olelo, a real-time biomedical question answering application.\n\nQuestion answering (QA) can support physicians and biomedical researchers to find answers to their questions in the scientific literature. Such systems process large collections of documents in real time and include many natural language processing (NLP) procedures. We recently developed Olelo, a QA system for biomedicine which includes various NLP components, such as question processing, document and passage retrieval, answer processing and multi-document summarization. In this work, we present an evaluation of our system on the the fifth BioASQ challenge. We participated with the current state of the application and with an extension based on semantic role labeling that we are currently investigating. In addition to the BioASQ evaluation, we compared our system to other on-line biomedical QA systems in terms of the response time and the quality of the answers.", "A parallel collection of clinical trials in Portuguese and English.\n\nParallel collections of documents are crucial resources for training and evaluating machine translation (MT) systems. Even though large collections are available for certain domains and language pairs, these are still scarce in the biomedical domain. We developed a parallel corpus of clinical trials in Portuguese and English. The documents are derived from the Brazilian Clinical Trials Registry and the corpus currently contains a total of 1188 documents. In this paper, we describe the corpus construction and discuss the quality of the translation and the sentence alignment that we obtained.", "Olelo: A Question Answering Application for Biomedicine.\n\nDespite the importance of the biomedical domain, there are few reliable applications to support researchers and physicians for retrieving particular facts that fit their needs. Users typically rely on search engines that only support keyword- and filter-based searches. We present Olelo, a question answering system for biomedicine. Olelo is built on top of an in-memory database, integrates domain resources, such as document collections and terminologies, and uses various natural language processing components. Olelo is fast, intuitive and easy to use. We evaluated the systems on two use cases: answering questions related to a particular gene and on the BioASQ benchmark. Olelo is available at: https://hpi.de/plattner/olelo.", "External Evaluation of Event Extraction Classifiers for Automatic Pathway Curation: An extended study of the mTOR pathway.\n\nThis paper evaluates the impact of various event extraction systems on automatic pathway curation using the popular mTOR pathway. We quantify the impact of training data sets as well as different machine learning classifiers and show that some improve the quality of automatically extracted pathways.", "Macquarie University at BioASQ 5b -- Query-based Summarisation Techniques for Selecting the Ideal Answers.\n\nMacquarie University's contribution to the BioASQ challenge (Task 5b Phase B) focused on the use of query-based extractive summarisation techniques for the generation of the ideal answers. Four runs were submitted, with approaches ranging from a trivial system that selected the first $n$ snippets, to the use of deep learning approaches under a regression framework. Our experiments and the ROUGE results of the five test batches of BioASQ indicate surprisingly good results for the trivial approach. Overall, most of our runs on the first three test batches achieved the best ROUGE-SU4 results in the challenge.", "A Simple and Accurate Syntax-Agnostic Neural Model for Dependency-based Semantic Role Labeling.\n\nWe introduce a simple and accurate neural model for dependency-based semantic role labeling. Our model predicts predicate-argument dependencies relying on states of a bidirectional LSTM encoder. The semantic role labeler achieves competitive performance on English, even without any kind of syntactic information and only using local inference. However, when automatically predicted part-of-speech tags are provided as input, it substantially outperforms all previous local models and approaches the best reported results on the English CoNLL-2009 dataset. We also consider Chinese, Czech and Spanish where our approach also achieves competitive results. Syntactic parsers are unreliable on out-of-domain data, so standard (i.e., syntactically-informed) SRL models are hindered when tested in this setting. Our syntax-agnostic model appears more robust, resulting in the best reported results on standard out-of-domain test sets.", "Extracting Drug-Drug Interactions with Attention CNNs.\n\nWe propose a novel attention mechanism for a Convolutional Neural Network (CNN)-based Drug-Drug Interaction (DDI) extraction model. CNNs have been shown to have a great potential on DDI extraction tasks; however, attention mechanisms, which emphasize important words in the sentence of a target-entity pair, have not been investigated with the CNNs despite the fact that attention mechanisms are shown to be effective for a general domain relation classification task. We evaluated our model on the Task 9.2 of the DDIExtraction-2013 shared task. As a result, our attention mechanism improved the performance of our base CNN-based DDI model, and the model achieved an F-score of 69.12%, which is competitive with the state-of-the-art models.", "Automatic classification of doctor-patient questions for a virtual patient record query task.\n\nWe present the work-in-progress of automating the classification of doctor-patient questions in the context of a simulated consultation with a virtual patient. We classify questions according to the computational strategy (rule-based or other) needed for looking up data in the clinical record. We compare \u2018traditional' machine learning methods (Gaussian and Multinomial Naive Bayes, and Support Vector Machines) and a neural network classifier (FastText). We obtained the best results with the SVM using semantic annotations, whereas the neural classifier achieved promising results without it.", "A Biomedical Question Answering System in BioASQ 2017.\n\nQuestion answering, the identification of short accurate answers to users questions, is a longstanding challenge widely studied over the last decades in the open domain. However, it still requires further efforts in the biomedical domain. In this paper, we describe our participation in phase B of task 5b in the 2017 BioASQ challenge using our biomedical question answering system. Our system, dealing with four types of questions (i.e., yes/no, factoid, list, and summary), is based on (1) a dictionary-based approach for generating the exact answers of yes/no questions, (2) UMLS metathesaurus and term frequency metric for extracting the exact answers of factoid and list questions, and (3) the BM25 model and UMLS concepts for retrieving the ideal answers (i.e., paragraph-sized summaries). Preliminary results show that our system achieves good and competitive results in both exact and ideal answers extraction tasks as compared with the participating systems.", "Evaluating Feature Extraction Methods for Knowledge-based Biomedical Word Sense Disambiguation.\n\nIn this paper, we present an analysis of feature extraction methods via dimensionality reduction for the task of biomedical Word Sense Disambiguation (WSD). We modify the vector representations in the 2-MRD WSD algorithm, and evaluate four dimensionality reduction methods: Word Embeddings using Continuous Bag of Words and Skip Gram, Singular Value Decomposition (SVD), and Principal Component Analysis (PCA). We also evaluate the effects of vector size on the performance of each of these methods. Results are evaluated on five standard evaluation datasets (Abbrev.100, Abbrev.200, Abbrev.300, NLM-WSD, and MSH-WSD). We find that vector sizes of 100 are sufficient for all techniques except SVD, for which a vector size of 1500 is referred. We also show that SVD performs on par with Word Embeddings for all but one dataset.", "English Event Detection With Translated Language Features.\n\nWe propose novel radical features from automatic translation for event extraction. Event detection is a complex language processing task for which it is expensive to collect training data, making generalisation challenging. We derive meaningful subword features from automatic translations into target language. Results suggest this method is particularly useful when using languages with writing systems that facilitate easy decomposition into subword features, e.g., logograms and Cangjie. The best result combines logogram features from Chinese and Japanese with syllable features from Korean, providing an additional 3.0 points f-score when added to state-of-the-art generalisation features on the TAC KBP 2015 Event Nugget task.", "Identifying Comparative Structures in Biomedical Text.\n\nComparison sentences are very commonly used by authors in biomedical literature to report results of experiments. In such comparisons, authors typically make observations under two different scenarios. In this paper, we present a system to automatically identify such comparative sentences and their components i.e. the compared entities, the scale of the comparison and the aspect on which the entities are being compared. Our methodology is based on dependencies obtained by applying a parser to extract a wide range of comparison structures. We evaluated our system for its effectiveness in identifying comparisons and their components. The system achieved a F-score of 0.87 for comparison sentence identification and 0.77-0.81 for identifying its components.", "Improving Correlation with Human Judgments by Integrating Semantic Similarity with Second--Order Vectors.\n\nVector space methods that measure semantic similarity and relatedness often rely on distributional information such as co--occurrence frequencies or statistical measures of association to weight the importance of particular co--occurrences. In this paper, we extend these methods by incorporating a measure of semantic similarity based on a human curated taxonomy into a second--order vector representation. This results in a measure of semantic relatedness that combines both the contextual  information available in a corpus--based vector space representation with the semantic knowledge found in a biomedical ontology. Our results show that incorporating semantic similarity into a second order co-occurrence matrices improves correlation with human judgments for both similarity and relatedness, and that our method compares favorably to various different word embedding methods that have recently been evaluated on the same reference standards we have used.", "Detecting mentions of pain and acute confusion in Finnish clinical text.\n\nWe study and compare two different approaches to the task of automatic assignment of predefined classes to clinical free-text narratives. In the first approach this is treated as a traditional mention-level named-entity recognition task, while the second approach treats it as a sentence-level multi-label classification task. Performance comparison across these two approaches is conducted in the form of sentence-level evaluation and state-of-the-art methods for both approaches are evaluated. The experiments are done on two data sets consisting of Finnish clinical text, manually annotated with respect to the topics pain and acute confusion. Our results suggest that the mention-level named-entity recognition approach outperforms sentence-level classification overall, but the latter approach still manages to achieve the best prediction scores on several annotation classes.", "Representation of complex terms in a vector space structured by an ontology for a normalization task.\n\nWe propose in this paper a semi-supervised method for labeling terms of texts with concepts of a domain ontology. The method generates continuous vector representations of complex terms in a semantic space structured by the ontology. The proposed method relies on a distributional semantics approach, which generates initial vectors for each of the extracted terms. Then these vectors are embedded in the vector space constructed from the structure of the ontology. This embedding is carried out by training a linear model. Finally, we apply a distance calculation to determine the proximity between vectors of terms and vectors of concepts and thus to assign ontology labels to terms. We have evaluated the quality of these representations for a normalization task by using the concepts of an ontology as semantic labels. Normalization of terms is an important step to extract a part of the information containing in texts, but the vector space generated might find other applications. The performance of this method is comparable to that of the state of the art for this task of standardization, opening up encouraging prospects.", "Painless Relation Extraction with Kindred.\n\nRelation extraction methods are essential for creating robust text mining tools to help researchers find useful knowledge in the vast published literature. Easy-to-use and generalizable methods are needed to encourage an ecosystem in which researchers can easily use shared resources and build upon each others' methods. We present the Kindred Python package for relation extraction. It builds upon methods from the most successful tools in the recent BioNLP Shared Task to predict high-quality predictions with low computational cost. It also integrates with PubAnnotation, PubTator, and BioNLP Shared Task data in order to allow easy development and application of relation extraction models.", "Target word prediction and paraphasia classification in spoken discourse.\n\nWe present a system for automatically detecting and classifying phonologically anomalous productions in the speech of individuals with aphasia. Working from transcribed discourse samples, our system identifies neologisms, and uses a combination of string alignment and language models to produce a lattice of plausible words that the speaker may have intended to produce. We then score this lattice according to various features, and attempt to determine whether the anomalous production represented a phonemic error or a genuine neologism. This approach has the potential to be expanded to consider other types of paraphasic errors, and could be applied to a wide variety of screening and therapeutic applications.", "Results of the fifth edition of the BioASQ Challenge.\n\nThe goal of the BioASQ challenge is to engage researchers into creating cuttingedge biomedical information systems. Specifically, it aims at the promotion of systems and methodologies that are able to deal with a plethora of different tasks in the biomedical domain. This is achieved through the organization of challenges. The fifth challenge consisted of three tasks: semantic indexing, question answering and a new task on information extraction. In total, 29 teams with more than 95 systems participated in the challenge. Overall, as in previous years, the best systems were able to outperform the strong baselines. This suggests that stateof- the art systems are continuously improving, pushing the frontier of research.", "Toward Automated Early Sepsis Alerting: Identifying Infection Patients from Nursing Notes.\n\nSevere sepsis and septic shock are conditions that affect millions of patients and have close to 50% mortality rate. Early identification of at-risk patients significantly improves outcomes. Electronic surveillance tools have been developed to monitor structured Electronic Medical Records and automatically recognize early signs of sepsis. However, many sepsis risk factors (e.g. symptoms and signs of infection) are often captured only in free text clinical notes. In this study, we developed a method for automatic monitoring of nursing notes for signs and symptoms of infection. We utilized a creative approach to automatically generate an annotated dataset. The dataset was used to create a Machine Learning model that achieved an F1-score ranging from 79 to 96%.", "Automatic Extraction of Parallel Speech Corpora from Dubbed Movies.\n\nThis paper presents a methodology to extract parallel speech corpora based on any language pair from dubbed movies, together with an application framework in which some corresponding prosodic parameters are extracted. The obtained parallel corpora are especially suitable for speech-to-speech translation applications when a prosody transfer between source and target languages is desired.", "Acquisition of Translation Lexicons for Historically Unwritten Languages via Bridging Loanwords.\n\nWith the advent of informal electronic communications such as social media, colloquial languages that were historically unwritten are being written for the first time in heavily code-switched environments. We present a method for inducing portions of translation lexicons through the use of expert knowledge in these settings where there are approximately zero resources available other than a language informant, potentially not even large amounts of monolingual data. We investigate inducing a Moroccan Darija-English translation lexicon via French loanwords bridging into English and find that a useful lexicon is induced for human-assisted translation and statistical machine translation.", "Code-Switching as a Social Act: The Case of Arabic Wikipedia Talk Pages.\n\nCode-switching has been found to have social motivations in addition to syntactic constraints. In this work, we explore the social effect of code-switching in an online community. We present a task from the Arabic Wikipedia to capture language choice, in this case code-switching between Arabic and other languages, as a predictor of social influence in collaborative editing. We find that code-switching is positively associated with Wikipedia editor success, particularly borrowing technical language on pages with topics less directly related to Arabic-speaking regions.", "Stronger Baselines for Trustable Results in Neural Machine Translation.\n\nInterest in neural machine translation has grown rapidly as its effectiveness has been demonstrated across language and data scenarios.  New research regularly introduces architectural and algorithmic improvements that lead to significant gains over ``vanilla'' NMT implementations.  However, these new techniques are rarely evaluated in the context of previously published techniques, specifically those that are widely used in state-of-the-art production and shared-task systems.  As a result, it is often difficult to determine whether improvements from research will carry over to systems deployed for real-world use.  In this work, we recommend three specific methods that are relatively easy to implement and result in much stronger experimental systems.  Beyond reporting significantly higher BLEU scores, we conduct an in-depth analysis of where improvements originate and what inherent weaknesses of basic NMT models are being addressed.  We then compare the relative gains afforded by several other techniques proposed in the literature when starting with vanilla systems versus our stronger baselines, showing that experimental conclusions may change depending on the baseline chosen.  This indicates that choosing a strong baseline is crucial for reporting reliable experimental results.", "Using Global Constraints and Reranking to Improve Cognates Detection.\n\nGlobal constraints and reranking have not been used in cognates detection research to date. We propose methods for using global constraints by performing rescoring of the score matrices produced by state of the art cognates detection systems. Using global constraints to perform rescoring is complementary to state of the art methods for performing cognates detection and results in significant performance improvements beyond current state of the art performance on publicly available datasets with different language pairs and various conditions such as different levels of baseline state of the art performance and different data size conditions, including with more realistic large data size conditions than have been evaluated with in the past.", "Weighted Set-Theoretic Alignment of Comparable Sentences.\n\nThis article presents the STACCw system for the BUCC 2017 shared task on parallel sentence extraction from comparable corpora. The original STACC approach, based on set-theoretic operations over bags of words, had been previously shown to be efficient and portable across domains and alignment scenarios. Wedescribe an extension of this approach with a new weighting scheme and show that it provides significant improvements on the datasets provided for the shared task.", "BUCC 2017 Shared Task: a First Attempt Toward a Deep Learning Framework for Identifying Parallel Sentences in Comparable Corpora.\n\nThis paper describes our participation in BUCC 2017 shared task: identifying parallel sentences in comparable corpora. Our goal is to leverage continuous vector representations and distributional semantics with a minimal use of external preprocessing and postprocessing tools. We report experiments that were conducted after transmitting our results.", "Frame-Based Continuous Lexical Semantics through Exponential Family Tensor Factorization and Semantic Proto-Roles.\n\nWe study how different frame annotations complement one another when learning continuous lexical semantics. We learn the representations from a tensorized skip-gram model that consistently encodes syntactic-semantic content better, with multiple 10% gains over baselines.", "zNLP: Identifying Parallel Sentences in Chinese-English Comparable Corpora.\n\nThis paper describes the zNLP system for the BUCC 2017 shared task. Our system identifies parallel sentence pairs in Chinese-English comparable corpora by translating word-by-word Chinese sentences into English, using the search engine Solr to select near-parallel sentences and then by using an SVM classifier to identify true parallel sentences from the previous results. It obtains an F1-score of 45% (resp. 32%) on the test (training) set.", "Pay Attention to the Ending:Strong Neural Baselines for the ROC Story Cloze Task.\n\nWe consider the ROC story cloze task (Mostafazadeh et al., 2016) and present several findings. We develop a model that uses hierarchical recurrent networks with attention to encode the sentences in the story and score candidate endings. By discarding the large training set and only training on the validation set, we achieve an accuracy of 74.7%. Even when we discard the story plots (sentences before the ending) and only train to choose the better of two endings, we can still reach 72.5%. We then analyze this ``ending-only'' task setting. We estimate human accuracy to be 78% and find several types of clues that lead to this high accuracy, including those related to sentiment, negation, and general ending likelihood regardless of the story context.", "Users and Data: The Two Neglected Children of Bilingual Natural Language Processing Research.\n\nDespite numerous studies devoted to mining parallel material from bilingual data, we have yet to see the resulting technologies wholeheartedly adopted by professional translators and terminologists alike. I argue that this state of affairs is mainly due to two factors: the emphasis published authors put on models (even though data is as important), and the conspicuous lack of concern for actual end-users.", "Overview of the Second BUCC Shared Task: Spotting Parallel Sentences in Comparable Corpora.\n\nThis paper presents the BUCC 2017 shared task on parallel sentence extraction from comparable corpora.  It recalls the design of the datasets, presents their final construction and statistics and the methods used to evaluate system results. 13 runs were submitted to the shared task by 4 teams, covering three of the four proposed language pairs: French-English (7 runs), German-English (3 runs), and Chinese-English (3 runs). The best F-scores as measured against the gold standard were 0.84 (German-English), 0.80 (French-English), and 0.43 (Chinese-English).  Because of the design of the dataset, in which not all gold parallel sentence pairs are known, these are only minimum values. We examined manually a small sample of the false negative sentence pairs for the most precise French-English runs and estimated the number of parallel sentence pairs not yet in the provided gold standard.  Adding them to the gold standard leads to revised estimates for the French-English F-scores of at most +1.5pt.  This suggests that the BUCC 2017 datasets provide a reasonable approximate evaluation of the parallel sentence spotting task.", "Investigating Patient Attitudes Towards the use of Social Media Data to Augment Depression Diagnosis and Treatment: a Qualitative Study.\n\nIn this paper, we use qualitative research methods to investigate the attitudes of social media users towards the (opt-in) integration of social media data with routine mental health care and diagnosis. Our investigation was based on secondary analysis of a series of five focus groups with Twitter users, including three groups consisting of participants with a self-reported history of depression, and two groups consisting of participants without a self reported history of depression. Our results indicate that, overall, research participants were enthusiastic about the possibility of using social media (in conjunction with automated Natural Language Processing algorithms) for mood tracking under the supervision of a mental health practitioner. However, for at least some participants, there was skepticism related to how well social media represents the mental health of users, and hence its usefulness in the clinical context.", "A Cross-modal Review of Indicators for Depression Detection Systems.\n\nAutomatic detection of depression has attracted increasing attention from researchers in psychology, computer science, linguistics, and related disciplines. As a result, promising depression detection systems have been reported. This paper surveys these efforts by presenting the first cross-modal review of depression detection systems and discusses best practices and most promising approaches to this task.", "Natural-language Interactive Narratives in Imaginal Exposure Therapy for Obsessive-Compulsive Disorder.\n\nObsessive-compulsive disorder (OCD) is an anxiety-based disorder that affects around 2.5% of the population. A common treatment for OCD is exposure therapy, where the patient repeatedly confronts a feared experience, which has the long-term effect of decreasing their anxiety. Some exposures consist of reading and writing stories about an imagined anxiety-provoking scenario. In this paper, we present a technology that enables patients to interactively contribute to exposure stories by supplying natural language input (typed or spoken) that advances a scenario. This interactivity could potentially increase the patient's sense of immersion in an exposure and contribute to its success. We introduce the NLP task behind processing inputs to predict new events in the scenario, and describe our initial approach. We then illustrate the future possibility of this work with an example of an exposure scenario authored with our application.", "Monitoring Tweets for Depression to Detect At-risk Users.\n\nWe propose an automated system that can identify at-risk users from their public social media activity, more specifically, from Twitter. The data that we collected is from the \\#BellLetsTalk campaign, which is a wide-reaching, multi-year program designed to break the silence around mental illness and support mental health across Canada. To achieve our goal, we trained a user-level classifier that can detect at-risk users that achieves a reasonable precision and recall. We also trained a tweet-level classifier that predicts if a tweet indicates depression. This task was much more difficult due to the imbalanced data. In the dataset that we labeled, we came across 5% depression tweets and 95% non-depression tweets. To handle this class imbalance, we used undersampling methods. The resulting classifier had high recall, but low precision. Therefore, we only use this classifier to compute the estimated percentage of depressed tweets and to add this value as a feature for the user-level classifier.", "Small but Mighty: Affective Micropatterns for Quantifying Mental Health from Social Media Language.\n\nMany psychological phenomena occur in small time windows, measured in minutes or hours. However, most computational linguistic techniques look at data on the order of weeks, months, or years. We explore micropatterns in sequences of messages occurring over a short time window for their prevalence and power for quantifying psychological phenomena, specifically, patterns in affect. We examine affective micropatterns in social media posts from users with anxiety, eating disorders, panic attacks, schizophrenia, suicidality, and matched controls.", "In your wildest dreams: the language and psychological features of dreams.\n\nIn this paper, we provide the first quantified exploration of the structure of the language of dreams, their linguistic style and emotional content. We present a collection of digital dream logs as a viable corpus for the growing study of mental health through the lens of language, complementary to the work done examining more traditional social media. This paper is largely exploratory in nature to lay the groundwork for subsequent research in mental health, rather than optimizing a particular text classification task.", "Detecting and Explaining Crisis.\n\nIndividuals on social media may reveal themselves to be in various states of crisis (e.g. suicide, self-harm, abuse, or eating disorders). Detecting crisis from social media text automatically and accurately can have profound consequences. However, detecting a general state of crisis without explaining why has limited applications. An explanation in this context is a coherent, concise subset of the text that rationalizes the crisis detection. We explore several methods to detect and explain crisis using a combination of neural and non-neural techniques. We evaluate these techniques on a unique data set obtained from Koko, an anonymous emotional support network available through various messaging applications. We annotate a small subset of the samples labeled with crisis with corresponding explanations. Our best technique significantly outperforms the baseline for detection and explanation.", "An Artificial Language Evaluation of Distributional Semantic Models.\n\nRecent studies of distributional semantic models have set up a competition between word embeddings obtained from predictive neural networks and word vectors obtained from abstractive count-based models. This paper is an attempt to reveal the underlying contribution of additional training data and post-processing steps on each type of model in word similarity and relatedness inference tasks. We do so by designing an artificial language framework, training a predictive and a count-based model on data sampled from this grammar, and evaluating the resulting word vectors in paradigmatic and syntagmatic tasks defined with respect to the grammar.", "On the Distribution of Lexical Features at Multiple Levels of Analysis.\n\nNatural language processing has increasingly moved from modeling documents and words toward studying the people behind the language. This move to working with data at the user or community level has presented the field with different characteristics of linguistic data. In this paper, we empirically characterize various lexical distributions at different levels of analysis, showing that, while most features are decidedly sparse and non-normal at the message-level (as with traditional NLP), they follow the central limit theorem to become much more Log-normal or even Normal at the user- and county-levels. Finally, we demonstrate that modeling lexical features for the correct level of analysis leads to marked improvements in common social scientific prediction tasks.", "Cross-language Learning with Adversarial Neural Networks.\n\nWe address the problem of cross-language adaptation for question-question similarity reranking in community question answering, with the objective to port a system trained on one input language to another input language given labeled training data for the first language and only unlabeled data for the second language. In particular, we propose to use adversarial training of neural networks to learn high-level features that are discriminative for the main learning task, and at the same time are invariant across the input languages. The evaluation results show sizable improvements for our cross-language adversarial neural network (CLANN) model over a strong non-adversarial system.", "Modeling Context Words as Regions: An Ordinal Regression Approach to Word Embedding.\n\nVector representations of word meaning have found many applications in the field of natural language processing. Word vectors intuitively represent the average context in which a given word tends to occur, but they cannot explicitly model the diversity of these contexts. Although region representations of word meaning offer a natural alternative to word vectors, only few methods have been proposed that can effectively learn word regions. In this paper, we propose a new word embedding model which is based on SVM regression. We show that the underlying ranking interpretation of word contexts is sufficient to match, and sometimes outperform, the performance of popular methods such as Skip-gram. Furthermore, we show that by using a quadratic kernel, we can effectively learn word regions, which outperform existing unsupervised models for the task of hypernym detection.", "German in Flux: Detecting Metaphoric Change via Word Entropy.\n\nThis paper explores the information-theoretic measure entropy to detect metaphoric change, transferring ideas from hypernym detection to research on language change. We build the first diachronic test set for German as a standard for metaphoric change annotation. Our model is unsupervised, language-independent and generalizable to other processes of semantic change.", "A Supervised Approach to Extractive Summarisation of Scientific Papers.\n\nAutomatic summarisation is a popular approach to reduce a document to its main arguments. Recent research in the area has focused on neural approaches to summarisation, which can be very data-hungry. However, few large datasets exist and none for the traditionally popular domain of scientific publications, which opens up challenging research avenues centered on encoding large, complex documents. In this paper, we introduce a new dataset for summarisation of computer science publications by exploiting a large resource of author provided summaries and show straightforward ways of extending it further. We develop models on the dataset making use of both neural sentence encoding and traditionally used summarisation features and show that models which encode sentences as well as their local and global context perform best, significantly outperforming well-established baseline methods.", "Collaborative Partitioning for Coreference Resolution.\n\nThis paper presents a collaborative partitioning algorithm---a novel ensemble-based approach to coreference resolution. Starting from the all-singleton partition, we search for a solution close to the ensemble's outputs in terms of a task-specific similarity measure. Our approach assumes a loose integration of individual components of the ensemble and can therefore combine arbitrary coreference resolvers, regardless of their models. Our experiments on the CoNLL dataset show that collaborative partitioning yields results superior to those attained by the individual components, for ensembles of both strong and weak systems. Moreover, by applying the collaborative partitioning algorithm on top of three state-of-the-art resolvers, we obtain the best coreference performance reported so far in the literature (MELA v08 score of 64.47).", "UWaterloo at SemEval-2017 Task 7: Locating the Pun Using Syntactic Characteristics and Corpus-based Metrics.\n\nThe paper presents a system for locating a pun word. The developed method calculates a score for each word in a pun, using a number of components, including its Inverse Document Frequency (IDF), Normalized Pointwise Mutual Information (NPMI) with other words in the pun text, its position in the text, part-of-speech and some syntactic features. The method achieved the best performance in the Heterographic category and the second best in the Homographic. Further analysis showed that IDF is the most useful characteristic, whereas the count of words with which the given word has high NPMI has a negative effect on performance.", "Learning from Relatives: Unified Dialectal Arabic Segmentation.\n\nArabic dialects do not just share a common koin\u00e9, but there are shared pan-dialectal linguistic phenomena that allow computational models for dialects to learn from each other. In this paper we build a unified segmentation model where the training data for different dialects are combined and a single model is trained. The model yields higher accuracies than dialect-specific models, eliminating the need for dialect identification before segmentation. We also measure the degree of relatedness between four major Arabic dialects by testing how a segmentation model trained on one dialect performs on the other dialects. We found that linguistic relatedness is contingent with geographical proximity. In our experiments we use SVM-based ranking and bi-LSTM-CRF sequence labeling.", "Optimizing Differentiable Relaxations of Coreference Evaluation Metrics.\n\nCoreference evaluation metrics are hard to optimize directly as they are non-differentiable functions, not easily decomposable into elementary decisions. Consequently, most approaches optimize objectives only indirectly related to the end goal, resulting in suboptimal performance. Instead, we propose a differentiable relaxation that lends itself to gradient-based optimisation, thus bypassing the need for reinforcement learning or heuristic modification of cross-entropy. We show that by modifying the training objective of a competitive neural coreference system, we obtain a substantial gain in performance. This suggests that our approach can be regarded as a viable alternative to using reinforcement learning or more computationally expensive imitation learning.", "Knowledge Tracing in Sequential Learning of Inflected Vocabulary.\n\nWe present a feature-rich knowledge tracing method that captures a student's acquisition and retention of knowledge during a foreign language phrase learning task. We model the student's behavior as making predictions under a log-linear model, and adopt a neural gating mechanism to model how the student updates their log-linear parameters in response to feedback.  The gating mechanism allows the model to learn complex patterns of retention and acquisition for each feature, while the log-linear parameterization results in an interpretable knowledge state. We collect human data and evaluate several versions of the model.", "Learning Contextual Embeddings for Structural Semantic Similarity using Categorical Information.\n\nTree kernels (TKs) and neural networks are two effective approaches for automatic feature engineering. In this paper, we combine them by modeling context word similarity in semantic TKs. This way, the latter can operate subtree matching by applying neural-based similarity on tree lexical nodes. We study how to learn representations for the words in context such that TKs can exploit more focused information. We found that neural embeddings produced by current methods do not provide a suitable contextual similarity. Thus, we define a new approach based on a Siamese Network, which produces word representations while learning a binary text similarity. We set the latter considering examples in the same category as similar. The experiments on question and sentiment classification show that our semantic TK highly improves previous results.", "Multilingual Semantic Parsing And Code-Switching.\n\nExtending semantic parsing systems to new domains and languages is a highly expensive, time-consuming process, so making effective use of existing resources is critical. In this paper, we describe a transfer learning method using crosslingual word embeddings in a sequence-to-sequence model.  On the NLmaps corpus, our approach achieves state-of-the-art accuracy of 85.7% for English.  Most importantly, we observed a consistent improvement for German compared with several baseline domain adaptation techniques.  As a by-product of this approach, our models that are trained on a combination of English and German utterances perform reasonably well on code-switching utterances which contain a mixture of English and German, even though the training data does not contain any such. As far as we know, this is the first study of code-switching in semantic parsing. We manually constructed the set of code-switching test utterances for the NLmaps corpus and achieve 78.3% accuracy on this dataset.", "Neural System Combination for Machine Translation.\n\nNeural machine translation (NMT) becomes a new approach to machine translation and generates much more fluent results compared to statistical machine translation (SMT). However, SMT is usually better than NMT in translation adequacy. It is therefore a promising direction to combine the advantages of both NMT and SMT. In this paper, we propose a neural system combination framework leveraging multi-source NMT, which takes as input the outputs of NMT and SMT systems and produces the final translation. Extensive experiments on the Chinese-to-English translation task show that our model archives significant improvement by 5.3 BLEU points over the best single system output and 3.4 BLEU points over the state-of-the-art traditional system combination methods.", "Neural Sequence-to-sequence Learning of Internal Word Structure.\n\nLearning internal word structure has recently been recognized as an important step in various multilingual processing tasks and in theoretical language comparison. In this paper, we present a neural encoder-decoder model for learning canonical morphological segmentation. Our model combines character-level sequence-to-sequence transformation with a language model over canonical segments. We obtain up to 4% improvement over a strong character-level encoder-decoder baseline for three languages. Our model outperforms the previous state-of-the-art for two languages, while eliminating the need for external resources such as large dictionaries. Finally, by comparing the performance of encoder-decoder and classical statistical machine translation systems trained with and without corpus counts, we show that including corpus counts is beneficial to both approaches.", "Rational Distortions of Learners' Linguistic Input.\n\nLanguage acquisition can be modeled as a statistical inference problem: children use sentences and sounds in their input to infer linguistic structure. However, in many cases, children learn from data whose statistical structure is distorted relative to the language they are learning.  Such distortions can arise either in the input itself, or as a result of children's immature strategies for encoding their input.  This work examines several cases in which the statistical structure of children's input differs from the language being learned.  Analyses show that these distortions of the input can be accounted for with a statistical learning framework by carefully considering the inference problems that learners solve during language acquisition", "Embedding Words and Senses Together via Joint Knowledge-Enhanced Training.\n\nWord embeddings are widely used in Natural Language Processing, mainly due to their success in capturing semantic information from massive corpora. However, their creation process does not allow the different meanings of a word to be automatically separated, as it conflates them into a single vector. We address this issue by proposing a new model which learns word and sense embeddings jointly. Our model exploits large corpora and knowledge from semantic networks in order to produce a unified vector space of word and sense embeddings. We evaluate the main features of our approach both qualitatively and quantitatively in a variety of tasks, highlighting the advantages of the proposed method in comparison to state-of-the-art word- and sense-based models.", "Zero-Shot Relation Extraction via Reading Comprehension.\n\nWe show that relation extraction can be reduced to answering simple reading comprehension questions, by associating one or more natural-language questions with each relation slot. This reduction has several advantages: we can (1) learn relation-extraction models by extending recent neural reading-comprehension techniques, (2) build very large training sets for those models by combining relation-specific crowd-sourced questions with distant supervision, and even (3) do zero-shot learning by extracting new relation types that are only specified at test-time, for which we have no labeled training examples. Experiments on a Wikipedia slot-filling task demonstrate that the approach can generalize to new questions for known relation types with high accuracy, and that zero-shot generalization to unseen relation types is possible, at lower accuracy levels, setting the bar for future work on this task.", "Named Entity Disambiguation for Noisy Text.\n\nWe address the task of Named Entity Disambiguation (NED) for noisy text. We present WikilinksNED, a large-scale NED dataset of text fragments from the web, which is significantly noisier and more challenging than existing news-based datasets. To capture the limited and noisy local context surrounding each mention, we design a neural model and train it with a novel method for sampling informative negative examples. We also describe a new way of initializing word and entity embeddings that significantly improves performance. Our model significantly outperforms existing state-of-the-art methods on WikilinksNED while achieving comparable performance on a smaller newswire dataset.", "Encoding of phonology in a recurrent neural model of grounded speech.\n\nWe study the representation and encoding of phonemes in a recurrent neural network model of grounded speech. We use a model which processes images and their spoken descriptions, and projects the visual and auditory representations into the same semantic space. We perform a number of analyses on how information about individual phonemes is encoded in the MFCC features extracted from the speech signal, and the activations of the layers of the model. Via experiments with phoneme decoding and phoneme discrimination we show that phoneme representations are most salient in the lower layers of the model, where low-level signals are processed at a fine-grained level, although a large amount of phonological information is retain at the top recurrent layer. We further find out that the attention mechanism following the top recurrent layer significantly attenuates encoding of phonology and makes the utterance embeddings much more invariant to synonymy. Moreover, a hierarchical clustering of phoneme representations learned by the network shows an organizational structure of phonemes similar to those proposed in linguistics.", "Tell Me Why: Using Question Answering as Distant Supervision for Answer Justification.\n\nFor many applications of question answering (QA), being able to explain why a given model chose an answer is critical.  However, the lack of labeled data for answer justifications makes learning this difficult and expensive.  Here we propose an approach that uses answer ranking as distant supervision for learning how to select informative justifications, where justifications serve as inferential connections between the question and the correct answer while often containing little lexical overlap with either. We propose a neural network architecture for QA that reranks answer justifications as an intermediate (and human-interpretable) step in answer selection. Our approach is informed by a set of features designed to combine both learned representations and explicit features to capture the connection between questions, answers, and answer justifications. We show that with this end-to-end approach we are able to significantly improve upon a strong IR baseline in both justification ranking (+9% rated highly relevant) and answer selection (+6% P@1).", "Automatic Selection of Context Configurations for Improved Class-Specific Word Representations.\n\nThis paper is concerned with identifying contexts useful for training word representation models for different word classes such as adjectives (A), verbs (V), and nouns (N). We introduce a simple yet effective framework for an automatic selection of class-specific context configurations. We construct a context configuration space based on universal dependency relations between words, and efficiently search this space with an adapted beam search algorithm. In word similarity tasks for each word class, we show that our framework is both effective and efficient. Particularly, it improves the Spearman's rho correlation with human scores on SimLex-999 over the best previously proposed class-specific contexts by 6 (A), 6 (V) and 5 (N) rho points. With our selected context configurations, we train on only 14% (A), 26.2% (V), and 33.6% (N) of all dependency-based contexts, resulting in a reduced training time. Our results generalise: we show that the configurations our algorithm learns for one English training setup outperform previously proposed context types in another training setup for English. Moreover, basing the configuration space on universal dependencies, it is possible to transfer the learned configurations to German and Italian. We also demonstrate improved per-class results over other context types in these two languages..", "Morph-fitting: Fine-Tuning Word Vector Spaces with Simple Language-Specific Rules.\n\nMorphologically rich languages accentuate two properties of distributional vector space models: 1) the difficulty of inducing accurate representations for low-frequency word forms; and 2) insensitivity to distinct lexical relations that have similar distributional signatures. These effects are detrimental for language understanding systems, which may infer that  'inexpensive' is a rephrasing for 'expensive' or may not associate 'acquire' with 'acquires'. In this work, we propose a novel morph-fitting procedure which moves past the use of curated semantic lexicons for improving distributional vector spaces. Instead, our method injects morphological constraints generated using simple language-specific rules, pulling inflectional forms of the same word close together and pushing derivational antonyms far apart. In intrinsic evaluation over four languages, we show that our approach: 1) improves low-frequency word estimates; and 2) boosts the semantic quality of the entire word vector collection. Finally, we show that morph-fitted vectors yield large gains in the downstream task of dialogue state tracking, highlighting the importance of morphology for tackling long-tail phenomena in language understanding tasks.", "The Effect of Different Writing Tasks on Linguistic Style: A Case Study of the ROC Story Cloze Task.\n\nA writer's style depends not just on personal traits but also on her intent and mental state. In this paper, we show how variants of the same writing task can lead to measurable differences in writing style. We present a case study based on the story cloze task (Mostafazadeh et al., 2016a), where annotators were assigned similar writing tasks with different constraints: (1) writing an entire story, (2) adding a story ending for a given story context, and (3) adding an incoherent ending to a story. We show that a simple linear classifier informed by stylistic features is able to successfully distinguish among the three cases, without even looking at the story context. In addition, combining our stylistic features with language model predictions reaches state of the art performance on the story cloze challenge. Our results demonstrate that different task framings can dramatically affect the way people write.", "Learning What is Essential in Questions.\n\nQuestion answering (QA) systems are easily  distracted by  irrelevant or redundant words in questions, especially when faced with  long or multi-sentence                          questions  in difficult  domains. This paper introduces and studies  the  notion  of essential  question  terms with  the goal  of improving such QA  solvers. We                          illustrate the importance            of essential question  terms  by showing  that  humans'  ability  to  answer questions drops significantly when essential  terms  are eliminated  from  questions.We then develop a classifier that reliably (90%  mean  average  precision) identifies and ranks essential terms in questions. Finally, we use the classifier to demonstrate that                          the  notion  of  question term essentiality allows state-of-the-art  QA  solver for  elementary-level  science  questions to make better and more informed decisions,improving performance by up to 5%.We also  introduce  a  new  dataset  of  over 2,200 crowd-sourced essential terms annotated science questions.", "Personality Driven Differences in Paraphrase Preference.\n\nPersonality plays a decisive role in how people behave in different scenarios, including online social media. Researchers have used such data to study how personality can be predicted from language use. In this paper, we study phrase choice as a particular stylistic linguistic difference, as opposed to the mostly topical differences identified previously. Building on previous work on demographic preferences, we quantify differences in paraphrase choice from a massive Facebook data set with posts from over 115,000 users. We quantify the predictive power of phrase choice in user profiling and use phrase choice to study psycholinguistic hypotheses. This work is relevant to future applications that aim to personalize text generation to specific personality types.", "A Transition-Based Directed Acyclic Graph Parser for UCCA.\n\nWe present the first parser for UCCA, a cross-linguistically applicable framework for semantic representation, which builds on extensive typological work and supports rapid annotation. UCCA poses a challenge for existing parsing techniques, as it exhibits reentrancy (resulting in DAG structures), discontinuous structures and non-terminal nodes corresponding to complex semantic units. To our knowledge, the conjunction of these formal properties is not supported by any existing parser. Our transition-based parser, which uses a novel transition set and features based on bidirectional LSTMs, has value not just for UCCA parsing: its ability to handle more general graph structures can inform the development of parsers for other semantic DAG structures, and in languages that frequently use discontinuous structures.", "Beyond Binary Labels: Political Ideology Prediction of Twitter Users.\n\nAutomatic political orientation prediction from social media posts has to date proven successful only in distinguishing between publicly declared liberals and conservatives in the US. This study examines users' political ideology using a seven-point scale which enables us to identify politically moderate and neutral users --- groups which are of particular interest to political scientists and pollsters. Using a novel data set with political ideology labels self-reported through surveys, our goal is two-fold: a) to characterize the groups of politically engaged users through language use on Twitter; b) to build a fine-grained model that predicts political ideology of unseen users. Our results identify differences in both political leaning and engagement and the extent to which each group tweets using political keywords. Finally, we demonstrate how to improve ideology prediction accuracy by exploiting the relationships between the user groups.", "A Full Non-Monotonic Transition System for Unrestricted Non-Projective Parsing.\n\nRestricted non-monotonicity has been shown beneficial for the projective arc-eager dependency parser in previous research, as posterior decisions can repair mistakes made in previous states due to the lack of information. In this paper, we propose a novel, fully non-monotonic transition system based on the non-projective Covington algorithm. As a non-monotonic system requires exploration of erroneous actions during the training process, we develop several non-monotonic variants of the recently defined dynamic oracle for the Covington parser, based on tight approximations of the loss. Experiments on datasets from the CoNLL-X and CoNLL-XI shared tasks show that a non-monotonic dynamic oracle outperforms the monotonic version in the majority of languages.", "SemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation.\n\nSemantic Textual Similarity (STS) measures the meaning similarity of sentences. Applications include machine translation (MT), summarization, generation, question answering (QA), short answer grading, semantic search, dialog and conversational systems. The STS shared task is a venue for assessing the current state-of-the-art. The 2017 task focuses on multilingual and cross-lingual pairs with one sub-track exploring MT quality estimation (MTQE) data. The task obtained strong participation from 31 teams, with 17 participating in \\emph{all  language tracks}. We summarize performance and review a selection of well performing methods. Analysis highlights common errors, providing insight into the limitations of existing models. To support ongoing work on semantic representations, the {\\em STS Benchmark} is introduced as a new shared training and evaluation set carefully selected from the corpus of English STS shared task data (2012-2017).", "On the Challenges of Translating NLP Research into Commercial Products.\n\nThis paper highlights challenges in industrial research related to translating research in natural language processing into commercial products. While the interest in natural language processing from industry is significant, the transfer of research to commercial products is non-trivial and its challenges are often unknown to or underestimated by many researchers. I discuss current obstacles and provide suggestions for increasing the chances for translating research to commercial success based on my experience in industrial research.", "Improving Neural Parsing by Disentangling Model Combination and Reranking Effects.\n\nRecent work has proposed several generative neural models for constituency parsing that achieve state-of-the-art results. Since direct search in these generative models is difficult, they have primarily been used to rescore candidate outputs from base parsers in which decoding is more straightforward. We first present an algorithm for direct search in these generative models.  We then demonstrate that the rescoring results are at least partly due to implicit model combination rather than reranking effects.  Finally, we show that explicit model combination can improve performance even further, resulting in new state-of-the-art numbers on the PTB of 94.25 F1 when training only on gold data and 94.66 F1 when using external data.", "Making Neural QA as Simple as Possible but not Simpler.\n\nRecent development of large-scale question answering (QA) datasets triggered a substantial amount of research into end-to-end neural architectures for QA. Increasingly complex systems have been conceived without comparison to simpler neural baseline systems that would justify their complexity. In this work, we propose a simple heuristic that guides the development of neural baseline systems for the extractive QA task. We find that there are two ingredients necessary for building a high-performing neural QA system: first, the awareness of question words while processing the context and second, a composition function that goes beyond simple bag-of-words modeling, such as recurrent neural networks. Our results show that FastQA, a system that meets these two requirements, can achieve very competitive performance compared with existing models. We argue that this surprising finding puts results of previous systems and the complexity of recent QA datasets into perspective.", "Swanson linking revisited: Accelerating literature-based discovery across domains using a conceptual influence graph.\n\nWe introduce a modular approach for literature-based discovery consisting of a machine reading and knowledge assembly component that together produce a graph of influence relations (e.g., ``A promotes B'') from a collection of publications.  A search engine is used to explore direct and indirect influence chains. Query results are substantiated with textual evidence, ranked according to their relevance, and presented in both a table-based view, as well as a network graph visualization.  Our approach operates in both domain-specific settings, where there are knowledge bases and ontologies available to guide reading, and in multi-domain settings where such resources are absent. We demonstrate that this deep reading and search system reduces the effort needed to uncover ``undiscovered public knowledge'', and that with the aid of this tool a domain expert was able to drastically reduce her model building time from months to two days.", "Scattertext: a Browser-Based Tool for Visualizing how Corpora Differ.\n\nScattertext is an open source tool for visualizing linguistic variation between document categories in a language-independent way. The tool presents a scatterplot, where each axis corresponds to the rank-frequency a term occurs in a category of documents.  Through a tie-breaking strategy, the tool is able to display thousands of visible term-representing points and find space to legibly label hundreds of them.   Scattertext also lends itself to a query-based visualization of how the use of terms with similar embeddings differs between document categories, as well as a visualization for comparing the importance scores of bag-of-words features to univariate metrics.", "Hafez: an Interactive Poetry Generation System.\n\nHafez is an automatic poetry generation system that integrates a Recurrent Neural Network (RNN) with a Finite State Acceptor (FSA). It generates sonnets given arbitrary topics. Furthermore, Hafez enables users to revise and polish generated poems by adjusting various style configurations. Experiments demonstrate that such ``polish'' mechanisms consider the user's intention and lead to a better poem. For evaluation, we build a web interface where users can rate the quality of each poem from 1 to 5 stars. We also speed up the whole system by a factor of 10, via vocabulary pruning and GPU computation, so that adequate feedback can be collected at a fast pace. Based on such feedback, the system learns to adjust its parameters to improve poetry quality. .", "SuperAgent: A Customer Service Chatbot for E-commerce Websites.\n\nConventional customer service chatbots are usually built upon human dialogs, yet confronted with the problems of data scale and privacy. In this paper, we present SuperAgent, which is a customer service chatbot leveraging large-scale and public available e-commerce data. Distinct from existing counterparts, SuperAgent takes advantage of data from in-page product descriptions as well as user-generated content from e-commerce websites, which is more practical and cost-effective to answer repetitive questions, thereby freeing up support staffs to answer much higher value questions. We demonstrate SuperAgent as an add-on extension to mainstream web browsers and show its usefulness to user's online shopping experience.", "Lifelong Learning CRF for Supervised Aspect Extraction.\n\nThis paper makes a focused contribution to supervised aspect extraction. It shows that if the system has performed aspect extraction from many past domains and retained their results as knowledge, Conditional Random Fields (CRF) can leverage this knowledge in a lifelong learning manner to extract in a new domain markedly better than the traditional CRF without using this prior knowledge. The key innovation is that even after CRF training, the model can still improve its extraction with experiences in its applications.", "End-to-End Non-Factoid Question Answering with an Interactive Visualization of Neural Attention Weights.\n\nAdvanced attention mechanisms are an important part of successful neural network approaches for non-factoid answer selection because they allow the models to focus on few important segments within rather long answer texts. Analyzing attention mechanisms is thus crucial for understanding strengths and weaknesses of particular models. We present an extensible, highly modular service architecture that enables to transform neural network models for non-factoid answer selection into fully featured end-to-end question answering systems. The primary objective of our system is to enable researchers a way to interactively explore and compare attention-based neural networks for answer selection. Our interactive user interface helps researchers to better understand the capabilities of the different approaches and can aid qualitative analyses. The source-code of our system is publicly available.", "PyDial: A Multi-domain Statistical Dialogue System Toolkit.\n\nStatistical Spoken Dialogue Systems have been around for many years. However, access to these systems has always been difficult as there is still no publicly available end-to-end system implementation. To alleviate this, we present CU-PyDial, an open-source end-to-end statistical spoken dialogue system toolkit which provides implementations of statistical approaches for all dialogue system modules. Moreover, it has been extended to provide multi-domain conversational functionality. It offers easy configuration, easy extensibility, and domain-independent implementations of the respective dialogue system modules. The toolkit is available for download under the Apache 2.0 license.", "UCCAApp: Web-application for Syntactic and Semantic Phrase-based Annotation.\n\nWe present UCCAApp, an open-source, flexible web-application for syntactic and semantic phrase-based annotation in general, and for UCCA annotation in particular. UCCAApp supports a variety of formal properties that have proven useful for syntactic and semantic representation, such as discontiguous phrases, multiple parents and empty elements, making it useful to a variety of other annotation schemes with similar formal properties. UCCAApp's user interface is intuitive and user friendly, so as to support annotation by users with no background in linguistics or formal representation. Indeed, a pilot version of the application has been successfully used in the compilation of the UCCA Wikipedia treebank by annotators with no previous linguistic training. The application and all accompanying resources are released as open source under the GNU public license, and are available online along with a live demo.", "The State of the Art in Semantic Representation.\n\nSemantic representation is receiving growing attention in NLP in the past few years, and many proposals for semantic schemes (e.g., AMR, UCCA, GMB, UDS) have been put forth. Yet, little has been done to assess the achievements and the shortcomings of these new contenders, compare them with syntactic schemes, and clarify the general goals of research on semantic representation. We address these gaps by critically surveying the state of the art in the field.", "Semedico: A Comprehensive Semantic Search Engine for the Life Sciences.\n\nSemedico is a semantic search engine designed to support literature search in the life sciences by integrating the semantics of the domain at all stages of the search process - from query formulation via query processing up to the presentation of results. Semedico excels with an ad-hoc search approach which directly reflects relevance in terms of information density of entities and relations among them (events) and, a truly unique feature, ranks interaction events by certainty information reflecting the degree of factuality of the encountered event.", "Exploring Diachronic Lexical Semantics with JeSemE.\n\nRecent advances in distributional semantics combined with the availability of large-scale diachronic corpora offer new research avenues for the Digital Humanities. JeSemE, the Jena Semantic Explorer, renders assistance to a non-technical audience to investigate diachronic semantic topics. JeSemE runs as a website with query options and interactive visualizations of results, as well as a REST API for access to the underlying diachronic data sets.", "ResSim at SemEval-2017 Task 1: Multilingual Word Representations for Semantic Textual Similarity.\n\nShared Task 1 at SemEval-2017 deals with assessing the semantic similarity between sentences, either in the same or in different languages. In our system submission, we employ multilingual word representations, in which similar words in different languages are close to one another. Using such representations is advantageous, since the increasing amount of available parallel data allows for the application of such methods to many of the languages in the world. Hence, semantic similarity can be inferred even for languages for which no annotated data exists. Our system is trained and evaluated on all language pairs included in the shared task (English, Spanish, Arabic, and Turkish). Although development results are promising, our system does not yield high performance on the shared task test sets.", "Life-iNet: A Structured Network-Based Knowledge Exploration and Analytics System for Life Sciences.\n\nSearch engines running on scientific literature have been widely used by life scientists to find publications related to their research. However, existing search engines in life-science domain, such as PubMed, have limitations when applied to exploring and analyzing factual knowledge (e.g., disease-gene associations) in massive text corpora. These limitations are mainly due to the problems that factual information exists as an unstructured form in text, and also keyword and MeSH term-based queries cannot effectively imply semantic relations between entities. This demo paper presents the LifeNet system to address the limitations in existing search engines on facilitating life sciences research. LifeNet automatically constructs structured networks of factual knowledge from large amounts of background documents, to support efficient exploration of structured factual knowledge in the unstructured literature. It also provides functionalities for finding distinctive entities for given entity types, and generating hypothetical facts to assist literature-based knowledge discovery (e.g., drug target prediction).", "Character Composition Model with Convolutional Neural Networks for Dependency Parsing on Morphologically Rich Languages.\n\nWe present a transition-based dependency parser that uses a convolutional neural network to compose word representations from characters. The character composition model shows great improvement over the word-lookup model, especially for parsing agglutinative languages. These improvements are even better than using pre-trained word embeddings from extra data. On the SPMRL data sets, our system outperforms the previous best greedy parser (Ballesteros et. al, 2015) by a margin of 3% on average.", "Annotating tense, mood and voice for English, French and German.\n\nWe present the first open-source tool for annotating morphosyntactic tense, mood and voice for English, French and German verbal complexes. The annotation is based on a set of language-specific rules, which are applied on dependency trees and leverage information about lemmas, morphological properties and POS-tags of the verbs. Our tool has an average accuracy of about 76%. The tense, mood and voice features are useful both as features in computational modeling and for corpus-linguistic research.", "Automating Biomedical Evidence Synthesis: RobotReviewer.\n\nWe present RobotReviewer, an open-source web-based system that uses machine learning and NLP to semi-automate biomedical evidence synthesis, to aid the practice of Evidence-Based Medicine. RobotReviewer processes full-text journal articles (PDFs) describing randomized controlled trials (RCTs). It appraises the reliability of RCTs and extracts text describing key trial characteristics (e.g., descriptions of the population) using novel NLP methods. RobotReviewer then automatically generates a report synthesising this information. Our goal is for RobotReviewer to automatically extract and synthesise the full-range of structured data needed to inform evidence-based practice.", "ESTEEM: A Novel Framework for Qualitatively Evaluating and Visualizing Spatiotemporal Embeddings in Social Media.\n\nAnalyzing and visualizing large amounts of social media communications and contrasting short-term conversation changes over time and geolocations is extremely important for commercial and government applications. Earlier approaches for large-scale text stream summarization used dynamic topic models and trending words. Instead, we rely on text embeddings -- low-dimensional word representations in a continuous vector space where similar words are embedded nearby each other. This paper presents ESTEEM, a novel tool for visualizing and evaluating spatiotemporal embeddings learned from streaming social media texts. Our tool allows users to monitor and analyze query words and their closest neighbors with an interactive interface. We used state-of-the-art techniques to learn embeddings and developed a visualization to represent dynamically changing relations between words in social media over time and other dimensions. This is the first interactive visualization of streaming text representations learned from social media texts that also allows users to contrast differences across multiple dimensions of the data.", "OpenNMT: Open-Source Toolkit for Neural Machine Translation.\n\nWe describe an open-source toolkit for neural machine translation (NMT). The toolkit prioritizes efficiency, modularity, and extensibility with the goal of supporting NMT research into model architectures, feature representations, and source modalities, while maintaining competitive performance and reasonable training requirements. The toolkit consists of modeling and translation support, as well as detailed pedagogical documentation about the underlying techniques.", "WebChild 2.0 : Fine-Grained Commonsense Knowledge Distillation.\n\nDespite important progress in the area of intelligent systems, most such systems still lack commonsense knowledge that appears crucial for enabling smarter, more human-like decisions. In this paper, we present a system based on a series of algorithms to distill fine-grained disambiguated commonsense knowledge from massive amounts of text. Our WebChild 2.0 knowledge base is one of the largest commonsense knowledge bases available, describing over 2 million disambiguated concepts and activities, connected by over 18 million assertions.", "RelTextRank: An Open Source Framework for Building Relational Syntactic-Semantic Text Pair Representations.\n\nWe present a highly-flexible UIMA-based pipeline for developing structural kernel-based systems for relational learning from text, i.e., for generating training and test data for ranking, classifying short text pairs or measuring similarity between pieces of text. For example, the proposed pipeline can represent an input question and answer sentence pairs as syntactic-semantic structures, enriching them with relational information,  e.g., links between question class, focus and named entities, and serializes them as training and test files for the tree kernel-based reranking framework. The pipeline generates a number of dependency and shallow chunk-based representations shown to achieve competitive results in previous work. It also enables easy evaluation of the models thanks to cross-validation facilities.", "Tracing armed conflicts with diachronic word embedding models.\n\nRecent studies have shown that word embedding models can be used to trace time-related (diachronic) semantic shifts in particular words. In this paper, we evaluate some of these approaches on the new task of predicting the dynamics of global armed conflicts on a year-to-year basis, using a dataset from the conflict research field as the gold standard and the Gigaword news corpus as the training data. The results show that much work still remains in extracting `cultural' semantic shifts from diachronic word embedding models. At the same time, we present a new task complete with an evaluation set and introduce the `anchor words' method which outperforms previous approaches on this set.", "Incorporating Uncertainty into Deep Learning for Spoken Language Assessment.\n\nThere is a growing demand for automatic assessment of spoken English proficiency. These systems need to handle large variations in input data owing to the wide range of candidate skill levels and L1s, and errors from ASR. Some candidates will be a poor match to the training data set, undermining the validity of the predicted grade. For high stakes tests it is essential for such systems not only to grade well, but also to provide a measure of their uncertainty in their predictions, enabling rejection to human graders. Previous work examined Gaussian Process (GP) graders which, though successful, do not scale well with large data sets. Deep Neural Network (DNN) may also be used to provide uncertainty using Monte-Carlo Dropout (MCD). This paper proposes a novel method to yield uncertainty and compares it to GPs and DNNs with MCD. The proposed approach explicitly teaches a DNN to have low uncertainty on training data and high uncertainty on generated artificial data. On experiments conducted on data from the Business Language Testing Service (BULATS), the proposed approach is found to outperform GPs and DNNs with MCD in uncertainty-based rejection whilst achieving comparable grading performance.", "The Rich Event Ontology.\n\nIn this paper we describe a new lexical semantic resource, The Rich Event On-tology, which provides an independent conceptual backbone to unify existing semantic role labeling (SRL) schemas and augment them with event-to-event causal and temporal relations.        By unifying the FrameNet, VerbNet, Automatic Content Extraction, and Rich Entities, Relations and Events resources, the ontology serves as a shared hub for the disparate annotation schemas and therefore enables the combination of SRL training data into a larger, more diverse corpus.  By adding temporal and causal relational information not found in any of the independent resources, the ontology facilitates reasoning on and across documents, revealing relationships between events that come together in temporal and causal chains to build more complex scenarios.  We envision the open resource serving as a valuable tool for both moving from the ontology to text to query for event types and scenarios of interest, and for moving from text to the ontology to access interpretations of events using the combined semantic information housed there.", "Integrating Decompositional Event Structures into Storylines.\n\nStoryline research links together events in stories and specifies shared participants in those stories. In these analyses, an atomic event is assumed to be a single clause headed by a single verb. However, many analyses of verbal semantics assume a decompositional analysis of events expressed in single clauses. We present a formalization of a decompositional analysis of events in which each participant in a clausal event has their own temporally extended subevent, and the subevents are related through causal and other interactions. This decomposition allows us to represent storylines as an evolving set of interactions between participants over time.", "Abstract Meaning Representation Parsing using LSTM Recurrent Neural Networks.\n\nWe present a system which parses sentences into Abstract Meaning Representations, improving state-of-the-art results for this task by more than 5%.  AMR graphs represent semantic content using linguistic properties such as semantic roles, coreference, negation, and more.  The AMR parser does not rely on a syntactic pre-parse, or heavily engineered features, and uses five recurrent neural networks as the key architectural components for inferring AMR graphs.", "On the Creation of a Security-Related Event Corpus.\n\nThis paper reports on an effort of creating a corpus of structured information on security-related events automatically extracted from on-line news, part of which has been manually curated. The main motivation behind this effort is to provide material to the NLP community working on event extraction that could be used both for training and evaluation purposes.", "Generating Contrastive Referring Expressions.\n\nThe referring expressions (REs) produced by a natural language generation (NLG) system can be misunderstood by the hearer, even when they are semantically correct. In an interactive setting, the NLG system can try to recognize such misunderstandings and correct them. We present an algorithm for generating corrective REs that use contrastive focus (``no, the BLUE button'') to emphasize the information the hearer most likely misunderstood. We show empirically that these contrastive REs are preferred over REs without contrast marking.", "Event Detection Using Frame-Semantic Parser.\n\nRecent methods for Event Detection focus on Deep Learning for automatic feature generation and feature ranking. However, most of those approaches fail to exploit rich semantic information, which results in relatively poor recall. This paper is a small \\& focused contribution, where we introduce an Event Detection and classification system, based on deep semantic information retrieved from a frame-semantic parser. Our experiments show that our system achieves higher recall than state-of-the-art systems. Further, we claim that enhancing our system with deep learning techniques like feature ranking can achieve even better results, as it can benefit from both approaches.", "newsLens: building and visualizing long-ranging news stories.\n\nWe propose a method to aggregate and organize a large, multi-source dataset of news articles into a collection of major stories, and automatically name and visualize these stories in a working system. The approach is able to run online, as new articles are added, processing 4 million news articles from 20 news sources, and extracting 80000 major stories, some of which span several years. The visual interface consists of lanes of timelines, each annotated with information that is deemed important for the story, including extracted quotations. The working system allows a user to search and navigate 8 years of story information.", "The Event StoryLine Corpus: A New Benchmark for Causal and Temporal Relation Extraction.\n\nThis paper reports on the Event StoryLine Corpus (ESC) v1.0, a new benchmark dataset for the temporal and causal relation detection. By developing this dataset, we also introduce a new task, the StoryLine Extraction from news data, which aims at extracting and classifying events relevant for stories, from across news documents spread in time and clustered around a single seminal event or topic. In addition to describing the dataset, we also report on three baselines systems whose results show the complexity of the task and suggest directions for the development of more robust systems.", "The Circumstantial Event Ontology (CEO).\n\nIn this paper we describe the ongoing work on the Circumstantial Event Ontology (CEO), a newly developed ontology for calamity events that models semantic circumstantial relations between event classes. The circumstantial relations are designed manually, based on the shared properties of each event class. We discuss and contrast two types of event circumstantial relations: semantic circumstantial relations and episodic circumstantial relations. Further, we show the metamodel and the current contents of the ontology and outline the evaluation of the CEO.", "Inducing Event Types and Roles in Reverse: Using Function to Discover Theme.\n\nWith growing interest in automated event extraction, there is an increasing need to overcome the labor costs of hand-written event templates, entity lists, and annotated corpora. In the last few years, more inductive approaches have emerged, seeking to discover unknown event types and roles in raw text. The main recent efforts use probabilistic generative models, as in topic modeling, which are formally concise but do not always yield stable or easily interpretable results. We argue that event schema induction can benefit from greater structure in the process and in linguistic features that distinguish words' functions and themes. To maximize our use of limited data, we reverse the typical schema induction steps and introduce new similarity measures, building an intuitive process for inducing the structure of unknown events.", "Plotting Markson's ``Mistress''.\n\nThe post-modern novel ``Wittgenstein's Mistress'' by David Markson (1988) presents the reader with a very challenging non-linear narrative, that itself appears to one of the novel's themes. We present a distant reading of this work designed to complement a close reading of it by David Foster Wallace (1990).   Using a combination of text analysis, entity recognition and networks, we plot repetitive structures in the novel's narrative relating them to its critical analysis.", "A Dataset for Sanskrit Word Segmentation.\n\nThe last decade saw a surge in digitisation efforts for ancient manuscripts in Sanskrit. Due to various linguistic peculiarities inherent to the language, even the preliminary tasks such as word segmentation are non-trivial in Sanskrit. Elegant models for Word Segmentation in Sanskrit are indispensable for further syntactic and semantic processing of the manuscripts. Current works in word segmentation for Sanskrit, though commendable in their novelty, often have variations in their objective and evaluation criteria. In this work, we set the record straight. We formally define the objectives and the requirements for the word segmentation task. In order to encourage research in the field and to alleviate the time and effort required in pre-processing, we release a dataset of 115,000 sentences for word segmentation. For each sentence in the dataset we include the input character sequence, ground truth segmentation, and additionally lexical and morphological information about all the phonetically possible segments for the given sentence. In this work, we also discuss the linguistic considerations made while generating the candidate space of the possible segments.", "A Graph Based Semi-Supervised Approach for Analysis of Derivational Nouns in Sanskrit.\n\nDerivational nouns are widely used in Sanskrit corpora and represent an important cornerstone of productivity in the language. Currently there exists no analyser that identifies the derivational nouns. We propose a semi supervised approach for identification of derivational nouns in Sanskrit. We not only identify the derivational words, but also link them to their corresponding source words. Our novelty comes in the design of the network structure for the task. The edge weights are featurised based on the phonetic, morphological, syntactic and the semantic similarity shared between the words to be identified. We find that our model is effective for the task, even when we employ a labelled dataset which is only 5 \\% to that of the entire dataset.", "An End-to-end Environment for Research Question-Driven Entity Extraction and Network Analysis.\n\nThis paper presents an approach to extract co-occurrence networks from literary texts. It is a deliberate decision not to aim for a fully automatic pipeline, as the literary research questions need to guide both the definition of the nature of the things that co-occur as well as how to decide co-occurrence. We showcase the approach on a Middle High German romance, \\parz. Manual inspection and discussion shows the huge impact various choices  have.", "ULISBOA at SemEval-2017 Task 12: Extraction and classification of temporal expressions and events.\n\nThis paper presents our approach to participate in the SemEval 2017 Task 12: Clinical TempEval challenge, specifically in the event and time expressions span and attribute identification subtasks (ES, EA, TS, TA). Our approach consisted in training Conditional Random Fields (CRF) classifiers using the provided annotations, and in creating manually curated rules to classify the attributes of each event and time expression. We used a set of common features for the event and time CRF classifiers, and a set of features specific to each type of entity, based on domain knowledge. Training only on the source domain data, our best F-scores were 0.683 and 0.485 for event and time span identification subtasks. When adding target domain annotations to the training data, the best F-scores obtained were 0.729 and 0.554, for the same subtasks. We obtained the second highest F-score of the challenge on the event polarity subtask (0.708). The source code of our system, Clinical Timeline Annotation (CiTA), is available at https://github.com/lasigeBioTM/CiTA.", "Modeling intra-textual variation with entropy and surprisal: topical vs. stylistic patterns.\n\nWe present a data-driven approach to investigate intra-textual variation by combining entropy and surprisal. With this approach we detect linguistic variation based on phrasal lexico-grammatical patterns across sections of research articles. Entropy is used to detect patterns typical of specific sections. Surprisal is used to differentiate between more and less informationally-loaded patterns as well as type of information (topical vs. stylistic). While we here focus on research articles in biology/genetics, the methodology is especially interesting for digital humanities scholars, as it can be applied to any text type or domain and combined with additional variables (e.g. time, author or social group).", "Enjambment Detection in a Large Diachronic Corpus of Spanish Sonnets.\n\nEnjambment takes place when a syntactic unit is broken up across two lines of poetry, giving rise to different stylistic effects. In Spanish literary studies, there are unclear points about the types of stylistic effects that can arise, and under which linguistic conditions. To systematically gather evidence about this, we developed a system to automatically identify enjambment (and its type) in Spanish. For evaluation, we manually annotated a reference corpus covering different periods. As a scholarly corpus to apply the tool, from public HTML sources we created a diachronic corpus covering four centuries of sonnets (3750 poems), and we analyzed the occurrence of enjambment across stanzaic boundaries in different periods. Besides, we found examples that highlight limitations in current definitions of enjambment.", "Sense Contextualization in a Dependency-Based Compositional Distributional Model.\n\nLittle attention has been paid to distributional compositional methods which employ syntactically structured vector models. As word vectors belonging to different syntactic categories                                      have incompatible syntactic distributions, no trivial compositional operation can be applied to combine them into a new compositional vector. In this article, we generalize the method described by Erk and Pad\u00f3 (2009) by proposing a dependency-base framework that contextualize not only lemmas but also selectional preferences.  The main contribution of the article is to expand their model to a fully compositional framework in which syntactic dependencies are put at the core of semantic composition. We claim that semantic composition is mainly driven by syntactic dependencies. Each syntactic dependency generates two new compositional vectors representing the contextualized sense of the two related lemmas.  The sequential application of the compositional operations associated to the dependencies results in as many contextualized vectors as lemmas the composite expression contains. At the end of the semantic process, we do not obtain a single compositional vector representing the semantic denotation of the whole composite expression, but one contextualized vector for each lemma of the whole expression. Our method avoids the troublesome high-order tensor representations by defining lemmas and selectional restrictions as first-order tensors (i.e. standard vectors). A corpus-based experiment is performed to both evaluate the quality of the compositional vectors built with our strategy, and to compare them to other approaches on distributional compositional semantics. The experiments show that our dependency-based compositional method performs as  (or even better than) the state-of-the-art.", "Citius at SemEval-2017 Task 2: Cross-Lingual Similarity from Comparable Corpora and Dependency-Based Contexts.\n\nThis article describes the distributional strategy submitted by the Citius team to the SemEval 2017 Task 2. Even though the team participated in two subtasks, namely monolingual and cross-lingual word similarity, the article is mainly focused on the cross-lingual subtask. Our method uses comparable corpora and syntactic dependencies to extract count-based and transparent bilingual distributional contexts. The evaluation of the results show that our method is competitive with other cross-lingual strategies, even those using aligned and parallel texts.", "A Neural Architecture for Generating Natural Language Descriptions from Source Code Changes.\n\nWe propose a model to automatically describe changes introduced in the source code of a program using natural language. Our method receives as input a set of code commits, which contains both the modifications and  message introduced by an user. These two modalities are used to train  an encoder-decoder architecture. We evaluated our approach on twelve real world open source projects from four different programming languages. Quantitative and qualitative results showed that the proposed approach can generate feasible and semantically sound descriptions not only in standard in-project settings, but also in a cross-project setting.", "Lexical Correction of Polish Twitter Political Data.\n\nLanguage processing architectures are often evaluated in near-to-perfect conditions with respect to processed content. The tools which perform sufficiently well on electronic press, books and other type of non-interactive content may poorly handle littered, colloquial and multilingual textual data which make the majority of communication today. This paper aims at investigating how Polish Twitter data (in a slightly controlled `political' flavour) differs from expectation of linguistic tools and how they could be corrected to be ready for processing by standard language processing chains available for Polish. The setting includes specialised components for spelling correction of tweets as well as hashtag and username decoding.", "Metaphor Detection in a Poetry Corpus.\n\nMetaphor is indispensable in poetry. It showcases the poet's creativity, and contributes to the overall emotional pertinence of the poem while honing its specific rhetorical impact. Previous work on metaphor detection relies on either rule-based or statistical models, none of them applied to poetry. Our method focuses on metaphor detection in a poetry corpus. It combines rule-based and statistical models (word embeddings) to develop a new classification system. Our system has achieved a precision of 0.759 and a recall of 0.804 in identifying one type of metaphor in poetry.", "Annotation Challenges for Reconstructing the Structural Elaboration of Middle Low German.\n\nIn this paper, we present the annotation challenges we have encountered when working on a historical language that was undergoing elaboration processes. We especially focus on syntactic ambiguity and gradience in Middle Low German, which causes uncertainty to some extent. Since current annotation tools consider construction contexts and the dynamics of the grammaticalization only partially, we plan to extend CorA - a web-based annotation tool for historical and other non-standard language data - to capture elaboration phenomena and annotator unsureness. Moreover, we seek to interactively learn morphological as well as syntactic annotations.", "Distantly Supervised POS Tagging of Low-Resource Languages under Extreme Data Sparsity: The Case of Hittite.\n\nThis paper presents a statistical approach to automatic morphosyntactic annotation of Hittite transcripts. Hittite is an extinct Indo-European language using the cuneiform script. There are currently no morphosyntactic annotations available for Hittite, so we explored methods of distant supervision. The annotations were projected from parallel German translations of the Hittite texts. In order to reduce data sparsity, we applied stemming of German and Hittite texts. As there is no off-the-shelf Hittite stemmer, a stemmer for Hittite was developed for this purpose. The resulting annotation projections were used to train a POS tagger, achieving an accuracy of 69% on a test sample. To our knowledge, this is the first attempt of statistical POS tagging of a cuneiform language.", "Automatic Compositor Attribution in the First Folio of Shakespeare.\n\nCompositor attribution, the clustering of pages in a historical printed document by the individual who set the type, is a bibliographic task that relies on analysis of orthographic variation and inspection of visual details of the printed page. In this paper, we introduce a novel unsupervised model that jointly describes the textual and visual features needed to distinguish compositors. Applied to images of Shakespeare's First Folio, our model predicts attributions that agree with the manual judgements of bibliographers with an accuracy of 87%, even on text that is the output of OCR.", "Classifying Semantic Clause Types: Modeling Context and Genre Characteristics with Recurrent Neural Networks and Attention.\n\nDetecting aspectual properties of clauses in the form of situation entity types has been shown to depend on a combination of syntactic-semantic and contextual features. We explore this task in a deep-learning framework, where tuned word representations capture lexical, syntactic and semantic features. We introduce an attention mechanism that pinpoints relevant context not only for the current instance, but also for the larger context. Apart from implicitly capturing task relevant features, the advantage of our neural model is that it avoids the need to reproduce linguistic features for other languages and is thus more easily transferable. We present experiments for English and German that achieve competitive performance. We present a novel take on modeling and exploiting genre information and showcase the adaptation of our system from one language to another.", "Phonological Soundscapes in Medieval Poetry.\n\nThe oral component of medieval poetry was integral to its performance and reception. Yet many believe that the medieval voice has been forever lost, and any attempts at rediscovering it are doomed to failure due to scribal practices, manuscript mouvance, and linguistic normalization in editing practices. This paper offers a method to abstract from this noise and better understand relative differences in phonological soundscapes by considering syllable qualities. The presented syllabification method and soundscape analysis offer themselves as cross-disciplinary tools for low-resource languages. As a case study, we examine medieval German lyric and argue that the heavily debated lyrical \u2018I' follows a unique trajectory through soundscapes, shedding light on the performance and practice of these poets.", "Automatic Annotation and Evaluation of Error Types for Grammatical Error Correction.\n\nUntil now, error type performance for Grammatical Error Correction (GEC) systems could only be measured in terms of recall because system output is not annotated. To overcome this problem, we introduce ERRANT, a grammatical ERRor ANnotation Toolkit designed to automatically extract edits from parallel original and corrected sentences and classify them according to a new, dataset-agnostic, rule-based framework. This not only facilitates error type evaluation at different levels of granularity, but can also be used to reduce annotator workload and standardise existing GEC datasets. Human experts rated the automatic edits as ``Good'' or ``Acceptable'' in at least 95\\% of cases, so we applied ERRANT to the system output of the CoNLL-2014 shared task to carry out a detailed error type analysis for the first time.", "When does a compliment become sexist? Analysis and classification of ambivalent sexism using twitter data.\n\nSexism is prevalent in today's society, both offline and online, and poses a credible threat to social equality with respect to gender. According to ambivalent sexism theory (Glick and Fiske, 1996), it comes in two forms: Hostile and Benevolent. While hostile sexism is characterized by an explicitly negative attitude, benevolent sexism is more subtle. Previous works on computationally detecting sexism present online are restricted to identifying the hostile form. Our objective is to investigate the less pronounced form of sexism demonstrated online. We achieve this by creating and analyzing a dataset of tweets that exhibit benevolent sexism. By using Support Vector Machines (SVM), sequence-to-sequence models and FastText classifier, we classify tweets into \u2018Hostile', \u2018Benevolent' or \u2018Others' class depending on the kind of sexism they exhibit. We have been able to achieve an F1-score of 87.22% using FastText classifier. Our work helps analyze and understand the much prevalent ambivalent sexism in social media.", "Cross-Lingual Classification of Topics in Political Texts.\n\nIn this paper, we propose an approach for cross-lingual topical coding of sentences from electoral manifestos of political parties in different languages. To this end, we exploit continuous semantic text representations and induce a joint multilingual semantic vector spaces to enable supervised learning using manually-coded sentences across different languages. Our experimental results show that classifiers trained on multilingual data yield performance boosts over monolingual topic classification.", "Mining Social Science Publications for Survey Variables.\n\nResearch in Social Science is usually based on survey data where individual research questions relate to observable concepts (variables). However, due to a lack of standards for data citations a reliable identification of the variables used is often difficult. In this paper, we present a work-in-progress study that seeks to provide a solution to the variable detection task based on supervised machine learning algorithms, using a linguistic analysis pipeline to extract a rich feature set, including terminological concepts and similarity metric scores. Further, we present preliminary results on a small dataset that has been specifically designed for this task, yielding a significant increase in performance over the random baseline.", "Structured Learning for Context-aware Spoken Language Understanding of Robotic Commands.\n\nService robots are expected to operate in specific environments, where the presence of humans plays a key role. A major feature of such robotics platforms is thus the ability to react to spoken commands. This requires the understanding of the user utterance with an accuracy able to trigger the robot reaction. Such correct interpretation of linguistic exchanges depends on physical, cognitive and language-dependent aspects related to the environment. In this work, we present the empirical evaluation of an adaptive Spoken Language Understanding chain for robotic commands, that explicitly depends on the operational environment during both the learning and recognition stages. The effectiveness of such a context-sensitive command interpretation is tested against an extension of an already existing corpus of commands, that introduced explicit perceptual knowledge: this enabled deeper measures proving that more accurate disambiguation capabilities can be actually obtained.", "Non-lexical Features Encode Political Affiliation on Twitter.\n\nPrevious work on classifying Twitter users' political alignment has mainly focused on lexical and social network features. This study provides evidence that political affiliation is also reflected in features which have been previously overlooked: users' discourse patterns (proportion of Tweets that are retweets or replies) and their rate of use of capitalization and punctuation. We find robust differences between politically left- and right-leaning communities with respect to these discourse and sub-lexical features, although they are not enough to train a high-accuracy classifier.", "Modelling Participation in Small Group Social Sequences with Markov Rewards Analysis.\n\nWe explore a novel computational approach for analyzing member participation in small group social sequences. Using a complex state representation combining information about dialogue act types, sentiment expression, and participant roles, we explore which sequence states are associated with high levels of member participation. Using a Markov Rewards framework, we associate particular states with immediate positive and negative rewards, and employ a Value Iteration algorithm to calculate the expected value of all states. In our findings, we focus on discourse states belonging to team leaders and project managers which are either very likely or very unlikely to lead to participation from the rest of the group members.", "Alignment at Work: Using Language to Distinguish the Internalization and Self-Regulation Components of Cultural Fit in Organizations.\n\nCultural fit is widely believed to affect the success of individuals and the groups to which they belong. Yet it remains an elusive, poorly measured construct. Recent research draws on computational linguistics to measure cultural fit but overlooks asymmetries in cultural adaptation. By contrast, we develop a directed, dynamic measure of cultural fit based on linguistic alignment, which estimates the influence of one person's word use on another's and distinguishes between two enculturation mechanisms: internalization and self-regulation. We use this measure to trace employees' enculturation trajectories over a large, multi-year corpus of corporate emails and find that patterns of alignment in the first six months of employment are predictive of individuals' downstream outcomes, especially involuntary exit. Further predictive analyses suggest referential alignment plays an overlooked role in linguistic alignment.", "Integrating Deep Linguistic Features in Factuality Prediction over Unified Datasets.\n\nPrevious models for the assessment of commitment towards a predicate in a sentence (also known as factuality prediction) were trained and tested against a specific annotated dataset, subsequently limiting the generality of their results. In this work we propose an intuitive method for mapping three previously annotated corpora onto a single factuality scale, thereby enabling models to be tested across these corpora. In addition, we design a novel model for factuality prediction by first extending a previous rule-based factuality prediction system and applying it over an abstraction of dependency trees, and then using the output of this system in a supervised classifier. We show that this model outperforms previous methods on all three datasets. We make both the unified factuality corpus and our new model publicly available.", "How Does Twitter User Behavior Vary Across Demographic Groups?.\n\nDemographically-tagged social media messages are a common source of data for computational social science.  While these messages can indicate differences in beliefs and behaviors between demographic groups, we do not have a clear understanding of how different demographic groups use platforms such as Twitter.  This paper presents a preliminary analysis of how groups' differing behaviors may confound analyses of the groups themselves.  We analyzed one million Twitter users by first inferring demographic attributes, and then measuring several indicators of Twitter behavior. We find differences in these indicators across demographic groups, suggesting that there may be underlying differences in how different demographic groups use Twitter.", "Ideological Phrase Indicators for Classification of Political Discourse Framing on Twitter.\n\nPoliticians carefully word their statements in order to influence how others view an issue, a political strategy called framing. Simultaneously, these frames may also reveal the beliefs or positions on an issue of the politician. Simple language features such as unigrams, bigrams, and trigrams are important indicators for identifying the general frame of a text, for both longer congressional speeches and shorter tweets of politicians. However, tweets may contain multiple unigrams across different frames which limits the effectiveness of this approach. In this paper, we present a joint model which uses both linguistic features of tweets and ideological phrase indicators extracted from a state-of-the-art embedding-based model to predict the general frame of political tweets.", "Leveraging Behavioral and Social Information for Weakly Supervised Collective Classification of Political Discourse on Twitter.\n\nFraming is a political strategy in which politicians carefully word their statements in order to control public perception of issues. Previous works exploring political framing typically analyze frame usage in longer texts, such as congressional speeches. We present a collection of weakly supervised models which harness collective classification to predict the frames used in political discourse on the microblogging platform, Twitter. Our global probabilistic models show that by combining both lexical features of tweets and network-based behavioral features of Twitter, we are able to increase the average, unsupervised F1 score by 21.52 points over a lexical baseline alone.", "community2vec: Vector representations of online communities encode semantic relationships.\n\nVector embeddings of words have been shown to encode meaningful semantic relationships that enable solving of complex analogies. This vector embedding concept has been extended successfully to many different domains and in this paper we both create and visualize vector representations of an unstructured collection of online communities based on user participation. Further, we quantitatively and qualitatively show that these representations allow solving of semantically meaningful community analogies and also other more general types of relationships. These results could help improve community recommendation engines and also serve as a tool for sociological studies of community relatedness.", "An Empirical Study of Mini-Batch Creation Strategies for Neural Machine Translation.\n\nTraining of neural machine translation (NMT) models usually uses mini-batches for efficiency purposes. During the mini-batched training process, it is necessary to pad shorter sentences in a mini-batch to be equal in length to the longest sentence therein for efficient computation. Previous work has noted that sorting the corpus based on the sentence length before making mini-batches reduces the amount of padding and increases the processing speed. However, despite the fact that mini-batch creation is an essential step in NMT training, widely used NMT toolkits implement disparate strategies for doing so, which have not been empirically validated or compared. This work investigates mini-batch creation strategies with experiments over two different datasets. Our results suggest that the choice of a mini-batch creation strategy has a large effect on NMT training and some length-based sorting strategies do not always work well compared with simple shuffling.", "Detecting Untranslated Content for Neural Machine Translation.\n\nDespite its promise, neural machine translation (NMT) has a serious problem in that source content may be mistakenly left untranslated. The ability to detect untranslated content is important for the practical use of NMT. We evaluate two types of probability with which to detect untranslated content: the cumulative attention (ATN) probability and back translation (BT) probability from the target sentence to the source sentence. Experiments on detecting untranslated content in Japanese-English patent translations show that ATN and BT are each more effective than random choice, BT is more effective than ATN, and the combination of the two provides further improvements. We also confirmed the effectiveness of using ATN and BT to rerank the n-best NMT outputs.", "Beam Search Strategies for Neural Machine Translation.\n\nThe basic concept in Neural Machine Translation (NMT) is to train a large Neural Network that maximizes the translation performance on a given parallel corpus. NMT is then using a simple left-to-right beam-search decoder to generate new translations that approximately maximize the trained conditional probability. The current beam search strategy generates the target sentence word by word from left-to-right while keeping a fixed amount of active candidates at each time step. First, this simple search is less adaptive as it also expands candidates whose scores are much worse than the current best. Secondly, it does not expand hypotheses if they are not within the best scoring candidates, even if their scores are close to the best one. The latter one can be avoided by increasing the beam size until no performance improvement can be observed. While you can reach better performance, this has the drawback of a slower decoding speed. In this paper, we concentrate on speeding up the decoder by applying a more flexible beam search strategy whose candidate size may vary at each time step depending on the candidate scores. We speed up the original decoder by up to 43% for the two language pairs German to English and Chinese to English without losing any translation quality.", "Six Challenges for Neural Machine Translation.\n\nWe explore six challenges for neural machine translation: domain mismatch, amount of training data, rare words, long sentences, word alignment, and beam search. We show both deficiencies and improvements over the quality of phrase-based statistical machine translation.", "Detecting Cross-Lingual Semantic Divergence for Neural Machine Translation.\n\nParallel corpora are often not as parallel as one might assume: non-literal translations and noisy translations abound, even in curated corpora routinely used for training and evaluation. We use a cross-lingual textual entailment system to distinguish sentence pairs that are parallel in meaning from those that are not, and show that filtering out divergent examples from training improves translation quality.", "An Empirical Study of Adequate Vision Span for Attention-Based Neural Machine Translation.\n\nRecently, the attention mechanism plays a key role to achieve high performance for Neural Machine Translation models. However, as it computes a score function for the encoder states in all positions at each decoding step, the attention model greatly increases the computational complexity. In this paper, we investigate the adequate vision span of attention models in the context of machine translation, by proposing a novel attention framework that is capable of reducing redundant score computation dynamically. The term ``vision span''' means a window of the encoder states considered by the attention model in one step. In our experiments, we found that the average window size of vision span can be reduced by over 50% with modest loss in accuracy on English-Japanese and German-English translation tasks.", "SentiME++ at SemEval-2017 Task 4: Stacking State-of-the-Art Classifiers to Enhance Sentiment Classification.\n\nIn this paper, we describe the participation of the SentiME++ system to the SemEval 2017 Task 4A ``Sentiment Analysis in Twitter'' that aims to classify whether English tweets are of positive, neutral or negative sentiment. SentiME++ is an ensemble approach to sentiment analysis that leverages stacked generalization to automatically combine the predictions of five state-of-the-art sentiment classifiers. SentiME++ achieved officially 61.30% F1-score, ranking 12th out of 38 participants.", "Bridge Text and Knowledge by Learning Multi-Prototype Entity Mention Embedding.\n\nIntegrating text and knowledge into a unified semantic space has attracted significant research interests recently. However, the ambiguity in the common space remains a challenge, namely that the same mention phrase usually refers to various entities. In this paper, to deal with the ambiguity of entity mentions, we propose a novel Multi-Prototype Mention Embedding model, which learns multiple sense embeddings for each mention by jointly modeling words from textual contexts and entities derived from a knowledge base. In addition, we further design an efficient language model based approach to disambiguate each mention to a specific sense. In experiments, both qualitative and quantitative analysis demonstrate the high quality of the word, entity and multi-prototype mention embeddings. Using entity linking as a study case, we apply our disambiguation method as well as the multi-prototype mention embeddings on the benchmark dataset, and achieve state-of-the-art performance.", "Morphological Inflection Generation with Hard Monotonic Attention.\n\nWe present a neural model for morphological inflection generation which employs a hard attention mechanism, inspired by the nearly-monotonic alignment commonly found between the characters in a word and the characters in its inflection. We evaluate the model on three previously studied morphological inflection generation datasets and show that it provides state of the art results in various setups compared to previous neural and non-neural approaches. Finally we present an analysis of the continuous representations learned by both the hard and soft (Bahdanau, 2014) attention models for the task, shedding some light on the features such models extract.", "Towards String-To-Tree Neural Machine Translation.\n\nWe present a simple method to incorporate syntactic information about the target language in a neural machine translation system by translating into linearized, lexicalized constituency trees. An experiment on the WMT16 German-English news translation task resulted in an improved BLEU score when compared to a syntax-agnostic NMT baseline trained on the same dataset. An analysis of the translations from the syntax-aware system shows that it performs more reordering during translation in comparison to the baseline. A small-scale human evaluation also showed an advantage to the syntax-aware system.", "Weakly Supervised Cross-Lingual Named Entity Recognition via Effective Annotation and Representation Projection.\n\nThe state-of-the-art named entity recognition (NER) systems are supervised machine learning models that require large amounts of manually annotated data to achieve high accuracy. However, annotating NER data by human is expensive and time-consuming, and can be quite difficult for a new language. In this paper, we present two weakly supervised approaches for cross-lingual NER with no human annotation in a target language. The first approach is to create automatically labeled NER data for a target language via annotation projection on comparable corpora, where we develop a heuristic scheme that effectively selects good-quality projection-labeled data from noisy data. The second approach is to project distributed representations of words (word embeddings) from a target language to a source language, so that the source-language NER system can be applied to the target language without re-training. We also design two co-decoding schemes that effectively combine the outputs of the two projection-based approaches. We evaluate the performance of the proposed approaches on both in-house and open NER data for several target languages. The results show that the combined systems outperform three other weakly supervised approaches on the CoNLL data.", "Improved Neural Relation Detection for Knowledge Base Question Answering.\n\nRelation detection is a core component of many NLP applications including Knowledge Base Question Answering (KBQA). In this paper, we propose a hierarchical recurrent neural network enhanced by residual learning which detects KB relations given an input question. Our method uses deep residual bidirectional LSTMs to compare questions and relation names via different levels of abstraction. Additionally, we propose a simple KBQA system that integrates entity linking and our proposed relation detector to make the two components enhance each other. Our experimental results show that our approach not only achieves outstanding relation detection performance, but more importantly, it helps our KBQA system achieve state-of-the-art accuracy for both single-relation (SimpleQuestions) and multi-relation (WebQSP) QA benchmarks.", "Linguistic analysis of differences in portrayal of movie characters.\n\nWe examine differences in portrayal of characters in movies using psycholinguistic and graph theoretic measures computed directly from screenplays. Differences are examined with respect to characters' gender, race, age and other metadata. Psycholinguistic metrics are extrapolated to dialogues in movies using a linear regression model built on a set of manually annotated seed words. Interesting patterns are revealed about relationships between genders of production team and the gender ratio of characters. Several correlations are noted between gender, race, age of characters and the linguistic metrics.", "Enriching Complex Networks with Word Embeddings for Detecting Mild Cognitive Impairment from Speech Transcripts.\n\nMild Cognitive Impairment (MCI) is a mental disorder difficult to diagnose. Linguistic features, mainly from parsers, have been used to detect MCI, but this is not suitable for large-scale assessments. MCI disfluencies produce non-grammatical speech that requires manual or high precision automatic correction of transcripts.  In this paper, we modeled transcripts into complex networks and enriched them with word embedding (CNE) to better represent short texts produced in neuropsychological assessments. The network measurements were applied with well-known classifiers to automatically identify MCI in transcripts, in a binary classification task. A comparison was made with the performance of traditional approaches using Bag of Words (BoW) and linguistic features for three datasets: DementiaBank in English, and Cinderella and Arizona-Battery in Portuguese. Overall, CNE provided higher accuracy than using only complex networks, while Support Vector Machine was superior to other classifiers. CNE provided the highest accuracies for DementiaBank and Cinderella, but BoW was more efficient for the Arizona-Battery dataset probably owing to its short narratives. The approach using linguistic features yielded higher accuracy if the transcriptions of the Cinderella dataset were manually revised. Taken together, the results indicate that complex networks enriched with embedding is promising for detecting MCI in large-scale assessments.", "Neural End-to-End Learning for Computational Argumentation Mining.\n\nWe investigate neural techniques for end-to-end computational argumentation mining (AM). We frame AM both as a token-based dependency parsing and as a token-based sequence tagging problem, including a multi-task learning setup. Contrary to models that operate on the argument component level, we find that framing AM as dependency parsing leads to subpar performance results. In contrast, less complex (local) tagging models based on BiLSTMs perform robustly across classification scenarios, being able to catch long-range dependencies inherent to the AM problem. Moreover, we find that jointly learning `natural' subtasks, in a multi-task learning setup, improves performance.", "EELECTION at SemEval-2017 Task 10: Ensemble of nEural Learners for kEyphrase ClassificaTION.\n\nThis paper describes our approach to the SemEval 2017 Task 10: Extracting Keyphrases and Relations from Scientific Publications, specifically to Subtask (B): Classification of identified keyphrases. We explored three different deep learning approaches: a character-level convolutional neural network (CNN), a stacked learner with an MLP meta-classifier, and an attention based Bi-LSTM. From these approaches, we created an ensemble of differently hyper-parameterized systems, achieving a micro-$F\\_1$-score of 0.63 on the test data. Our approach ranks 2nd (score of 1st placed system: 0.64) out of four according to this official score. However, we erroneously trained 2 out of 3 neural nets (the stacker and the CNN) on only roughly 15\\% of the full data, namely, the original development set. When trained on the full data (training$+$development), our ensemble has a micro-$F\\_{1}$-score of 0.69. Our code is available from https://github.com/UKPLab/semeval2017-scienceie.", "A Convolutional Encoder Model for Neural Machine Translation.\n\nThe prevalent approach to neural machine translation relies on bi-directional LSTMs to encode the source sentence. We present a faster and simpler architecture based on a succession of convolutional layers. This allows to encode the source sentence simultaneously compared to recurrent networks for which computation is constrained by temporal dependencies. On WMT'16 English-Romanian translation we achieve competitive accuracy to the state-of-the-art and on WMT'15 English-German we outperform several recently published results. Our models obtain almost the same accuracy as a very deep LSTM setup on WMT'14 English-French translation. We speed up CPU decoding by more than two times at the same or higher accuracy as a strong bi-directional LSTM.", "Adversarial Training for Unsupervised Bilingual Lexicon Induction.\n\nWord embeddings are well known to capture linguistic regularities of the language on which they are trained. Researchers also observe that these regularities can transfer across languages. However, previous endeavors to connect separate monolingual word embeddings typically require cross-lingual signals as supervision, either in the form of parallel corpus or seed lexicon. In this work, we show that such cross-lingual connection can actually be established without any form of supervision. We achieve this end by formulating the problem as a natural adversarial game, and investigating techniques that are crucial to successful training. We carry out evaluation on the unsupervised bilingual lexicon induction task. Even though this task appears intrinsically cross-lingual, we are able to demonstrate encouraging performance without any cross-lingual clues.", "Model Transfer for Tagging Low-resource Languages using a Bilingual Dictionary.\n\nCross-lingual model transfer is a compelling and popular method for predicting annotations in a low-resource language, whereby parallel corpora provide a bridge to a high-resource language, and its associated annotated corpora. However, parallel data is not readily available for many languages, limiting the applicability of these approaches. We address these drawbacks in our framework which takes advantage of cross-lingual word embeddings trained solely on a high coverage dictionary. We propose a novel neural network model for joint training from both sources of data based on cross-lingual word embeddings, and show substantial empirical improvements over baseline techniques. We also propose several active learning heuristics, which result in improvements over competitive benchmark methods.", "Multimodal Word Distributions.\n\nWord embeddings provide point representations of words containing useful semantic information. We introduce multimodal word distributions formed from Gaussian mixtures, for multiple word meanings, entailment, and rich uncertainty information.  To learn these distributions, we propose an energy-based max-margin objective. We show that the resulting approach captures uniquely  expressive semantic information, and outperforms alternatives, such as word2vec skip-grams, and Gaussian embeddings, on benchmark datasets such as word similarity and entailment.", "Evaluation Metrics for Machine Reading Comprehension: Prerequisite Skills and Readability.\n\nKnowing the quality of reading comprehension (RC) datasets is important for the development of natural-language understanding systems. In this study, two classes of metrics were adopted for evaluating RC datasets: prerequisite skills and readability. We applied these classes to six existing datasets, including MCTest and SQuAD, and highlighted the characteristics of the datasets according to each metric and the correlation between the two classes. Our dataset analysis suggests that the readability of RC datasets does not directly affect the question difficulty and that it is possible to create an RC dataset that is easy to read but difficult to answer.", "Attention-over-Attention Neural Networks for Reading Comprehension.\n\nCloze-style reading comprehension is a representative problem in mining relationship between document and query. In this paper, we present a simple but novel model called attention-over-attention reader for better solving cloze-style reading comprehension task. The proposed model aims to place another attention mechanism over the document-level attention and induces ``attended attention'' for final answer predictions. One advantage of our model is that it is simpler than related works while giving excellent performance. In addition to the primary model, we also propose an N-best re-ranking strategy to double check the validity of the candidates and further improve the performance. Experimental results show that the proposed methods significantly outperform various state-of-the-art systems by a large margin in public datasets, such as CNN and Children's Book Test.", "Chat Detection in an Intelligent Assistant: Combining Task-oriented and Non-task-oriented Spoken Dialogue Systems.\n\nRecently emerged intelligent assistants on smartphones and home electronics (e.g., Siri and Alexa) can be seen as novel hybrids of domain-specific task-oriented spoken dialogue systems and open-domain non-task-oriented ones. To realize such hybrid dialogue systems, this paper investigates determining whether or not a user is going to have a chat with the system. To address the lack of benchmark datasets for this task, we construct a new dataset consisting of 15,160 utterances collected from the real log data of a commercial intelligent assistant (and will release the dataset to facilitate future research activity). In addition, we investigate using tweets and Web search queries for handling open-domain user utterances, which characterize the task of chat detection. Experimental experiments demonstrated that, while simple supervised methods are effective, the use of the tweets and search queries further improves the F$\\_1$-score from 86.21 to 87.53.", "Deep Pyramid Convolutional Neural Networks for Text Categorization.\n\nThis paper proposes a low-complexity word-level deep convolutional neural network (CNN) architecture for text categorization that can efficiently represent long-range associations in text.  In the literature, several deep and complex neural networks have been proposed for this task, assuming availability of relatively large amounts of training data.  However, the associated computational complexity increases as the networks go deeper, which poses serious challenges in practical applications.  Moreover, it was shown recently that shallow word-level CNNs are more accurate and much faster than the state-of-the-art very deep nets such as character-level CNNs even in the setting of large training data.  Motivated by these findings, we carefully studied deepening of word-level CNNs to capture global representations of text, and found a simple network architecture with which the best accuracy can be obtained by increasing the network depth without increasing computational cost by much.  We call it deep pyramid CNN. The proposed model with 15 weight layers outperforms the previous best models on six benchmark datasets for sentiment classification and topic categorization.", "Transductive Non-linear Learning for Chinese Hypernym Prediction.\n\nFinding the correct hypernyms for entities\u00a0is essential for taxonomy learning, fine-grained entity categorization, query understanding, etc. Due to the flexibility\u00a0of the Chinese language, it is challenging\u00a0to identify hypernyms in Chinese accurately. Rather than extracting hypernyms from texts, in this paper, we present a transductive learning approach to establish mappings from entities to hypernyms in\u00a0the embedding space directly. It combines linear and non-linear embedding projection models, with the capacity of encoding\u00a0arbitrary language-specific rules. Experiments on real-world datasets illustrate that our approach outperforms previous methods for Chinese hypernym prediction.", "Data-Driven Broad-Coverage Grammars for Opinionated Natural Language Generation (ONLG).\n\nOpinionated Natural Language Generation (ONLG) is a new, challenging, task that aims to automatically generate human-like, subjective, responses to opinionated articles online. We present a data-driven architecture for ONLG that generates subjective responses triggered by users' agendas, consisting of topics and sentiments, and based on wide-coverage automatically-acquired generative grammars. We compare three types of grammatical representations that we design for ONLG, which interleave different layers of linguistic information and are induced from a new, enriched dataset we developed. Our evaluation shows that generation with Relational-Realizational (Tsarfaty and Sima'an, 2008) inspired grammar gets better language model scores than lexicalized grammars `a la Collins (2003), and that the latter gets better human-evaluation scores. We also show that conditioning the generation on topic models makes generated responses more relevant to the document content.", "Polish evaluation dataset for compositional distributional semantics models.\n\nThe paper presents a procedure of building an evaluation dataset. for the validation of compositional distributional semantics models estimated for languages other than English. The procedure generally builds on steps designed to assemble the SICK corpus, which contains pairs of English sentences annotated for semantic relatedness and entailment, because we aim at building a comparable dataset. However, the implementation of particular building steps significantly differs from the original SICK design assumptions, which is caused by both lack of necessary extraneous resources for an investigated language and the need for language-specific transformation rules. The designed procedure is verified on Polish, a fusional language with a relatively free word order, and contributes to building a Polish evaluation dataset. The resource consists of 10K sentence pairs which are human-annotated for semantic relatedness and entailment. The dataset may be used for the evaluation of compositional distributional semantics models of Polish.", "Unsupervised Text Segmentation Based on Native Language Characteristics.\n\nMost work on segmenting text does so on the basis of topic changes, but it can be of interest to segment by other, stylistically expressed characteristics such as change of authorship or native language.  We propose a Bayesian unsupervised text segmentation approach to the latter.  While baseline models achieve essentially random segmentation on our task, indicating its difficulty, a Bayesian model that incorporates appropriately compact language models and alternating asymmetric priors can achieve scores on the standard metrics around halfway to perfect segmentation.", "Feature Hashing for Language and Dialect Identification.\n\nWe evaluate feature hashing for language identification (LID), a method not previously used for this task. Using a standard dataset, we first show that while feature performance is high, LID data is highly dimensional and mostly sparse (>99.5%) as it includes large vocabularies for many languages; memory requirements grow as languages are added. Next we apply hashing using various hash sizes, demonstrating that there is no performance loss with dimensionality reductions of up to 86%. We also show that using an ensemble of low-dimension hash-based classifiers further boosts performance. Feature hashing is highly useful for LID and holds great promise for future work in this area.", "Skip-Gram - Zipf + Uniform = Vector Additivity.\n\nIn recent years word-embedding models have gained great popularity due to their remarkable performance on several tasks, including word analogy questions and caption generation. An unexpected ``side-effect'' of such models is that their vectors often exhibit compositionality, i.e., \\emph{adding} two word-vectors results in a vector that is only a small angle away from the vector of a word representing the semantic composite of the original words, e.g., ``man'' + ``royal'' = ``king''. This work provides a theoretical justification for the presence of additive compositionality in word vectors learned using the Skip-Gram model. In particular, it shows that additive compositionality holds in an even stricter sense (small distance rather than small angle) under certain assumptions on the process generating the corpus. As a corollary, it explains the success of vector calculus in solving word analogies. When these assumptions do not hold, this work describes the correct non-linear composition operator. Finally, this work establishes a connection between the Skip-Gram model and the Sufficient Dimensionality Reduction (SDR) framework of Globerson and Tishby: the parameters of SDR models can be obtained from those of Skip-Gram models simply by adding information on symbol frequencies. This shows that Skip-Gram embeddings are optimal in the sense of Globerson and Tishby and, further, implies that the heuristics commonly used to approximately fit Skip-Gram models can be used to fit SDR models.", "Enhanced LSTM for Natural Language Inference.\n\nReasoning and inference are central to human and artificial intelligence. Modeling inference in human language is very challenging. With the availability of large annotated data (Bowman et al., 2015), it has recently become feasible to train neural network based inference models, which have shown to be very effective. In this paper, we present a new state-of-the-art result, achieving the accuracy of 88.6% on the Stanford Natural Language Inference Dataset. Unlike the previous top models that use very complicated network architectures, we first demonstrate that carefully designing sequential inference models based on chain LSTMs can outperform all previous models. Based on this, we further show that by explicitly considering recursive architectures in both local inference modeling and inference composition, we achieve additional improvement. Particularly, incorporating syntactic parsing information contributes to our best result---it further improves the performance even when added to the already very strong model.", "Semi-supervised Multitask Learning for Sequence Labeling.\n\nWe propose a sequence labeling framework with a secondary training objective, learning to predict surrounding words for every word in the dataset. This language modeling objective incentivises the system to learn general-purpose patterns of semantic and syntactic composition, which are also useful for improving accuracy on different sequence labeling tasks. The architecture was evaluated on a range of datasets, covering the tasks of error detection in learner texts, named entity recognition, chunking and POS-tagging. The novel language modeling objective provided consistent performance improvements on every benchmark, without requiring any additional annotated or unannotated data.", "EUDAMU at SemEval-2017 Task 11: Action Ranking and Type Matching for End-User Development.\n\nThe paper describes a system for end-user development using natural language. Our approach uses a ranking model to identify the actions to be executed followed by reference and parameter matching models to select parameter values that should be set for the given commands. We discuss the results of evaluation and possible improvements for future work.", "Found in Translation: Reconstructing Phylogenetic Language Trees from Translations.\n\nTranslation has played an important role in trade, law, commerce, politics, and literature for thousands of years. Translators have always tried to be invisible; ideal translations should look as if they were written originally in the target language. We show that traces of the source language remain in the translation product to the extent that it is possible to uncover the history of the source language by looking only at the translation. Specifically, we automatically reconstruct phylogenetic language trees from monolingual texts (translated from several source languages). The signal of the source language is so powerful that it is retained even after two phases of translation. This strongly indicates that source language interference is the most dominant characteristic of translated texts, overshadowing the more subtle signals of universal properties of translation.", "Parsing to 1-Endpoint-Crossing, Pagenumber-2 Graphs.\n\nWe study the Maximum Subgraph problem in deep dependency parsing. We consider two restrictions to deep dependency graphs: (a) 1-endpoint-crossing and (b) pagenumber-2. Our main contribution is an exact algorithm that ob- tains maximum subgraphs satisfying both restrictions simultaneously in time O(n5). Moreover, ignoring one linguistically-rare structure descreases the complexity to O(n4). We also extend our quartic-time algorithm into a practical parser with a discriminative disambiguation model and evaluate its performance on four linguistic data sets used in semantic dependency parsing.", "A Neural Local Coherence Model.\n\nWe propose a local coherence model based on a convolutional neural network that operates over the entity grid representation of a text. The model captures long range en- tity transitions along with entity-specific features without loosing generalization, thanks to the power of distributed representation. We present a pairwise ranking method to train the model in an end-to-end fashion on a task and learn task-specific high level features. Our evaluation on three different coherence assessment tasks demonstrates that our model achieves state of the art results outperforming existing models by a good margin.", "Neural Joint Model for Transition-based Chinese Syntactic Analysis.\n\nWe present neural network-based joint models for Chinese word segmentation, POS tagging and dependency parsing. Our models are the first neural approaches for fully joint Chinese analysis that is known to prevent the error propagation problem of pipeline models. Although word embeddings play a key role in dependency parsing, they cannot be applied directly to the joint task in the previous work. To address this problem, we propose embeddings of character strings, in addition to words. Experiments show that our models outperform existing systems in Chinese word segmentation and POS tagging, and perform preferable accuracies in dependency parsing. We also explore bi-LSTM models with fewer features.", "Jointly Extracting Relations with Class Ties via Effective Deep Ranking.\n\nConnections between relations in relation extraction, which we call class ties, are common. In distantly supervised scenario, one entity tuple may have multiple relation facts. Exploiting class ties between relations of one entity tuple will be promising for distantly supervised relation extraction. However, previous models are not effective or ignore to model this property. In this work, to effectively leverage class ties, we propose to make joint relation extraction with a unified model that integrates convolutional neural network (CNN) with a general pairwise ranking framework, in which three novel ranking loss functions are introduced. Additionally, an effective method is presented to relieve the severe class imbalance problem from NR (not relation) for model training. Experiments on a widely used dataset show that leveraging class ties will enhance extraction and demonstrate the effectiveness of our model to learn class ties. Our model outperforms the baselines significantly, achieving state-of-the-art performance.", "Emergent Predication Structure in Hidden State Vectors of Neural Readers.\n\nA significant number of neural architectures for reading comprehension have recently been developed and evaluated on large cloze-style datasets. We present experiments supporting the emergence of ``predication structure'' in the hidden state vectors of these readers.  More specifically, we provide evidence that the hidden state vectors represent atomic formulas $\\Phi[c]$ where $\\Phi$ is a semantic property (predicate) and $c$ is a constant symbol entity identifier.", "Neural Modeling of Multi-Predicate Interactions for Japanese Predicate Argument Structure Analysis.\n\nThe performance of Japanese predicate argument structure (PAS) analysis has improved in recent years thanks to the joint modeling of interactions between multiple predicates. However, this approach relies heavily on syntactic information predicted by parsers, and suffers from errorpropagation. To remedy this problem, we introduce a model that uses grid-type recurrent neural networks. The proposed model automatically induces features sensitive to multi-predicate interactions from the word sequence information of a sentence. Experiments on the NAIST Text Corpus demonstrate that without syntactic information, our model outperforms previous syntax-dependent models.", "Learning attention for historical text normalization by learning to pronounce.\n\nAutomated processing of historical texts often relies on pre-normalization to modern word forms. Training encoder-decoder architectures to solve such problems typically requires a lot of training data, which is not available for the named task. We address this problem by using several novel encoder-decoder architectures, including a multi-task learning (MTL) architecture using a grapheme-to-phoneme dictionary as auxiliary data, pushing the state-of-the-art by an absolute 2% increase in performance. We analyze the induced models across 44 different texts from Early New High German. Interestingly, we observe that, as previously conjectured, multi-task learning can learn to focus attention during decoding, in ways remarkably similar to recently proposed attention mechanisms. This, we believe, is an important step toward understanding how MTL works.", "Argument Mining with Structured SVMs and RNNs.\n\nWe propose a novel factor graph model for argument mining, designed for settings in which the argumentative relations in a document do not necessarily form a tree structure. (This is the case in over 20% of the web comments dataset we release.) Our model jointly learns elementary unit type classification and argumentative relation prediction. Moreover, our model supports SVM and RNN parametrizations, can enforce structure constraints (e.g., transitivity), and can express dependencies between adjacent relations and propositions. Our approaches outperform unstructured baselines in both web comments and argumentative essay datasets.", "Creating Training Corpora for NLG Micro-Planners.\n\nIn this paper, we present a novel framework for semi-automatically creating linguistically challenging micro-planning data-to-text corpora from existing Knowledge Bases. Because our method pairs data of varying size and shape with texts ranging from simple clauses to short texts, a dataset created using this framework provides a challenging benchmark for microplanning. Another feature of this framework is that it can be applied to any large scale knowledge base and can therefore be used to train and learn KB verbalisers.  We apply our framework to DBpedia data and compare the resulting dataset with Wen et al. 2016's. We show that while Wen et al.'s dataset is more than twice larger than ours, it is less diverse both in terms of input and in terms of text. We thus propose our corpus generation framework as a novel method for creating challenging data sets from which NLG models can be learned which are capable of handling the complex interactions occurring during in micro-planning between lexicalisation, aggregation, surface realisation, referring expression generation and sentence segmentation. To encourage researchers to take up this challenge, we made available a dataset of 21,855 data/text pairs created using this framework in the context of the WebNLG shared task.", "Identifying 1950s American Jazz Musicians: Fine-Grained IsA Extraction via Modifier Composition.\n\nWe present a method for populating fine-grained classes (e.g., ``1950s American jazz musicians'') with instances (e.g., Charles Mingus ). While state-of-the-art methods tend to treat class labels as single lexical units, the proposed method considers each of the individual modifiers in the class label relative to the head. An evaluation on the task of reconstructing Wikipedia category pages demonstrates a >10 point increase in AUC, over a strong baseline relying on widely-used Hearst patterns.", "Learning Cognitive Features from Gaze Data for Sentiment and Sarcasm Classification using Convolutional Neural Network.\n\nCognitive NLP systems- i.e., NLP systems that make use of behavioral data - augment traditional text-based features with cognitive features extracted from eye-movement patterns, EEG signals, brain-imaging etc. Such extraction of features is typically manual. We contend that manual extraction of features may not be the best way to tackle text subtleties that characteristically prevail in complex classification tasks like Sentiment Analysis and Sarcasm Detection, and that even the extraction and choice of features should be delegated to the learning system.  We introduce a framework to automatically extract cognitive features from the eye-movement/gaze data of human readers reading the text and use them as features along with textual features for the tasks of sentiment polarity and sarcasm detection. Our proposed framework is based on Convolutional Neural Network (CNN). The CNN learns features from both gaze and text and uses them to classify the input text. We test our technique on published sentiment and sarcasm labeled datasets, enriched with gaze information, to show that using a combination of automatically learned text and gaze features often yields better classification performance over (i)  CNN based systems that rely on text input alone and (ii) existing systems that rely on handcrafted gaze and textual features.", "One-Shot Neural Cross-Lingual Transfer for Paradigm Completion.\n\nWe present a novel cross-lingual transfer method for paradigm completion, the task of mapping a lemma to its inflected forms, using a neural encoder-decoder model, the state of the art for the monolingual task. We use labeled data from a high-resource language to increase performance on a low-resource language. In experiments on 21 language pairs from four different language families, we obtain up to 58% higher accuracy than without transfer and show that even zero-shot and one-shot learning are possible. We further find that the degree of language relatedness strongly influences the ability to transfer morphological knowledge.", "Supervised Learning of Automatic Pyramid for Optimization-Based Multi-Document Summarization.\n\nWe present a  new supervised framework that learns to estimate automatic Pyramid scores and uses them for optimization-based extractive multi-document summarization. For learning automatic Pyramid scores, we developed a method for automatic training data generation which is based on a genetic algorithm using automatic Pyramid as the fitness function. Our experimental evaluation shows that  our new framework significantly outperforms strong baselines regarding automatic Pyramid, and that there is much room for improvement in comparison with the upper-bound for automatic Pyramid.", "A Principled Framework for Evaluating Summarizers: Comparing Models of Summary Quality against Human Judgments.\n\nWe present a new framework for evaluating extractive summarizers, which is based on a principled representation as optimization problem. We prove that every extractive summarizer can be decomposed into an objective function  and an optimization technique. We perform a comparative analysis and evaluation of several objective functions embedded in well-known summarizers regarding their correlation with human judgments. Our comparison of these correlations across two datasets yields surprising insights into the role and performance of objective functions in the different  summarizers.", "Affect-LM: A Neural Language Model for Customizable Affective Text Generation.\n\nHuman verbal communication includes affective messages which are conveyed through use of emotionally colored words. There has been a lot of research effort in this direction but the problem of integrating state-of-the-art neural language models with affective information remains an area ripe for exploration. In this paper, we propose an extension to an LSTM (Long Short-Term Memory) language model for generation of conversational text, conditioned on affect categories. Our proposed model, Affect-LM enables us to customize the degree of emotional content in generated sentences through an additional design parameter. Perception studies conducted using Amazon Mechanical Turk show that Affect-LM can generate naturally looking emotional sentences without sacrificing grammatical correctness. Affect-LM also learns affect-discriminative word representations, and perplexity experiments show that additional affective information in conversational text can improve language model prediction.", "Learning Semantic Correspondences in Technical Documentation.\n\nWe consider the problem of translating high-level textual descriptions to formal representations in technical documentation as part of an effort to model the meaning of such documentation.  We focus specifically on the problem of learning translational correspondences between text descriptions and grounded representations in the target documentation, such as formal representation of functions or code templates.  Our approach exploits the parallel nature of such documentation, or the tight coupling between high-level text and the low-level representations we aim to learn. Data is collected by mining technical documents for such parallel text-representation pairs, which we use to train a simple semantic parsing model. We report new baseline results on sixteen novel datasets, including the standard library documentation for nine popular programming languages across seven natural languages, and a small collection of Unix utility manuals.", "A* CCG Parsing with a Supertag and Dependency Factored Model.\n\nWe propose a new A* CCG parsing model in which the probability of a tree is decomposed into factors of CCG categories and its syntactic dependencies both defined on bi-directional LSTMs. Our factored model allows the precomputation of all probabilities and runs very efficiently, while modeling sentence structures explicitly via dependencies. Our model achieves the state-of-the-art results on English and Japanese CCG parsing.", "Volatility Prediction using Financial Disclosures Sentiments with Word Embedding-based IR Models.\n\nVolatility prediction\u2014an essential concept in financial markets\u2014has recently been addressed using sentiment analysis methods. We investigate the sentiment of annual disclosures of companies in stock markets to forecast volatility. We specifically explore the use of recent Information Retrieval (IR) term weighting models that are effectively extended by related terms using word embeddings. In parallel to textual information, factual market data have been widely used as the mainstream approach to forecast market risk. We therefore study different fusion methods to combine text and market data resources. Our word embedding-based approach significantly outperforms state-of-the-art methods. In addition, we investigate the characteristics of the reports of the companies in different financial sectors.", "Learning bilingual word embeddings with (almost) no bilingual data.\n\nMost methods to learn bilingual word embeddings rely on large parallel corpora, which is difficult to obtain for most language pairs. This has motivated an active research line to relax this requirement, with methods that use document-aligned corpora or bilingual dictionaries of a few thousand words instead. In this work, we further reduce the need of bilingual resources using a very simple self-learning approach that can be combined with any dictionary-based mapping technique. Our method exploits the structural similarity of embedding spaces, and works with as little bilingual evidence as a 25 word dictionary or even an automatically generated list of numerals, obtaining results comparable to those of systems that use richer resources.", "From Characters to Words to in Between: Do We Capture Morphology?.\n\nWords can be represented by composing the representations of subword units such as word segments, characters, and/or character n-grams. While such representations are effective and may capture the morphological regularities of words, they have not been systematically compared, and it is not understood how they interact with different morphological typologies. On a language modeling task, we present experiments that systematically vary (1) the basic unit of representation, (2) the composition of these representations, and (3) the morphological typology of the language modeled. Our results extend previous findings that character representations are effective across typologies, and we find that a previously unstudied combination of character trigram representations composed with bi-LSTMs outperforms most others. But we also find room for improvement: none of the character-level models match the predictive accuracy of a model with access to true morphological analyses, even when learned from an order of magnitude more data.", "FOIL it! Find One mismatch between Image and Language caption.\n\nIn this paper, we aim to understand whether current language and vision (LaVi) models truly grasp the interaction between the two modalities. To this end, we propose an extension of the MS-COCO dataset, FOIL-COCO, which associates images with both correct and `foil' captions, that is, descriptions of the image that are highly similar to the original ones, but contain one single mistake (`foil word'). We show that current LaVi models fall into the traps of this data and perform badly on three tasks: a) caption  classification (correct vs. foil); b) foil word detection; c) foil word correction. Humans, in contrast, have near-perfect performance on those tasks. We demonstrate that merely utilising language cues is not enough to model FOIL-COCO and that it challenges the state-of-the-art by requiring a fine-grained understanding of the relation between text and image.", "Representations of language in a model of visually grounded speech signal.\n\nWe present a visually grounded model of speech perception which projects spoken utterances and images to a joint semantic space. We use a multi-layer recurrent highway network to model the temporal nature of spoken speech, and show that it learns to extract both form and meaning-based linguistic knowledge from the input signal. We carry out an in-depth analysis of the representations used by different components of the trained model and show that encoding of semantic aspects tends to become richer as we go up the hierarchy of layers, whereas encoding of form-related aspects of the language input tends to initially increase and then plateau or decrease.", "What do Neural Machine Translation Models Learn about Morphology?.\n\nNeural machine translation (MT) models obtain state-of-the-art performance while maintaining a simple, end-to-end architecture. However, little is known about what these models learn about source and target languages during the training process. In this work, we analyze the representations learned by neural MT models at various levels of granularity and empirically evaluate the quality of the representations for learning morphology through extrinsic part-of-speech and morphological tagging tasks. We conduct a thorough investigation along several parameters: word-based vs. character-based representations, depth of the encoding layer, the identity of the target language, and encoder vs. decoder representations. Our data-driven, quantitative evaluation sheds light on important aspects in the neural MT system and its ability to capture word structure.", "Evaluating Layers of Representation in Neural Machine Translation on Syntactic and Semantic Tagging.\n\nWhile neural machine translation (NMT) models provide improved translation quality in an elegant framework, it is less clear what they learn about language. Recent work has started evaluating the quality of vector representations learned by NMT models on morphological and semantic tasks. In this paper, we investigate the representations learned at different layers of NMT encoders. We train NMT systems on parallel data and use the models to extract features for training a classifier on two tasks: part-of-speech (POS) and semantic tagging. We then measure the performance of the classifier as a proxy to the quality of the original NMT model for the given task. Our quantitative analysis yields interesting insights regarding representation learning in NMT models. For instance, we find that higher layers are better at learning semantics while lower layers are better for POS tagging.", "Riemannian Optimization for Skip-Gram Negative Sampling.\n\nSkip-Gram Negative Sampling (SGNS) word embedding model, well known by its implementation in ``word2vec'' software, is usually optimized by stochastic gradient descent. However, the optimization of SGNS objective can be viewed as a problem of searching for a good matrix with the low-rank constraint. The most standard way to solve this type of problems is to apply Riemannian optimization framework to optimize the SGNS objective over the manifold of required low-rank matrices. In this paper, we propose an algorithm that optimizes SGNS objective using Riemannian optimization and demonstrates its superiority over popular competitors, such as the original method to train SGNS and SVD over SPPMI matrix.", "Learning when to skim and when to read.\n\nMany recent advances in deep learning for natural language processing have come at increasing computational cost, but the power of these state-of-the-art models is not needed for every example in a dataset. We demonstrate two approaches to reducing unnecessary computation in cases where a fast but weak baseline classier and a stronger, slower model are both available. Applying an AUC-based metric to the task of sentiment classification, we find significant efficiency gains with both a probability-threshold method for reducing computational cost and one that uses a secondary decision network.", "Tandem Anchoring: a Multiword Anchor Approach for Interactive Topic Modeling.\n\nInteractive topic models are powerful tools for those seeking to understand large collections of text. However, existing sampling-based interactive topic modeling approaches scale poorly to large data sets. Anchor methods, which use a single word to uniquely identify a topic, offer the speed needed for interactive work but lack both a mechanism to inject prior knowledge and lack the intuitive semantics needed for user-facing applications. We propose combinations of words as anchors, go- ing beyond existing single word anchor algorithms\u2014an approach we call ``Tan- dem Anchors''. We begin with a synthetic investigation of this approach then apply the approach to interactive topic modeling in a user study and compare it to interac- tive and non-interactive approaches. Tan- dem anchors are faster and more intuitive than existing interactive approaches.", "EmoNet: Fine-Grained Emotion Detection with Gated Recurrent Neural Networks.\n\nAccurate detection of emotion from natural language has applications ranging from building emotional chatbots to better understanding individuals and their lives. However, progress on emotion detection has been hampered by the absence of large labeled datasets.  In this work, we build a very large dataset for fine-grained emotions and develop deep learning models on it. We achieve a new state-of-the-art on 24 fine-grained types of emotions (with an average accuracy of 87.58%). We also extend the task beyond emotion types to model Robert Plutick's 8 primary emotion dimensions, acquiring a superior accuracy of 95.68%.", "Learning Character-level Compositionality with Visual Features.\n\nPrevious work has modeled the compositionality of words by creating character-level models of meaning, reducing problems of sparsity for rare words. However, in many writing systems compositionality has an effect even on the character-level: the meaning of a character is derived by the sum of its parts. In this paper, we model this effect by creating embeddings for characters based on their visual characteristics, creating an image for the character and running it through a convolutional neural network to produce a visual character embedding. Experiments on a text classification task demonstrate that such model allows for better processing of instances with rare characters in languages such as Chinese, Japanese, and Korean. Additionally, qualitative analyses demonstrate that our proposed model learns to focus on the parts of characters that carry topical content which resulting in embeddings that are coherent in visual space.", "Learning to Create and Reuse Words in Open-Vocabulary Neural Language Modeling.\n\nFixed-vocabulary language models fail to account for one of the most characteristic statistical facts of natural language: the frequent creation and reuse of new word types. Although character-level language models offer a partial solution in that they can create word types not attested in the training corpus, they do not capture the ``bursty'' distribution of such words. In this paper, we augment a hierarchical LSTM language model that generates sequences of word tokens character by character with a caching mechanism that learns to reuse previously generated words. To validate our model we construct a new open-vocabulary language modeling corpus (the Multilingual Wikipedia Corpus; MWC) from comparable Wikipedia articles in 7 typologically diverse languages and demonstrate the effectiveness of our model across this range of languages.", "Program Induction by Rationale Generation: Learning to Solve and Explain Algebraic Word Problems.\n\nSolving algebraic word problems requires executing a series of arithmetic operations---a program---to obtain a final answer. However, since programs can be arbitrarily complicated, inducing them directly from question-answer pairs is a formidable challenge. To make this task more feasible, we solve these problems by generating answer rationales, sequences of natural language and human-readable mathematical expressions that derive the final answer through a series of small steps. Although rationales do not explicitly specify programs, they provide a scaffolding for their structure via intermediate milestones. To evaluate our approach, we have created a new 100,000-sample dataset of questions, answers and rationales. Experimental results show that indirect supervision of program learning via answer rationales is a promising strategy for inducing arithmetic programs.", "EICA at SemEval-2017 Task 4: A Simple Convolutional Neural Network for Topic-based Sentiment Classification.\n\nThis paper describes our approach for SemEval-2017 Task 4 - Sentiment Analysis in Twitter (SAT). Its five subtasks are divided into two categories: (1) sentiment classification, i.e., predicting topic-based tweet sentiment polarity, and (2) sentiment quantification, that is, estimating the sentiment distributions of a set of given tweets. We build a convolutional sentence classification system for the task of SAT. Official results show that the experimental results of our system are comparative.", "Semi-supervised sequence tagging with bidirectional language models.\n\nPre-trained word embeddings learned from unlabeled text have become a stan- dard component of neural network archi- tectures for NLP tasks. However, in most cases, the recurrent network that oper- ates on word-level representations to pro- duce context sensitive representations is trained on relatively little labeled data. In this paper, we demonstrate a general semi-supervised approach for adding pre- trained context embeddings from bidi- rectional language models to NLP sys- tems and apply it to sequence labeling tasks. We evaluate our model on two stan- dard datasets for named entity recognition (NER) and chunking, and in both cases achieve state of the art results, surpassing previous systems that use other forms of transfer or joint learning with additional labeled data and task specific gazetteers.", "Exploring Variation of Natural Human Commands to a Robot in a Collaborative Navigation Task.\n\nRobot-directed communication is variable, and may change based on human perception of robot capabilities. To collect training data for a dialogue system and to investigate possible communication changes over time, we developed a Wizard-of-Oz study that (a) simulates a robot's limited understanding, and (b) collects dialogues where human participants build a progressively better mental model of the robot's understanding. With ten participants, we collected ten hours of human-robot dialogue. We analyzed the structure of instructions that participants gave to a remote robot before it responded. Our findings show a general initial preference for including metric information (e.g., move forward 3 feet) over landmarks (e.g., move to the desk) in motion commands, but this decreased over time, suggesting changes in perception.", "Accent Adaptation for the Air Traffic Control Domain.\n\nAutomated speech recognition (ASR) plays a significant role in training and simulation systems for air traffic controllers. However, because English is the default language used in air traffic control (ATC), ASR systems often encounter difficulty with speakers' non-native accents, for which there is a paucity of data. This paper examines the effects of accent adaptation on the recognition of non-native English speech in the ATC domain. Accent adaptation has been demonstrated to be an effective way to model under-resourced speech, and can be applied to a variety of models. We use Subspace Gaussian Mixture Models (SGMMs) with the Kaldi Speech Recognition Toolkit to adapt acoustic models from American English to German-accented English, and compare it against other adaptation methods. Our results provide additional evidence that SGMMs can be an efficient and effective way to approach this problem, particularly with smaller amounts of accented training data.", "Semantic Word Clusters Using Signed Spectral Clustering.\n\nVector space representations of words capture many aspects of word similarity, but such methods tend to produce vector spaces in which antonyms (as well as synonyms) are close to each other. For spectral clustering using such word embeddings, words are points in a vector space where synonyms are linked with positive weights, while antonyms are linked with negative weights. We present a new signed spectral normalized graph cut algorithm, {\\em signed clustering}, that overlays existing thesauri upon distributionally derived vector representations of words, so that antonym relationships between word pairs are represented by negative weights. Our signed clustering algorithm produces clusters of words that simultaneously capture distributional and synonym relations. By using randomized spectral decomposition (Halko et al., 2011) and sparse matrices, our method is both fast and scalable. We validate our clusters using datasets containing human judgments of word pair similarities and show the benefit of using our word clusters for sentiment prediction.", "Detecting annotation noise in automatically labelled data.\n\nWe introduce a method for error detection in automatically annotated text, aimed at supporting the creation of high-quality language resources at affordable cost. Our method combines an unsupervised generative model with human supervision from active learning. We test our approach on in-domain and out-of-domain data in two languages, in AL simulations and in a real world setting. For all settings, the results show that our method is able to detect annotation errors with high precision and high recall.", "Learning Word-Like Units from Joint Audio-Visual Analysis.\n\nGiven a collection of images and spoken audio captions, we present a method for discovering word-like acoustic units in the continuous speech signal and grounding them to semantically relevant image regions. For example, our model is able to detect spoken instances of the word 'lighthouse' within an utterance and associate them with image regions containing lighthouses. We do not use any form of conventional automatic speech recognition, nor do we use any text transcriptions or conventional linguistic annotations. Our model effectively implements a form of spoken language acquisition, in which the computer learns not only to recognize word categories by sound, but also to enrich the words it learns with semantics by grounding them in images.", "TakeLab at SemEval-2017 Task 4: Recent Deaths and the Power of Nostalgia in Sentiment Analysis in Twitter.\n\nThis paper describes the system we submitted to SemEval-2017 Task 4 (Sentiment Analysis in Twitter), specifically subtasks A, B, and D. Our main focus was topic-based message polarity classification on a two-point scale (subtask B). The system we submitted uses a Support Vector Machine classifier with rich set of features, ranging from standard to more creative, task-specific features, including a series of rating-based features as well as features that account for sentimental reminiscence of past topics and deceased famous people. Our system ranked 14th out of 39 submissions in subtask A, 5th out of 24 submissions in subtask B, and 3rd out of 16 submissions in subtask D.", "HumorHawk at SemEval-2017 Task 6: Mixing Meaning and Sound for Humor Recognition.\n\nThis paper describes the winning system for SemEval-2017 Task 6: \\#HashtagWars: Learning a Sense of Humor. Humor detection has up until now been predominantly addressed using feature-based approaches. Our system utilizes recurrent deep learning methods with dense embeddings to predict humorous tweets from the @midnight show \\#HashtagWars. In order to include both meaning and sound in the analysis, GloVe embeddings are combined with a novel phonetic representation to serve as input to an LSTM component. The output is combined with a character-based CNN model, and an XGBoost component in an ensemble model which achieves 0.675 accuracy on the evaluation data.", "Incorporating Dialectal Variability for Socially Equitable Language Identification.\n\nLanguage identification (LID) is a critical first step for processing multilingual text.  Yet most LID systems are not designed to handle the linguistic diversity of global platforms like Twitter, where local dialects and rampant code-switching lead language classifiers to systematically miss minority dialect speakers and multilingual speakers.  We propose a new dataset and a character-based sequence-to-sequence model for LID designed to support dialectal and multilingual language varieties. Our model achieves state-of-the-art performance on multiple LID benchmarks.  Furthermore, in a case study using Twitter for health tracking,  our method substantially increases the availability of texts written by underrepresented populations, enabling the development of ``socially inclusive'' NLP tools.", "Deep Multitask Learning for Semantic Dependency Parsing.\n\nWe present a deep neural architecture that parses sentences into three semantic dependency graph formalisms. By using efficient, nearly arc-factored inference and a bidirectional-LSTM composed with a multi-layer perceptron,  our base system is able to significantly improve the state of the art for semantic dependency parsing, without using hand-engineered features or syntax. We then explore two multitask learning approaches---one that shares parameters across formalisms, and one that uses higher-order structures to predict the graphs jointly. We find that both approaches improve performance across formalisms on average, achieving a new state of the art. Our code is open-source and available at https://github.com/Noahs-ARK/NeurboParser.", "BIT at SemEval-2017 Task 1: Using Semantic Information Space to Evaluate Semantic Textual Similarity.\n\nThis paper presents three systems for semantic textual similarity (STS) evaluation at SemEval-2017 STS task. One is an unsupervised system and the other two are supervised systems which simply employ the unsupervised one. All our systems mainly depend on the (SIS), which is constructed based on the semantic hierarchical taxonomy in WordNet, to compute non-overlapping information content (IC) of sentences. Our team ranked 2nd among 31 participating teams by the primary score of Pearson correlation coefficient (PCC) mean of 7 tracks and achieved the best performance on Track 1 (AR-AR) dataset.", "Chunk-Based Bi-Scale Decoder for Neural Machine Translation.\n\nIn typical neural machine translation~(NMT), the decoder generates a sentence word by word, packing all linguistic granularities in the same time-scale of RNN. In this paper, we propose a new type of decoder for NMT, which splits the decode state into two parts and updates them in two different time-scales. Specifically, we first predict a chunk time-scale state for phrasal modeling, on top of which multiple word time-scale states are generated. In this way, the target sentence is translated hierarchically from chunks to words, with information in different granularities being leveraged. Experiments show that our proposed model significantly improves the translation performance over the state-of-the-art NMT model.", "Bandit Structured Prediction for Neural Sequence-to-Sequence Learning.\n\nBandit structured prediction describes a stochastic optimization framework where learning is performed from partial feedback. This feedback is received in the form of a task loss evaluation to a predicted output structure, without having access to gold standard structures. We advance this framework by lifting linear bandit learning to neural sequence-to-sequence learning problems using attention-based recurrent neural networks. Furthermore, we show how to incorporate control variates into our learning algorithms for variance reduction and improved generalization. We present an evaluation on a neural machine translation task that shows improvements of up to 5.89 BLEU points for domain adaptation from simulated bandit feedback.", "A Corpus of Annotated Revisions for Studying Argumentative Writing.\n\nThis paper presents ArgRewrite, a corpus of between-draft revisions of argumentative essays. Drafts are manually aligned at the sentence level, and the writer's purpose for each revision is annotated with categories analogous to those used in argument mining and discourse analysis. The corpus should enable advanced research in writing comparison and revision analysis, as demonstrated via our own studies of student revision behavior and of automatic revision purpose prediction.", "Going out on a limb: Joint Extraction of Entity Mentions and Relations without Dependency Trees.\n\nWe present a novel attention-based recurrent neural network for joint extraction of entity mentions and relations. We show that attention along with long short term memory (LSTM) network can extract semantic relations between entity mentions without having access to dependency trees. Experiments on Automatic Content Extraction (ACE) corpora show that our model significantly outperforms feature-based joint model by Li and Ji (2014). We also compare our model with an end-to-end tree-based LSTM model (SPTree) by Miwa and Bansal (2016) and show that our model performs within 1\\% on entity mentions and 2\\% on relations. Our fine-grained analysis also shows that our model performs significantly better on Agent-Artifact relations, while SPTree performs better on Physical and Part-Whole relations.", "Towards an Automatic Turing Test: Learning to Evaluate Dialogue Responses.\n\nAutomatically evaluating the quality of dialogue responses for unstructured domains is a challenging problem.  Unfortunately, existing automatic evaluation metrics are biased and correlate very poorly with human judgements of response quality (Liu et al., 2016). Yet having an accurate automatic evaluation procedure is crucial for dialogue research, as it allows rapid prototyping and testing of new models with fewer expensive human evaluations. In response to this challenge, we formulate automatic dialogue evaluation as a learning problem.We present an evaluation model (ADEM)that learns to predict human-like scores to input responses, using a new dataset of human response scores.   We show that the ADEM model's predictions correlate significantly,  and at a level much higher than word-overlap metrics such as BLEU, with human judgements at both the utterance and system-level. We also show that ADEM can generalize to evaluating dialogue mod-els unseen during training,                    an important step for automatic dialogue evaluation.", "Probabilistic Typology: Deep Generative Models of Vowel Inventories.\n\nLinguistic typology studies the range of structures present in human language. The main goal of the field is to discover which sets of possible phenomena are universal, and which are merely frequent. For example, all languages have vowels, while most---but not all---languages have an /u/ sound. In this paper we present the first probabilistic treatment of a basic question in phonological typology: What makes a natural vowel inventory?  We introduce a series of deep stochastic point processes, and contrast them with previous computational, simulation-based approaches.  We provide a comprehensive suite of experiments on over 200 distinct languages.", "Automatically Generating Rhythmic Verse with Neural Networks.\n\nWe propose two novel methodologies for the automatic generation of rhythmic poetry in a variety of forms. The first approach uses a neural language model trained on a phonetic encoding to learn an implicit representation of both the form and content of English poetry. This model can effectively learn common poetic devices such as rhyme, rhythm and alliteration. The second approach considers poetry generation as a constraint satisfaction problem where a generative neural language model is tasked with learning a representation of content, and a discriminative weighted finite state machine constrains it on the basis of form. By manipulating the constraints of the latter model, we can generate coherent poetry with arbitrary forms and themes. A large-scale extrinsic evaluation demonstrated that participants consider machine-generated poems to be written by humans 54% of the time. In addition, participants rated a machine-generated poem to be the best amongst all evaluated.", "Neural Machine Translation via Binary Code Prediction.\n\nIn this paper, we propose a new method for calculating the output layer in neural machine translation systems. The method is based on predicting a binary code for each word and can reduce computation time/memory requirements of the output layer to be logarithmic in vocabulary size in the best case. In addition, we also introduce two advanced approaches to improve the robustness of the proposed model: using error-correcting codes and combining softmax and binary codes. Experiments on two English-Japanese bidirectional translation tasks show proposed models achieve BLEU scores that approach the softmax, while reducing memory usage to the order of less than 1/10 and improving decoding speed on CPUs by x5 to x10.", "Estimating Code-Switching on Twitter with a Novel Generalized Word-Level Language Detection Technique.\n\nWord-level language detection is necessary for analyzing code-switched text, where multiple languages could be mixed within a sentence. Existing models are restricted to code-switching between two specific languages and fail in real-world scenarios as text input rarely has a priori information on the languages used. We present a novel unsupervised word-level language detection technique for code-switched text for an arbitrarily large number of languages, which does not require any manually annotated training data. Our experiments with tweets in seven languages show a 74% relative error reduction in word-level labeling with respect to competitive baselines. We then use this system to conduct a large-scale quantitative analysis of code-switching patterns on Twitter, both global as well as region-specific, with 58M tweets.", "Ontology-Aware Token Embeddings for Prepositional Phrase Attachment.\n\nType-level word embeddings use the same set of parameters to represent all instances of a word regardless of its context, ignoring the inherent lexical ambiguity in language. Instead, we embed semantic concepts (or synsets) as defined in WordNet and represent a word token in a particular context by estimating a distribution over relevant semantic concepts. We use the new, context-sensitive embeddings in a model for predicting prepositional phrase (PP) attachments and jointly learn the concept embeddings and model parameters. We show that using context-sensitive embeddings improves the accuracy of the PP attachment model by 5.4% absolute points, which amounts to a 34.4% relative reduction in errors.", "Apples to Apples: Learning Semantics of Common Entities Through a Novel Comprehension Task.\n\nUnderstanding common entities and their attributes is a primary requirement for any system that comprehends natural language. In order to enable learning about common entities, we introduce a novel machine comprehension task, GuessTwo: given a short paragraph comparing different aspects of two real-world semantically-similar entities, a system should guess what those entities are. Accomplishing this task requires deep language understanding which enables inference, connecting each comparison paragraph to different levels of knowledge about world entities and their attributes. So far we have crowdsourced a dataset of more than 14K comparison paragraphs comparing entities from a variety of categories such as fruits and animals. We have designed two schemes for evaluation: open-ended, and binary-choice prediction. For benchmarking further progress in the task, we have collected a set of paragraphs as the test set on which human can accomplish the task with an accuracy of 94.2\\% on open-ended prediction. We have implemented various models for tackling the task, ranging from semantic-driven to neural models. The semantic-driven approach outperforms the neural models, however, the results indicate that the task is very challenging across the models.", "Deep Keyphrase Generation.\n\nKeyphrase provides highly-summative information that can be effectively used for understanding, organizing and retrieving text content. Though previous studies have provided many workable solutions for automated keyphrase extraction, they commonly divided the to-be-summarized content into multiple text chunks, then ranked and selected the most meaningful ones. These approaches could neither identify keyphrases that do not appear in the text, nor capture the real semantic meaning behind the text. We propose a generative model for keyphrase prediction with an encoder-decoder framework, which can effectively overcome the above drawbacks.  We name it as \\textit{deep keyphrase generation} since it attempts to capture the deep semantic meaning of the content with a deep learning method. Empirical analysis on six datasets demonstrates that our proposed model not only achieves a significant performance boost on extracting keyphrases that appear in the source text, but also can generate absent keyphrases based on the semantic meaning of the text. Code and dataset are available at https://github.com/memray/seq2seq-keyphrase.", "Sentence Embedding for Neural Machine Translation Domain Adaptation.\n\nAlthough new corpora are becoming increasingly available for machine translation, only those that belong to the same or similar domains are typically able to improve translation performance. Recently Neural Machine Translation (NMT) has become prominent in the field. However, most of the existing domain adaptation methods only focus on phrase-based machine translation. In this paper, we exploit the NMT's internal embedding of the source sentence and use the sentence embedding similarity to select the sentences which are close to in-domain data. The empirical adaptation results on the IWSLT English-French and NIST Chinese-English tasks show that the proposed methods can substantially improve NMT performance by 2.4-9.0 BLEU points, outperforming the existing state-of-the-art baseline by 2.3-4.5 BLEU points.", "Diversity driven attention model for query-based abstractive summarization.\n\nAbstractive summarization aims to generate a shorter version of the document covering all the salient points in a compact and coherent fashion. On the other hand, query-based summarization highlights those points that are relevant in the context of a given query. The encode-attend-decode paradigm has achieved notable success in machine translation, extractive summarization, dialog systems, etc. But it suffers from the drawback of generation of repeated phrases. In this work we propose a model for the query-based summarization task based on the encode-attend-decode paradigm with two key additions (i) a query attention model (in addition to document attention model) which learns to focus on different portions of the query at different time steps (instead of using a static representation for the query) and (ii) a new diversity based attention model which aims to alleviate the problem of repeating phrases in the summary. In order to enable the testing of this model we introduce a new query-based summarization dataset building on debatepedia. Our experiments show that with these two additions the proposed model clearly outperforms vanilla encode-attend-decode models with a gain of 28\\% (absolute) in ROUGE-L scores.", "Abstract Syntax Networks for Code Generation and Semantic Parsing.\n\nTasks like code generation and semantic parsing require mapping unstructured (or partially structured) inputs to well-formed, executable outputs. We introduce abstract syntax networks, a modeling framework for these problems. The outputs are represented as abstract syntax trees (ASTs) and constructed by a decoder with a dynamically-determined modular structure paralleling the structure of the output tree. On the benchmark Hearthstone dataset for code generation, our model obtains 79.2 BLEU and 22.7% exact match accuracy, compared to previous state-of-the-art values of 67.1 and 6.1%. Furthermore, we perform competitively on the Atis, Jobs, and Geo semantic parsing datasets with no task-specific engineering.", "Fine-Grained Entity Typing with High-Multiplicity Assignments.\n\nAs entity type systems become richer and more fine-grained, we expect the number of types assigned to a given entity to increase. However, most fine-grained typing work has focused on datasets that exhibit a low degree of type multiplicity. In this paper, we consider the high-multiplicity regime inherent in data sources such as Wikipedia that have semi-open type systems. We introduce a set-prediction approach to this problem and show that our model outperforms unstructured baselines on a new Wikipedia-based fine-grained typing corpus.", "Combating Human Trafficking with Multimodal Deep Models.\n\nHuman trafficking is a global epidemic affecting millions of people across the planet. Sex trafficking, the dominant form of human trafficking, has seen a significant rise mostly due to the abundance of escort websites, where human traffickers can openly advertise among at-will escort advertisements. In this paper, we take a major step in the automatic detection of advertisements suspected to pertain to human trafficking. We present a novel dataset called Trafficking-10k, with more than 10,000~advertisements annotated for this task. The dataset contains two sources of information per advertisement: text and images. For the accurate detection of trafficking advertisements, we designed and trained a deep multimodal model called the Human Trafficking Deep Network (HTDN).", "MORSE: Semantic-ally Drive-n MORpheme SEgment-er.\n\nWe present in this paper a novel framework for morpheme segmentation which uses the morpho-syntactic regularities preserved by word representations, in addition to orthographic features, to segment words into morphemes. This framework is the first to consider vocabulary-wide syntactico-semantic information for this task. We also analyze the deficiencies  of  available benchmarking datasets and introduce our own dataset that was created on the basis of compositionality.  We validate our algorithm across datasets and present state-of-the-art results.", "Detect Rumors in Microblog Posts Using Propagation Structure via Kernel Learning.\n\nHow fake news goes viral via social media? How does its propagation pattern differ from real stories? In this paper, we attempt to address the problem of identifying rumors, i.e., fake information, out of microblog posts based on their propagation structure. We firstly model microblog posts diffusion with propagation trees, which provide valuable clues on how an original message is transmitted and developed over time. We then propose a kernel-based method called Propagation Tree Kernel, which captures high-order patterns differentiating different types of rumors by evaluating the similarities between their propagation tree structures. Experimental results on two real-world datasets demonstrate that the proposed kernel-based approach can detect rumors more quickly and accurately than state-of-the-art rumor detection models.", "Joint Learning for Event Coreference Resolution.\n\nWhile joint models have been developed for many NLP tasks, the vast majority of event coreference resolvers, including the top-performing resolvers competing in the recent TAC KBP 2016 Event Nugget Detection and Coreference task, are pipeline-based, where the propagation of errors from the trigger detection component to the event coreference component is a major performance limiting factor. To address this problem, we propose a model for jointly learning event coreference, trigger detection, and event anaphoricity. Our joint model is novel in its choice of tasks and its features for capturing cross-task interactions. To our knowledge, this is the first attempt to train a mention-ranking model and employ event anaphoricity for event coreference. Our model achieves the best results to date on the KBP 2016 English and Chinese datasets.", "Deep Learning in Semantic Kernel Spaces.\n\nKernel methods enable the direct usage of structured representations of textual data during language learning and inference tasks. Expressive kernels, such as Tree Kernels, achieve excellent performance in NLP. On the other side, deep neural networks have been demonstrated effective in automatically learning feature representations during training. However, their input is tensor data, i.e., they can not manage rich structured information. In this paper, we show that expressive kernels and deep neural networks can be combined in a common framework in order to (i) explicitly model structured information and (ii) learn non-linear decision functions. We show that the input layer of a deep architecture can be pre-trained through the application of the Nystrom low-rank approximation of kernel spaces. The resulting ``kernelized'' neural network achieves state-of-the-art accuracy in three different tasks.", "Automatic Induction of Synsets from a Graph of Synonyms.\n\nThis paper presents a new graph-based approach that induces synsets using synonymy dictionaries and word embeddings. First, we build a weighted graph of synonyms extracted from commonly available resources, such as Wiktionary. Second, we apply word sense induction to deal with ambiguous words. Finally, we cluster the disambiguated version of the ambiguous input graph into synsets. Our meta-clustering approach lets us use an efficient hard clustering algorithm to perform a fuzzy clustering of the graph. Despite its simplicity, our approach shows excellent results, outperforming five competitive state-of-the-art methods in terms of F-score on three gold standard datasets for English and Russian derived from large-scale manually constructed lexical resources.", "Prior Knowledge Integration for Neural Machine Translation using Posterior Regularization.\n\nAlthough neural machine translation has made significant progress recently, how to integrate multiple overlapping, arbitrary prior knowledge sources remains a challenge. In this work, we propose to use posterior regularization to provide a general framework for integrating prior knowledge into neural machine translation. We represent prior knowledge sources as features in a log-linear model, which guides the learning processing of the neural translation model. Experiments on Chinese-English dataset show that our approach leads to significant improvements.", "Translating Neuralese.\n\nSeveral approaches have recently been proposed for learning decentralized deep multiagent policies that coordinate via a differentiable communication channel. While these policies are effective for many tasks, interpretation of their induced communication strategies has remained a challenge. Here we propose to interpret agents' messages by translating them.  Unlike in typical machine translation problems, we have no parallel data to learn from. Instead we develop a translation model based on the insight that agent messages and natural language strings mean the same thing if they induce the same belief about the world in a listener.  We present theoretical guarantees and empirical evidence that our approach preserves both the semantics and pragmatics of messages by ensuring that players communicating through a translation layer do not suffer a substantial loss in reward relative to players with a common language.", "Neural AMR: Sequence-to-Sequence Models for Parsing and Generation.\n\nSequence-to-sequence models have shown strong performance across a broad range of applications. However, their application to parsing and generating text using Abstract Meaning Representation (AMR) has been limited, due to the relatively limited amount of labeled data and the non-sequential nature of the AMR graphs. We present a novel training procedure that can lift this limitation using millions of unlabeled sentences and careful preprocessing of the AMR graphs. For AMR parsing, our model achieves competitive results of 62.1 SMATCH, the current best score reported without significant use of external semantic resources. For AMR generation, our model establishes a new state-of-the-art performance of BLEU 33.8. We present extensive ablative and qualitative analysis including strong evidence that sequence-based AMR models are robust against ordering variations of graph-to-sequence conversions.", "Get To The Point: Summarization with Pointer-Generator Networks.\n\nNeural sequence-to-sequence models have provided a viable new approach for abstractive text summarization (meaning they are not restricted to simply selecting and rearranging passages from the original text). However, these models have two shortcomings: they are liable to reproduce factual details inaccurately, and they tend to repeat themselves. In this work we propose a novel architecture that augments the standard sequence-to-sequence attentional model in two orthogonal ways. First, we use a hybrid pointer-generator network that can copy words from the source text via pointing, which aids accurate reproduction of information, while retaining the ability to produce novel words through the generator. Second, we use coverage to keep track of what has been summarized, which discourages repetition. We apply our model to the CNN / Daily Mail summarization task, outperforming the current abstractive state-of-the-art by at least 2 ROUGE points.", "Bayesian Modeling of Lexical Resources for Low-Resource Settings.\n\nLexical resources such as dictionaries and gazetteers are often used as auxiliary data for tasks such as part-of-speech induction and named-entity recognition. However, discriminative training with lexical features requires annotated data to reliably estimate the lexical feature weights and may result in overfitting the lexical features at the expense of features which generalize better. In this paper, we investigate a more robust approach: we stipulate that the lexicon is the result of an assumed generative process. Practically, this means that we may treat the lexical resources as observations under the proposed generative model. The lexical resources provide training data for the generative model without requiring separate data to estimate lexical feature weights. We evaluate the proposed approach in two settings: part-of-speech induction and low-resource named-entity recognition.", "Search-based Neural Structured Learning for Sequential Question Answering.\n\nRecent work in semantic parsing for question answering has focused on long and complicated questions, many of which would seem unnatural if asked in a normal conversation between two humans. In an effort to explore a conversational QA setting, we present a more realistic task: answering sequences of simple but inter-related questions. We collect a dataset of 6,066 question sequences that inquire about semi-structured tables from Wikipedia, with 17,553 question-answer pairs in total. To solve this sequential question answering task, we propose a novel dynamic neural semantic parsing framework trained using a weakly supervised reward-guided search. Our model effectively leverages the sequential context to outperform state-of-the-art QA systems that are designed to answer highly complex questions.", "Don't understand a measure? Learn it: Structured Prediction for Coreference Resolution optimizing its measures.\n\nAn interesting aspect of structured prediction is the evaluation of an output structure against the gold standard. Especially in the loss-augmented setting, the need of finding the max-violating constraint has severely limited the expressivity of effective loss functions. In this paper, we trade off exact computation for enabling the use and study of more complex loss functions for coreference resolution. Most interestingly, we show that such functions can be (i) automatically learned also from controversial but commonly accepted coreference measures, e.g., MELA, and (ii) successfully used in learning algorithms. The accurate model comparison on the standard CoNLL-2012 setting shows the benefit of more expressive loss functions.", "From Language to Programs: Bridging Reinforcement Learning and Maximum Marginal Likelihood.\n\nOur goal is to learn a semantic parser that maps natural language utterances into executable programs when only indirect supervision is available: examples are labeled with the correct execution result, but not the program itself. Consequently, we must search the space of programs for those that output the correct result, while not being misled by \\emph{spurious programs}: incorrect programs that coincidentally output the correct result. We connect two common learning paradigms, reinforcement learning (RL) and maximum marginal likelihood (MML), and then present a new learning algorithm that combines the strengths of both. The new algorithm guards against spurious programs by combining the systematic search traditionally employed in MML with the randomized exploration of RL, and by updating parameters such that probability is spread more evenly across consistent programs. We apply our learning algorithm to a new neural semantic parser and show significant gains over existing state-of-the-art results on a recent context-dependent semantic parsing task.", "A Minimal Span-Based Neural Constituency Parser.\n\nIn this work, we present a minimal neural model for constituency parsing based on independent scoring of labels and spans. We show that this model is not only compatible with classical dynamic programming techniques, but also admits a novel greedy top-down inference algorithm based on recursive partitioning of the input. We demonstrate empirically that both prediction schemes are competitive with recent work, and when combined with basic extensions to the scoring model are capable of achieving state-of-the-art single-model performance on the Penn Treebank (91.79 F1) and strong performance on the French Treebank (82.23 F1).", "TextFlow: A Text Similarity Measure based on Continuous Sequences.\n\nText similarity measures are used in multiple tasks such as plagiarism detection, information ranking and recognition of paraphrases and textual entailment. While recent advances in deep learning highlighted the relevance of sequential models in natural language generation, existing similarity measures do not fully exploit the sequential nature of language. Examples of such similarity measures include n-grams and skip-grams overlap which rely on distinct slices of the input texts. In this paper we present a novel text similarity measure inspired from a common representation in DNA sequence alignment algorithms. The new measure, called TextFlow, represents input text pairs as continuous curves and uses both the actual position of the words and sequence matching to compute the similarity value. Our experiments on 8 different datasets show very encouraging results in paraphrase detection, textual entailment recognition and ranking relevance.", "UPC-USMBA at SemEval-2017 Task 3: Combining multiple approaches for CQA for Arabic.\n\nThis paper presents a description of the participation of the UPC-USMBA team in the SemEval 2017 Task 3, subtask D, Arabic. Our approach for facing the task is based on a combination of a set of atomic classifiers. The atomic classifiers include lexical string based, based on vectorial representations and rulebased. Several combination approaches have been tried.", "Verb Physics: Relative Physical Knowledge of Actions and Objects.\n\nLearning commonsense knowledge from natural language text is nontrivial due to reporting bias: people rarely state the obvious, e.g., ``My house is bigger than me.'' However, while rarely stated explicitly, this trivial everyday knowledge does influence the way people talk about the world, which provides indirect clues to reason about the world. For example, a statement like, ``Tyler entered his house'' implies that his house is bigger than Tyler. In this paper, we present an approach to infer relative physical knowledge of actions and objects along five dimensions (e.g., size, weight, and strength) from unstructured natural language text. We frame knowledge acquisition as joint inference over two closely related problems: learning (1) relative physical knowledge of object pairs and (2) physical implications of actions when applied to those object pairs. Empirical results demonstrate that it is possible to extract knowledge of actions and objects from language and that joint inference over different types of knowledge improves performance.", "Semantic Parsing of Pre-university Math Problems.\n\nWe have been developing an end-to-end math problem solving system that accepts natural language input. The current paper focuses on how we analyze the problem sentences to produce logical forms. We chose a hybrid approach combining a shallow syntactic analyzer and a manually-developed lexicalized grammar. A feature of the grammar is that it is extensively typed on the basis of a formal ontology for pre-university math. These types are helpful in semantic disambiguation inside and across sentences. Experimental results show that the hybrid system produces a well-formed logical form with 88\\% precision and 56\\% recall.", "An Algebra for Feature Extraction.\n\nThough feature extraction is a necessary first step in statistical NLP, it is often seen as a mere preprocessing step. Yet, it can dominate computation time, both during training, and especially at deployment. In this paper, we formalize feature extraction from an algebraic perspective. Our formalization allows us to define a message passing algorithm that can restructure feature templates to be more computationally efficient. We show via experiments on text chunking and relation extraction that this restructuring does indeed speed up feature extraction in practice by reducing redundant computation.", "PositionRank: An Unsupervised Approach to Keyphrase Extraction from Scholarly Documents.\n\nThe large and growing amounts of online scholarly data present both challenges and opportunities to enhance knowledge discovery. One such challenge is to automatically extract a small set of keyphrases from a document that can accurately describe the document's content and can facilitate fast information processing. In this paper, we propose PositionRank, an unsupervised model for keyphrase extraction from scholarly documents that incorporates information from all positions of a word's occurrences into a biased PageRank. Our model obtains remarkable improvements in performance over PageRank models that do not take into account word positions as well as over strong baselines for this task. Specifically, on several datasets of research papers, PositionRank achieves improvements as high as $29.09\\%$.", "Towards Harnessing Memory Networks for Coreference Resolution.\n\nCoreference resolution task demands comprehending a discourse, especially for anaphoric mentions which require semantic information for resolving antecedents. We investigate into how memory networks can be helpful for coreference resolution when posed as question answering problem. The comprehension capability of memory networks assists coreference resolution, particularly for the mentions that require semantic and context information. We experiment memory networks for coreference resolution, with 4 synthetic datasets generated for coreference resolu- tion with varying difficulty levels. Our system's performance is compared with a traditional coreference resolution system to show why memory network can be promising for coreference resolution.", "UMDeep at SemEval-2017 Task 1: End-to-End Shared Weight LSTM Model for Semantic Textual Similarity.\n\nWe describe a modified shared-LSTM network for the Semantic Textual Similarity (STS) task at SemEval-2017. The network builds on previously explored Siamese network architectures. We treat max sentence length as an additional hyperparameter to be tuned (beyond learning rate, regularization, and dropout). Our results demonstrate that hand-tuning max sentence training length significantly improves final accuracy. After optimizing hyperparameters, we train the network on the multilingual semantic similarity task using pre-translated sentences. We achieved a correlation of 0.4792 for all the subtasks.  We achieved the fourth highest team correlation for Task 4b, which was our best relative placement.", "Regularized Topic Models for Sparse Interpretable Word Embeddings.\n\nProbabilistic topic modeling is a tool for semantic analysis of texts widely used during the last decades. Word embeddings have gained their popularity more recently being inspired by achievements in neural networks. In this paper we consider both approaches from the perspective of learning hidden semantic representations of words via matrix factorization techniques. We show that a topic modeling performed over word co-occurrence data is capable of producing state-of-the-art results for word similarity task. Unlike SGNS, the components of obtained word embeddings are interpretable and highly sparse. We impose further requirements by additive regularization approach thus bridging the gap between word embeddings and extensions of topic models.", "The (too Many) Problems of Analogical Reasoning with Word Vectors.\n\nThis paper explores the possibilities of analogical reasoning with vector space models. Given two pairs of words with the same relation (e.g. man:woman :: king:queen), it was proposed that the offset between one pair of the corresponding word vectors can be used to identify the unknown member of the other pair (king - man + woman = queen). We argue against such ``linguistic regularities'' as a model for linguistic relations in vector space models and as a benchmark, and we show that the vector offset (as well as two other, better-performing methods) suffers from dependence on vector similarity.", "Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings.\n\nThe blind application of machine learning runs the risk of amplifying biases present in data. Such a danger is facing us with word embedding, a popular framework to represent text data as vectors which has been used in many machine learning and natural language processing tasks. We show that even word embeddings trained on Google News articles exhibit female/male gender stereotypes to a disturbing extent. This raises concerns because their widespread use, as we describe, often tends to amplify these biases. Geometrically, gender bias is first shown to be captured by a direction in the word embedding. Second, gender neutral words are shown to be linearly separable from gender definition words in the word embedding. Using these properties, we provide a methodology for modifying an embedding to remove gender stereotypes, such as the association between the words receptionist and female, while maintaining desired associations such as between the words queen and female. Using crowd-worker evaluation as well as standard benchmarks, we empirically demonstrate that our algorithms significantly reduce gender bias in embeddings while preserving the its useful properties such as the ability to cluster related concepts and to solve analogy tasks. The resulting embeddings can be used in applications without amplifying gender bias.", "Knowledge Base Completion: Baselines Strike Back.\n\nMany papers have been published on the knowledge base completion task in the past few years. Most of these introduce novel architectures for relation learning that are evaluated on standard datasets like FB15k and WN18. This paper shows that the accuracy of almost all models published on the FB15k can be outperformed by an appropriately tuned baseline --- our reimplementation of the DistMult model. Our findings cast doubt on the claim that the performance improvements of recent models are due to architectural changes as opposed to hyper-parameter tuning or different training objectives. This should prompt future research to re-consider how the performance of models is evaluated and reported.", "Sequential Attention: A Context-Aware Alignment Function for Machine Reading.\n\nIn this paper we  propose a neural network model with a novel Sequential Attention layer that extends soft attention by assigning weights to words in an input sequence in a way that takes into account not just how well that word matches a query, but how well surrounding words match. We evaluate this approach on the task of reading comprehension (on the Who did What and CNN datasets) and show that it dramatically improves a strong baseline---the Stanford Reader---and is competitive with the state of the art.", "Beyond Bilingual: Multi-sense Word Embeddings using Multilingual Context.\n\nWord embeddings, which represent a word as a point in a vector space, have become ubiquitous to several NLP tasks. A recent line of work uses bilingual (two languages) corpora to learn a different vector for each sense of a word, by exploiting crosslingual signals to aid sense identification. We present a multi-view Bayesian non-parametric algorithm which improves multi-sense wor d embeddings by (a) using multilingual (i.e., more than two languages) corpora to significantly improve sense embeddings beyond what one achieves with bilingual information, and (b) uses a principled approach to learn a variable number of senses per word, in a data-driven manner. Ours is the first approach with the ability to leverage multilingual corpora efficiently for multi-sense representation learning. Experiments show that multilingual training significantly improves performance over monolingual and bilingual training, by allowing us to combine different parallel corpora to leverage multilingual context. Multilingual training yields comparable performance to a state of the art monolingual model trained on five times more training data.", "DocTag2Vec: An Embedding Based Multi-label Learning Approach for Document Tagging.\n\nTagging news articles or blog posts with relevant tags from a collection of predefined ones is coined as document tagging in this work. Accurate tagging of articles can benefit several downstream applications such as recommendation and search. In this work, we propose a novel yet simple approach called DocTag2Vec to accomplish this task. We substantially extend Word2Vec and Doc2Vec -- two popular models for learning  distributed representation of words and documents. In DocTag2Vec, we simultaneously learn the representation of words, documents, and tags in a joint vector space during training, and employ the simple k-nearest neighbor search to predict tags for unseen documents. In contrast to previous multi-label learning methods, DocTag2Vec directly deals with raw text instead of provided feature vector, and in addition, enjoys advantages like the learning of tag representation, and the ability of handling newly created tags. To demonstrate the effectiveness of our approach, we conduct experiments on several datasets and show promising results against state-of-the-art methods.", "FuRongWang at SemEval-2017 Task 3: Deep Neural Networks for Selecting Relevant Answers in Community Question Answering.\n\nWe describes deep neural networks frameworks in this paper to address the community question answering (cQA) ranking task (SemEval-2017 task 3). Convolutional neural networks and bi-directional long-short term memory networks are applied in our methods to extract semantic information from questions and answers (comments). In addition, in order to take the full advantage of question-comment semantic relevance, we deploy interaction layer and augmented features before calculating the similarity. The results show that our methods have the great effectiveness for both subtask A and subtask C.", "Prediction of Frame-to-Frame Relations in the FrameNet Hierarchy with Frame Embeddings.\n\nAutomatic completion of frame-to-frame (F2F) relations in the FrameNet (FN) hierarchy has received little attention, although they incorporate meta-level commonsense knowledge and are used in downstream approaches. We address the problem of sparsely annotated F2F relations. First, we examine whether the manually defined F2F relations emerge from text by learning text-based frame embeddings. Our analysis reveals insights about the difficulty of reconstructing F2F relations purely from text. Second, we present different systems for predicting F2F relations; our best-performing one uses the FN hierarchy to train on and to ground embeddings in. A comparison of systems and embeddings exposes the crucial influence of knowledge-based embeddings to a system's performance in predicting F2F relations.", "Learning Joint Multilingual Sentence Representations with Neural Machine Translation.\n\nIn this paper, we use the framework of neural machine translation to learn joint sentence representations across six very different languages. Our aim is that a representation which is independent of the language, is likely to capture the underlying semantics.  We define a new cross-lingual similarity measure, compare up to 1.4M sentence representations and study the characteristics of close sentences. We provide experimental evidence that sentences that are close in embedding space are indeed semantically highly related, but often have quite different structure and syntax.  These relations also hold when comparing sentences in different languages.", "Transfer Learning for Speech Recognition on a Budget.\n\nEnd-to-end training of automated speech recognition (ASR) systems requires massive data and compute resources. We explore transfer learning based on model adaptation as an approach for training ASR models under constrained GPU memory, throughput and training data. We conduct several systematic experiments adapting a Wav2Letter convolutional neural network originally trained for English ASR to the German language. We show that this technique allows faster training on consumer-grade resources while requiring less training data in order to achieve the same accuracy, thereby lowering the cost of training ASR models in other languages. Model introspection revealed that small adaptations to the network's weights were sufficient for good performance, especially for inner layers.", "Gradual Learning of Matrix-Space Models of Language for Sentiment Analysis.\n\nLearning word representations to capture the semantics and compositionality of language has received much research interest in natural language processing. Beyond the popular vector space models, matrix representations for words have been proposed, since then, matrix multiplication can serve as natural composition operation. In this work, we investigate the problem of learning matrix representations of words. We present a learning approach for compositional matrix-space models for the task of sentiment analysis. We show that our approach, which learns the matrices gradually in two steps, outperforms other approaches and a gradient-descent baseline in terms of quality and computational cost.", "NewsQA: A Machine Comprehension Dataset.\n\nWe present NewsQA, a challenging machine comprehension dataset of over 100,000 human-generated question-answer pairs. Crowdworkers supply questions and answers based on a set of over 10,000 news articles from CNN, with answers consisting of spans of text in the articles. We collect this dataset through a four-stage process designed to solicit exploratory questions that require reasoning. Analysis confirms that NewsQA demands abilities beyond simple word matching and recognizing textual entailment. We measure human performance on the dataset and compare it to several strong neural models. The performance gap between humans and machines (13.3% F1) indicates that significant progress can be made on NewsQA through future research. The dataset is freely available online.", "Intrinsic and Extrinsic Evaluation of Spatiotemporal Text Representations in Twitter Streams.\n\nLanguage in social media is a dynamic system, constantly evolving and adapting, with words and concepts rapidly emerging, disappearing, and changing their meaning. These changes can be estimated using word representations in context, over time and across locations. A number of methods have been proposed to track these spatiotemporal changes but no general method exists to evaluate the quality of these representations. Previous work largely focused on qualitative evaluation, which we improve by proposing a set of visualizations that highlight changes in text representation over both space and time. We demonstrate usefulness of novel spatiotemporal representations to explore and characterize specific aspects of the corpus of tweets collected from European countries over a two-week period centered around the terrorist attacks in Brussels in March 2016. In addition, we quantitatively evaluate spatiotemporal representations by feeding them into a downstream classification task -- event type prediction. Thus, our work is the first to provide both intrinsic (qualitative) and extrinsic (quantitative) evaluation of text representations for spatiotemporal trends.", "A Frame Tracking Model for Memory-Enhanced Dialogue Systems.\n\nRecently, resources and tasks were proposed to go beyond state tracking in dialogue systems. An example is the frame tracking task, which requires recording multiple frames, one for each user goal set during the dialogue. This allows a user, for instance, to compare items corresponding to different goals. This paper proposes a model which takes as input the list of frames created so far during the dialogue, the current user utterance as well as the dialogue acts, slot types, and slot values associated with this utterance. The model then outputs the frame being referenced by each  triple of dialogue act, slot type, and slot value. We show that on the recently published Frames dataset, this model significantly outperforms a previously proposed rule-based baseline. In addition, we propose an extensive analysis of the frame tracking task by dividing it into sub-tasks and assessing their difficulty with respect to our model.", "Does the Geometry of Word Embeddings Help Document Classification? A Case Study on Persistent Homology-Based Representations.\n\nWe investigate the pertinence of methods from algebraic topology for text data analysis. These methods enable the development of mathematically-principled isometric-invariant mappings from a set of vectors to a document embedding, which is stable with respect to the geometry of the document in the selected metric space. In this work, we evaluate the utility of these topology-based document representations in traditional NLP tasks, specifically document clustering and sentiment classification. We find that the embeddings do not benefit text analysis. In fact, performance is worse than simple techniques like tf-idf, indicating that the geometry of the document does not provide enough variability for classification on the basis of topic or sentiment in the chosen datasets.", "Blind Phoneme Segmentation With Temporal Prediction Errors.\n\nPhonemic segmentation of speech is a critical step of speech recognition systems. We propose a novel unsupervised algorithm based on sequence prediction models such as Markov chains and recurrent neural networks. Our approach consists in analyzing the error profile of a model trained to predict speech features frame-by-frame.Specifically, we try to learn the dynamics of speech in the MFCC space and hypothesize boundaries from local maxima in the prediction error. We evaluate our system on the TIMIT dataset, with improvements over similar methods", "The Coadaptation Problem when Learning How and What to Compose.\n\nThis paper discusses a potential problem with tree-sequence models that induce syntax, in that there exists a failure mode when naively treating the relationship between composition and parsing. The first section presents a tree-sequence model that induces syntax. The second section proposes a strategy that attempts to prevent coadaptation between composition and parsing. The third section covers a method for randomly sampling binary trees in a transition-based setting, a simple and useful technique for transition-based parsing models.", "Lancaster A at SemEval-2017 Task 5: Evaluation metrics matter: predicting sentiment from financial news headlines.\n\nThis paper describes our participation in Task 5 track 2 of SemEval 2017 to predict the sentiment of financial news headlines for a specific company on a continuous scale between -1 and 1. We tackled the problem using a number of approaches, utilising a Support Vector Regression (SVR) and a Bidirectional Long Short-Term Memory (BLSTM). We found an improvement of 4-6\\% using the LSTM model over the SVR and came fourth in the track. We report a number of different evaluations using a finance specific word embedding model and reflect on the effects of using different evaluation metrics.", "SRHR at SemEval-2017 Task 6: Word Associations for Humour Recognition.\n\nThis paper explores the role of semantic relatedness features, such as word associations, in humour recognition. Specifically, we examine the task of inferring pairwise humour judgments in Twitter hashtag wars. We examine a variety of word association features derived from University of Southern Florida Free Association Norms (USF) and the Edinburgh Associative Thesaurus (EAT) and find that word association-based features outperform Word2Vec similarity, a popular semantic relatedness measure. Our system achieves an accuracy of 56.42% using a combination of unigram perplexity, bigram perplexity, EAT difference (tweet-avg), USF forward (max), EAT difference (word-avg), USF difference (word-avg), EAT forward (min), USF difference (tweet-max), and EAT backward (min).", "Context encoders as a simple but powerful extension of word2vec.\n\nWith a strikingly simple architecture and the ability to learn meaningful word embeddings efficiently from texts containing billions of words, word2vec remains one of the most popular neural language models used today. However, as only a single embedding is learned for every word in the vocabulary, the model fails to optimally represent words with multiple meanings and, additionally, it is not possible to create embeddings for new (out-of-vocabulary) words on the spot. Based on an intuitive interpretation of the continuous bag-of-words (CBOW) word2vec model's negative sampling training objective in terms of predicting context based similarities, we motivate an extension of the model we call context encoders (ConEc). By multiplying the matrix of trained word2vec embeddings with a word's average context vector, out-of-vocabulary (OOV) embeddings and representations for words with multiple meanings can be created based on the words' local contexts. The benefits of this approach are illustrated by using these word embeddings as features in the CoNLL 2003 named entity recognition (NER) task.", "Grounding Symbols in Multi-Modal Instructions.\n\nAs robots begin to cohabit with humans in semi-structured environments, the need arises to understand instructions involving rich variability---for instance, learning to ground symbols in the physical world. Realistically, this task must cope with small datasets consisting of a particular users' contextual assignment of meaning to terms. We present a method for processing a raw stream of cross-modal input---i.e., linguistic instructions, visual perception of a scene and a concurrent trace of 3D eye tracking fixations---to produce the segmentation of objects with a correspondent association to high-level concepts. To test our framework we present experiments in a table-top object manipulation scenario. Our results show our model learns the user's notion of colour and shape from a small number of physical demonstrations, generalising to identifying physical referents for novel combinations of the words.", "A Tale of Two DRAGGNs: A Hybrid Approach for Interpreting Action-Oriented and Goal-Oriented Instructions.\n\nRobots operating alongside humans in diverse, stochastic environments must be able to accurately interpret natural language commands. These instructions often fall into one of two categories: those that specify a goal condition or target state, and those that specify explicit actions, or how to perform a given task. Recent approaches have used reward functions as a semantic representation of goal-based commands, which allows for the use of a state-of-the-art planner to find a policy for the given task. However, these reward functions cannot be directly used to represent action-oriented commands. We introduce a new hybrid approach, the Deep Recurrent Action-Goal Grounding Network (DRAGGN), for task grounding and execution that handles natural language from either category as input, and generalizes to unseen environments. Our robot-simulation results demonstrate that a system successfully interpreting both goal-oriented and action-oriented task specifications brings us closer to robust natural language understanding for human-robot interaction.", "Grounding Language for Interactive Task Learning.\n\nThis paper describes how language is grounded by a comprehension system called Lucia within a robotic agent called Rosie that can manipulate objects and navigate indoors. The whole system is built within the Soar cognitive architecture and uses Embodied Construction Grammar (ECG) as a formalism for describing linguistic knowledge. Grounding is performed using knowledge from the grammar itself, from the linguistic context, from the agents perception, and from an ontology of long-term knowledge about object categories and properties and actions the agent can perform. The paper also describes a benchmark corpus of 200 sentences in this domain along with test versions of the world model and ontology and gold-standard meanings for each of the sentences. The benchmark is contained in the supplemental materials.", "SemEval-2017 Task 6: \\#HashtagWars: Learning a Sense of Humor.\n\nThis paper describes a new shared task for humor understanding that attempts to eschew the ubiquitous binary approach to humor detection and focus on comparative humor ranking instead. The task is based on a new dataset of funny tweets posted in response to shared hashtags, collected from the `Hashtag Wars' segment of the TV show @midnight. The results are evaluated in two subtasks that require the participants to generate either the correct pairwise comparisons of tweets (subtask A), or the correct ranking of the tweets (subtask B) in terms of how funny they are. 7 teams participated in subtask A, and 5 teams participated in subtask B. The best accuracy in subtask A was 0.675. The best (lowest) rank edit distance for subtask B was 0.872.", "Towards Problem Solving Agents that Communicate and Learn.\n\nAgents that communicate back and forth with humans to help them execute non-linguistic tasks are a long sought goal of AI. These agents need to translate between utterances and actionable meaning representations that can be interpreted by task-specific problem solvers in a context-dependent manner. They should also be able to learn such actionable interpretations for new predicates on the fly. We define an agent architecture for this scenario and present a series of experiments in the Blocks World domain that illustrate how our architecture supports language learning and problem solving in this domain.", "Guiding Interaction Behaviors for Multi-modal Grounded Language Learning.\n\nMulti-modal grounded language learning connects language predicates to physical properties of objects in the world. Sensing with multiple modalities, such as audio, haptics, and visual colors and shapes while performing interaction behaviors like lifting, dropping, and looking on objects enables a robot to ground non-visual predicates like ``empty'' as well as visual predicates like ``red''. Previous work has established that grounding in multi-modal space improves performance on object retrieval from human descriptions. In this work, we gather behavior annotations from humans and demonstrate that these improve language grounding performance by allowing a system to focus on relevant behaviors for words like ``white'' or ``half-full'' that can be understood by looking or lifting, respectively. We also explore adding modality annotations (whether to focus on audio or haptics when performing a behavior), which improves performance, and sharing information between linguistically related predicates (if ``green'' is a color, ``white'' is a color), which improves grounding recall but at the cost of precision.", "Natural Language Grounding and Grammar Induction for Robotic Manipulation Commands.\n\nWe present a cognitively plausible system capable of acquiring knowledge in language and vision from pairs of short video clips and linguistic descriptions. The aim of this work is to teach a robot manipulator how to execute natural language commands by demonstration. This is achieved by first learning a set of visual `concepts' that abstract the visual feature spaces into concepts that have human-level meaning. Second, learning the mapping/grounding between words and the extracted visual concepts. Third, inducing grammar rules via a semantic representation known as Robot Control Language (RCL). We evaluate our approach against state-of-the-art supervised and unsupervised grounding and grammar induction systems, and show that a robot can learn to execute never seen-before commands from pairs of unlabelled linguistic and visual inputs.", "Duluth at SemEval-2017 Task 7 : Puns Upon a Midnight Dreary, Lexical Semantics for the Weak and Weary.\n\nThis paper describes the Duluth systems that participated in SemEval-2017 Task 7 : Detection and Interpretation of English Puns. The Duluth systems participated in all three subtasks, and relied on methods that included word sense disambiguation and measures of semantic relatedness.", "TwiSe at SemEval-2017 Task 4: Five-point Twitter Sentiment Classification and Quantification.\n\nThe paper describes the participation of the team ``TwiSE'' in the SemEval-2017 challenge. Specifically, I participated at Task 4 entitled ``Sentiment Analysis in Twitter'' for which I implemented systems for five-point tweet classification (Subtask C) and five-point tweet quantification (Subtask E) for English tweets. In the feature extraction steps the systems rely on the vector space model, morpho-syntactic analysis of the tweets and several sentiment lexicons. The classification step of Subtask C uses a Logistic Regression trained with the one-versus-rest approach. Another instance of Logistic Regression combined with the classify-and-count approach is trained for the quantification task of Subtask E. In the official leaderboard the system is ranked \\textit{5/15} in Subtask C and \\textit{2/12} in Subtask E.", "The Meaning Factory at SemEval-2017 Task 9: Producing AMRs with Neural Semantic Parsing.\n\nWe evaluate a semantic parser based on a character-based sequence-to-sequence model in the context of the SemEval-2017 shared task on semantic parsing for AMRs. With data augmentation, super characters, and POS-tagging we gain major improvements in performance compared to a baseline character-level model. Although we improve on previous character-based neural semantic parsing models, the overall accuracy is still lower than a state-of-the-art AMR parser. An ensemble combining our neural semantic parser with an existing, traditional parser, yields a small gain in performance.", "RUFINO at SemEval-2017 Task 2: Cross-lingual lexical similarity by extending PMI and word embeddings systems with a Swadesh's-like list.\n\nThe RUFINO team proposed a non-supervised, conceptually-simple and low-cost approach for addressing the Multilingual and Cross-lingual Semantic Word Similarity challenge at SemEval 2017. The proposed systems were cross-lingual extensions of popular monolingual lexical similarity approaches such as PMI and word2vec. The extensions were possible by means of a small parallel list of concepts similar to the Swadesh's list, which we obtained in a semi-automatic way. In spite of its simplicity, our approach showed to be effective obtaining statistically-significant and consistent results in all datasets proposed for the task. Besides, we provide some research directions for improving this novel and affordable approach.", "LIA at SemEval-2017 Task 4: An Ensemble of Neural Networks for Sentiment Classification.\n\nThis paper describes the system developed at LIA for the SemEval-2017 evaluation campaign. The goal of Task 4.A was to identify sentiment polarity in tweets. The system is an ensemble of Deep Neural Network (DNN) models: Convolutional Neural Network (CNN) and Recurrent Neural Network Long Short-Term Memory (RNN-LSTM). We initialize the input representation of DNN with different sets of embeddings trained on large datasets. The ensemble of DNNs are combined using a score-level fusion approach. The system ranked 2nd at SemEval-2017 and obtained an average recall of 67.6%.", "Know-Center at SemEval-2017 Task 10: Sequence Classification with the CODE Annotator.\n\nThis paper describes our participation in SemEval-2017 Task 10. We competed in Subtask 1 and 2 which consist respectively in identifying all the key phrases in scientific publications and label them with one of the three categories: Task, Process, and Material. These scientific publications are selected from Computer Science, Material Sciences, and Physics domains. We followed a supervised approach for both subtasks by using a sequential classifier (CRF - Conditional Random Fields). For generating our solution we used a web-based application implemented in the EU-funded research project, named CODE. Our system achieved an F1 score of 0.39 for the Subtask 1 and 0.28 for the Subtask 2.", "INGEOTEC at SemEval 2017 Task 4: A B4MSA Ensemble based on Genetic Programming for Twitter Sentiment Analysis.\n\nThis paper describes the system used in SemEval-2017 Task 4 (Subtask A): Message Polarity Classification for both English and Arabic languages. Our proposed system is an ensemble of two layers, the first one uses our generic framework for multilingual polarity classification (B4MSA) and the second layer combines all the decision function values predicted by B4MSA systems using a non-linear function evolved using a Genetic Programming system, EvoDAG. With this approach, the best performances reached by our system were macro-recall 0.68 (English) and 0.477 (Arabic) which set us in sixth and fourth positions in the results table, respectively.", "UWAV at SemEval-2017 Task 7: Automated feature-based system for locating puns.\n\nIn this paper we describe our system created for SemEval-2017 Task 7: Detection and Interpretation of English Puns. We tackle subtask 1, pun detection, by leveraging features selected from sentences to design a classifier that can disambiguate between the presence or absence of a pun. We address subtask 2, pun location, by utilizing a decision flow structure that uses presence or absence of certain features to decide the next action. The results obtained by our system are encouraging, considering the simplicity of the system. We consider this system as a precursor for deeper exploration on efficient feature selection for pun detection.", "DFKI-DKT at SemEval-2017 Task 8: Rumour Detection and Classification using Cascading Heuristics.\n\nWe describe our submissions for SemEval-2017 Task~8, Determining Rumour Veracity and Support for Rumours. The Digital Curation Technologies (DKT) team at the German Research Center for Artificial Intelligence (DFKI) participated in two subtasks: Subtask A (determining the stance of a message) and Subtask B (determining veracity of a message, closed variant). In both cases, our implementation consisted of a Multivariate Logistic Regression (Maximum Entropy) classifier coupled with hand-written patterns and rules (heuristics) applied in a post-process cascading fashion. We provide a detailed analysis of the system performance and report on variants of our systems that were not part of the official submission.", "Idiom Savant at Semeval-2017 Task 7: Detection and Interpretation of English Puns.\n\nThis paper describes our system, entitled Idiom Savant, for the 7th Task of the Se- meval 2017 workshop, ``Detection and in- terpretation of English Puns''. Our sys- tem consists of two probabilistic models for each type of puns using Google n- gram and Word2Vec. Our system achieved f-score of calculating, 0.663, and 0.07 in homographic puns and 0.8439, 0.6631, and 0.0806 in heterographic puns in task 1, task 2, and task 3 respectively.", "A Recurrent Neural Model with Attention for the Recognition of Chinese Implicit Discourse Relations.\n\nWe introduce an attention-based Bi-LSTM for Chinese implicit discourse relations and demonstrate that modeling argument pairs as a joint sequence can outperform word order-agnostic approaches. Our model benefits from a partial sampling scheme and is conceptually simple, yet achieves state-of-the-art performance on the Chinese Discourse Treebank. We also visualize its attention activity to illustrate the model's ability to selectively focus on the relevant parts of an input sequence.", "MERALI at SemEval-2017 Task 2 Subtask 1: a Cognitively Inspired approach.\n\nIn this paper we report on the participation of the MERALI system to the SemEval Task 2 Subtask 1. The MERALI system approaches conceptual similarity through a simple, cognitively inspired, heuristics; it builds on a linguistic resource, the TTCS-e, that relies on BabelNet, NASARI and ConceptNet. The linguistic resource in fact contains a novel mixture of common-sense and encyclopedic knowledge. The obtained results point out that there is ample room for improvement, so that they are used to elaborate on present limitations and on future steps.", "SentiHeros at SemEval-2017 Task 5: An application of Sentiment Analysis on Financial Tweets.\n\nSentiment analysis is the process of identifying the opinion expressed in text. Recently it has been used to study behavioral finance, and in particular the effect of opinions and emotions on economic or financial decisions. SemEval-2017 task 5 focuses on the financial market as the do- main for sentiment analysis of text; specifically, task 5, subtask 1 focuses on financial tweets about stock symbols. In this paper, we describe a machine learning classifier for binary classification of financial tweets. We used natural language processing techniques and the random forest algorithm to train our model, and tuned it for the training dataset of Task 5, subtask 1. Our system achieves the 7th rank on the leaderboard of the task.", "LIMSI-COT at SemEval-2017 Task 12: Neural Architecture for Temporal Information Extraction from Clinical Narratives.\n\nIn this paper we present our participation to SemEval 2017 Task 12. We used a neural network based approach for entity and temporal relation extraction, and experimented with two domain adaptation strategies. We achieved competitive performance for both tasks.", "Neural Architecture for Temporal Relation Extraction: A Bi-LSTM Approach for Detecting Narrative Containers.\n\nWe present a neural architecture for containment relation identification between medical events and/or temporal expressions. We experiment on a corpus of de-identified clinical notes in English from the Mayo Clinic, namely the THYME corpus. Our model achieves an F-measure of 0.613 and outperforms the best result reported on this corpus to date.", "DataStories at SemEval-2017 Task 6: Siamese LSTM with Attention for Humorous Text Comparison.\n\nIn this paper we present a deep-learning system that competed at SemEval-2017 Task 6 ``\\#HashtagWars: Learning a Sense of Humor''. We participated in Subtask A, in which the goal was, given two Twitter messages, to identify which one is funnier. We propose a Siamese architecture with bidirectional Long Short-Term Memory (LSTM) networks, augmented with an attention mechanism. Our system works on the token-level, leveraging word embeddings trained on a big collection of unlabeled Twitter messages. We ranked 2nd in 7 teams. A post-completion improvement of our model, achieves state-of-the-art results on \\#HashtagWars dataset.", "DataStories at SemEval-2017 Task 4: Deep LSTM with Attention for Message-level and Topic-based Sentiment Analysis.\n\nIn this paper we present two deep-learning systems that competed at SemEval-2017 Task 4 ``Sentiment Analysis in Twitter''. We participated in all subtasks for English tweets, involving message-level and topic-based sentiment polarity classification and quantification. We use Long Short-Term Memory (LSTM) networks augmented with two kinds of attention mechanisms, on top of word embeddings pre-trained on a big collection of Twitter messages. Also, we present a text processing tool suitable for social network messages, which performs tokenization, word normalization, segmentation and spell correction. Moreover, our approach uses no hand-crafted features or sentiment lexicons. We ranked 1st (tie) in Subtask A, and achieved very competitive results in the rest of the Subtasks. Both the word embeddings and our text processing tool are available to the research community.", "Sheffield at SemEval-2017 Task 9: Transition-based language generation from AMR..\n\nThis paper describes the submission by the University of Sheffield to the SemEval 2017 Abstract Meaning Representation Parsing and Generation task (SemEval 2017 Task 9, Subtask 2). We cast language generation from AMR as a sequence of actions (e.g., insert/remove/rename edges and nodes) that progressively transform the AMR  graph into a dependency parse tree. This transition-based approach relies on the fact that an AMR graph can be considered structurally similar to a dependency tree, with a focus on content rather than function words. An added benefit to this approach is the greater amount of data we can take advantage of to train the parse-to-text linearizer. Our submitted run on the test data achieved a BLEU score of 3.32 and a Trueskill score of -22.04 on automatic and human evaluation respectively.", "ConceptNet at SemEval-2017 Task 2: Extending Word Embeddings with Multilingual Relational Knowledge.\n\nThis paper describes Luminoso's participation in SemEval 2017 Task 2, ``Multilingual and Cross-lingual Semantic Word Similarity'', with a system based on ConceptNet. ConceptNet is an open, multilingual knowledge graph that focuses on general knowledge that relates the meanings of words and phrases. Our submission to SemEval was an update of previous work that builds high-quality, multilingual word embeddings from a combination of ConceptNet and distributional semantics. Our system took first place in both subtasks. It ranked first in 4 out of 5 of the separate languages, and also ranked first in all 10 of the cross-lingual language pairs.", "HHU at SemEval-2017 Task 2: Fast Hash-Based Embeddings for Semantic Word Similarity Assessment.\n\nThis paper describes the HHU system that participated in Task 2 of SemEval 2017, Multilingual and Cross-lingual Semantic Word Similarity. We introduce our unsupervised embedding learning technique and describe how it was employed and configured to address the problems of monolingual and multilingual word similarity measurement. This paper reports from empirical evaluations on the benchmark provided by the task's organizers.", "TakeLab-QA at SemEval-2017 Task 3: Classification Experiments for Answer Retrieval in Community QA.\n\nIn this paper we present the TakeLab-QA entry to SemEval 2017 task 3, which is a question-comment re-ranking problem. We present a classification based approach, including two supervised learning models --- Support Vector Machines (SVM) and Convolutional Neural Networks (CNN). We use features based on different semantic similarity models (e.g., Latent Dirichlet Allocation), as well as features based on several types of pre-trained word embeddings. Moreover, we also use some hand-crafted task-specific features. For training, our system uses no external labeled data apart from that provided by the organizers. Our primary submission achieves a MAP-score of 81.14 and F1-score of 66.99 --- ranking us 10th on the SemEval 2017 task 3, subtask A.", "STS-UHH at SemEval-2017 Task 1: Scoring Semantic Textual Similarity Using Supervised and Unsupervised Ensemble.\n\nThis paper reports the STS-UHH participation in the SemEval 2017 shared Task 1 of Semantic Textual Similarity (STS). Overall, we submitted 3 runs covering monolingual and cross-lingual STS tracks. Our participation involves two approaches: unsupervised approach, which estimates a word alignment-based similarity score, and supervised approach, which combines dependency graph similarity and coverage features with lexical similarity measures using regression methods. We also present a way on ensembling both models. Out of 84 submitted runs, our team best multi-lingual run has been ranked 12th in overall performance with correlation of 0.61, 7th among 31 participating teams.", "GUIR at SemEval-2017 Task 12: A Framework for Cross-Domain Clinical Temporal Information Extraction.\n\nClinical TempEval 2017 (SemEval 2017 Task 12) addresses the task of cross-domain temporal extraction from clinical text. We present a system for this task that uses supervised learning for the extraction of temporal expression and event spans with corresponding attributes and narrative container relations. Approaches include conditional random fields and decision tree ensembles, using lexical, syntactic, semantic, distributional, and rule-based features. Our system received best or second best scores in TIMEX3 span, EVENT span, and CONTAINS relation extraction.", "DUTH at SemEval-2017 Task 5: Sentiment Predictability in Financial Microblogging and News Articles.\n\nWe present the system developed by the team DUTH for the participation in Semeval-2017 task 5 - Fine-Grained Sentiment Analysis on Financial Microblogs and News, in subtasks A and B. Our approach to determine the sentiment of Microblog Messages and News Statements \\& Headlines is based on linguistic preprocessing, feature engineering, and supervised machine learning techniques. To train our model, we used Neural Network Regression, Linear Regression, Boosted Decision Tree Regression and Decision Forrest Regression classifiers to forecast sentiment scores. At the end, we present an error measure, so as to improve the performance about forecasting methods of the system.", "DUTH at SemEval-2017 Task 4: A Voting Classification Approach for Twitter Sentiment Analysis.\n\nThis report describes our participation to SemEval-2017 Task 4: Sentiment Analysis in Twitter, specifically in subtasks A, B, and C. The approach for text sentiment classification is based on a Majority Vote scheme and combined supervised machine learning methods with classical linguistic resources, including bag-of-words and sentiment lexicon features.", "TakeLab at SemEval-2017 Task 5: Linear aggregation of word embeddings for fine-grained sentiment analysis of financial news.\n\nThis paper describes our system for fine-grained sentiment scoring of news headlines submitted to SemEval 2017 task 5--subtask 2. Our system uses a feature-light method that consists of a Support Vector Regression (SVR) with various kernels and word vectors as features. Our best-performing submission scored 3rd on the task out of 29 teams and 4th out of 45 submissions with a cosine score of 0.733.", "SemEval-2017 Task 8: RumourEval: Determining rumour veracity and support for rumours.\n\nMedia is full of false claims. Even Oxford Dictionaries named ``post-truth'' as the word of 2016. This makes it more important than ever to build systems that can identify the veracity of a story, and the nature of the discourse around it. RumourEval is a SemEval shared task that aims to identify and handle rumours and reactions to them, in text. We present an annotation scheme, a large dataset covering multiple topics --- each having their own families of claims and replies --- and use these to pose two concrete challenges as well as the results achieved by participants on these challenges.", "NileTMRG at SemEval-2017 Task 8: Determining Rumour and Veracity Support for Rumours on Twitter..\n\nFinal submission for NileTMRG on RumourEval 2017.", "WING-NUS at SemEval-2017 Task 10: Keyphrase Extraction and Classification as Joint Sequence Labeling.\n\nWe describe an end-to-end pipeline processing approach for SemEval 2017's Task 10 to extract keyphrases and their relations from scientific publications.  We jointly identify and classify keyphrases by modeling the subtasks as sequential labeling.  Our system utilizes standard, surface-level features along with the adjacent word features, and performs conditional decoding on whole text to extract keyphrases. We focus only on the identification and typing of keyphrases (Subtasks A and B, together referred as extraction), but provide an end-to-end system inclusive of keyphrase relation identification (Subtask C) for completeness.  Our top performing configuration achieves an $F\\_1$ of 0.27 for the end-to-end keyphrase extraction and relation identification scenario on the final test data, and compares on par to other top ranked systems for keyphrase extraction.  Our system outperforms other techniques that do not employ global decoding and hence do not account for dependencies between keyphrases. We believe this is crucial for keyphrase classification in the given context of scientific document mining.", "UW-FinSent at SemEval-2017 Task 5: Sentiment Analysis on Financial News Headlines using Training Dataset Augmentation.\n\nThis paper discusses the approach taken by the UWaterloo team to arrive at a solution for the Fine-Grained Sentiment Analysis problem posed by Task 5 of SemEval 2017. The paper describes the document vectorization and sentiment score prediction techniques used, as well as the design and implementation decisions taken while building the system for this task. The system uses text vectorization models, such as N-gram, TF-IDF and paragraph embeddings, coupled with regression model variants to predict the sentiment scores. Amongst the methods examined, unigrams and bigrams coupled with simple linear regression obtained the best baseline accuracy. The paper also explores data augmentation methods to supplement the training dataset. This system was designed for Subtask 2 (News Statements and Headlines).", "Turing at SemEval-2017 Task 8: Sequential Approach to Rumour Stance Classification with Branch-LSTM.\n\nThis paper describes team Turing's submission to SemEval 2017 RumourEval: Determining rumour veracity and support for rumours (SemEval 2017 Task 8, Subtask A). Subtask A addresses the challenge of rumour stance classification, which involves identifying the attitude of Twitter users towards the truthfulness of the rumour they are discussing. Stance classification is considered to be an important step towards rumour verification, therefore performing well in this task is expected to be useful in debunking false rumours. In this work we classify a set of Twitter posts discussing rumours into either supporting, denying, questioning or commenting on the underlying rumours. We propose a LSTM-based sequential model that, through modelling the conversational structure of tweets, which achieves an accuracy of 0.784 on the RumourEval test set outperforming all other systems in Subtask A.", "PunFields at SemEval-2017 Task 7: Employing Roget's Thesaurus in Automatic Pun Recognition and Interpretation.\n\nThe article describes a model of automatic interpretation of English puns, based on Roget{'}s Thesaurus, and its implementation, PunFields. In a pun, the algorithm discovers two groups of words that belong to two main semantic fields. The fields become a semantic vector based on which an SVM classifier learns to recognize puns. A rule-based model is then applied for recognition of intentionally ambiguous (target) words and their definitions. In SemEval Task 7 PunFields shows a considerably good result in pun classification, but requires improvement in searching for the target word and its definition.", "PKU\\_ICL at SemEval-2017 Task 10: Keyphrase Extraction with Model Ensemble and External Knowledge.\n\nThis paper presents a system that participated in SemEval 2017 Task 10 (subtask A and subtask B): Extracting Keyphrases and Relations from Scientific Publications (Augenstein et al., 2017). Our proposed approach utilizes external knowledge to enrich feature representation of candidate keyphrase, including Wikipedia, IEEE taxonomy and pre-trained word embeddings etc. Ensemble of unsupervised models, random forest and linear models are used for candidate keyphrase ranking and keyphrase type classification. Our system achieves the 3rd place in subtask A and 4th place in subtask B.", "Mama Edha at SemEval-2017 Task 8: Stance Classification with CNN and Rules.\n\nFor the competition SemEval-2017 we investigated the possibility of performing stance classification (support, deny, query or comment) for messages in Twitter conversation threads related to rumours. Stance classification is interesting since it can provide a basis for rumour veracity assessment. Our ensemble classification approach of combining convolutional neural networks with both automatic rule mining and manually written rules achieved a final accuracy of 74.9% on the competition's test data set for Task 8A. To improve classification we also experimented with data relabeling and using the grammatical structure of the tweet contents for classification.", "GW\\_QA at SemEval-2017 Task 3: Question Answer Re-ranking on Arabic Fora.\n\nThis paper describes our submission to SemEval-2017 Task 3 Subtask D, ``Question Answer Ranking in Arabic Community Question Answering''. In this work, we applied a supervised machine learning approach to automatically re-rank a set of QA pairs according to their relevance to a given question. We employ features based on latent semantic models, namely WTMF, as well as a set of lexical features based on string lengths and surface level matching. The proposed system ranked first out of 3 submissions, with a MAP score of 61.16\\%.", "NLM\\_NIH at SemEval-2017 Task 3: from Question Entailment to Question Similarity for Community Question Answering.\n\nThis paper describes our participation in SemEval-2017 Task 3 on Community Question  Answering (cQA). The Question Similarity subtask (B) aims to rank  a set of related questions retrieved by a search engine according to their similarity to the original question. We adapted our feature-based system for Recognizing Question Entailment (RQE) to the question similarity task. Tested on cQA-B-2016 test data, our RQE system outperformed the best system of the 2016 challenge in all measures with 77.47 MAP and 80.57 Accuracy. On cQA-B-2017 test data, performances of all systems dropped by around 30 points. Our primary system obtained 44.62 MAP, 67.27 Accuracy and 47.25 F1 score. The cQA-B-2017 best system achieved 47.22 MAP and 42.37 F1 score. Our system is ranked sixth in terms of MAP and third in terms of F1 out of 13 participating teams.", "TTI-COIN at SemEval-2017 Task 10: Investigating Embeddings for End-to-End Relation Extraction from Scientific Papers.\n\nThis paper describes our TTI-COIN system that participated in SemEval-2017 Task 10. We investigated appropriate embeddings to adapt a neural end-to-end entity and relation extraction system LSTM-ER to this task. We participated in the full task setting of the entity segmentation, entity classification and relation classification (scenario 1) and the setting of relation classification only (scenario 3). The system was directly applied to the scenario 1 without modifying the codes thanks to its generality and flexibility. Our evaluation results show that the choice of appropriate pre-trained embeddings affected the performance significantly. With the best embeddings, our system was ranked third in the scenario 1 with the micro F1 score of 0.38. We also confirm that our system can produce the micro F1 score of 0.48 for the scenario 3 on the test data, and this score is close to the score of the 3rd ranked system in the task.", "bunji at SemEval-2017 Task 3: Combination of Neural Similarity Features and Comment Plausibility Features.\n\nThis paper describes a text-ranking system developed by bunji team in SemEval-2017 Task 3: Community Question Answering, Subtask A and C. The goal of the task is to re-rank the comments in a question-and-answer forum such that useful comments for answering the question are ranked high. We proposed a method that combines neural similarity features and hand-crafted comment plausibility features, and we modeled inter-comments relationship using conditional random field. Our approach obtained the fifth place in the Subtask A and the second place in the Subtask C.", "Sew-Embed at SemEval-2017 Task 2: Language-Independent Concept Representations from a Semantically Enriched Wikipedia.\n\nThis paper describes Sew-Embed, our language-independent approach to multilingual and cross-lingual semantic word similarity as part of the SemEval-2017 Task 2. We leverage the Wikipedia-based concept representations developed by Raganato et al. (2016), and propose an embedded augmentation of their explicit high-dimensional vectors, which we obtain by plugging in an arbitrary word (or sense) embedding representation, and computing a weighted average in the continuous vector space. We evaluate Sew-Embed with two different off-the-shelf embedding representations, and report their performances across all monolingual and cross-lingual benchmarks available for the task. Despite its simplicity, especially compared with supervised or overly tuned approaches, Sew-Embed achieves competitive results in the cross-lingual setting (3rd best result in the global ranking of subtask 2, score 0.56).", "EuroSense: Automatic Harvesting of Multilingual Sense Annotations from Parallel Text.\n\nParallel corpora are widely used in a variety of Natural Language Processing tasks, from Machine Translation to cross-lingual Word Sense Disambiguation, where parallel sentences can be exploited to automatically generate high-quality sense annotations on a large scale. In this paper we present EuroSense, a multilingual sense-annotated resource based on the joint disambiguation of the Europarl parallel corpus, with almost 123 million sense annotations for over 155 thousand distinct concepts and entities from a language-independent unified sense inventory. We evaluate the quality of our sense annotations intrinsically and extrinsically, showing their effectiveness as training data for Word Sense Disambiguation.", "QU-BIGIR at SemEval 2017 Task 3: Using Similarity Features for Arabic Community Question Answering Forums.\n\nIn this paper we describe our QU-BIGIR system for the Arabic subtask D of the SemEval 2017 Task 3. Our approach builds on our participation in the past version of the same subtask. This year, our system uses different similarity measures that encodes lexical and semantic pairwise similarity of text pairs. In addition to well known similarity measures such as cosine similarity, we use other measures based on the summary statistics of word embedding representation for a given text. To rank a list of candidate question answer pairs for a given question, we learn a linear SVM classifier over our similarity features. Our best resulting run came second in subtask D with a very competitive performance to the first-ranking system.", "IITP at SemEval-2017 Task 8 : A Supervised Approach for Rumour Evaluation.\n\nThis paper describes our system participation in the SemEval-2017 Task 8 'RumourEval: Determining rumour veracity and support for rumours'. The objective of this task was to predict the stance and veracity of the underlying rumour. We propose a supervised classification approach employing several lexical, content and twitter specific features for learning. Evaluation shows promising results for both the problems.", "LIPN-IIMAS at SemEval-2017 Task 1: Subword Embeddings, Attention Recurrent Neural Networks and Cross Word Alignment for Semantic Textual Similarity.\n\nIn this paper we report our attempt to use, on the one hand, state-of-the-art neural approaches that are proposed to measure Semantic Textual Similarity (STS). On the other hand, we propose an unsupervised cross-word alignment approach, which is linguistically motivated. The neural approaches proposed herein are divided into two main stages. The first stage deals with constructing neural word embeddings, the components of sentence embeddings. The second stage deals with constructing a semantic similarity function relating pairs of sentence embeddings. Unfortunately our competition results were poor in all tracks, therefore we concentrated our research to improve them for Track 5 (EN-EN).", "IITPB at SemEval-2017 Task 5: Sentiment Prediction in Financial Text.\n\nThis paper reports team IITPB's participation in the SemEval 2017 Task 5 on `Fine-grained sentiment analysis on financial microblogs and news'. We developed 2 systems for the two tracks. One system was based on an ensemble of Support Vector Classifier and Logistic Regression. This system relied on Distributional Thesaurus (DT), word embeddings and lexicon features to predict a floating sentiment value between -1 and +1. The other system was based on Support Vector Regression using word embeddings, lexicon features, and PMI scores as features. The system was ranked 5th in track 1 and 8th in track 2.", "FEUP at SemEval-2017 Task 5: Predicting Sentiment Polarity and Intensity with Financial Word Embeddings.\n\nThis paper presents the approach developed at the Faculty of Engineering of University of Porto, to participate in SemEval 2017, Task 5: Fine-grained Sentiment Analysis on Financial Microblogs and News. The task consisted in predicting a real continuous variable from -1.0 to +1.0 representing the polarity and intensity of sentiment concerning companies/stocks mentioned in short texts. We modeled the task as a regression analysis problem and combined traditional techniques such as pre-processing short texts, bag-of-words representations and lexical-based features with enhanced financial specific bag-of-embeddings. We used an external collection of tweets and news headlines mentioning companies/stocks from S\\\\&P 500 to create financial word embeddings which are able to capture domain-specific syntactic and semantic similarities. The resulting approach obtained a cosine similarity score of 0.69 in sub-task 5.1 - Microblogs and 0.68 in sub-task 5.2 - News Headlines.", "L2F/INESC-ID at SemEval-2017 Tasks 1 and 2: Lexical and semantic features in word and textual similarity.\n\nThis paper describes our approach to the SemEval-2017 ``Semantic Textual Similarity'' and ``Multilingual Word Similarity'' tasks. In the former, we test our approach in both English and Spanish, and use a linguistically-rich set of features. These move from lexical to semantic features. In particular, we try to take advantage of the recent Abstract Meaning Representation and SMATCH measure. Although without state of the art results, we introduce semantic structures in textual similarity and analyze their impact. Regarding word similarity, we target the English language and combine WordNet information with Word Embeddings. Without matching the best systems, our approach proved to be simple and effective.", "Talla at SemEval-2017 Task 3: Identifying Similar Questions Through Paraphrase Detection.\n\nThis paper describes our approach to the SemEval-2017 shared task of determining question-question similarity in a community question-answering setting (Task 3B). We extracted both syntactic and semantic similarity features between candidate questions, performed pairwise-preference learning to optimize for ranking order, and then trained a random forest classifier to predict whether the candidate questions are paraphrases of each other. This approach achieved a MAP of 45.7% out of max achievable 67.0% on the test set.", "SemEval-2017 Task 2: Multilingual and Cross-lingual Semantic Word Similarity.\n\nThis paper introduces a new task on Multilingual and Cross-lingual SemanticThis paper introduces a new task on Multilingual and Cross-lingual Semantic Word Similarity which measures the semantic similarity of word pairs within and across five languages: English, Farsi, German, Italian and Spanish. High quality datasets were manually curated for the five languages with high inter-annotator agreements (consistently in the 0.9 ballpark). These were used for semi-automatic construction of ten cross-lingual datasets. 17 teams participated in the task, submitting 24 systems in subtask 1 and 14 systems in subtask 2. Results show that systems that combine statistical knowledge from text corpora, in the form of word embeddings, and external knowledge from lexical resources are best performers in both subtasks. More information can be found on the task website: https://alt.qcri.org/semeval2017/task2/", "SoccEval: An Annotation Schema for Rating Soccer Players.\n\nThis paper describes the SoccEval Annotation Project, an annotation schema designed to support machine-learning classification efforts to evaluate the performance of soccer players based on match reports taken from online news sources. In addition to factual information about player attributes and actions, the schema annotates subjective opinions about them. After explaining the annotation schema and annotation process, we describe a machine learning experiment. Classifiers trained on features derived from annotated data performed better than a baseline trained on unigram features. Initial results suggest that improvements can be made to the annotation scheme and guidelines as well as the amount of data annotated. We believe our schema could be potentially expanded to extract more information about soccer players and teams.", "SemEval 2017 Task 10: ScienceIE - Extracting Keyphrases and Relations from Scientific Publications.\n\nWe describe the SemEval task of extracting keyphrases and relations between them from scientific documents, which is crucial for understanding which publications describe which processes, tasks and materials. Although this was a new task, we had a total of 26 submissions across 3 evaluation scenarios. We expect the task and the findings reported in this paper to be relevant for researchers working on understanding scientific content, as well as the broader knowledge base population and information extraction communities.", "Multi-Task Learning of Keyphrase Boundary Classification.\n\nKeyphrase boundary classification (KBC) is the task of detecting keyphrases in scientific articles and labelling them with respect to predefined types. Although important in practice, this task is so far underexplored, partly due to the lack of labelled data. To overcome this, we explore several auxiliary tasks, including semantic super-sense tagging and identification of multi-word expressions, and cast the task as a multi-task learning problem with deep recurrent neural networks. Our multi-task models perform significantly better than previous state of the art approaches on two scientific KBC datasets, particularly for long keyphrases.", "SemEval-2017 Task 7: Detection and Interpretation of English Puns.\n\nA pun is a form of wordplay in which a word suggests two or more meanings by exploiting polysemy, homonymy, or phonological similarity to another word, for an intended humorous or rhetorical effect.  Though a recurrent and expected feature in many discourse types, puns stymie traditional approaches to computational lexical semantics because they violate their one-sense-per-context assumption.  This paper describes the first competitive evaluation for the automatic detection, location, and interpretation of puns. We describe the motivation for these tasks, the evaluation methods, and the manually annotated data set.  Finally, we present an overview and discussion of the participating systems' methodologies, resources, and results.", "SemEval-2017 Task 5: Fine-Grained Sentiment Analysis on Financial Microblogs and News.\n\nThis paper discusses the ``Fine-Grained Sentiment Analysis on Financial Microblogs and News'' task as part of SemEval-2017, specifically under the ``Detecting sentiment, humour, and truth'' theme. This task contains two tracks, where the first one concerns Microblog messages and the second one covers News Statements and Headlines. The main goal behind both tracks was to predict the sentiment score for each of the mentioned companies/stocks. The sentiment scores for each text instance adopted floating point values in the range of -1 (very negative/bearish) to 1 (very positive/bullish), with 0 designating neutral sentiment. This task attracted a total of 32 participants, with 25 participating in Track 1 and 29 in Track 2.", "SemEval-2017 Task 9: Abstract Meaning Representation Parsing and Generation.\n\nIn this report we summarize the results of the 2017 AMR SemEval shared task. The task consisted of two separate yet related subtasks. In the parsing subtask, participants were asked to produce Abstract Meaning Representation (AMR) (Banarescu et al., 2013) graphs for a set of English sentences in the biomedical domain. In the generation subtask, participants were asked to generate English sentences given AMR graphs in the news/forum domain. A total of five sites participated in the parsing subtask, and four participated in the generation subtask. Along with a description of the task and the participants' systems, we show various score ablations and some sample outputs.", "Neural Semantic Parsing over Multiple Knowledge-bases.\n\nA fundamental challenge in developing semantic parsers is the paucity of strong supervision in the form of language utterances annotated with logical form. In this paper, we propose to exploit structural regularities in language in different domains, and train semantic parsers over multiple knowledge-bases (KBs), while sharing information across datasets. We find that we can substantially improve parsing accuracy by training a single sequence-to-sequence model over multiple KBs, when providing an encoding of the domain at decoding time. Our model achieves state-of-the-art performance on the Overnight dataset (containing eight domains), improves performance over a single KB baseline from 75.6% to 79.6%, while obtaining a 7x reduction in the number of model parameters.", "SemEval-2017 Task 4: Sentiment Analysis in Twitter.\n\nThis paper describes the fifth year of the Sentiment Analysis in Twitter task. SemEval-2017 Task 4 continues with a rerun of the subtasks of SemEval-2016 Task 4, which include identifying the overall sentiment of the tweet, sentiment towards a topic with classification on a two-point and on a five-point ordinal scale, and quantification of the distribution of sentiment towards a topic across a number of tweets: again on a two-point and on a five-point ordinal scale. Compared to 2016, we made two changes: (i) we introduced a new language, Arabic, for all subtasks, and (ii) we made available information from the profiles of the Twitter users who posted the target tweets. The task continues to be very popular, with a total of 48 teams participating this year.", "SemEval-2017 Task 12: Clinical TempEval.\n\nClinical TempEval 2017 aimed to answer the question: how well do systems trained on annotated timelines for one medical condition (colon cancer) perform in predicting timelines on another medical condition (brain cancer)? Nine sub-tasks were included, covering problems in time expression identification, event expression identification and temporal relation identification. Participant systems were evaluated on clinical and pathology notes from Mayo Clinic cancer patients, annotated with an extension of TimeML for the clinical domain. 11 teams participated in the tasks, with the best systems achieving F1 scores above 0.55 for time expressions, above 0.70 for event expressions, and above 0.40 for temporal relations. Most tasks observed about a 20 point drop over Clinical TempEval 2016, where systems were trained and evaluated on the same domain (colon cancer).", "Fortia-FBK at SemEval-2017 Task 5: Bullish or Bearish? Inferring Sentiment towards Brands from Financial News Headlines.\n\nIn this paper, we describe a methodology to infer Bullish or Bearish sentiment towards companies/brands. More specifically, our approach leverages affective lexica and word embeddings in combination with convolutional neural networks to infer the sentiment of financial news headlines towards a target company. Such architecture was used and evaluated in the context of the SemEval 2017 challenge (task 5, subtask 2), in which it obtained the best performance.", "SemEval-2017 Task 11: End-User Development using Natural Language.\n\nThis task proposes a challenge to support the interaction between users and applications, micro-services and software APIs using natural language. The task aims for supporting the evaluation and evolution of the discussions surrounding the natural language processing approaches within the context of end-user natural language programming, under scenarios of high semantic heterogeneity/gap.", "IBA-Sys at SemEval-2017 Task 5: Fine-Grained Sentiment Analysis on Financial Microblogs and News.\n\nThis paper presents the details of our system IBA-Sys that participated in SemEval Task: Fine-grained sentiment analysis on Financial Microblogs and News. Our system participated in both tracks. For microblogs track, a supervised learning approach was adopted and the regressor was trained using XgBoost regression algorithm on lexicon features. For news headlines track, an ensemble of regressors was used to predict sentiment score. One regressor was trained using TF-IDF features and another was trained using the n-gram features. The source code is available at Github 1.", "BB\\_twtr at SemEval-2017 Task 4: Twitter Sentiment Analysis with CNNs and LSTMs.\n\nIn this paper we describe our attempt at producing a state-of-the-art Twitter sentiment classifier using Convolutional Neural Networks (CNNs) and Long Short Term Memory (LSTMs) networks.  Our system leverages a large amount of unlabeled data to pre-train word embeddings.  We then use a subset of the unlabeled data to fine tune the embeddings using distant supervision.                          The final CNNs and LSTMs are trained on the SemEval-2017 Twitter dataset where the embeddings are fined tuned again.  To boost performances we ensemble several CNNs and LSTMs together. Our approach achieved first rank on all of the five English subtasks amongst 40 teams.", "EICA Team at SemEval-2017 Task 3: Semantic and Metadata-based Features for Community Question Answering.\n\nWe describe our system for participating in SemEval-2017 Task 3 on Community Question Answering. Our approach relies on combining a rich set of various types of features: semantic and metadata. The most important group turned out to be the metadata feature and the semantic vectors trained on QatarLiving data. In the main Subtask C, our primary submission was ranked fourth, with a MAP of 13.48 and accuracy of 97.08. In Subtask A, our primary submission get into the top 50%.", "JU CSE NLP @ SemEval 2017 Task 7: Employing Rules to Detect and Interpret English Puns.\n\nSystem description. Implementation of HMM and Cyclic Dependency Network.", "UIT-DANGNT-CLNLP at SemEval-2017 Task 9: Building Scientific Concept Fixing Patterns for Improving CAMR.\n\nThis paper describes the improvements that we have applied on CAMR baseline parser (Wang et al., 2016) at Task 8 of SemEval-2016. Our objective is to increase the performance of CAMR when parsing sentences from scientific articles, especially articles of biology domain more accurately. To achieve this goal, we built two wrapper layers for CAMR. The first layer, which covers the input data, will normalize, add necessary information to the input sentences to make the input dependency parser and the aligner better handle reference citations, scientific figures, formulas, etc. The second layer, which covers the output data, will modify and standardize output data based on a list of scientific concept fixing patterns. This will help CAMR better handle biological concepts which are not in the training dataset. Finally, after applying our approach, CAMR has scored 0.65 F-score on the test set of Biomedical training data and 0.61 F-score on the official blind test dataset.", "Amobee at SemEval-2017 Task 4: Deep Learning System for Sentiment Detection on Twitter.\n\nThis paper describes the Amobee sentiment analysis system, adapted to compete in SemEval 2017 task 4. The system consists of two parts: a supervised training of RNN models based on a Twitter sentiment treebank, and the use of feedforward NN, Naive Bayes and logistic regression classifiers to produce predictions for the different sub-tasks. The algorithm reached the 3rd place on the 5-label classification task (sub-task C).", "Evaluating Semantic Parsing against a Simple Web-based Question Answering Model.\n\nSemantic parsing shines at analyzing complex natural language that involves composition and computation over multiple pieces of evidence. However, datasets for semantic parsing contain many factoid questions that can be answered from a single web document. In this paper, we propose to evaluate semantic parsing-based question answering models by comparing them to a question answering baseline that queries the web and extracts the answer only from web snippets, without access to the target knowledge-base. We investigate this approach on COMPLEXQUESTIONS, a dataset designed to focus on compositional language, and find that our model obtains reasonable performance (\u223c35 F1 compared to 41 F1 of state-of-the-art). We find in our analysis that our model performs well on complex questions involving conjunctions, but struggles on questions that involve relation composition and superlatives.", "FA3L at SemEval-2017 Task 3: A ThRee Embeddings Recurrent Neural Network for Question Answering.\n\nIn this paper we present ThReeNN, a model for Community Question Answering, Task 3, of SemEval-2017. The proposed model exploits both syntactic and semantic information to build a single and meaningful embedding space. Using a dependency parser in combination with word embeddings, the model creates sequences of inputs for a Recurrent Neural Network, which are then used for the ranking purposes of the Task. The score obtained on the official test data shows promising results.", "Tw-StAR at SemEval-2017 Task 4: Sentiment Classification of Arabic Tweets.\n\nIn this paper, we present our contribution in SemEval 2017 international workshop. We have tackled task 4 entitled ``Sentiment analysis in Twitter'', specifically subtask 4A-Arabic. We propose two Arabic sentiment classification models implemented using supervised and unsupervised learning strategies. In both models, Arabic tweets were preprocessed first then various schemes of bag-of-N-grams were extracted to be used as features. The final submission was selected upon the best performance achieved by the supervised learning-based model. However, the results obtained by the unsupervised learning-based model are considered promising and evolvable if more rich lexica are adopted in further work.", "Tweester at SemEval-2017 Task 4: Fusion of Semantic-Affective and pairwise classification models for sentiment analysis in Twitter.\n\nIn this paper, we describe our submission to SemEval2017 Task 4: Sentiment Analysis in Twitter. Specifically the proposed system participated both to tweet polarity classification (two-, three- and five class) and tweet quantification (two and five-class) tasks.", "NRU-HSE at SemEval-2017 Task 4: Tweet Quantification Using Deep Learning Architecture.\n\nIn many areas, such as social science, politics or market research, people need to deal with dataset shifting over time. Distribution drift phenomenon usually appears in the field of sentiment analysis, when proportions of instances are changing over time. In this case, the task is to correctly estimate proportions of each sentiment expressed in the set of documents (quantification task). Basically, our study was aimed to analyze the effectiveness of a mixture of quantification technique with one of deep learning architecture. All the techniques are evaluated using the SemEval-2017 Task4 dataset and source code, mentioned in this paper and available online in the Python programming language. The results of an application of the quantification techniques are discussed.", "The AI2 system at SemEval-2017 Task 10 (ScienceIE): semi-supervised end-to-end entity and relation extraction.\n\nThis paper describes our submission for the ScienceIE shared task (SemEval- 2017 Task 10) on entity and relation extraction from scientific papers. Our model is based on the end-to-end relation extraction model of Miwa and Bansal (2016) with several enhancements such as semi-supervised learning via neural language models, character-level encoding, gazetteers extracted from existing knowledge bases, and model ensembles. Our of- ficial submission ranked first in end-to-end entity and relation extraction (scenario 1), and second in the relation-only extraction (scenario 3).", "OMAM at SemEval-2017 Task 4: Evaluation of English State-of-the-Art Sentiment Analysis Models for Arabic and a New Topic-based Model.\n\nWhile sentiment analysis in English has achieved significant progress, it remains a challenging task in Arabic given the rich morphology of the language. It becomes more challenging when applied to Twitter data that comes with additional sources of noise including dialects, misspellings, grammatical mistakes, code switching and the use of non-textual objects to express sentiments. This paper describes the ``OMAM'' systems that we developed as part of SemEval-2017 task 4. We evaluate English state-of-the-art methods on Arabic tweets for subtask A. As for the remaining subtasks, we introduce a topic-based approach that accounts for topic specificities by predicting topics or domains of upcoming tweets, and then using this information to predict their sentiment. Results indicate that applying the English state-of-the-art method to Arabic has achieved solid results without significant enhancements. Furthermore, the topic-based method ranked 1st in subtasks C and E, and 2nd in subtask D.", "LearningToQuestion at SemEval 2017 Task 3: Ranking Similar Questions by Learning to Rank Using Rich Features.\n\nThis paper describes our official entry LearningToQuestion for SemEval 2017 task 3 community question answer, subtask B. The objective is to rerank questions obtained in web forum as per their similarity to original question. Our system uses pairwise learning to rank methods on rich set of hand designed and representation learning features. We use various semantic features that help our system to achieve promising results on the task. The system achieved second highest results on official metrics MAP and good results on other search metrics.", "SimBow at SemEval-2017 Task 3: Soft-Cosine Semantic Similarity between Questions for Community Question Answering.\n\nThis paper describes the SimBow system submitted at SemEval2017-Task3, for the question-question similarity subtask B. The proposed approach is a supervised combination of different unsupervised textual similarities. These textual similarities rely on the introduction of a relation matrix in the classical cosine similarity between bag-of-words, so as to get a soft-cosine that takes into account relations between words. According to the type of relation matrix embedded in the soft-cosine, semantic or lexical relations can be considered. Our system ranked first among the official submissions of subtask B.", "FCICU at SemEval-2017 Task 1: Sense-Based Language Independent Semantic Textual Similarity Approach.\n\nThis paper describes FCICU team systems that participated in SemEval-2017 Semantic Textual Similarity task (Task1) for monolingual and cross-lingual sentence pairs. A sense-based language independent textual similarity approach is presented, in which a proposed alignment similarity method coupled with new usage of a semantic network (BabelNet) is used. Additionally, a previously proposed integration between sense-based and sur-face-based semantic textual similarity approach is applied together with our proposed approach. For all the tracks in Task1, Run1 is a string kernel with alignments metric and Run2 is a sense-based alignment similarity method. The first run is ranked 10th, and the second is ranked 12th in the primary track, with correlation 0.619 and 0.617 respectively", "NTNU-1@ScienceIE at SemEval-2017 Task 10: Identifying and Labelling Keyphrases with Conditional Random Fields.\n\nWe present NTNU's systems for Task A (prediction of keyphrases) and Task B (labelling as Material, Process or Task) at SemEval 2017 Task 10: Extracting Keyphrases and Relations from Scientific Publications \\cite{augenstein2017scienceie}. Our approach relies on supervised machine learning using Conditional Random Fields. Our system yields a micro F-score of 0.34 for Tasks A and B combined on the test data. For Task C (relation extraction), we relied on an independently developed system described in \\cite{Barik:2017}. For the full Scenario 1 (including relations), our approach reaches a micro F-score of 0.33 (5th place). Here we describe our systems, report results and discuss errors.", "SiTAKA at SemEval-2017 Task 4: Sentiment Analysis in Twitter Based on a Rich Set of Features.\n\nThis paper describes SiTAKA, our system that has been used in task 4A, English and Arabic languages, Sentiment Analysis in Twitter of SemEval2017. The system proposes the representation of tweets using a novel set of features, which include a bag of negated words and the information provided by some lexicons. The polarity of tweets is determined by a classifier based on a Support Vector Machine. Our system ranks 2nd among 8 systems in the Arabic language tweets and ranks 8th among 38 systems in the English-language tweets.", "Methodical Evaluation of Arabic Word Embeddings.\n\nMany unsupervised learning techniques have been proposed to obtain meaningful representations of words from text. In this study, we evaluate these various techniques when used to generate Arabic word embeddings. We first build a benchmark for the Arabic language that can be utilized to perform intrinsic evaluation of different word embeddings. We then perform additional extrinsic evaluations of the embeddings based on two NLP tasks.", "Temporal Orientation of Tweets for Predicting Income of Users.\n\nAutomatically estimating a user's socio-economic profile from their language use in social media can significantly help social science research and various downstream applications ranging from business to politics. The current paper presents the first study where user cognitive structure is used to build a predictive model of income. In particular, we first develop a classifier using a weakly supervised learning framework to automatically time-tag tweets as past, present, or future. We quantify a user's overall temporal orientation based on their distribution of tweets, and use it to build a predictive model of income. Our analysis uncovers a correlation between future temporal orientation and income. Finally, we measure the predictive power of future temporal orientation on income by performing regression.", "Senti17 at SemEval-2017 Task 4: Ten Convolutional Neural Network Voters for Tweet Polarity Classification.\n\nThis paper presents Senti17 system which uses ten convolutional neural networks (Con- vNet) to assign a sentiment label to a tweet. The network consists of a convolutional layer followed by a fully-connected layer and a Soft- max on top. Ten instances of this network are initialized with the same word embeddings  as inputs but with different initializations for the network weights. We combine the results of all instances by selecting the sentiment label given by the majority of the ten voters. This system is ranked fourth in SemEval-2017 Task4 over 38 systems with 67.4\\% average recall.", "HHU at SemEval-2017 Task 5: Fine-Grained Sentiment Analysis on Financial Data using Machine Learning Methods.\n\nIn this Paper a system for solving SemEval-2017 Task 5 is presented. This task is divided into two tracks where the sentiment of microblog messages and news headlines has to be predicted. Since two submissions were allowed, two different machine learning methods were developed to solve this task, a support vector machine approach and a recurrent neural network approach. To feed in data for these approaches, different feature extraction methods are used, mainly word representations and lexica. The best submissions for both tracks are provided by the recurrent neural network which achieves a F1-score of 0.729 in track 1 and 0.702 in track 2.", "OPI-JSA at SemEval-2017 Task 1: Application of Ensemble learning for computing semantic textual similarity.\n\nSemantic Textual Similarity (STS) evaluation assesses the degree to which two parts of texts are similar, based on their semantic evaluation. In this paper, we describe three models submitted to STS SemEval 2017. Given two English parts of a text, each of proposed methods outputs the assessment of their semantic similarity. We propose an approach for computing monolingual semantic textual similarity based on an ensemble of three distinct methods. Our model consists of recursive neural network (RNN) text auto-encoders ensemble with supervised a model of vectorized sentences using reduced part of speech (PoS) weighted word embeddings as well as unsupervised a method based on word coverage (TakeLab). Additionally, we enrich our model with additional features that allow disambiguation of ensemble methods based on their efficiency. We have used Multi-Layer Perceptron as an ensemble classifier basing on estimations of trained Gradient Boosting Regressors. Results of our research proves that using such ensemble leads to a higher accuracy due to a fact that each member-algorithm tends to specialize in particular type of sentences. Simple model based on PoS weighted Word2Vec word embeddings seem to improve performance of more complex RNN based auto-encoders in the ensemble. In the monolingual English-English STS subtask our Ensemble based model achieved mean Pearson correlation of .785 compared with human annotators.", "INF-UFRGS at SemEval-2017 Task 5: A Supervised Identification of Sentiment Score in Tweets and Headlines.\n\nThis paper describes a supervised solution for detecting the polarity scores of tweets or headline news in the financial domain, submitted to the SemEval 2017 Fine-Grained Sentiment Analysis on Financial Microblogs and News Task. The premise is that it is possible to understand market reaction over a company stock by measuring the positive/negative sentiment contained in the financial tweets and news headlines, where polarity is measured in a continuous scale ranging from -1.0 (very bearish) to 1.0 (very bullish). Our system receives as input the textual content of tweets or news headlines, together with their ids, stock cashtag or name of target company, and the polarity score gold standard for the training dataset. Our solution retrieves features from these text instances using n-gram, hashtags, sentiment score calculated by a external APIs and others features to train a regression model capable to detect continuous score of these sentiments with precision.", "Lump at SemEval-2017 Task 1: Towards an Interlingua Semantic Similarity.\n\nThis is the Lump team participation at SemEval 2017 Task 1 on Semantic Textual Similarity. Our supervised model relies on features which are multilingual or interlingual in nature. We include lexical similarities, cross-language explicit semantic analysis, internal representations of multilingual neural networks and interlingual word embeddings. Our representations allow to use large datasets in language pairs with many instances to better classify instances in smaller language pairs avoiding the necessity of translating into a single language. Hence we can deal with all the languages in the task: Arabic, English, Spanish, and Turkish.", "LABDA at SemEval-2017 Task 10: Extracting Keyphrases from Scientific Publications by combining the BANNER tool and the UMLS Semantic Network.\n\nThis paper describes the system presented by the LABDA group at SemEval 2017 Task 10 ScienceIE, specifically for the subtasks of identification and classification of keyphrases from scientific articles. For the task of identification, we use the BANNER tool, a named entity recognition system, which is based on conditional random fields (CRF) and has obtained successful results in the biomedical domain. To classify keyphrases, we study the UMLS semantic network and propose a possible linking between the keyphrase types and the UMLS semantic groups. Based on this semantic linking, we create a dictionary for each keyphrase type. Then, a feature indicating if a token is found in one of these dictionaries is incorporated to feature set used by the BANNER tool. The final results on the test dataset show that our system still needs to be improved, but the conditional random fields and, consequently, the BANNER system can be used as a first approximation to identify and classify keyphrases.", "KeLP at SemEval-2017 Task 3: Learning Pairwise Patterns in Community Question Answering.\n\nThis paper describes the KeLP system participating in the SemEval-2017 community Question Answering (cQA) task. The system is a refinement of the kernel-based sentence pair modeling we proposed for the previous year challenge. It is implemented within the Kernel-based Learning Platform called KeLP, from which we inherit the team's name. Our primary submission ranked first in subtask A, and third in subtasks B and C, being the only systems appearing in the top-3 ranking for all the English subtasks. This shows that the proposed framework, which has minor variations among the three subtasks, is extremely flexible and effective in tackling learning tasks defined on sentence pairs.", "HCS at SemEval-2017 Task 5: Polarity detection in business news using convolutional neural networks.\n\nTask 5 of SemEval-2017 involves fine-grained sentiment analysis on financial microblogs and news.  Our solution for determining the sentiment score extends an earlier convolutional neural network for sentiment analysis in several ways. We explicitly encode a focus on a particular company, we apply a data augmentation   scheme, and use a larger data collection to complement the small training data provided by the task organizers.                          The best results were achieved by training a model on an external dataset and then tuning it using the provided training dataset.", "Implicitly-Defined Neural Networks for Sequence Labeling.\n\nIn this work, we propose a novel, implicitly-defined neural network architecture and describe a method to compute its components. The proposed architecture forgoes the causality assumption used to formulate recurrent neural networks and instead couples the hidden states of the network, allowing improvement on problems with complex, long-distance dependencies. Initial experiments demonstrate the new architecture outperforms both the Stanford Parser and baseline bidirectional networks on the Penn Treebank Part-of-Speech tagging task and a baseline bidirectional network on an additional artificial random biased walk task.", "Fast and Accurate Neural Word Segmentation for Chinese.\n\nNeural models with minimal feature engineering have achieved competitive performance against traditional methods for the task of Chinese word segmentation. However, both training and working procedures of the current neural models are computationally inefficient. In this paper, we propose a greedy neural word segmenter with balanced word and character embedding inputs to alleviate the existing drawbacks. Our segmenter is truly end-to-end, capable of performing segmentation much faster and even more accurate than state-of-the-art neural models on Chinese benchmark datasets.", "An Analysis of Action Recognition Datasets for Language and Vision Tasks.\n\nA large amount of recent research has focused on tasks that combine language and vision, resulting in a proliferation of datasets and methods. One such task is action recognition, whose applications include image annotation, scene understanding and image retrieval. In this survey, we categorize the existing approaches based on how they conceptualize this problem and provide a detailed review of existing datasets, highlighting their diversity as well as advantages and disadvantages. We focus on recently developed datasets which link visual information with linguistic resources and provide a fine-grained syntactic and semantic analysis of actions in images.", "Evaluating Compound Splitters Extrinsically with Textual Entailment.\n\nTraditionally, compound splitters are evaluated intrinsically on gold-standard data or extrinsically on the task of statistical machine translation. We explore a novel way for the extrinsic evaluation of compound splitters, namely recognizing textual entailment. Compound splitting has great potential for this novel task that is both transparent and well-defined. Moreover, we show that it addresses certain aspects that are either ignored in intrinsic evaluations or compensated for by taskinternal mechanisms in statistical machine translation. We show significant improvements using different compound splitting methods on a German textual entailment dataset.", "Learning Lexico-Functional Patterns for First-Person Affect.\n\nInformal first-person narratives are a unique resource for computational mod- els of everyday events and people's affective reactions to them. People blogging about their day tend not to explicitly say I am happy. Instead they describe situations from which other humans can readily infer their affective reactions. However current sentiment dictionaries are missing much of the information needed to make similar inferences. We build on recent work that models affect in terms of lexical predicate functions and affect on the predicate's arguments. We present a method to learn proxies for these functions from first- person narratives. We construct a novel fine-grained test set, and show that the pat- terns we learn improve our ability to pre- dict first-person affective reactions to everyday events, from a Stanford sentiment baseline of .67F to .75F.", "STAIR Captions: Constructing a Large-Scale Japanese Image Caption Dataset.\n\nIn recent years, automatic generation of image descriptions (captions), that is, image captioning, has attracted a great deal of attention. In this paper, we particularly consider generating Japanese captions for images. Since most available caption datasets have been constructed for English language, there are few datasets for Japanese. To tackle this problem, we construct a large-scale Japanese image caption dataset based on images from MS-COCO, which is called STAIR Captions. STAIR Captions consists of 820,310 Japanese captions for 164,062 images. In the experiment, we show that a neural network trained using STAIR Captions can generate more natural and better Japanese captions, compared to those generated using English-Japanese machine translation after generating English captions.", "Temporal Word Analogies: Identifying Lexical Replacement with Diachronic Word Embeddings.\n\nThis paper introduces the concept of temporal word analogies: pairs of words which occupy the same semantic space at different points in time. One well-known property of word embeddings is that they are able to effectively model traditional word analogies (``word w1 is to word w2 as word w3 is to word w4'') through vector addition. Here, I show that temporal word analogies (``word w1 at time t\u03b1 is like word w2 at time t\u03b2'') can effectively be modeled with diachronic word embeddings, provided that the independent embedding spaces from each time period are appropriately transformed into a common vector space. When applied to a diachronic corpus of news articles, this method is able to identify temporal word analogies such as ``Ronald Reagan in 1987 is like Bill Clinton in 1997'', or ``Walkman in 1987 is like iPod in 2007''.", "Efficient Extraction of Pseudo-Parallel Sentences from Raw Monolingual Data Using Word Embeddings.\n\nWe propose a new method for extracting pseudo-parallel sentences from a pair of large monolingual corpora, without relying on any document-level information. Our method first exploits word embeddings in order to efficiently evaluate trillions of candidate sentence pairs and then a classifier to find the most reliable ones. We report significant improvements in domain adaptation for statistical machine translation when using a translation model trained on the sentence pairs extracted from in-domain monolingual corpora.", "Disfluency Detection using a Noisy Channel Model and a Deep Neural Language Model.\n\nThis paper presents a model for disfluency detection in spontaneous speech transcripts called LSTM Noisy Channel Model. The model uses a Noisy Channel Model (NCM) to generate n-best candidate disfluency analyses and a Long Short-Term Memory (LSTM) language model to score the underlying fluent sentences of each analysis. The LSTM language model scores, along with other features, are used in a MaxEnt reranker to identify the most plausible analysis. We show that using an LSTM language model in the reranking process of noisy channel disfluency model improves the state-of-the-art in disfluency detection.", "Sentence Alignment Methods for Improving Text Simplification Systems.\n\nWe provide several methods for sentence-alignment of texts with different complexity levels. Using the best of them, we sentence-align the Newsela corpora, thus providing large training materials for automatic text simplification (ATS) systems. We show that using this dataset, even the standard phrase-based statistical machine translation models for ATS can outperform the state-of-the-art ATS systems.", "Improving Semantic Composition with Offset Inference.\n\nCount-based distributional semantic models suffer from sparsity due to unobserved but plausible co-occurrences in any text collection. This problem is amplified for models like Anchored Packed Trees (APTs), that take the grammatical type of a co-occurrence into account. We therefore introduce a novel form of distributional inference that exploits the rich type structure in APTs and infers missing data by the same mechanism that is used for semantic composition.", "Argumentation Quality Assessment: Theory vs. Practice.\n\nArgumentation quality is viewed differently in argumentation theory and in practical assessment approaches. This paper studies to what extent the views match empirically. We find that most observations on quality phrased spontaneously are in fact adequately represented by theory. Even more, relative comparisons of arguments in practice correlate with absolute quality ratings based on theory. Our results clarify how the two views can learn from each other.", "The Role of Prosody and Speech Register in Word Segmentation: A Computational Modelling Perspective.\n\nThis study explores the role of speech register and prosody for the task of word segmentation. Since these two factors are thought to play an important role in early language acquisition, we aim to quantify their contribution for this task. We study a Japanese corpus containing both infant- and adult-directed speech and we apply four different word segmentation models, with and without knowledge of prosodic boundaries. The results showed that the difference between registers is smaller than previously reported and that prosodic boundary information helps more adult- than infant-directed speech.", "A Deep Network with Visual Text Composition Behavior.\n\nWhile natural languages are compositional, how state-of-the-art neural models achieve compositionality is still unclear. We propose a deep network, which not only achieves competitive accuracy for text classification, but also exhibits compositional behavior. That is, while creating hierarchical representations of a piece of text, such as a sentence, the lower layers of the network distribute their layer-specific attention weights to individual words. In contrast, the higher layers compose meaningful phrases and clauses, whose lengths increase as the networks get deeper until fully composing the sentence.", "Learning to Parse and Translate Improves Neural Machine Translation.\n\nThere has been relatively little attention to incorporating linguistic prior to neural machine translation. Much of the previous work was further constrained to considering linguistic prior on the source side. In this paper, we propose a hybrid model, called NMT+RNNG, that learns to parse and translate by combining the recurrent neural network grammar into the attention-based neural machine translation. Our approach encourages the neural machine translation model to incorporate linguistic prior during training, and lets it translate on its own afterward. Extensive experiments with four language pairs show the effectiveness of the proposed NMT+RNNG.", "Best-Worst Scaling More Reliable than Rating Scales: A Case Study on Sentiment Intensity Annotation.\n\nRating scales are a widely used method for data annotation; however, they present several challenges, such as difficulty in maintaining inter- and intra-annotator consistency. Best---worst scaling (BWS) is an alternative method of annotation that is claimed to produce high-quality annotations while keeping the required number of annotations similar to that of rating scales. However, the veracity of this claim has never been systematically established. Here for the first time, we set up an experiment that directly compares the rating scale method with BWS. We show that with the same total number of annotations, BWS produces significantly more reliable results than the rating scale.", "Challenging Language-Dependent Segmentation for Arabic: An Application to Machine Translation and Part-of-Speech Tagging.\n\nWord segmentation plays a pivotal role in improving any Arabic NLP application. Therefore, a lot of research has been spent in improving its accuracy. Off-the-shelf tools, however, are: i) complicated to use and ii) domain/dialect dependent. We explore three language-independent alternatives to morphological segmentation us- ing: i) data-driven sub-word units, ii) characters as a unit of learning, and iii) word embeddings learned using a character CNN (Convolution Neural Network). On the tasks of Machine Translation and POS tagging, we found these methods to achieve close to, and occasionally surpass state-of-the-art performance. In our analysis, we show that a neural machine translation system is sensitive to the ratio of source and target tokens, and a ratio close to 1 or greater, gives optimal performance.", "Information-Theory Interpretation of the Skip-Gram Negative-Sampling Objective Function.\n\nIn this paper we define a measure of dependency between two random variables, based on the Jensen-Shannon (JS) divergence between their joint distribution and the product of their marginal distributions. Then, we show that word2vec's skip-gram with negative sampling embedding algorithm finds the optimal low-dimensional approximation of this JS dependency measure between the words and their contexts. The gap between the optimal score and the low-dimensional approximation is demonstrated on a standard text corpus.", "Error-repair Dependency Parsing for Ungrammatical Texts.\n\nWe propose a new dependency parsing scheme which jointly parses a sentence and repairs grammatical errors by extending the non-directional transition-based formalism of Goldberg and Elhadad (2010) with three additional actions: SUBSTITUTE, DELETE, INSERT. Because these actions may cause an infinite loop in derivation, we also introduce simple constraints that ensure the parser termination. We evaluate our model with respect to dependency accuracy and grammaticality improvements for ungrammatical sentences, demonstrating the robustness and applicability of our scheme.", "Detecting Good Arguments in a Non-Topic-Specific Way: An Oxymoron?.\n\nAutomatic identification of good arguments on a controversial topic has applications in civics and education, to name a few. While in the civics context it might be acceptable to create separate models for  each topic, in the context of              scoring of students' writing there is a preference for a single model that applies to all responses. Given that good arguments for one topic are likely to be irrelevant for another, is a single model for detecting good arguments a contradiction in terms? We investigate the extent to which it is possible to close the performance gap between topic-specific and across-topics models for identification of good arguments.", "Representing Sentences as Low-Rank Subspaces.\n\nSentences are important semantic units of natural language. A generic, distributional representation of sentences that can capture the latent semantics is beneficial to multiple downstream applications. We observe a simple geometry of sentences -- the word representations of a given sentence (on average 10.23 words in all SemEval datasets with a standard deviation 4.84) roughly lie in a low-rank subspace (roughly, rank 4). Motivated by this observation, we represent a sentence by the low-rank subspace spanned by its word vectors. Such an unsupervised representation is empirically validated via semantic textual similarity tasks on 19 different datasets, where it outperforms the sophisticated neural network models,  including skip-thought vectors, by 15% on average.", "Self-Crowdsourcing Training for Relation Extraction.\n\nIn this paper we introduce a self-training strategy for crowdsourcing. The training examples are automatically selected to train the crowd workers. Our experimental results show an impact of 5% Improvement in terms of F1 for relation extraction task, compared to the method based on distant supervision.", "Arc-swift: A Novel Transition System for Dependency Parsing.\n\nTransition-based dependency parsers often need sequences of local shift and reduce operations to produce certain attachments. Correct individual decisions hence require global information about the sentence context and mistakes cause error propagation. This paper proposes a novel transition system, arc-swift, that enables direct attachments between tokens farther apart with a single transition. This allows the parser to leverage lexical information more directly in transition decisions. Hence, arc-swift can achieve significantly better performance with a very small beam size. Our parsers reduce error by 3.7--7.6% relative to those using existing transition systems on the Penn Treebank dependency parsing task and English Universal Dependencies.", "Understanding and Detecting Diverse Supporting Arguments on Controversial Issues.\n\nWe investigate the problem of sentence-level supporting argument detection from relevant documents for user-specified claims. A dataset containing claims and associated citation articles is collected from online debate website idebate.org. We then manually label sentence-level supporting arguments from the documents along with their types as study, factual, opinion, or reasoning. We further characterize arguments of different types, and explore whether leveraging type information can facilitate the supporting arguments detection task. Experimental results show that LambdaMART (Burges, 2010) ranker that uses features informed by argument types yields better performance than the same ranker trained without type information.", "Pocket Knowledge Base Population.\n\nExisting Knowledge Base Population methods extract relations from a closed relational schema with limited coverage leading to sparse KBs. We propose Pocket Knowledge Base Population (PKBP), the task of dynamically constructing a KB of entities related to a query and finding the best characterization of relationships between entities. We describe novel Open Information Extraction methods which leverage the PKB to find informative trigger words. We evaluate using existing KBP shared-task data as well anew annotations collected for this work. Our methods produce high quality KB from just text with many more entities and relationships than existing KBP systems.", "A Neural Model for User Geolocation and Lexical Dialectology.\n\nWe propose a simple yet effective text-based user geolocation model based on a neural network with one hidden layer, which achieves state of the art performance over three Twitter benchmark geolocation datasets, in addition to producing word                                and phrase embeddings in the hidden layer that we show to be useful for detecting dialectal terms. As part of our analysis of dialectal terms, we release DAREDS, a dataset for evaluating dialect term detection methods.", "Answering Complex Questions Using Open Information Extraction.\n\nWhile there has been substantial progress in factoid question-answering (QA), answering complex questions remains challenging, typically requiring both a large body of knowledge and inference techniques. Open Information Extraction (Open IE) provides a way to generate semi-structured knowledge for QA, but to date such knowledge has only been used to answer simple questions with retrieval-based methods. We overcome this limitation by presenting a method for reasoning with Open IE knowledge, allowing more complex questions to be handled. Using a recently proposed support graph optimization framework for QA, we develop a new inference model for Open IE, in particular one that can work effectively with multiple short facts, noise, and the relational structure of tuples. Our model significantly outperforms a state-of-the-art structured solver on complex questions of varying difficulty, while also removing the reliance on manually curated knowledge.", "Multilingual Connotation Frames: A Case Study on Social Media for Targeted Sentiment Analysis and Forecast.\n\nPeople around the globe respond to major real world events through social media.              To study targeted public sentiments across many languages and geographic locations, we introduce multilingual connotation frames: an extension from English connotation frames of Rashkin et al. (2016) with 10 additional European languages, focusing on the implied sentiments among event participants engaged in a frame. As a case study, we present large scale analysis on targeted public sentiments toward salient events and entities using 1.2 million multilingual connotation frames extracted from Twitter.", "A Corpus of Natural Language for Visual Reasoning.\n\nWe present a new visual reasoning language dataset, containing 92,244 pairs of examples of natural statements grounded in synthetic images with 3,962 unique sentences. We describe a method of crowdsourcing linguistically-diverse data, and present an analysis of our data. The data demonstrates a broad set of linguistic phenomena, requiring visual and set-theoretic reasoning. We experiment with various models, and show the data presents a strong challenge for future research.", "Vector space models for evaluating semantic fluency in autism.\n\nA common test administered during neurological examination is the semantic fluency test, in which the patient must list as many examples of a given semantic category as possible under timed conditions. Poor performance is associated with neurological conditions characterized by impairments in executive function, such as dementia, schizophrenia, and autism spectrum disorder (ASD). Methods for analyzing semantic fluency responses at the level of detail necessary to uncover these differences have typically relied on subjective manual annotation. In this paper, we explore automated approaches for scoring semantic fluency responses that leverage ontological resources and distributional semantic models to characterize the semantic fluency responses produced by young children with and without ASD. Using these methods, we find significant differences in the semantic fluency responses of children with ASD, demonstrating the utility of using objective methods for clinical language analysis. \\end{abstract}", "Differentiable Scheduled Sampling for Credit Assignment.\n\nWe demonstrate that a continuous relaxation of the argmax operation can be used to create a differentiable approximation to greedy decoding in sequence-to-sequence (seq2seq) models. By incorporating this approximation into the scheduled sampling training procedure--a well-known technique for correcting exposure bias--we introduce a new training objective that is continuous and differentiable everywhere and can provide informative gradients near points where previous decoding decisions change their value. By using a related approximation, we also demonstrate  a similar approach to sampled-based training. We show that our approach outperforms both standard cross-entropy training and scheduled sampling procedures in two sequence prediction tasks: named entity recognition and machine translation.", "Oracle Summaries of Compressive Summarization.\n\nThis paper derives an Integer Linear Programming (ILP) formulation to obtain an oracle summary of the compressive summarization paradigm in terms of ROUGE. The oracle summary is essential to reveal the upper bound performance of the paradigm. Experimental results on the DUC dataset showed that ROUGE scores of compressive oracles are significantly higher than those of extractive oracles and state-of-the-art summarization systems. These results reveal that compressive summarization is a promising  paradigm and encourage us to continue with the research to produce informative summaries.", "Twitter Demographic Classification Using Deep Multi-modal Multi-task Learning.\n\nTwitter should be an ideal place to get a fresh read on how different issues are playing with the public, one that's potentially more reflective of democracy in this new media age than traditional polls. Pollsters typically ask people a fixed set of questions, while in social media people use their own voices to speak about whatever is on their minds. However, the demographic distribution of users on Twitter is not representative of the general population. In this paper, we present a demographic classifier for gender, age, political orientation and location on Twitter. We collected and curated a robust Twitter demographic dataset for this task. Our classifier uses a deep multi-modal multi-task learning architecture to reach a state-of-the-art performance, achieving an F1-score of 0.89, 0.82, 0.86, and 0.68 for gender, age, political orientation, and location respectively.", "Japanese Sentence Compression with a Large Training Dataset.\n\nIn English, high-quality sentence compression models by deleting words have been trained on automatically created large training datasets. We work on Japanese sentence compression by a similar approach. To create a large Japanese training dataset, a method of creating English training dataset is modified based on the characteristics of the Japanese language. The created dataset is used to train Japanese sentence compression models based on the recurrent neural network.", "Parser Adaptation for Social Media by Integrating Normalization.\n\nThis work explores different approaches of using normalization for parser adaptation.  Traditionally, normalization is used as separate pre-processing step. We show that integrating the normalization model into the parsing algorithm is more beneficial. This way, multiple normalization candidates can be leveraged, which improves parsing performance on social media. We test this hypothesis by modifying the Berkeley parser; out-of-the-box it achieves an F1 score of 66.52.                          Our integrated approach reaches a significant improvement with an F1 score of 67.36, while using the best normalization sequence results in an F1 score of only 66.94.", "Feature-Rich Networks for Knowledge Base Completion.\n\nWe propose jointly modelling Knowledge Bases and aligned text with Feature-Rich Networks. Our models perform Knowledge Base Completion by learning to represent and compose diverse feature types from partially aligned and noisy resources. We perform experiments on Freebase utilizing additional entity type information and syntactic textual relations. Our evaluation suggests that the proposed models can better incorporate side information than previously proposed combinations of bilinear models with convolutional neural networks, showing large improvements when scoring the plausibility of unobserved facts with associated textual mentions.", "Computational Characterization of Mental States: A Natural Language Processing Approach.\n\nPsychiatry is an area of medicine that strongly bases its diagnoses on the psychiatrist's subjective appreciation. More precisely, speech is used almost exclusively as a window to the patient's mind. Few other cues are available to objectively justify a diagnostic, unlike what happens in other disciplines which count on laboratory tests or imaging procedures, such as X-rays. Daily practice is based on the use of semi-structured interviews and standardized tests to build the diagnoses, heavily relying on her personal experience. This methodology has a big problem: diagnoses are commonly validated a posteriori in function of how the pharmacological treatment works. This validation cannot be done until months after the start of the treatment and, if the patient condition does not improve, the psychiatrist often changes the diagnosis and along with the pharmacological treatment. This delay prolongs the patient's suffering until the correct diagnosis is found. According to NIMH, more than 1% and 2% of US population is affected by Schizophrenia and Bipolar Disorder, respectively. Moreover, the WHO reported that the global cost of mental illness reached $2.5T in 2010 [1] . The task of diagnosis, largely simplified, mainly consists of understanding the mind state through the extraction of patterns from the patient's speech and finding the best matching pathology in the standard diagnostic literature. This pipeline, consisting of extracting patterns and then classifying them, loosely resembles the common pipelines used in supervised learning schema. Therefore, we propose to augment the psychiatrists' diagnosis toolbox with an artificial intelligence system based on natural language processing and machine learning algorithms. The proposed system would assist in the diagnostic using a patient's speech as input. The understanding and insights obtained from customizing these systems to specific pathologies is likely to be more broadly applicable to other NLP tasks, therefore we expect to make contributions not only for psychiatry but also within the computer science community. We intend to develop these ideas and evaluate them beyond the lab setting. Our end goal is to make it possible for a practitioner to integrate our tools into her daily practice with minimal effort", "nQuery - A Natural Language Statement to SQL Query Generator.\n\nIn this research, an intelligent system is designed between the user and the database system which accepts natural language input and then converts it into an SQL query. The research focuses on incorporating complex queries along with simple queries irrespective of the database. The system accommodates aggregate functions, multiple conditions in WHERE clause, advanced clauses like ORDER BY, GROUP BY and HAVING. The system handles single sentence natural language inputs, which are with respect to selected database. The research currently concentrates on MySQL database system. The natural language statement goes through various stages of Natural Language Processing like morphological, lexical, syntactic and semantic analysis resulting in SQL query formation.", "Building a Non-Trivial Paraphrase Corpus Using Multiple Machine Translation Systems.\n\nWe propose a novel sentential paraphrase acquisition method. To build a well-balanced corpus for Paraphrase Identification, we especially focus on acquiring both non-trivial positive and negative instances. We use multiple machine translation systems to generate positive candidates and a monolingual corpus to extract negative candidates. To collect non-trivial instances, the candidates are uniformly sampled by word overlap rate. Finally, annotators judge whether the candidates are either positive or negative. Using this method, we built and released the first evaluation corpus for Japanese paraphrase identification, which comprises 655 sentence pairs.", "Segmentation Guided Attention Networks for Visual Question Answering.\n\nIn this paper we propose to solve the problem of Visual Question answering by using a novel segmentation guided attention based networks which we call SegAttendNet. We use image segmentation maps, generated by a Fully Convolutional Deep Neural Network to refine our attention maps and use these refined attention maps to make the model focus on the relevant parts of the image to answer a question. The refined attention maps are used by the LSTM network to learn to produce the answer. We presently train our model on the visual7W dataset and do a category wise evaluation of the 7 question categories. We achieve state of the art results on this dataset and beat the previous benchmark on this dataset by a 1.5% margin improving the question answering accuracy from 54.1% to 55.6% and demonstrate improvements in each of the question categories. We also visualize our generated attention maps and note their improvement over the attention maps generated by the previous best approach.", "Variation Autoencoder Based Network Representation Learning for Classification.\n\nNetwork representation is the basis of many applications and of extensive interest in various fields, such as information retrieval, social network analysis, and recommendation systems. Most previous methods for network representation only consider the incomplete aspects of a problem, including link structure, node information, and partial integration. The present study introduces a deep network representation model that seamlessly integrates the text information and structure of a network. The model captures highly non-linear relationships between nodes and complex features of a network by exploiting the variational autoencoder (VAE), which is a deep unsupervised generation algorithm. The representation learned with a paragraph vector model is merged with that learned with the VAE to obtain the network representation, which preserves both structure and text information. Comprehensive experiments is conducted on benchmark datasets and find that the introduced model performs better than state-of-the-art techniques.", "Automatic Generation of Jokes in Hindi.\n\nWhen it comes to computational language processing systems, humour is a relatively unexplored domain, especially more so for Hindi (or rather, most languages other than English). Most researchers agree that a joke consists of two main parts - the setup and the punchline, which the humour being encoded in the incongruity between the two. In this paper, we look at Dur se Dekha jokes, a restricted domain of humorous three liner poetry in Hindi. We analyze their structure to understand how humour is encoded in them and formalize it. We then develop a system which is successfully able to generate a basic form of these jokes.", "Word Embedding for Response-To-Text Assessment of Evidence.\n\nManually grading the Response to Text Assessment (RTA) is labor intensive. Therefore, an automatic method is being developed for scoring analytical writing when the RTA is administered in large numbers of classrooms. Our long-term goal is to also use this scoring method to provide formative feedback to students and teachers about students' writing quality.  As a first step towards this goal, interpretable features for automatically scoring the evidence rubric of the RTA have been developed. In this paper, we present a simple but promising method for improving evidence scoring by employing the word embedding model. We evaluate our method on corpora of responses written by upper elementary students.", "Domain Specific Automatic Question Generation from Text.\n\nThe goal of my doctoral thesis is to automatically generate interrogative sentences from descriptive sentences of Turkish biology text. We employ syntactic and semantic approaches to parse descriptive sentences. Syntactic and semantic approaches utilize syntactic (constituent or dependency) parsing and semantic role labeling systems respectively. After parsing step, question statements whose answers are embedded in the descriptive sentences are going to be formulated by using some predefined rules and templates. Syntactic parsing is done using an open source dependency parser called MaltParser (Nivre et al. 2007). Whereas to accomplish semantic parsing, we will construct a biological proposition bank (BioPropBank) and a corpus annotated with semantic roles. Then we will employ supervised methods to automatic label the semantic roles of a sentence.", "Generating Steganographic Text with LSTMs.\n\nMotivated by concerns for user privacy, we design a steganographic system (''stegosystem'') that enables two users to exchange encrypted messages without an adversary detecting that such an exchange is taking place. In this paper, we propose a novel linguistic stegosystem based on a Long-Short Term Memory (LSTM) neural network. We demonstrate our approach on the Twitter and Enron email datasets and show that it yields high-quality steganographic text while significantly improving capacity (encrypted bits per word) relative to the state-of-the-art.", "Predicting Depression for Japanese Blog Text.\n\nThis study aims to predict clinical depression, a prevalent mental disorder, from blog posts written in Japanese by using machine learning approaches. The study focuses on how data quality and various types of linguistic features (characters, tokens, and lemmas) affect prediction outcome. Depression prediction achieved 95.5% accuracy using selected lemmas as features.", "Fast Forward Through Opportunistic Incremental Meaning Representation Construction.\n\nOne of the challenges semantic parsers face involves upstream errors originating from pre-processing modules such as ASR and syntactic parsers, which undermine the end result from the get go. We report the work in progress on a novel incremental semantic parsing algorithm that supports simultaneous application of independent heuristics and facilitates the construction of partial but potentially actionable meaning representations to overcome this problem. Our contribution to this point is mainly theoretical. In future work we intend to evaluate the algorithm as part of a dialogue understanding system on state of the art benchmarks.", "Improving Distributed Representations of Tweets - Present and Future.\n\nUnsupervised representation learning for tweets is an important research field which helps in solving several business applications such as sentiment analysis, hashtag prediction, paraphrase detection and microblog ranking. A good tweet representation learning model must handle the idiosyncratic nature of tweets which poses several challenges such as short length, informal words, unusual grammar and misspellings. However, there is a lack of prior work which surveys the representation learning models with a focus on tweets. In this work, we organize the models based on its objective function which aids the understanding of the literature. We also provide interesting future directions, which we believe are fruitful in advancing this field by building high-quality tweet representation learning models.", "Parsing Graphs with Regular Graph Grammars.\n\nRecently, several datasets have become available which represent natural language phenomena as graphs. Hyperedge Replacement Languages (HRL) have been the focus of much attention as a formalism to represent the graphs in these datasets. Chiang et al. (2013) prove that HRL graphs can be parsed in polynomial time with respect to the size of the input graph. We believe that HRL are more expressive than is necessary to represent semantic graphs and we propose the use of Regular Graph Languages (RGL; Courcelle 1991), which is a subfamily of HRL, as a possible alternative. We provide a top-down parsing algorithm for RGL that runs in time linear in the size of the input graph.", "Distributed Prediction of Relations for Entities: The Easy, The Difficult, and The Impossible.\n\nWord embeddings are supposed to provide easy access to semantic relations such as ``male of'' (man---woman). While this claim has been investigated for concepts, little is known about the distributional behavior of relations of (Named) Entities. We describe two word embedding-based models that predict values for relational attributes of entities, and analyse them. The task is challenging, with major performance differences between relations. Contrary to many NLP tasks, high difficulty for a relation does not result from low frequency, but from (a) one-to-many mappings; and (b) lack of context patterns expressing the relation that are easy to pick up by word embeddings.", "Issues of Mass and Count: Dealing with `Dual-Life' Nouns.\n\nThe topics of mass and count have been studied for many decades in philosophy (e.g., Quine, 1960; Pelletier, 1975), linguistics (e.g., McCawley, 1975; Allen, 1980; Krifka, 1991) and psychology (e.g., Middleton et al, 2004; Barner et al, 2009).                          More recently, interest from within computational linguistics has studied the issues involved (e.g., Pustejovsky, 1991; Bond, 2005; Schmidtke \\& Kuperman, 2016), to name just a few.  As is pointed out in these works, there are many difficult conceptual issues involved in the study of this contrast. In this article we study one of these issues -- the ``Dual-Life'' of being simultaneously +mass and +count -- by means of an unusual combination of human annotation, online lexical resources, and online corpora.", "Semantic Frames and Visual Scenes: Learning Semantic Role Inventories from Image and Video Descriptions.\n\nFrame-semantic parsing and semantic role labelling, that aim to automatically assign semantic roles to arguments of verbs in a sentence, have become an active strand of research in NLP. However, to date these methods have relied on a predefined inventory of semantic roles. In this paper, we present a method to automatically learn argument role inventories for verbs from large corpora of text, images and videos. We evaluate the method against manually constructed role inventories in FrameNet and show that the visual model outperforms the language-only model and operates with a high precision.", "Emotion Intensities in Tweets.\n\nThis paper examines the task of detecting intensity of emotion from text. We create the first datasets of tweets annotated for anger, fear, joy, and sadness intensities. We use a technique called best---worst scaling (BWS) that improves annotation consistency and obtains reliable fine-grained scores. We show that emotion-word hashtags often impact emotion intensity, usually conveying a more intense emotion. Finally, we create a benchmark regression system and conduct experiments to determine: which features are useful for detecting emotion intensity; and, the extent to which two emotions are similar in terms of how they manifest in language.", "Does Free Word Order Hurt? Assessing the Practical Lexical Function Model for Croatian.\n\nThe Practical Lexical Function (PLF) model is a model of computational distributional semantics that attempts to strike a balance between expressivity and learnability in predicting phrase meaning and shows competitive results. We investigate how well the PLF carries over to free word order languages, given that it builds on observations of predicate-argument combinations that are harder to recover in free word order languages. We evaluate variants of the PLF for Croatian, using a new lexical substitution dataset. We find that the PLF works about as well for Croatian as for English, but demonstrate that its strength lies in modeling verbs, and that the free word order affects the less robust PLF variant.", "Deep Learning Models For Multiword Expression Identification.\n\nMultiword expressions (MWEs) are lexical items that can be decomposed into multiple component words, but have properties that are unpredictable with respect to their component words. In this paper we propose the first deep learning models for token-level identification of MWEs. Specifically, we consider a layered feedforward network, a recurrent neural network, and convolutional neural networks. In experimental results we show that convolutional neural networks are able to outperform the previous state-of-the-art for MWE identification, with a convolutional neural network with three hidden layers giving the best performance.", "Mapping the Paraphrase Database to WordNet.\n\nWordNet has facilitated important research in natural language processing but its usefulness is somewhat limited by its relatively small lexical coverage. The Paraphrase Database (PPDB) covers 650 times more words, but lacks the semantic structure of WordNet that would make it more directly useful for downstream tasks. We present a method for mapping words from PPDB to WordNet synsets with 89\\% accuracy. The mapping also lays important groundwork for incorporating WordNet's relations into PPDB so as to increase its utility for semantic reasoning in applications.", "Generating Pattern-Based Entailment Graphs for Relation Extraction.\n\nRelation extraction is the task of recognizing and extracting relations between entities or concepts in texts. A common approach is to exploit existing knowledge to learn linguistic patterns expressing the target relation and use these patterns for extracting new relation mentions. Deriving relation patterns automatically usually results in large numbers of candidates, which need to be filtered to derive a subset of patterns that reliably extract correct relation mentions. We address the pattern selection task by exploiting the knowledge represented by entailment graphs, which capture semantic relationships holding among the learned pattern candidates. This is motivated by the fact that a pattern may not express the target relation explicitly, but still be useful for extracting instances for which the relation holds, because its meaning entails the meaning of the target relation. We evaluate the usage of both automatically generated and gold-standard entailment graphs in a relation extraction scenario and present favorable experimental results, exhibiting the benefits of structuring and selecting patterns based on entailment graphs.", "Deep Active Learning for Dialogue Generation.\n\nWe propose an online, end-to-end, neural generative conversational model for open-domain dialogue. It is trained using a unique combination of offline two-phase supervised learning and online human-in-the-loop active learning. While most existing research proposes offline supervision or hand-crafted reward functions for online reinforcement, we devise a novel interactive learning mechanism based on hamming-diverse beam search for response generation and one-character user-feedback at each step. Experiments show that our model inherently promotes the generation of semantically relevant and interesting responses, and can be used to train agents with customized personas, moods and conversational styles.", "Learning Antonyms with Paraphrases and a Morphology-Aware Neural Network.\n\nRecognizing and distinguishing antonyms from other types of semantic relations is an essential part of language understanding systems. In this paper, we present a novel method for deriving antonym pairs using paraphrase pairs containing negation markers. We further propose a neural network model, AntNET, that integrates morphological features indicative of antonymy into a path-based relation detection algorithm. We demonstrate that our model outperforms state-of-the-art models in distinguishing antonyms from other semantic relations and is capable of efficiently handling multi-word expressions.", "What Analogies Reveal about Word Vectors and their Compositionality.\n\nAnalogy completion via vector arithmetic has become a common means of demonstrating the compositionality of word embeddings. Previous work have shown that this strategy works more reliably for certain types of analogical word relationships than for others, but these studies have not offered a convincing account for why this is the case. We arrive at such an account through an experiment that targets a wide variety of analogy questions and defines a baseline condition to more accurately measure the efficacy of our system. We find that the most reliably solvable analogy categories involve either 1) the application of a morpheme with clear syntactic effects, 2) male--female alternations, or 3) named entities. These broader types do not pattern cleanly along a syntactic--semantic divide. We suggest instead that their commonality is distributional, in that the difference between the distributions of two words in any given pair encompasses a relatively small number of word types. Our study offers a needed explanation for why analogy tests succeed and fail where they do and provides nuanced insight into the relationship between word distributions and the theoretical linguistic domains of syntax and semantics.", "Graph Methods for Multilingual FrameNets.\n\nThis paper introduces a new, graph-based view of the data of the FrameNet project, which we hope will make it easier to understand the mixture of semantic and syntactic information contained in FrameNet annotation.  We show how English FrameNet and other Frame Semantic resources can be represented as sets of interconnected graphs of frames, frame elements, semantic types, and annotated instances of them in text.  We display examples of the new graphical representation based on the annotations, which combine Frame Semantics and Construction Grammar, thus capturing most of the syntax and semantics of each sentence.  We consider how graph theory could help researchers to make better use of FrameNet data for tasks such as automatic Frame Semantic role labeling, paraphrasing, and translation.              Finally, we describe the development of FrameNet-like lexical resources for other languages in the current Multilingual FrameNet project.  which seeks to discover cross-lingual alignments, both in the lexicon (for frames and lexical units within frames) and across parallel or comparable texts.  We conclude with an example showing graphically the semantic and syntactic similarities and differences between parallel sentences in English and Japanese.  We will release software for displaying such graphs from the current data releases.", "Spectral Graph-Based Method of Multimodal Word Embedding.\n\nIn this paper, we propose a novel method for multimodal word embedding, which exploit a generalized framework of multi-view spectral graph embedding to take into account visual appearances or scenes denoted by words in a corpus. We evaluated our method through word similarity tasks and a concept-to-image search task, having found that it provides word representations that reflect visual information, while somewhat trading-off the performance on the word similarity tasks. Moreover, we demonstrate that our method captures multimodal linguistic regularities, which enable recovering relational similarities between words and images by vector arithmetics."], "categories": ["f", "m"]}}; }
buildViz(1000,undefined,null,null,true,false,false,false,false,true,false,false,true,0.05,false,undefined,undefined);
</script>

